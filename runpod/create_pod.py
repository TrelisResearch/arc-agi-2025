#!/usr/bin/env python3
import requests
import os
import argparse
import signal
import sys
import time
import json
import yaml
import socket
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# Add the runpod directory to Python path for imports
runpod_dir = Path(__file__).parent.absolute()
if str(runpod_dir) not in sys.path:
    sys.path.insert(0, str(runpod_dir))

# Import shared configuration
from config import DEFAULT_DATA_CENTERS, get_regions

# Global variable to store pod ID for cleanup
pod_id = None
cleanup_in_progress = False

def signal_handler(signum, frame):
    """Handle interrupt signals for graceful shutdown"""
    global cleanup_in_progress
    
    if cleanup_in_progress:
        print("\n‚ö†Ô∏è  WARNING: Pod deletion already in progress. Please wait...")
        print("‚ö†Ô∏è  Do NOT press Ctrl+C again while the pod is being terminated!")
        return
    
    print(f"\nüõë Received signal {signum}. Initiating graceful shutdown...")
    cleanup_pod()
    sys.exit(0)

def cleanup_pod():
    """Delete the pod and perform cleanup"""
    global pod_id, cleanup_in_progress
    
    if not pod_id:
        print("No pod to cleanup.")
        return
    
    if cleanup_in_progress:
        return
    
    cleanup_in_progress = True
    print(f"\nüóëÔ∏è  Deleting pod {pod_id}...")
    
    try:
        headers = {
            "Authorization": f"Bearer {os.environ['RUNPOD_API_KEY']}",
            "Content-Type": "application/json"
        }
        
        delete_url = f"https://rest.runpod.io/v1/pods/{pod_id}"
        response = requests.delete(delete_url, headers=headers)
        
        if response.status_code in [200, 204]:
            print(f"‚úÖ Pod {pod_id} successfully deleted.")
        else:
            print(f"‚ùå Failed to delete pod {pod_id}. Status: {response.status_code}")
            print(f"Response: {response.text}")
    except Exception as e:
        print(f"‚ùå Error deleting pod: {e}")

def get_pod_status(pod_id):
    """Get the current status of a pod"""
    try:
        headers = {
            "Authorization": f"Bearer {os.environ['RUNPOD_API_KEY']}",
            "Content-Type": "application/json"
        }
        
        status_url = f"https://rest.runpod.io/v1/pods/{pod_id}"
        response = requests.get(status_url, headers=headers)
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ùå Failed to get pod status. Status: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ùå Error getting pod status: {e}")
        return None

def get_machine_info(machine_id):
    """Get machine information which might contain the public IP"""
    try:
        headers = {
            "Authorization": f"Bearer {os.environ['RUNPOD_API_KEY']}",
            "Content-Type": "application/json"
        }
        
        machine_url = f"https://rest.runpod.io/v1/machines/{machine_id}"
        response = requests.get(machine_url, headers=headers)
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ùå Failed to get machine info. Status: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ùå Error getting machine info: {e}")
        return None

def check_tcp_endpoint_health(host, port, timeout=5):
    """Check if the TCP endpoint is responding"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, int(port)))
        sock.close()
        return result == 0
    except Exception:
        return False

def test_openai_endpoint(base_url, model_name, timeout=10):
    """Test if the OpenAI-compatible endpoint is responding"""
    try:
        import openai
        client = openai.OpenAI(
            api_key="dummy",  # RunPod doesn't need real key
            base_url=base_url
        )
        
        client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=10,
            timeout=timeout
        )
        return True
    except Exception as e:
        print(f"    üêõ OpenAI-style endpoint test failed: {str(e)}")
        return False

def test_custom_endpoint(url, timeout=10):
    """Test a custom endpoint with HTTP GET"""
    try:
        response = requests.get(url, timeout=timeout)
        return response.status_code < 400
    except Exception:
        return False

def perform_health_check(health_check_config, pod_id, ports, direct_ip, port_mappings, full_model_path):
    """Perform health check based on configuration"""
    if not health_check_config:
        # Default behavior: OpenAI check for TCP ports, /health for HTTP
        has_tcp_ports = any('tcp' in port for port in ports)
        if has_tcp_ports:
            return perform_openai_health_check(pod_id, ports, direct_ip, port_mappings, full_model_path)
        else:
            return perform_http_health_check(pod_id, ports[0].split('/')[0])
    
    health_type = health_check_config.get('type', 'http')
    path = health_check_config.get('path', '/health')
    timeout = health_check_config.get('timeout', 300)
    
    if health_type == 'openai':
        return perform_openai_health_check(pod_id, ports, direct_ip, port_mappings, full_model_path, timeout)
    elif health_type == 'http':
        return perform_http_health_check(pod_id, ports[0].split('/')[0], path, timeout)
    elif health_type == 'tcp':
        return perform_tcp_health_check(pod_id, ports, direct_ip, port_mappings, timeout)
    elif health_type == 'none':
        print("Health check disabled by configuration")
        return True
    else:
        print(f"Unknown health check type: {health_type}, falling back to default")
        return perform_http_health_check(pod_id, ports[0].split('/')[0])

def perform_openai_health_check(pod_id, ports, direct_ip, port_mappings, full_model_path, timeout=600):
    """Perform OpenAI-style health check"""
    print("\nüß† STAGE 3: Testing OpenAI-compatible endpoint...")
    
    start_time = time.time()
    connection_working = False
    
    while time.time() - start_time < timeout and not connection_working:
        # Test direct connection first
        if direct_ip and port_mappings:
            for port in ports:
                port_num = port.split('/')[0]
                if port_num in port_mappings:
                    external_port = port_mappings[port_num]
                    direct_url = f"http://{direct_ip}:{external_port}/v1"
                    print(f"‚è≥ Testing direct connection: {direct_url}")
                    
                    if test_openai_endpoint(direct_url, full_model_path):
                        print("‚úÖ Direct connection working!")
                        connection_working = True
                        break
                    else:
                        print("‚ùå Direct connection failed, trying proxy...")
        
        # Test proxy connection if direct failed
        if not connection_working:
            for port in ports:
                port_num, protocol = port.split('/')
                if protocol == 'tcp':
                    proxy_url = f"http://{pod_id}-{port_num}.proxy.runpod.net/v1"
                    print(f"‚è≥ Testing proxy connection: {proxy_url}")
                    
                    if test_openai_endpoint(proxy_url, full_model_path):
                        print("‚úÖ Proxy connection working!")
                        connection_working = True
                        break
                    else:
                        print("‚ùå Proxy connection failed")
        
        if not connection_working:
            elapsed = int(time.time() - start_time)
            print(f"‚è≥ Waiting for endpoint to be ready... ({elapsed}s elapsed)")
            time.sleep(10)
    
    if connection_working:
        print("\nüéâ OPENAI ENDPOINT READY!")
        print("   The pod is now ready to handle your requests!")
        print("   You can start making API calls to the endpoint above.")
        return True
    else:
        print("\n‚ö†Ô∏è  OPENAI ENDPOINT NOT READY")
        print("   The pod is running but the endpoint may still be loading.")
        print("   You can try making requests, but they may fail until loading completes.")
        return False

def perform_http_health_check(pod_id, port_num, path="/health", timeout=300):
    """Perform HTTP health check"""
    print(f"\nüîç STAGE 3: Testing HTTP endpoint at {path}...")
    print("\n‚è≥ Waiting for health check", end="", flush=True)
    
    start_time = time.time()
    while not check_http_endpoint_health(pod_id, port_num, path):
        if time.time() - start_time > timeout:
            print(f"\n‚ö†Ô∏è  Health check timed out after {timeout}s")
            return False
        print(".", end="", flush=True)
        time.sleep(10)
    else:
        print(" ‚úÖ Health check passed!")
        return True

def perform_tcp_health_check(pod_id, ports, direct_ip, port_mappings, timeout=300):
    """Perform basic TCP connectivity check"""
    print("\nüîå STAGE 3: Testing TCP connectivity...")
    
    start_time = time.time()
    connection_working = False
    
    while time.time() - start_time < timeout and not connection_working:
        # Test direct connection first
        if direct_ip and port_mappings:
            for port in ports:
                port_num = port.split('/')[0]
                if port_num in port_mappings:
                    external_port = port_mappings[port_num]
                    print(f"‚è≥ Testing direct TCP connection: {direct_ip}:{external_port}")
                    
                    if check_tcp_endpoint_health(direct_ip, external_port):
                        print("‚úÖ Direct TCP connection working!")
                        connection_working = True
                        break
                    else:
                        print("‚ùå Direct TCP connection failed")
        
        if not connection_working:
            elapsed = int(time.time() - start_time)
            print(f"‚è≥ Waiting for TCP endpoint... ({elapsed}s elapsed)")
            time.sleep(10)
    
    if connection_working:
        print("\nüéâ TCP ENDPOINT READY!")
        return True
    else:
        print(f"\n‚ö†Ô∏è  TCP endpoint not ready after {timeout}s")
        return False

def check_http_endpoint_health(pod_id, port, health_path="/health"):
    """Check if the endpoint is responding"""
    try:
        health_url = f"https://{pod_id}-{port}.proxy.runpod.net{health_path}"
        response = requests.get(health_url, timeout=5)
        return response.status_code < 400
    except Exception:
        return False

def load_template(template_name):
    """Load pod configuration from YAML or JSON file in templates/ folder"""
    try:
        # Get the directory of the current script
        script_dir = os.path.dirname(os.path.abspath(__file__))
        templates_dir = os.path.join(script_dir, 'templates')
        
        # If template_name doesn't have an extension, try common ones
        if not os.path.splitext(template_name)[1]:
            # Try different extensions
            for ext in ['.yaml', '.yml', '.json']:
                template_path = os.path.join(templates_dir, template_name + ext)
                if os.path.exists(template_path):
                    break
            else:
                print(f"‚ùå Template '{template_name}' not found in {templates_dir}")
                print(f"Available templates: {', '.join(os.listdir(templates_dir)) if os.path.exists(templates_dir) else 'None'}")
                return None
        else:
            template_path = os.path.join(templates_dir, template_name)
            if not os.path.exists(template_path):
                print(f"‚ùå Template file '{template_path}' not found")
                return None
        
        with open(template_path, 'r') as f:
            if template_path.endswith('.yaml') or template_path.endswith('.yml'):
                config = yaml.safe_load(f)
            else:
                config = json.load(f)
        
        print(f"üìÅ Loaded template: {template_path}")
        
        # Set default data centers if not specified
        if 'dataCenterIds' not in config:
            config['dataCenterIds'] = DEFAULT_DATA_CENTERS
            
        return config
    except Exception as e:
        print(f"‚ùå Error loading template {template_name}: {e}")
        return None

def create_pod(config, extra_args):
    """Create a RunPod pod with specified configuration"""
    global pod_id
    
    payload = config.copy()
    
    # Extract health check configuration before removing it from payload
    health_check_config = payload.pop('healthCheck', None)
    
    # Add extra arguments to docker command if provided
    if extra_args and 'dockerStartCmd' in payload:
        if isinstance(payload['dockerStartCmd'], list):
            payload['dockerStartCmd'].extend(extra_args)
        else:
            # Convert string to list and add args
            cmd_list = payload['dockerStartCmd'].split()
            cmd_list.extend(extra_args)
            payload['dockerStartCmd'] = cmd_list
    
    # Extract model name from arguments for better pod naming
    model_name = "unknown"
    if extra_args:
        for i, arg in enumerate(extra_args):
            if arg in ["--model-path", "--model"] and i + 1 < len(extra_args):
                model_name = extra_args[i + 1].split('/')[-1]  # Get last part of model path
                break
    
    headers = {
        "Authorization": f"Bearer {os.environ['RUNPOD_API_KEY']}",
        "Content-Type": "application/json"
    }
    
    # Create a more descriptive pod name
    base_name = payload.get('name', 'sglang-pod')
    pod_name = f"{base_name}-{model_name}-{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    payload['name'] = pod_name
    print(f"üöÄ Creating pod '{pod_name}'")
    
    # Print docker command if available
    if 'dockerStartCmd' in payload:
        cmd = payload['dockerStartCmd']
        if isinstance(cmd, list):
            print(f"üìù Docker command: {' '.join(cmd)}")
        else:
            print(f"üìù Docker command: {cmd}")
    
    try:
        url = "https://rest.runpod.io/v1/pods"
        response = requests.post(url, json=payload, headers=headers)
        
        if response.status_code == 201:
            pod_info = response.json()
            pod_id = pod_info['id']
            print(f"‚úÖ Pod created successfully! ID: {pod_id}")
            print(f"üí∞ Cost per hour: ${pod_info.get('costPerHr', 'Unknown')}")
            print(f"üñ•Ô∏è  Console: https://console.runpod.io/pods/{pod_id}")
            return pod_id, health_check_config
        else:
            print(f"‚ùå Failed to create pod. Status: {response.status_code}")
            print(f"Response: {response.text}")
            return None, None
    except Exception as e:
        print(f"‚ùå Error creating pod: {e}")
        return None, None

def main():
    parser = argparse.ArgumentParser(
        description='Create and manage a RunPod pod using configuration templates with configurable health checks',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s sglang Qwen/Qwen3-4B
  %(prog)s vllm Trelis/Qwen3-4B --gpu-count 2
  %(prog)s sglang Qwen/Qwen3-4B --regions us_only --gpu-count 4

Template names are loaded from the templates/ folder. File extensions are optional.
The model path is automatically passed with the correct flag (--model-path for sglang, --model for vllm).

GPU Configuration:
- Use --gpu-count to specify number of GPUs (default: 1)
- For sglang: sets --dp (data parallel) to match GPU count
- For vllm: sets --data-parallel-size to match GPU count

Region Configuration:
- Default regions are defined in config.py and used automatically
- Use --regions to override: default, us_only, eu_only, low_latency, cost_optimized
- Templates can specify dataCenterIds to override both defaults and --regions

Health Check Configuration:
Templates can include a 'healthCheck' section to configure health monitoring:
- type: "http" (test HTTP endpoint), "openai" (test OpenAI API), "tcp" (basic connectivity), "none" (skip)
- path: "/health" (for HTTP checks)
- timeout: 300 (timeout in seconds)

The healthCheck section is automatically stripped before sending to RunPod.
        """
    )
    
    parser.add_argument('template', help='Template name (from templates/ folder, extension optional)')
    parser.add_argument('model', help='Model path (e.g., Qwen/Qwen3-4B or Trelis/model-name)')
    parser.add_argument('--gpu-count', type=int, default=1,
                       help='Number of GPUs to allocate (default: 1)')
    parser.add_argument('--no-health-check', action='store_true',
                       help='Skip health check after pod creation')
    parser.add_argument('--debug', action='store_true',
                       help='Show debug information about pod status')
    parser.add_argument('--regions', 
                       choices=['default', 'us_only', 'eu_only', 'low_latency', 'cost_optimized'],
                       help='Region set to use (overrides template dataCenterIds)')
    parser.add_argument('--kv-cache-dtype', type=str,
                       help='KV cache data type (e.g., fp8_e5m2)')
    
    # Parse arguments
    args = parser.parse_args()
    
    # Check for required environment variable
    if 'RUNPOD_API_KEY' not in os.environ:
        print("‚ùå Error: RUNPOD_API_KEY environment variable not set!")
        sys.exit(1)
    
    # Load template
    config = load_template(args.template)
    if not config:
        sys.exit(1)
    
    # Build docker arguments based on template type
    extra_args = []
    
    # Add model argument
    if 'vllm' in args.template.lower():
        extra_args.extend(['--model', args.model])
        # Add data-parallel-size
        extra_args.extend(['--data-parallel-size', str(args.gpu_count)])
    else:
        # Default to sglang style
        extra_args.extend(['--model-path', args.model])
        # Add dp (data parallel)
        extra_args.extend(['--dp', str(args.gpu_count)])
    
    # Add kv-cache-dtype (use specified or default to fp8_e4m3)
    kv_cache = args.kv_cache_dtype if args.kv_cache_dtype else 'fp8_e4m3'
    extra_args.extend(['--kv-cache-dtype', kv_cache])
    
    # Check if this is a GPT-OSS model and add reasoning parser
    model_lower = args.model.lower()
    if 'gpt-oss' in model_lower and ('20b' in model_lower or '120b' in model_lower):
        extra_args.extend(['--reasoning-parser', 'gpt-oss'])
        print(f"üß† Detected GPT-OSS or Qwen Thinking model, adding --reasoning-parser gpt-oss")
    
    # Print configuration info
    print(f"üöÄ Creating pod with model: {args.model}")
    print(f"   GPUs: {args.gpu_count} (data parallel)")
    print(f"   KV cache dtype: {kv_cache}")
    
    # Set GPU count in config
    config['gpuCount'] = args.gpu_count
    
    # Override regions if specified
    if args.regions:
        config['dataCenterIds'] = get_regions(args.regions)
        print(f"üåç Using {args.regions} regions: {config['dataCenterIds']}")
    
    # Register signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # Create the pod
    pod_id, health_check_config = create_pod(config, extra_args)
    if not pod_id:
        sys.exit(1)
    
    # Stage 1: Wait for container to be running with necessary information
    print(f"\nüöÄ STAGE 1: Waiting for container to be ready...")
    
    # Initial wait of 30 seconds
    print("‚è≥ Initial wait: 30 seconds...")
    time.sleep(30)
    
    # Then check every 10 seconds
    max_wait_time = 600  # 10 minutes total
    start_time = time.time()
    pod_info = None
    
    while time.time() - start_time < max_wait_time:
        pod_info = get_pod_status(pod_id)
        if not pod_info:
            cleanup_pod()
            sys.exit(1)
        
        # Check if pod is running and has the necessary information
        # For TCP ports, we need publicIp and portMappings
        # For HTTP ports, we just need the pod to be running
        ports = pod_info.get('ports', [])
        has_tcp_ports = any('tcp' in port for port in ports)
        
        if pod_info.get('desiredStatus') == 'RUNNING':
            if has_tcp_ports:
                # For TCP ports, wait for public IP and port mappings
                if pod_info.get('publicIp') and pod_info.get('portMappings'):
                    print(f"‚úÖ Container is ready with IP: {pod_info.get('publicIp')}")
                    break
            else:
                # For HTTP-only ports, just need the pod to be running
                print(f"‚úÖ Container is ready")
                break
        
        elapsed = int(time.time() - start_time)
        print(f"‚è≥ Waiting for container to be ready... ({elapsed}s elapsed)")
        time.sleep(10)
    else:
        print(f"\n‚ö†Ô∏è  Container didn't become ready within {max_wait_time}s, continuing anyway...")
        pod_info = get_pod_status(pod_id)
        if not pod_info:
            cleanup_pod()
            sys.exit(1)
    
    # Debug: Show full pod info if requested
    if args.debug:
        print(f"\nüîç DEBUG: Full pod info:")
        print(json.dumps(pod_info, indent=2))
    
    # Always show the raw pod info structure for debugging
    print(f"\nüîç Pod info keys: {list(pod_info.keys())}")
    if 'runtime' in pod_info:
        print(f"üîç Runtime keys: {list(pod_info['runtime'].keys())}")
        if 'network' in pod_info['runtime']:
            print(f"üîç Network keys: {list(pod_info['runtime']['network'].keys())}")
    
    # Stage 2: Display connection information
    ports = pod_info.get('ports', [])
    direct_ip = pod_info.get('publicIp')
    port_mappings = pod_info.get('portMappings', {})
    
    print(f"\nüîå STAGE 2: Connection Information")
    for port in ports:
        port_num, protocol = port.split('/')
        if protocol == 'http':
            print(f"üåê HTTP endpoint: https://{pod_id}-{port_num}.proxy.runpod.net/")
        elif protocol == 'tcp':
            print(f"üîå TCP proxy: {pod_id}-{port_num}.proxy.runpod.net:{port_num}")
        else:
            print(f"üîå {protocol.upper()} proxy: {pod_id}-{port_num}.proxy.runpod.net:{port_num}")
    
    if direct_ip and port_mappings and any('tcp' in port for port in ports):
        print(f"\nüåç DIRECT CONNECTION:")
        print(f"   IP Address: {direct_ip}")
        for port in ports:
            port_num = port.split('/')[0]
            if port_num in port_mappings:
                external_port = port_mappings[port_num]
                print(f"   Direct TCP: {direct_ip}:{external_port}")
            else:
                print(f"   Direct TCP: {direct_ip}:{port_num} (port mapping not found)")
    elif any('tcp' in port for port in ports):
        print(f"\n‚ö†Ô∏è  No direct IP available for TCP ports - using proxy only")
    
    # Stage 3: Health checks
    if not args.no_health_check and ports:
        health_check_passed = perform_health_check(
            health_check_config, pod_id, ports, direct_ip, port_mappings, args.model
        )
        if health_check_passed:
            print("‚úÖ Health check completed successfully!")
        else:
            print("‚ö†Ô∏è  Health check did not pass, but continuing anyway.")
            print(f"   Check the RunPod console for more details: https://console.runpod.io/pods/{pod_id}")
    
    print(f"\nüí° The pod is now running. Press Ctrl+C to stop and delete the pod.")
    print(f"‚ö†Ô∏è  After pressing Ctrl+C, DO NOT press it again while the pod is being deleted!")
    
    # Keep the script running until interrupted
    try:
        while True:
            time.sleep(60)
            # Check pod status periodically
            pod_info = get_pod_status(pod_id)
            if pod_info and pod_info.get('desiredStatus') not in ['RUNNING']:
                print(f"‚ö†Ô∏è  Pod status changed to: {pod_info.get('desiredStatus')}")
                break
    except KeyboardInterrupt:
        pass  # Will be handled by signal_handler
    
    # Cleanup on exit
    cleanup_pod()

if __name__ == "__main__":
    main()
