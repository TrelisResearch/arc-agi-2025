name: "sglang-pod-tcp"
cloudType: "SECURE"
computeType: "GPU"
imageName: "lmsysorg/sglang:latest"
gpuCount: 1
gpuTypeIds: ["NVIDIA H200"]
containerDiskInGb: 50
volumeInGb: 50
volumeMountPath: "/root/.cache/huggingface"
ports: ["8080/tcp"]
# Try specific data centers if having network issues
# dataCenterIds: ["US-IL-1", "US-TX-1", "US-GA-1"]

# ‚Üê Add this
env:
  HUGGING_FACE_HUB_TOKEN: "{{ RUNPOD_SECRET_HUGGING_FACE_HUB_TOKEN }}"
  HF_TOKEN: "{{ RUNPOD_SECRET_HUGGING_FACE_HUB_TOKEN }}"   # some libs read HF_TOKEN
  HF_HOME: "/root/.cache/huggingface"                      # optional: ensure cache on the mounted volume

dockerStartCmd:
  - "python3"
  - "-m"
  - "sglang.launch_server"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8080"

# stripped by your script before POST
healthCheck:
  type: "openai"
  timeout: 600
