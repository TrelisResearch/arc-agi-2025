{
  "model_version": "smol-iT-v0",
  "tag": "aa1",
  "model": {
    "vocab_size": 11,
    "d_model": 384,
    "nhead": 6,
    "num_layers": 4,
    "max_size": 30,
    "max_steps": 8,
    "embedding_dropout": 0.1,
    "input_grid_dropout": 0.05
  },
  "training": {
    "K": 8,
    "batch_size": 128,
    "learning_rate": 0.0004,
    "weight_decay": 0.01,
    "optimizer_steps": 96000,
    "lr_warmup_steps": 1500,
    "gradient_accumulation_steps": 1,
    "augment": true,
    "log_every": 50,
    "val_every_steps": 250,
    "vis_every_steps": 1000,
    "use_mixed_precision": true,
    "pixel_noise_prob": 0.1,
    "pixel_noise_rate": 0.05
  },
  "data": {
    "data_dir": "data/arc-prize-2024",
    "datasets": ["training_challenges","evaluation_challenges"],
    "include_training_test_examples": true,
    "max_val_examples": 128,
    "eval_weight": 1.0
  },
  "auxiliary_loss": {
    "include_size_head": true,
    "size_head_hidden_dim": 256,
    "auxiliary_size_loss_weight": 0.1,
    "auxiliary_size_loss_warmup": 0
  },
  "lora": {
    "enabled": false
  },
  "output": {
    "output_dir": "itransformer/outputs/smol",
    "use_wandb": true,
    "save_best": true,
    "save_final": true
  }
}