{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3 Tuning\n",
    "for ARC AGI 2\n",
    "\n",
    "Updates 29 July 2025:\n",
    "- Now using utils from the repo.\n",
    "- Updated lora r to 128, down from 256 as prob 128 is sufficient.\n",
    "\n",
    "Updates 24 July 2025:\n",
    "- Now supports calculation of metrics BUT requires validation data have code. This will be updated later to just pass grids for validation.\n",
    "\n",
    "Updates 23 July 2025:\n",
    "- Back to constant scheduler for one epoch. Note that SOAR use 3 epochs with cosine scheduler.\n",
    "\n",
    "Updates 22 July 2025:\n",
    "- Increased lora r to 256\n",
    "- Added training on completions only\n",
    "- Moved to cosine rather than constant scheduler. Moved from 1 to 2 epochs. Note that SOAR use 3 epochs with cosine scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git config --global user.name ‚ÄúRonanMcGovern‚Äù\n",
    "# !git config --global user.email \"78278410+RonanKMcGovern@users.noreply.github.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/workspace\"\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/workspace/hub\" # (recommended) override just the repo cache\n",
    "print(os.environ[\"HF_HOME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGuJWXIFu44v"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To run with vllm.\n",
    "!uv pip install vllm --system -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temporary Fix while unsloth is broken! - SHOULD BE FIXED AS OF JULY 20TH 2025\n",
    "!rm -rf /tmp/unsloth_compiled_cache\n",
    "!uv pip uninstall trl unsloth --system -q\n",
    "!uv pip install unsloth -qU --system\n",
    "!uv pip install trl==0.19.1 --system -q\n",
    "\n",
    "# sometimes unsloth throws numpy issues\n",
    "!uv pip uninstall numpy --system -q\n",
    "!uv pip install numpy==2.2 --system -q\n",
    "!uv pip show numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q2HoHBMsu44v"
   },
   "outputs": [],
   "source": [
    "# INSTALLED IN THE CONTAINER IF USING the [arc-agi-2025 container on runpod](https://console.runpod.io/deploy?template=bh0rvngapk&ref=jmfkcdio)\n",
    "# %%capture\n",
    "# import os\n",
    "# !pip install uv -qU\n",
    "# !uv pip install unsloth matplotlib tensorboard -qU --system\n",
    "# !export HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # if you face model download issues\n",
    "# import os\n",
    "# os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder, login\n",
    "\n",
    "# Call this at the top of your script / notebook\n",
    "if HfFolder.get_token() is None:   # no token cached or in $HF_TOKEN\n",
    "    login()                        # interactive prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cd15f7de8446b65e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cd15f7de8446b65e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "iajq1W8ipjyK",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip show trl unsloth vllm transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  1 14:12:56 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H200                    On  |   00000000:BA:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             75W /  700W |       1MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573,
     "referenced_widgets": [
      "145cc80490fa42258fe6e5a643b57dd5",
      "c3887400b6d34c30a54c6af94c2b612d",
      "7efa9f507c8546bb9b0b5d47be527c25",
      "74267e9cd64d44b58bdbd7dad03b681d",
      "dd2adf3e30304398b8340253dbd4489a",
      "7c6caf15c5de4a2fb699d034a6ab776c",
      "ebe9490475bc437c92ebc03187e53382",
      "46b625ee9ac041338432f548ee3ab51a",
      "fea4c81baaf84d9b806c1853216c89e2",
      "a151688c648045f399e32dc55dd9a1b3",
      "55b26ab90b1043cb8ed36aab316a45ad",
      "247ee0a6f4e64e5ca0a435d243690d0a",
      "4c1c1bc584cb456c9d07f4ac267cf2c5",
      "cc9479fb190742fd865613680e87e535",
      "ae9317b34ba341c4ac40797da3ac2478",
      "5012456fc82e47aca5a69f52a36cb8f5",
      "e84a5ae6c71d42ea8187ebbdcdb4791e",
      "2c04e534215f4d40b103be09e300b744",
      "d7ae6535329c45009bf5664fbd30bbf5",
      "0e112f4ad6974529a4c4f583e6a73950",
      "9c9b22a85e2049089b2194770637c91e",
      "fb2ce6370b1d4d5d9dbdb98aa236da71",
      "2dff2433978a477582b995bc6abafe68",
      "b998e55dd17b44d7a8c23ac427619036",
      "5210d369018a44d4ad2fbd26190aca9b",
      "64b00e376bb142c88a690757f27b8294",
      "09ce664a0a404087a9fe53a5c2d5316e",
      "1a09813436c24b5ea68e652254288ee0",
      "a469a1af99124ff6974265f45563deea",
      "36eed804652e4c6fb7fe2e969228decd",
      "7b8c883b15d84ca2a12bfd3f7a87101d",
      "d7afd9c01f68473387f009b05d829b3b",
      "f34c9b4f069f4fb281f4e0145f0e818e",
      "a99b117d78a8493c9f6ae80f5bf6ea5a",
      "b74e4e5971684b00b40ca42cf2aebb9e",
      "d9dcda48a37e41f7808a933cfd939ded",
      "23791684cb5349c4853cffb4e72ebe1d",
      "c6514d1ee44141d3bf83fde032d39a46",
      "6769817deaaf45fc8a0efb945570f412",
      "d7465d2830f64de996d4d3a306b97c82",
      "a68cbb7211b448c78cd418a90b908037",
      "eb052cc7147d474597529c462497b731",
      "2aefab33f6f345869c19899ca2952df1",
      "881919ffdd7940839c8b40edba7f8c01",
      "b8c184cdaa6b4d72ad28a604d1a8fa39",
      "179e343762ba440cbc094e0e85b4ee84",
      "ecd44b2e03794d5783ffbf07d8b8619f",
      "28d439d23bf54688963517fbdb482339",
      "7e7ac790b8af4cfb978bfe8ac8499900",
      "3cb88502cb1643a8927049baf40d56b7",
      "c37a4b08afa84b64b40ebbe08cbfb018",
      "2de7e147b2e14db38243c7656a29f0e4",
      "bce369933ce540d7b6ec670b04d7f1a4",
      "0940df31fc9047ccae4870b7d2c89b3d",
      "0b3d64dd05f841d68ad472ce933e36d7",
      "2068eb23121440ec83d8cd117b4c6ba5",
      "7054b1bcb73e4515afd29b42a32b20c5",
      "09cd31746a174e96bb346e1afc7b3c8b",
      "802bdf3c4293448bb00b625722f1a9f6",
      "f7c27321d53047479c1ed45b5d5109f6",
      "55a9f6bcb83d4a98a9efcf18253b5091",
      "5e18861f3fa24666869822349d1de377",
      "64eb3128b25448b48268ec61cac289d1",
      "bc277d60ad4a419a94ded28a1c27a9f4",
      "57ae3d07d1244ba495573895ff11e28e",
      "0e997f45717c44e1944d510ae6c51fb9",
      "9d02fcd7882345dea97be6decb5293a5",
      "7b34f538a42f4a9ba9de379ae57f0134",
      "1f9eba179bf847dcb47dbda34611459a",
      "844cd70bf80d40f79c520caf1d7e2a5b",
      "fa8721e596b74611945a1d76e9deff8f",
      "968919dd5d5f41ce91da5cdea02b438b",
      "31d4fb1807bc4ec0840d63ef0bf2e0f9",
      "f8f15be1afc44472bff560ca7316873a",
      "a40e10f372644d80b2830d0f42fcde6c",
      "2f4608614780453a826e3ad59817d7ae",
      "c89e5721ed7e48b295ccc74b841ec61e",
      "e3ecd73a9b86479e8596d8bb1ef5791d",
      "911bd3f394ce4394be92e50782d6ae39",
      "ce05df3e26834837b2db818657a9d175",
      "b25399bf6ae4414ba2836733f59e4ab0",
      "a81ef4374fde4d10a1cdc5daeec34dda",
      "dd1b79ecec114d28ace8c1b8b1fd4d5d",
      "d4b3982b73d046478f7c9b561ed42298",
      "63abaade8f464ed6bbd51d77014dfe66",
      "ef69f52b4c7a485b8708f171bb6acbd6",
      "92be8fd7a814466c983d689bd5d6e1a9",
      "7a3a67547e2043a0ac74b49c47009954",
      "196f35f21b97476a9814acd96dbec717",
      "3ad6055d2ba2481c83b1b136e5898986",
      "8147cc77ce3941c290982d21c42f9f66",
      "f1af17f7a7ee405dabd07f41b6b786d7",
      "aeb720eea25149deb34e6844a8bdd2c5",
      "7d574f195dfc4bc4b1ca86863d97e597",
      "c8faa5be5b88425298b5655a8f507a2a",
      "93a91db5fd6147c5a7982496f09c5b8b",
      "5132d82c92ac41d2b592bf6eebf92c19",
      "4b19bb0b66b248fdbcd01b6264e2ff02",
      "689f645af24947e8920b631d2aa7c3ad",
      "d9c143d31e494981b188be41bd52118f",
      "67a67c8affbe4ec38f99cbb0a3c52dcc",
      "0d0852d9ebb2409ea51650f538dd1621",
      "904f626a367745979ac664f4d2ea6409",
      "e0260495036b406fbf462b3c387205d2",
      "a86e54867d5141dfb1e31ed2d706434f",
      "9864096e9bb54228bf1d9e581b8485bc",
      "062f278ab1c94d8099e06074e0cd360c",
      "3ad57df96bec4267a220a739cfc72bc1",
      "e976be66ed774ce880463df39d0c25ce",
      "67e43763f2f7457487d8b5bfca51b8e4",
      "b1542f5b57f14b98be813e6b2540bb80",
      "34b0ab119eab40eda8b7a551642e0e31",
      "c519c7b69d70467c875a3d228e6b6fd2",
      "cd8774e4577a4652863469d3cb75f2ee",
      "40b0b562564b4e969c02902b1bbea6e8",
      "71c37d1f12294e858ceb337d2e37e375",
      "00d671d686af43c38b12a9448c5bbf06",
      "f85353b1b37342859c9aa71442781e95",
      "73d6e9b4704f40aab25fecd24154f9bc",
      "2167f3dc7050467a9f19f3f885cfb09b",
      "569ad7b2350d46549b2f385a126426d5",
      "6910d714dc854e959839e57b5123af86",
      "77f86f331a19461d94e4840213b256f6",
      "fcd0ee642395431e92a681ba8d829b20",
      "12d7cac449954aafa26c6b5bcb6e031f",
      "4ba6022d4efc4c2ebfdf87b288ed9fd4",
      "0fab32e1222f4431a255a36df0a22a35",
      "7013b9ae0d8a4bbfa744a5a3e3c18a1e",
      "3ddcfbdbb0fc49b0b53a296cdb2348b8",
      "2b72ac21d79c459395682f6692c4325f",
      "26dbcdc380e1404687020cbd9bf38513",
      "2abd7191bff846198b2fb033da32f8c8",
      "60c6d4d43a6445e78051c96a462d7c20",
      "06c646d514b448628424dc8c772994de",
      "7c33f0f45eca43cb8015416999b884a1",
      "3c2e07218b764906a278d6a367153548",
      "bf94cc1837ba486b895656b41c1e9c99",
      "8be1618a9f8840af8d89103c37ef02ef",
      "f0b8a9e00c0d4cc1aff1e3a748a8f039",
      "b1cd702821234a9f87933d099ef5273c",
      "6be394c3849a41a3937322325836d604",
      "db172381abdf4bb0a84417882fc462be",
      "0ab824fcbf0e46f7bbe75af9f662c31a"
     ]
    },
    "editable": true,
    "id": "QmUBVEnvCDJv",
    "outputId": "ad27d22a-d0a6-4659-be63-60bf3b3561b7",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 08-01 14:13:03 [__init__.py:235] Automatically detected platform cuda.\n",
      "Unsloth: We'll be using `/tmp/unsloth_compiled_cache` for temporary Unsloth patches.\n",
      "Standard import failed for UnslothDDPOTrainer: No module named 'UnslothDDPOTrainer'. Using tempfile instead!\n",
      "Unsloth: Patching vLLM v1 graph capture\n",
      "Unsloth: Patching vLLM v0 graph capture\n",
      "==((====))==  Unsloth 2025.7.11: Fast Qwen3 patching. Transformers: 4.54.1. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA H200. Num GPUs = 1. Max memory: 139.719 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/Qwen3-4B with actual GPU utilization = 29.87%\n",
      "Unsloth: Your GPU has CUDA compute capability 9.0 with VRAM = 139.72 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 32768. Num Sequences = 320.\n",
      "Unsloth: vLLM's KV Cache can use up to 34.44 GB. Also swap space = 6 GB.\n",
      "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
      "INFO 08-01 14:13:11 [config.py:1604] Using max model len 32768\n",
      "INFO 08-01 14:13:12 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=32768.\n",
      "INFO 08-01 14:13:12 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen3-4B', speculative_config=None, tokenizer='unsloth/Qwen3-4B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen3-4B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":true,\"trace.graph_diagram\":false,\"compile_threads\":32,\"combo_kernels\":false,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "INFO 08-01 14:13:13 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 08-01 14:13:13 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 08-01 14:13:13 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen3-4B...\n",
      "INFO 08-01 14:13:13 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "INFO 08-01 14:13:13 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "INFO 08-01 14:13:13 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82620edea9f04c8cb3aca55f353f37b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-01 14:13:22 [default_loader.py:262] Loading weights took 9.26 seconds\n",
      "INFO 08-01 14:13:22 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "INFO 08-01 14:13:23 [gpu_model_runner.py:1892] Model loading took 8.0059 GiB and 9.603944 seconds\n",
      "INFO 08-01 14:13:34 [backends.py:530] Using cache directory: /root/.cache/vllm/torch_compile_cache/4cd45fbc22/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 08-01 14:13:34 [backends.py:541] Dynamo bytecode transform time: 11.02 s\n",
      "INFO 08-01 14:13:45 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 9.675 s\n",
      "INFO 08-01 14:14:10 [monitor.py:34] torch.compile takes 11.02 s in total\n",
      "INFO 08-01 14:14:11 [gpu_worker.py:255] Available KV cache memory: 30.71 GiB\n",
      "INFO 08-01 14:14:11 [kv_cache_utils.py:833] GPU KV cache size: 223,616 tokens\n",
      "INFO 08-01 14:14:11 [kv_cache_utils.py:837] Maximum concurrency for 32,768 tokens per request: 6.82x\n",
      "INFO 08-01 14:14:11 [vllm_utils.py:641] Unsloth: Running patched vLLM v1 `capture_model`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:20<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-01 14:14:31 [gpu_model_runner.py:2485] Graph capturing finished in 20 secs, took 1.00 GiB\n",
      "INFO 08-01 14:14:31 [vllm_utils.py:648] Unsloth: Patched vLLM v1 graph capture finished in 20 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-01 14:14:32 [core.py:193] init engine (profile, create kv cache, warmup model) took 69.47 seconds\n",
      "Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'post_feedforward_layernorm']\n",
      "Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'post_feedforward_layernorm']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model_slug = \"Qwen/Qwen3-4B\"\n",
    "# model_slug = \"julien31/Soar-qwen-7b\"\n",
    "# model_slug = \"Qwen/Qwen2.5-Coder-7B-Instruct\"\n",
    "# model_slug = \"Qwen/Qwen3-30B-A3B\"\n",
    "\n",
    "model_max_length = 32768 #default is ~2k for unsloth!!!\n",
    "lora_rank = 128\n",
    "\n",
    "# Training AND validation batch size (incl. for autoregressive train/test example metrics calculations)\n",
    "batch_size_global = 4 # use 2 for 7/8B, use 4 for 4B on H200.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_slug,\n",
    "    max_seq_length = model_max_length,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = False,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # We have full finetuning now!\n",
    "    # cache_dir = '/workspace',\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    "    \n",
    "    # for using fast_inference\n",
    "    fast_inference = True, # allows for vLLM generation during evaluation\n",
    "    max_lora_rank=lora_rank,\n",
    "    gpu_memory_utilization=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  1 14:14:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H200                    On  |   00000000:BA:00.0 Off |                    0 |\n",
      "| N/A   27C    P0            113W /  700W |   41950MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n"
     ]
    }
   ],
   "source": [
    "print(model.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Print a summary of the transformer layers and key dimensions\n",
    "# for i, block in enumerate(model.model.layers):\n",
    "#     attn = block.self_attn\n",
    "#     mlp = block.mlp\n",
    "\n",
    "#     print(f\"Layer {i}:\")\n",
    "#     print(f\"  Attention:\")\n",
    "#     print(f\"    q_proj: {attn.q_proj.weight.shape}\")\n",
    "#     print(f\"    k_proj: {attn.k_proj.weight.shape}\")\n",
    "#     print(f\"    v_proj: {attn.v_proj.weight.shape}\")\n",
    "#     print(f\"    out_proj: {attn.o_proj.weight.shape}\")\n",
    "#     print(f\"  MLP:\")\n",
    "#     print(f\"    fc1: {mlp.gate_proj.weight.shape}\")\n",
    "#     print(f\"    fc2: {mlp.up_proj.weight.shape}\")\n",
    "#     print(f\"    fc3: {mlp.down_proj.weight.shape}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "SXd9bTZd1aaL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "6bZsfBuZDeCL",
    "outputId": "d50f06c8-4905-4f4e-c6da-980145c41e29",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.7.11 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128. could consider 128.\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                     ],\n",
    "    lora_alpha = 64,  # Best to choose alpha = rank or rank*2. EXCEPT if using rslora, in which case set it as sqrt(max matrix dimension). 64 is good for Qwen 4B\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Project root: /workspace/arc-agi-2025\n",
      "üìÅ Looking for utils in: /workspace/arc-agi-2025/llm_python\n",
      "‚úÖ Utils imported and initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Import utils using standard project root detection\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Find project root by looking for pyproject.toml\n",
    "project_root = next(\n",
    "    (parent for parent in [Path.cwd()] + list(Path.cwd().parents) \n",
    "     if (parent / \"pyproject.toml\").exists()), \n",
    "    Path.cwd()\n",
    ")\n",
    "\n",
    "# Add llm_python directory to path (where utils is located)\n",
    "llm_python_dir = project_root / \"llm_python\"\n",
    "sys.path.insert(0, str(llm_python_dir))\n",
    "\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(f\"üìÅ Looking for utils in: {llm_python_dir}\")\n",
    "\n",
    "from utils.task_loader import TaskLoader\n",
    "from utils.scoring import GridScorer, ProgramExecutor\n",
    "from utils.prompt_utils import create_arc_prompt, extract_python_code\n",
    "from utils.metrics_utils import calculate_task_metrics, format_metrics_display, metrics_to_percentages\n",
    "from utils.timeout_utils import execute_with_timeout\n",
    "from utils.transduction import is_transduction_cheating\n",
    "from utils.prompt_loader import PromptLoader\n",
    "\n",
    "# Initialize utility instances\n",
    "prompt_loader = PromptLoader()\n",
    "scorer = GridScorer()\n",
    "print(\"‚úÖ Utils imported and initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "vITh0KVJ10qX",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using SOAR prompts from utils:\n",
      "   System prompt: 129 chars\n",
      "   Initial turn prompt: 990 chars\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85b60ca05f7492889a26de8b0b7f770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "build chat + prompt fields (train):   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb2f64c3a1e40519275d470ab12c64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "build chat + prompt fields (train):   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Optional\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config (examples)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Set max_rows flag to limit train size. None for all\n",
    "max_rows = None # None for all rows\n",
    "max_validation_rows = 32\n",
    "\n",
    "# # CASE 1: single slug with both splits\n",
    "# train_slug = \"Trelis/synth_arc-agi-1_all_training_20250724_131808\"\n",
    "# val_slug = None\n",
    "\n",
    "# CASE 2: two different slugs\n",
    "train_slug = \"Trelis/soar-20250729_114431-1600\"\n",
    "val_slug   = \"Trelis/grids_only_arc-agi-1_all_evaluation_20250729_102313\"\n",
    "\n",
    "enable_thinking = False  # See note in original code\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Prompt management using utils (replacing hard-coded prompts)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Use prompt_loader to get SOAR prompts from utils\n",
    "SYSTEM_PROMPT = prompt_loader.get_system_message(\"soar\")\n",
    "INITIAL_TURN_PROMPT = prompt_loader.get_initial_turn_prompt(\"soar\")\n",
    "\n",
    "print(f\"‚úÖ Using SOAR prompts from utils:\")\n",
    "print(f\"   System prompt: {len(SYSTEM_PROMPT)} chars\")\n",
    "print(f\"   Initial turn prompt: {len(INITIAL_TURN_PROMPT)} chars\")\n",
    "\n",
    "# Custom formatting functions removed - using create_arc_prompt from utils instead\n",
    "\n",
    "def hf_dataset_to_chat_dataset(dataset_slug: str, split: str = \"train\"):\n",
    "    \"\"\"\n",
    "    Convert a HF split into the chat/prompt format using utils.\n",
    "    \"\"\"\n",
    "    ds = load_dataset(dataset_slug, split=split, keep_in_memory=True)\n",
    "\n",
    "    def select_output(example, output_key, predicted_key):\n",
    "        \"\"\"\n",
    "        Select between regular output and predicted output based on availability and non-zero values.\n",
    "        \"\"\"\n",
    "        # Check if predicted output exists and is non-zero\n",
    "        if predicted_key in example and example[predicted_key]:\n",
    "            predicted = example[predicted_key]\n",
    "            # Check if any predicted output is non-zero (has any non-zero cells)\n",
    "            if any(any(any(cell != 0 for cell in row) for row in grid) for grid in predicted):\n",
    "                return predicted\n",
    "        \n",
    "        # Fall back to regular output\n",
    "        return example[output_key]\n",
    "\n",
    "    def create_chat_messages(example):\n",
    "        # Select appropriate outputs (predicted if available and non-zero, otherwise regular)\n",
    "        train_outputs = select_output(example, \"train_output\", \"predicted_train_output\")\n",
    "        test_outputs = select_output(example, \"test_output\", \"predicted_test_output\")\n",
    "        \n",
    "        # Create task_data in the format expected by create_arc_prompt\n",
    "        task_data = {\n",
    "            'train': [{'input': inp, 'output': out} \n",
    "                     for inp, out in zip(example[\"train_input\"], train_outputs)],\n",
    "            'test': [{'input': inp, 'output': out} \n",
    "                     for inp, out in zip(example[\"test_input\"], test_outputs)]  # All test examples!\n",
    "        }\n",
    "        \n",
    "        # Use create_arc_prompt from utils (matches run_arc_tasks_soar.py)\n",
    "        system_content, user_content = create_arc_prompt(task_data, prompt_loader, \"soar\")\n",
    "\n",
    "        assistant_content = \"\"\n",
    "        if enable_thinking and example.get(\"reasoning\", \"\").strip():\n",
    "            assistant_content += f\"<think>{example['reasoning'].strip()}</think>\"\n",
    "        assistant_content += f\"```python\\n{example['code']}\\n```\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\",   \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "        ]\n",
    "\n",
    "        prompt_messages = [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\",   \"content\": user_content},\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False,\n",
    "            enable_thinking = enable_thinking\n",
    "        )\n",
    "\n",
    "        prompt_text = tokenizer.apply_chat_template(\n",
    "            prompt_messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking = enable_thinking\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"text\": text,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"train_input\": example[\"train_input\"],\n",
    "            \"train_output\": train_outputs,  # Use selected outputs (predicted when available)\n",
    "            \"test_input\": example[\"test_input\"],\n",
    "            \"test_output\": test_outputs,    # Use selected outputs (predicted when available)\n",
    "            \"reasoning\": example.get(\"reasoning\", \"\"),\n",
    "            \"code\": example[\"code\"],\n",
    "            \"task_id\": example.get(\"task_id\", \"\"),\n",
    "        }\n",
    "\n",
    "    ds = ds.map(create_chat_messages, desc=f\"build chat + prompt fields ({split})\")\n",
    "    return ds\n",
    "\n",
    "def build_dataset(train_slug: str,\n",
    "                  val_slug: Optional[str] = None,\n",
    "                  train_split: str = \"train\",\n",
    "                  val_split: str = \"validation\") -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Build a DatasetDict with 'train' and 'validation' keys.\n",
    "    - If val_slug is None, both splits are loaded from train_slug.\n",
    "    - Otherwise, load train_split from train_slug and val_split from val_slug.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load and filter\n",
    "    train_ds = hf_dataset_to_chat_dataset(train_slug, split=train_split)\n",
    "    if max_rows:\n",
    "        train_ds = train_ds.select(range(min(len(train_ds), max_rows)))\n",
    "    \n",
    "    # Validation logic\n",
    "    if val_slug is None:\n",
    "        try:\n",
    "            val_ds = hf_dataset_to_chat_dataset(train_slug, split=val_split)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\n",
    "                f\"Could not load split '{val_split}' from '{train_slug}'. \"\n",
    "                f\"Pass an explicit val_slug or choose a valid split.\\nOriginal error: {e}\"\n",
    "            )\n",
    "    else:\n",
    "        val_ds = hf_dataset_to_chat_dataset(val_slug, split=\"train\")\n",
    "    \n",
    "    # Corrected slice\n",
    "    if max_validation_rows:\n",
    "        val_ds = val_ds.select(range(min(len(val_ds), max_validation_rows)))\n",
    "    elif max_rows:\n",
    "        val_ds = val_ds.select(range(min(len(val_ds), max_rows)))\n",
    "    \n",
    "    return DatasetDict(train=train_ds, validation=val_ds)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Build the dataset\n",
    "# ---------------------------------------------------------------------\n",
    "data = build_dataset(train_slug, val_slug)  # val_slug may be None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split\n",
    "val_ids = [ex[\"task_id\"] for ex in data[\"validation\"]]\n",
    "assert all(val_ids), \"‚ùå some validation rows are missing task_id\"\n",
    "assert len(val_ids) == len(set(val_ids)), \"‚ùå duplicate task_id in validation slice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # print(data[\"train\"][0])\n",
    "# print(data[\"train\"][0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[\"train\"][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by reasoning and generating Python code.<|im_end|>\n",
      "<|im_start|>user\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by generating Python code.\n",
      "Your goal is to analyze input-output grid pairs. The outputs were produced by applying a transformation rule to the inputs. Implement the transformation rules as a Python function.\n",
      "You should only write the implemented the transformation in code.\n",
      "You must write code in triple backticks (```python and then ```). You must write a function called 'transform' which takes a single argument, the input grid as 'list[list[int]]', and returns the transformed grid (also as 'list[list[int]]').\n",
      "You should make sure that you implement a version of the transformation which works in general (at least for all given input-output pairs and test input pairs).\n",
      "The number in the input grid can be mapped to the following colors: 0:Black; 1:Blue; 2:Red; 3:Green; 4:Yellow; 5:Grey; 6:Pink; 7:Orange; 8:Purple; 9:Brown\n",
      "Now, solve the following ARC-AGI task:\n",
      "# Task to solve:\n",
      "## Input 1 (grid shape: 2 by 2):\n",
      "[[8 6] [6 4]]\n",
      "## Output 1 (grid shape: 6 by 6):\n",
      "[[8 6 8 6 8 6] [6 4 6 4 6 4] [6 8 6 8 6 8] [4 6 4 6 4 6] [8 6 8 6 8 6] [6 4 6 4 6 4]]\n",
      "\n",
      "## Input 2 (grid shape: 2 by 2):\n",
      "[[7 9] [4 3]]\n",
      "## Output 2 (grid shape: 6 by 6):\n",
      "[[7 9 7 9 7 9] [4 3 4 3 4 3] [9 7 9 7 9 7] [3 4 3 4 3 4] [7 9 7 9 7 9] [4 3 4 3 4 3]]\n",
      "\n",
      "## Test Input 1 (grid shape: 2 by 2):\n",
      "[[3 2] [7 8]]\n",
      "## Expected Test Output 1 (grid shape: 6 by 6):\n",
      "[[3 2 3 2 3 2] [7 8 7 8 7 8] [2 3 2 3 2 3] [8 7 8 7 8 7] [3 2 3 2 3 2] [7 8 7 8 7 8]]\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "```python\n",
      "\n",
      "```<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[\"validation\"][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "PTZICZtie3lQ",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's see the structure of both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true,
    "id": "jfV47_SXgXH4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45a1656119d47df88ae33d5ce0d823f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train:  min= 518  median=2303  max=19056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3305fa02e5a84384b5bcd793a6cef7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " validation:  min= 631  median=3561  max=15051\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "def length_stats(dataset, name=\"\"):\n",
    "    \"\"\"\n",
    "    Return min / median / max tokenised length for a ü§ó Dataset split that has a\n",
    "    single 'text' column. Uses the same tokenizer already in memory.\n",
    "    \"\"\"\n",
    "    # Tokenise in batches ‚Üí list of list[int] ‚Üí list[int] lengths\n",
    "    lengths = dataset.map(\n",
    "        lambda batch: {\n",
    "            \"len\": [len(ids) for ids in tokenizer(batch[\"text\"],\n",
    "                                                  add_special_tokens=False\n",
    "                                                 )[\"input_ids\"]]\n",
    "        },\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,   # drop 'text'\n",
    "        keep_in_memory=True,\n",
    "    )[\"len\"]\n",
    "\n",
    "    print(f\"{name:>11}:  min={min(lengths):>4}  \"\n",
    "          f\"median={int(median(lengths)):>4}  max={max(lengths):>4}\")\n",
    "\n",
    "# ‚îÄ‚îÄ run for both splits ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "length_stats(data[\"train\"],       \"train\")\n",
    "length_stats(data[\"validation\"],  \"validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Pre-Training Data Integrity Tests\n",
    "Before training, let's test the ground-truth code on a random sample of training examples to validate dataset quality and establish baseline performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running Pre-Training Data Integrity Tests\n",
      "üìä Testing 100 random examples from train split\n",
      "============================================================\n",
      "\n",
      "üîç Testing 100 examples...\n",
      "\n",
      "[1/100] Testing 2204b7a8\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[2/100] Testing b782dc8a\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[3/100] Testing 29ec7d0e\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[4/100] Testing be94b721\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[5/100] Testing c0f76784\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[6/100] Testing 94f9d214\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[7/100] Testing 6fa7a44f\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[8/100] Testing ded97339\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[9/100] Testing b94a9452\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[10/100] Testing a79310a0\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[11/100] Testing 5bd6f4ac\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[12/100] Testing be94b721\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[13/100] Testing 834ec97d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[14/100] Testing 91413438\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[15/100] Testing cbded52d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[16/100] Testing b6afb2da\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[17/100] Testing 3aa6fb7a\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[18/100] Testing 36d67576\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[19/100] Testing 99b1bc43\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[20/100] Testing 6a1e5592\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[21/100] Testing 82819916\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[22/100] Testing 41e4d17e\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[23/100] Testing d90796e8\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[24/100] Testing 2dd70a9a\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[25/100] Testing 9af7a82c\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[26/100] Testing 469497ad\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[27/100] Testing 995c5fa3\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[28/100] Testing 2dc579da\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[29/100] Testing 8403a5d5\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[30/100] Testing af902bf9\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[31/100] Testing 6cf79266\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[32/100] Testing db3e9e38\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[33/100] Testing c8f0f002\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[34/100] Testing c9f8e694\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[35/100] Testing 0d3d703e\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[36/100] Testing d9f24cd1\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[37/100] Testing 05269061\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[38/100] Testing 7ddcd7ec\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[39/100] Testing b6afb2da\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[40/100] Testing 3618c87e\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[41/100] Testing fcb5c309\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[42/100] Testing 67e8384a\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[43/100] Testing de1cd16c\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[44/100] Testing 2bee17df\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[45/100] Testing 99b1bc43\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[46/100] Testing 72322fa7\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[47/100] Testing a2fd1cf0\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[48/100] Testing 50846271\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[49/100] Testing 3af2c5a8\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[50/100] Testing db93a21d\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[51/100] Testing b230c067\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[52/100] Testing 48d8fb45\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[53/100] Testing ae3edfdc\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[54/100] Testing ec883f72\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[55/100] Testing 72ca375d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[56/100] Testing cdecee7f\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[57/100] Testing 6e19193c\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[58/100] Testing 846bdb03\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[59/100] Testing 8e5a5113\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[60/100] Testing dc1df850\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[61/100] Testing 08ed6ac7\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[62/100] Testing f25fbde4\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[63/100] Testing 5521c0d9\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[64/100] Testing b2862040\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[65/100] Testing 40853293\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[66/100] Testing 8731374e\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[67/100] Testing 7447852a\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[68/100] Testing 4c4377d9\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[69/100] Testing 4258a5f9\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[70/100] Testing 776ffc46\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[71/100] Testing ed36ccf7\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[72/100] Testing d89b689b\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[73/100] Testing 846bdb03\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[74/100] Testing a65b410d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[75/100] Testing e5062a87\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[76/100] Testing 1caeab9d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[77/100] Testing 57aa92db\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[78/100] Testing 0dfd9992\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[79/100] Testing 673ef223\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[80/100] Testing 46f33fce\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[81/100] Testing 5c2c9af4\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[82/100] Testing 50cb2852\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[83/100] Testing b60334d2\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[84/100] Testing 8403a5d5\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[85/100] Testing 67a3c6ac\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[86/100] Testing 29c11459\n",
      "  ‚úÖ Train: 2/2 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[87/100] Testing 760b3cac\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[88/100] Testing e26a3af2\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[89/100] Testing 1caeab9d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[90/100] Testing 1f876c06\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[91/100] Testing 6e82a1ae\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[92/100] Testing ae3edfdc\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[93/100] Testing 0dfd9992\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[94/100] Testing f1cefba8\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[95/100] Testing 72322fa7\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[96/100] Testing ba26e723\n",
      "  ‚úÖ Train: 5/5 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[97/100] Testing 2204b7a8\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[98/100] Testing 6d58a25d\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[99/100] Testing 9565186b\n",
      "  ‚úÖ Train: 4/4 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n",
      "[100/100] Testing 6cf79266\n",
      "  ‚úÖ Train: 3/3 (100.0%)\n",
      "  ‚úÖ Test:  1/1 (100.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Configuration for pre-training tests\n",
    "NUM_TEST_EXAMPLES = 100  # Number of random examples to test\n",
    "RANDOM_SEED = 42  # For reproducible results\n",
    "\n",
    "def run_pre_training_data_integrity_tests(dataset_split=\"train\", num_examples=NUM_TEST_EXAMPLES):\n",
    "    \"\"\"\n",
    "    Test ground-truth code from dataset on random examples to validate data quality.\n",
    "    \n",
    "    Args:\n",
    "        dataset_split: Which split to test (should be \"train\" since validation has no ground-truth code)\n",
    "        num_examples: Number of random examples to test\n",
    "    \"\"\"\n",
    "    print(f\"üß™ Running Pre-Training Data Integrity Tests\")\n",
    "    print(f\"üìä Testing {num_examples} random examples from {dataset_split} split\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set seed for reproducible sampling\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Get the dataset split\n",
    "    dataset = data[dataset_split]\n",
    "    \n",
    "    # Randomly sample examples\n",
    "    total_examples = len(dataset)\n",
    "    if num_examples > total_examples:\n",
    "        print(f\"‚ö†Ô∏è  Requested {num_examples} examples but only {total_examples} available. Testing all.\")\n",
    "        sample_indices = list(range(total_examples))\n",
    "    else:\n",
    "        sample_indices = random.sample(range(total_examples), num_examples)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    results = []\n",
    "    executor = ProgramExecutor(timeout=2.0, executor_type=\"unrestricted\")\n",
    "    \n",
    "    print(f\"\\nüîç Testing {len(sample_indices)} examples...\\n\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        example = dataset[idx]\n",
    "        task_id = example.get(\"task_id\", f\"idx_{idx}\")\n",
    "        code = example[\"code\"]\n",
    "        \n",
    "        print(f\"[{i+1}/{len(sample_indices)}] Testing {task_id}\")\n",
    "        \n",
    "        # Initialize results for this example\n",
    "        example_result = {\n",
    "            \"task_id\": task_id,\n",
    "            \"index\": idx,\n",
    "            \"code\": code,\n",
    "            \"train_results\": [],\n",
    "            \"test_results\": [],\n",
    "            \"train_success\": 0,\n",
    "            \"test_success\": 0,\n",
    "            \"code_executed\": False,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        \n",
    "        # Test on training examples\n",
    "        train_correct = 0\n",
    "        for t_idx, (train_in, train_out) in enumerate(zip(example[\"train_input\"], example[\"train_output\"])):\n",
    "            try:\n",
    "                predicted_output, error, timed_out = executor.execute_program_with_timeout(code, train_in)\n",
    "                \n",
    "                if predicted_output is not None:\n",
    "                    example_result[\"code_executed\"] = True\n",
    "                    score_result = scorer.score_grid(predicted_output, train_out)\n",
    "                    is_correct = score_result[\"correct\"]\n",
    "                    \n",
    "                    if is_correct:\n",
    "                        train_correct += 1\n",
    "                    \n",
    "                    example_result[\"train_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": is_correct,\n",
    "                        \"predicted\": predicted_output,\n",
    "                        \"expected\": train_out,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                else:\n",
    "                    example_result[\"train_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": False,\n",
    "                        \"error\": error,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                    if error:\n",
    "                        example_result[\"errors\"].append(f\"Train {t_idx}: {error}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                example_result[\"train_results\"].append({\n",
    "                    \"index\": t_idx,\n",
    "                    \"correct\": False,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                example_result[\"errors\"].append(f\"Train {t_idx}: {str(e)}\")\n",
    "        \n",
    "        # Test on test examples\n",
    "        test_correct = 0\n",
    "        for t_idx, (test_in, test_out) in enumerate(zip(example[\"test_input\"], example[\"test_output\"])):\n",
    "            try:\n",
    "                predicted_output, error, timed_out = executor.execute_program_with_timeout(code, test_in)\n",
    "                \n",
    "                if predicted_output is not None:\n",
    "                    example_result[\"code_executed\"] = True\n",
    "                    score_result = scorer.score_grid(predicted_output, test_out)\n",
    "                    is_correct = score_result[\"correct\"]\n",
    "                    \n",
    "                    if is_correct:\n",
    "                        test_correct += 1\n",
    "                    \n",
    "                    example_result[\"test_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": is_correct,\n",
    "                        \"predicted\": predicted_output,\n",
    "                        \"expected\": test_out,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                else:\n",
    "                    example_result[\"test_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": False,\n",
    "                        \"error\": error,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                    if error:\n",
    "                        example_result[\"errors\"].append(f\"Test {t_idx}: {error}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                example_result[\"test_results\"].append({\n",
    "                    \"index\": t_idx,\n",
    "                    \"correct\": False,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                example_result[\"errors\"].append(f\"Test {t_idx}: {str(e)}\")\n",
    "        \n",
    "        # Calculate success rates for this example\n",
    "        example_result[\"train_success\"] = train_correct / len(example[\"train_input\"]) if example[\"train_input\"] else 0\n",
    "        example_result[\"test_success\"] = test_correct / len(example[\"test_input\"]) if example[\"test_input\"] else 0\n",
    "        \n",
    "        # Print summary for this example\n",
    "        total_train = len(example[\"train_input\"])\n",
    "        total_test = len(example[\"test_input\"])\n",
    "        \n",
    "        print(f\"  ‚úÖ Train: {train_correct}/{total_train} ({example_result['train_success']:.1%})\")\n",
    "        print(f\"  ‚úÖ Test:  {test_correct}/{total_test} ({example_result['test_success']:.1%})\")\n",
    "        \n",
    "        if example_result[\"errors\"]:\n",
    "            print(f\"  ‚ùå Errors: {len(example_result['errors'])}\")\n",
    "        if not example_result[\"code_executed\"]:\n",
    "            print(f\"  ‚ö†Ô∏è  Code never executed successfully\")\n",
    "        print()\n",
    "        \n",
    "        results.append(example_result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the tests\n",
    "data_integrity_results = run_pre_training_data_integrity_tests(\"train\", NUM_TEST_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìà PRE-TRAINING DATA INTEGRITY RESULTS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üéØ OVERALL PERFORMANCE:\n",
      "   Examples tested: 100\n",
      "   Code executable: 100/100 (100.0%)\n",
      "   Examples with errors: 0/100 (0.0%)\n",
      "\n",
      "üìä TRAINING GRIDS PERFORMANCE:\n",
      "   Average success rate: 100.0%\n",
      "   Perfect examples (100%): 100/100 (100.0%)\n",
      "   Partial examples (>0% <100%): 0/100 (0.0%)\n",
      "   Failed examples (0%): 0/100 (0.0%)\n",
      "   Grid-level accuracy: 313/313 (100.0%)\n",
      "\n",
      "üéØ TEST GRIDS PERFORMANCE:\n",
      "   Average success rate: 100.0%\n",
      "   Perfect examples (100%): 100/100 (100.0%)\n",
      "   Partial examples (>0% <100%): 0/100 (0.0%)\n",
      "   Failed examples (0%): 0/100 (0.0%)\n",
      "   Grid-level accuracy: 100/100 (100.0%)\n",
      "\n",
      "üìã DETAILED BREAKDOWN BY EXAMPLE:\n",
      "------------------------------------------------------------\n",
      "[ 1] 2204b7a8\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 2] b782dc8a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 3] 29ec7d0e\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 4] be94b721\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 5] c0f76784\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 6] 94f9d214\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 7] 6fa7a44f\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 8] ded97339\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[ 9] b94a9452\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[10] a79310a0\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[11] 5bd6f4ac\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[12] be94b721\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[13] 834ec97d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[14] 91413438\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[15] cbded52d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[16] b6afb2da\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[17] 3aa6fb7a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[18] 36d67576\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[19] 99b1bc43\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[20] 6a1e5592\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[21] 82819916\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[22] 41e4d17e\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[23] d90796e8\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[24] 2dd70a9a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[25] 9af7a82c\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[26] 469497ad\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[27] 995c5fa3\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[28] 2dc579da\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[29] 8403a5d5\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[30] af902bf9\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[31] 6cf79266\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[32] db3e9e38\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[33] c8f0f002\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[34] c9f8e694\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[35] 0d3d703e\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[36] d9f24cd1\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[37] 05269061\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[38] 7ddcd7ec\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[39] b6afb2da\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[40] 3618c87e\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[41] fcb5c309\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[42] 67e8384a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[43] de1cd16c\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[44] 2bee17df\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[45] 99b1bc43\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[46] 72322fa7\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[47] a2fd1cf0\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[48] 50846271\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[49] 3af2c5a8\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[50] db93a21d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[51] b230c067\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[52] 48d8fb45\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[53] ae3edfdc\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[54] ec883f72\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[55] 72ca375d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[56] cdecee7f\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[57] 6e19193c\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[58] 846bdb03\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[59] 8e5a5113\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[60] dc1df850\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[61] 08ed6ac7\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[62] f25fbde4\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[63] 5521c0d9\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[64] b2862040\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[65] 40853293\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[66] 8731374e\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[67] 7447852a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[68] 4c4377d9\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[69] 4258a5f9\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[70] 776ffc46\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[71] ed36ccf7\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[72] d89b689b\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[73] 846bdb03\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[74] a65b410d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[75] e5062a87\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[76] 1caeab9d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[77] 57aa92db\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[78] 0dfd9992\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[79] 673ef223\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[80] 46f33fce\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[81] 5c2c9af4\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[82] 50cb2852\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[83] b60334d2\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[84] 8403a5d5\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[85] 67a3c6ac\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[86] 29c11459\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[87] 760b3cac\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[88] e26a3af2\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[89] 1caeab9d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[90] 1f876c06\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[91] 6e82a1ae\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[92] ae3edfdc\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[93] 0dfd9992\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[94] f1cefba8\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[95] 72322fa7\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[96] ba26e723\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[97] 2204b7a8\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[98] 6d58a25d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[99] 9565186b\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "[100] 6cf79266\n",
      "     Train: 100.0% | Test: 100.0% | Executed: ‚úÖ | Errors: 0\n",
      "\n",
      "üîç DATASET QUALITY ASSESSMENT:\n",
      "------------------------------------------------------------\n",
      "‚úÖ EXCELLENT: Ground-truth code performs very well on training examples\n",
      "‚úÖ EXCELLENT: Ground-truth code generalizes very well to test examples\n",
      "‚úÖ EXCELLENT: All ground-truth code is executable\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def analyze_data_integrity_results(results):\n",
    "    \"\"\"\n",
    "    Analyze and display comprehensive statistics from the data integrity tests.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìà PRE-TRAINING DATA INTEGRITY RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"‚ùå No results to analyze!\")\n",
    "        return\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_examples = len(results)\n",
    "    examples_with_executable_code = sum(1 for r in results if r[\"code_executed\"])\n",
    "    examples_with_errors = sum(1 for r in results if r[\"errors\"])\n",
    "    \n",
    "    # Training performance statistics\n",
    "    train_success_rates = [r[\"train_success\"] for r in results]\n",
    "    perfect_train = sum(1 for rate in train_success_rates if rate == 1.0)\n",
    "    partial_train = sum(1 for rate in train_success_rates if 0 < rate < 1.0)\n",
    "    failed_train = sum(1 for rate in train_success_rates if rate == 0.0)\n",
    "    \n",
    "    # Test performance statistics  \n",
    "    test_success_rates = [r[\"test_success\"] for r in results]\n",
    "    perfect_test = sum(1 for rate in test_success_rates if rate == 1.0)\n",
    "    partial_test = sum(1 for rate in test_success_rates if 0 < rate < 1.0)\n",
    "    failed_test = sum(1 for rate in test_success_rates if rate == 0.0)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    avg_train_success = sum(train_success_rates) / len(train_success_rates) if train_success_rates else 0\n",
    "    avg_test_success = sum(test_success_rates) / len(test_success_rates) if test_success_rates else 0\n",
    "    \n",
    "    # Count total grids tested\n",
    "    total_train_grids = sum(len(r[\"train_results\"]) for r in results)\n",
    "    total_test_grids = sum(len(r[\"test_results\"]) for r in results)\n",
    "    correct_train_grids = sum(sum(tr[\"correct\"] for tr in r[\"train_results\"]) for r in results)\n",
    "    correct_test_grids = sum(sum(tr[\"correct\"] for tr in r[\"test_results\"]) for r in results)\n",
    "    \n",
    "    print(f\"\\nüéØ OVERALL PERFORMANCE:\")\n",
    "    print(f\"   Examples tested: {total_examples}\")\n",
    "    print(f\"   Code executable: {examples_with_executable_code}/{total_examples} ({examples_with_executable_code/total_examples:.1%})\")\n",
    "    print(f\"   Examples with errors: {examples_with_errors}/{total_examples} ({examples_with_errors/total_examples:.1%})\")\n",
    "    \n",
    "    print(f\"\\nüìä TRAINING GRIDS PERFORMANCE:\")\n",
    "    print(f\"   Average success rate: {avg_train_success:.1%}\")\n",
    "    print(f\"   Perfect examples (100%): {perfect_train}/{total_examples} ({perfect_train/total_examples:.1%})\")\n",
    "    print(f\"   Partial examples (>0% <100%): {partial_train}/{total_examples} ({partial_train/total_examples:.1%})\")\n",
    "    print(f\"   Failed examples (0%): {failed_train}/{total_examples} ({failed_train/total_examples:.1%})\")\n",
    "    print(f\"   Grid-level accuracy: {correct_train_grids}/{total_train_grids} ({correct_train_grids/total_train_grids:.1%})\")\n",
    "    \n",
    "    print(f\"\\nüéØ TEST GRIDS PERFORMANCE:\")\n",
    "    print(f\"   Average success rate: {avg_test_success:.1%}\")\n",
    "    print(f\"   Perfect examples (100%): {perfect_test}/{total_examples} ({perfect_test/total_examples:.1%})\")\n",
    "    print(f\"   Partial examples (>0% <100%): {partial_test}/{total_examples} ({partial_test/total_examples:.1%})\")\n",
    "    print(f\"   Failed examples (0%): {failed_test}/{total_examples} ({failed_test/total_examples:.1%})\")\n",
    "    print(f\"   Grid-level accuracy: {correct_test_grids}/{total_test_grids} ({correct_test_grids/total_test_grids:.1%})\")\n",
    "    \n",
    "    # Detailed breakdown by example\n",
    "    print(f\"\\nüìã DETAILED BREAKDOWN BY EXAMPLE:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        task_id = result[\"task_id\"]\n",
    "        train_rate = result[\"train_success\"]\n",
    "        test_rate = result[\"test_success\"]\n",
    "        executed = \"‚úÖ\" if result[\"code_executed\"] else \"‚ùå\"\n",
    "        error_count = len(result[\"errors\"])\n",
    "        \n",
    "        print(f\"[{i+1:2d}] {task_id}\")\n",
    "        print(f\"     Train: {train_rate:5.1%} | Test: {test_rate:5.1%} | Executed: {executed} | Errors: {error_count}\")\n",
    "        \n",
    "        if result[\"errors\"] and len(result[\"errors\"]) <= 3:  # Show first few errors\n",
    "            for error in result[\"errors\"][:3]:\n",
    "                print(f\"     Error: {error}\")\n",
    "        elif len(result[\"errors\"]) > 3:\n",
    "            print(f\"     Errors: {result['errors'][0]} ... (+{len(result['errors'])-1} more)\")\n",
    "    \n",
    "    # Quality assessment\n",
    "    print(f\"\\nüîç DATASET QUALITY ASSESSMENT:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if avg_train_success > 0.9:\n",
    "        print(\"‚úÖ EXCELLENT: Ground-truth code performs very well on training examples\")\n",
    "    elif avg_train_success > 0.7:\n",
    "        print(\"‚úÖ GOOD: Ground-truth code performs well on training examples\")\n",
    "    elif avg_train_success > 0.5:\n",
    "        print(\"‚ö†Ô∏è  MODERATE: Ground-truth code has mixed performance on training examples\")\n",
    "    else:\n",
    "        print(\"‚ùå POOR: Ground-truth code has low performance on training examples\")\n",
    "    \n",
    "    if avg_test_success > 0.9:\n",
    "        print(\"‚úÖ EXCELLENT: Ground-truth code generalizes very well to test examples\")\n",
    "    elif avg_test_success > 0.7:\n",
    "        print(\"‚úÖ GOOD: Ground-truth code generalizes well to test examples\")\n",
    "    elif avg_test_success > 0.5:\n",
    "        print(\"‚ö†Ô∏è  MODERATE: Ground-truth code has mixed generalization to test examples\")\n",
    "    else:\n",
    "        print(\"‚ùå POOR: Ground-truth code has poor generalization to test examples\")\n",
    "    \n",
    "    if examples_with_executable_code == total_examples:\n",
    "        print(\"‚úÖ EXCELLENT: All ground-truth code is executable\")\n",
    "    elif examples_with_executable_code / total_examples > 0.9:\n",
    "        print(\"‚úÖ GOOD: Most ground-truth code is executable\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  ISSUE: Some ground-truth code is not executable\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        \"total_examples\": total_examples,\n",
    "        \"executable_rate\": examples_with_executable_code / total_examples,\n",
    "        \"avg_train_success\": avg_train_success,\n",
    "        \"avg_test_success\": avg_test_success,\n",
    "        \"perfect_train_rate\": perfect_train / total_examples,\n",
    "        \"perfect_test_rate\": perfect_test / total_examples,\n",
    "        \"train_grid_accuracy\": correct_train_grids / total_train_grids if total_train_grids > 0 else 0,\n",
    "        \"test_grid_accuracy\": correct_test_grids / total_test_grids if total_test_grids > 0 else 0\n",
    "    }\n",
    "\n",
    "# Analyze the results\n",
    "summary_stats = analyze_data_integrity_results(data_integrity_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç FAILING EXAMPLES SUMMARY:\n",
      "üéâ No failing examples found! All ground-truth code works perfectly.\n",
      "\n",
      "‚úÖ Pre-training data integrity tests complete!\n",
      "üìã Summary stats saved in 'summary_stats' variable\n",
      "üìä Detailed results saved in 'data_integrity_results' variable\n"
     ]
    }
   ],
   "source": [
    "# Note: Validation set typically doesn't have ground-truth programs, so we only test training set\n",
    "\n",
    "# Function to examine specific failing examples in detail\n",
    "def examine_failure(results, example_index):\n",
    "    \"\"\"Examine a specific failing example in detail.\"\"\"\n",
    "    if example_index >= len(results):\n",
    "        print(f\"‚ùå Invalid index {example_index}. Only {len(results)} examples available.\")\n",
    "        return\n",
    "    \n",
    "    result = results[example_index]\n",
    "    print(f\"\\nüîç DETAILED EXAMINATION: Example {example_index + 1}\")\n",
    "    print(f\"Task ID: {result['task_id']}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nüìù GROUND TRUTH CODE:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(result['code'])\n",
    "    \n",
    "    print(f\"\\nüìä EXECUTION SUMMARY:\")\n",
    "    print(f\"Code executed successfully: {result['code_executed']}\")\n",
    "    print(f\"Train success rate: {result['train_success']:.1%}\")\n",
    "    print(f\"Test success rate: {result['test_success']:.1%}\")\n",
    "    print(f\"Number of errors: {len(result['errors'])}\")\n",
    "    \n",
    "    if result['errors']:\n",
    "        print(f\"\\n‚ùå ERRORS:\")\n",
    "        for i, error in enumerate(result['errors']):\n",
    "            print(f\"  {i+1}. {error}\")\n",
    "\n",
    "# Check for failing examples\n",
    "failed_examples = [i for i, r in enumerate(data_integrity_results) \n",
    "                  if r['train_success'] < 1.0 or r['test_success'] < 1.0 or not r['code_executed']]\n",
    "\n",
    "print(f\"\\nüîç FAILING EXAMPLES SUMMARY:\")\n",
    "if failed_examples:\n",
    "    print(f\"Found {len(failed_examples)} examples with issues: {failed_examples}\")\n",
    "    print(\"To examine a specific failure, run: examine_failure(data_integrity_results, index)\")\n",
    "else:\n",
    "    print(\"üéâ No failing examples found! All ground-truth code works perfectly.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Pre-training data integrity tests complete!\")\n",
    "print(f\"üìã Summary stats saved in 'summary_stats' variable\")\n",
    "print(f\"üìä Detailed results saved in 'data_integrity_results' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç DETAILED EXAMINATION: Example 12\n",
      "Task ID: be94b721\n",
      "==================================================\n",
      "\n",
      "üìù GROUND TRUTH CODE:\n",
      "------------------------------\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    rows, cols = grid.shape\n",
      "    unique_elements = np.unique(grid)\n",
      "    if len(unique_elements) <= 1:\n",
      "        return grid.tolist()\n",
      "    counts = np.bincount(grid.flatten())\n",
      "    counts[0] = 0\n",
      "    most_frequent_element = np.argmax(counts)\n",
      "    non_zero_coords = np.argwhere(grid == most_frequent_element)\n",
      "    min_row, min_col = non_zero_coords.min(axis=0)\n",
      "    max_row, max_col = non_zero_coords.max(axis=0)\n",
      "    subgrid = grid[min_row:max_row + 1, min_col:max_col + 1]\n",
      "    return subgrid.tolist()\n",
      "\n",
      "üìä EXECUTION SUMMARY:\n",
      "Code executed successfully: True\n",
      "Train success rate: 100.0%\n",
      "Test success rate: 100.0%\n",
      "Number of errors: 0\n"
     ]
    }
   ],
   "source": [
    "examine_failure(data_integrity_results, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Training Setup\n",
    "Now we'll set up the trainer and then validate all evaluation components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(help(model.fast_generate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract training set date and time as dataset identifiers\n",
      "Date: 20250729 (YYYYMMDD)\n",
      "Time: 114431 (HHMMSS)\n",
      "Run name will be Qwen3-4B-ds20250729_114431-20250801-141514\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Extract date and time using regex\n",
    "print(\"Extract training set date and time as dataset identifiers\")\n",
    "\n",
    "# Try pattern 1: timestamp at end (original pattern)\n",
    "match = re.search(r'(\\d{8}_\\d{6})$', train_slug)\n",
    "if match:\n",
    "    timestamp = match.group(1)\n",
    "    date_str = timestamp[:8]\n",
    "    time_str = timestamp[9:]\n",
    "    print(f\"Date: {date_str} (YYYYMMDD)\")\n",
    "    print(f\"Time: {time_str} (HHMMSS)\")\n",
    "else:\n",
    "    # Try pattern 2: SOAR dataset format (soar-YYYYMMDD_HHMMSS-rows)\n",
    "    match = re.search(r'soar-(\\d{8}_\\d{6})-\\d+', train_slug)\n",
    "    if match:\n",
    "        timestamp = match.group(1)\n",
    "        date_str = timestamp[:8]\n",
    "        time_str = timestamp[9:]\n",
    "        print(f\"Date: {date_str} (YYYYMMDD)\")\n",
    "        print(f\"Time: {time_str} (HHMMSS)\")\n",
    "    else:\n",
    "        print(\"No timestamp found.\")\n",
    "        date_str = \"unknown\"\n",
    "        time_str = \"unknown\"\n",
    "\n",
    "run_name = f\"{model_slug.split('/')[-1]}-ds{date_str}_{time_str}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "print(f\"Run name will be {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Legacy code extraction imports - now using utils.prompt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, subprocess, os, gc, time\n",
    "\n",
    "def _print_gpu(prefix=\"\"):\n",
    "    alloc = torch.cuda.memory_allocated() / 2**20  # MiB\n",
    "    reserved = torch.cuda.memory_reserved() / 2**20\n",
    "    print(f\"{prefix}CUDA‚Äëalloc={alloc:.0f} MiB | reserved={reserved:.0f} MiB\")\n",
    "\n",
    "def _nvidia_smi():\n",
    "    try:\n",
    "        smi = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=memory.used,memory.free\",\n",
    "             \"--format=csv,noheader,nounits\"]).decode().strip()\n",
    "        print(\"nvidia-smi (used/free MiB):\", smi)\n",
    "    except Exception:\n",
    "        pass  # nvidia-smi not always available\n",
    "\n",
    "\n",
    "TEMPLATES = {\n",
    "    \"llama\": (\n",
    "        \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "    ),\n",
    "    \"gemma\": (\n",
    "        \"<start_of_turn>user\\n\",\n",
    "        \"<start_of_turn>model\\n\",\n",
    "    ),\n",
    "    \"qwen-coder\": (\n",
    "        \"<|im_start|>user\\n\",\n",
    "        \"<|im_start|>assistant\\n\", # this is actually how you properly allow the model to keep reasoning!\n",
    "    ),\n",
    "    \"qwen\": (\n",
    "        \"<|im_start|>user\\n\",\n",
    "        \"<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\", # this is actually how you properly allow the model to keep reasoning!\n",
    "    ),\n",
    "    \"mistral\": (\n",
    "        \"[INST]\",\n",
    "        \"[/INST]\",\n",
    "    )\n",
    "}\n",
    "\n",
    "# instruction_tag, response_tag = TEMPLATES[\"qwen-coder\"]   # ‚Üê change if needed and comment out below\n",
    "\n",
    "model_slug_lower = model_slug.lower()\n",
    "\n",
    "if \"qwen\" in model_slug_lower:\n",
    "    if \"coder\" in model_slug_lower:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen-coder\"]\n",
    "    elif \"soar-qwen\" in model_slug_lower:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen-coder\"]\n",
    "    else:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen\"]\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model slug for Qwen template: {model_slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response tag selected: <|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Response tag selected: {response_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VllmMemoryCallback removed - not compatible with vLLM training setup\n",
    "# Smaller batch size support\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from vllm import SamplingParams\n",
    "\n",
    "MAX_NEW_TOKENS = 1000  # one place to tune\n",
    "\n",
    "class VllmSFTTrainer(SFTTrainer):\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only=False, ignore_keys=None):\n",
    "        print(f\"[vLLM predict] batch size = {inputs['input_ids'].shape[0]}, generating {NUM_EVAL_ATTEMPTS} attempts per task\")\n",
    "        ids = inputs[\"input_ids\"].to(self.args.device)\n",
    "\n",
    "        # 1) Find prompts up to response_part\n",
    "        response_tag_ids = self.tokenizer(response_tag, add_special_tokens=False)[\"input_ids\"]\n",
    "        def _find_sublist(lst, sublst):\n",
    "            L, M = len(lst), len(sublst)\n",
    "            for i in range(L - M + 1):\n",
    "                if lst[i : i + M] == sublst:\n",
    "                    return i\n",
    "            raise ValueError\n",
    "\n",
    "        prompts = []\n",
    "        for batch_idx, row in enumerate(ids):\n",
    "            row_ids = row.tolist()\n",
    "            try:\n",
    "                start = _find_sublist(row_ids, response_tag_ids)\n",
    "                cut   = start + len(response_tag_ids)\n",
    "            except ValueError:\n",
    "                cut = len(row_ids)\n",
    "            text = self.tokenizer.decode(\n",
    "                row_ids[:cut],\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True\n",
    "            ).strip()\n",
    "            if not text:\n",
    "                print(f\"[prompt‚Äëdbg] row {batch_idx}: empty ‚Üí using response_part only\")\n",
    "                text = response_tag\n",
    "            prompts.append(text)\n",
    "\n",
    "        # 2) Generate NUM_EVAL_ATTEMPTS responses per prompt with multi-attempt sampling\n",
    "        # Use same parameters as compute_arc_metrics for consistency\n",
    "        params = SamplingParams(temperature=1.0, min_p=0.05, max_tokens=MAX_NEW_TOKENS)\n",
    "        \n",
    "        all_gen_seqs = []\n",
    "        for attempt in range(NUM_EVAL_ATTEMPTS):\n",
    "            with torch.no_grad():\n",
    "                outs = model.fast_generate(prompts, sampling_params=params)\n",
    "            \n",
    "            # Convert each output to a 1D LongTensor\n",
    "            gen_seqs = [\n",
    "                torch.tensor(o.outputs[0].token_ids, dtype=torch.long)\n",
    "                for o in outs\n",
    "            ]\n",
    "            all_gen_seqs.extend(gen_seqs)\n",
    "\n",
    "        # 3) Manually pad or truncate *every* sequence to EXACTLY MAX_NEW_TOKENS\n",
    "        pad_id = self.tokenizer.pad_token_id\n",
    "        total_sequences = len(all_gen_seqs)  # batch_size * NUM_EVAL_ATTEMPTS\n",
    "        \n",
    "        # allocate [total_sequences, MAX_NEW_TOKENS] filled with pad_id\n",
    "        fixed = all_gen_seqs[0].new_full((total_sequences, MAX_NEW_TOKENS), pad_id)\n",
    "        for i, seq in enumerate(all_gen_seqs):\n",
    "            length = min(seq.size(0), MAX_NEW_TOKENS)\n",
    "            fixed[i, :length] = seq[:length]\n",
    "\n",
    "        gen_ids = fixed.cpu()  # shape = [batch_size * NUM_EVAL_ATTEMPTS, MAX_NEW_TOKENS]\n",
    "\n",
    "        # 4) Return in HF‚ÄìTrainer's expected format\n",
    "        # Note: compute_metrics will need to handle the expanded batch size\n",
    "        return (None, gen_ids, inputs.get(\"labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False           # ‚Üê flip this or pass debug=True below\n",
    "NUM_EVAL_ATTEMPTS = 8   # Number of attempts per task during evaluation\n",
    "\n",
    "def compute_arc_metrics(eval_pred, *, debug: bool = DEBUG):\n",
    "    \"\"\"\n",
    "    Multi-attempt evaluation with predictions from VllmSFTTrainer:\n",
    "    ‚Ä¢ Uses NUM_EVAL_ATTEMPTS predictions per task from prediction_step\n",
    "    ‚Ä¢ Supports any number of test grids per task\n",
    "    ‚Ä¢ Uses voting/best-attempt metrics across multiple attempts\n",
    "    ‚Ä¢ Tracks comprehensive metrics like run_arc_tasks_soar.py\n",
    "    \"\"\"\n",
    "    print(f\"üéØ MULTI-ATTEMPT EVALUATION: {NUM_EVAL_ATTEMPTS} attempts per task from trainer prediction_step\")\n",
    "    \n",
    "    preds, _ = eval_pred\n",
    "    \n",
    "    # preds now contains NUM_EVAL_ATTEMPTS responses per task\n",
    "    total_predictions = preds.shape[0]\n",
    "    num_tasks = total_predictions // NUM_EVAL_ATTEMPTS\n",
    "    raw_dataset = trainer.eval_dataset\n",
    "\n",
    "    print(f\"üìä Processing {total_predictions} predictions for {num_tasks} tasks ({NUM_EVAL_ATTEMPTS} attempts each)\")\n",
    "\n",
    "    # --- Convert \"column-dict\" ‚Üí \"list of row-dicts\" when needed ----\n",
    "    if isinstance(raw_dataset, dict):\n",
    "        n = len(next(iter(raw_dataset.values())))\n",
    "        raw_dataset = [{k: v[i] for k, v in raw_dataset.items()} for i in range(n)]\n",
    "\n",
    "    scorer = GridScorer()\n",
    "    executor = ProgramExecutor(timeout=0.5, executor_type=\"unrestricted\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for task_idx in range(num_tasks):\n",
    "        ex = raw_dataset[task_idx]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n=== ARC task {task_idx} - processing {NUM_EVAL_ATTEMPTS} pre-generated attempts ===\")\n",
    "        \n",
    "        # Get all attempts for this task\n",
    "        start_idx = task_idx * NUM_EVAL_ATTEMPTS\n",
    "        end_idx = start_idx + NUM_EVAL_ATTEMPTS\n",
    "        task_predictions = preds[start_idx:end_idx]\n",
    "        \n",
    "        # Create task data in the format expected by calculate_task_metrics\n",
    "        task_data = {\n",
    "            \"task_id\": ex.get(\"task_id\", f\"task_{task_idx}\"),\n",
    "            \"train\": [\n",
    "                {\"input\": inp, \"output\": out} \n",
    "                for inp, out in zip(ex[\"train_input\"], ex[\"train_output\"])\n",
    "            ],\n",
    "            \"test\": [\n",
    "                {\"input\": inp, \"output\": out} \n",
    "                for inp, out in zip(ex[\"test_input\"], ex[\"test_output\"])\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        attempt_details = []\n",
    "        \n",
    "        for attempt_num in range(NUM_EVAL_ATTEMPTS):\n",
    "            pred_tokens = task_predictions[attempt_num]\n",
    "            \n",
    "            # Decode the prediction\n",
    "            try:\n",
    "                # Remove padding tokens\n",
    "                non_pad_mask = pred_tokens != tokenizer.pad_token_id\n",
    "                if non_pad_mask.any():\n",
    "                    clean_tokens = pred_tokens[non_pad_mask]\n",
    "                    generated_text = tokenizer.decode(clean_tokens, skip_special_tokens=True)\n",
    "                else:\n",
    "                    generated_text = \"\"\n",
    "                \n",
    "                # Extract and evaluate code\n",
    "                code = extract_python_code(generated_text)\n",
    "                program_extracted = bool(code and code.strip())\n",
    "                \n",
    "                # DEBUG: Check what we're actually generating\n",
    "                if debug or task_idx < 2:  # Always debug first 2 tasks\n",
    "                    print(f\"    Attempt {attempt_num}: Generated text preview: {generated_text[:200]}...\")\n",
    "                    print(f\"    Extracted code: {code[:100] if code else 'None'}...\")\n",
    "                    print(f\"    Program extracted: {program_extracted}\")\n",
    "                \n",
    "                # Initialize attempt tracking\n",
    "                train_results = []\n",
    "                test_results = []\n",
    "                test_predictions = []\n",
    "                any_timeout = False\n",
    "                code_ran = False\n",
    "                \n",
    "                # Evaluate on training examples\n",
    "                train_correct_count = 0\n",
    "                for tr_in, tr_out in zip(ex[\"train_input\"], ex[\"train_output\"]):\n",
    "                \n",
    "                    if program_extracted:\n",
    "                        pred, err, timed_out = executor.execute_program_with_timeout(code, tr_in)\n",
    "                        code_ran |= (err == \"\")\n",
    "                    else:\n",
    "                        pred, err, timed_out = None, \"no program\", False\n",
    "                \n",
    "                    any_timeout |= timed_out\n",
    "                \n",
    "                    is_correct = (\n",
    "                        pred is not None and\n",
    "                        scorer.score_grid(pred, tr_out)[\"correct\"]   # <-- Boolean!\n",
    "                    )\n",
    "                \n",
    "                    if is_correct:\n",
    "                        train_correct_count += 1\n",
    "                \n",
    "                    train_results.append(\n",
    "                        {\n",
    "                            \"correct\":    is_correct,   # MUST be a bool\n",
    "                            \"prediction\": pred,\n",
    "                            \"error\":      err,\n",
    "                            \"timeout\":    timed_out,\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                # Evaluate on test examples  \n",
    "                # ---------- TEST loop ----------\n",
    "                test_correct_count = 0\n",
    "                test_predictions   = []\n",
    "                \n",
    "                for te_in, te_out in zip(ex[\"test_input\"], ex[\"test_output\"]):\n",
    "                \n",
    "                    if program_extracted:\n",
    "                        pred, err, timed_out = executor.execute_program_with_timeout(code, te_in)\n",
    "                        code_ran |= (err == \"\")\n",
    "                    else:\n",
    "                        pred, err, timed_out = None, \"no program\", False\n",
    "                \n",
    "                    any_timeout |= timed_out\n",
    "                    test_predictions.append(pred)\n",
    "                \n",
    "                    is_correct = (\n",
    "                        pred is not None and\n",
    "                        scorer.score_grid(pred, te_out)[\"correct\"]\n",
    "                    )\n",
    "                \n",
    "                    if is_correct:\n",
    "                        test_correct_count += 1\n",
    "                \n",
    "                    test_results.append(\n",
    "                        {\n",
    "                            \"correct\":    is_correct,\n",
    "                            \"prediction\": pred,\n",
    "                            \"error\":      err,\n",
    "                            \"timeout\":    timed_out,\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                # Check for transduction before creating attempt detail\n",
    "                if program_extracted and code:\n",
    "                    from utils.transduction import is_transduction_cheating\n",
    "                    is_cheat, _ = is_transduction_cheating(code, task_data)\n",
    "                else:\n",
    "                    is_cheat = False  # No program means not transductive\n",
    "                \n",
    "                # Create attempt detail\n",
    "                attempt_detail = {\n",
    "                    \"task_id\": ex.get(\"task_id\", f\"task_{task_idx}\"),\n",
    "                    \"attempt\": attempt_num,\n",
    "                    \"program\": code,\n",
    "                    \"program_extracted\": program_extracted,\n",
    "                    \"code_ran\": code_ran,\n",
    "                    \"train_results\": train_results,\n",
    "                    \"test_results\": test_results, \n",
    "                    \"test_predicted\": test_predictions[0] if test_predictions else None,  # Single prediction, not list\n",
    "                    \"all_train_correct\": train_correct_count == len(ex[\"train_input\"]),\n",
    "                    \"all_test_correct\": test_correct_count == len(ex[\"test_input\"]),\n",
    "                    \"any_timeout\": any_timeout,\n",
    "                    \"max_length\": len(clean_tokens) >= MAX_NEW_TOKENS - 10,  # Near max length\n",
    "                    \"response_text\": generated_text[:200] + \"...\" if len(generated_text) > 200 else generated_text,\n",
    "                    \"train_accuracy\":  train_correct_count / len(ex[\"train_input\"]),\n",
    "                    \"is_transductive\": is_cheat,                              # <- prevent re-calculation\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(f\"  Task {task_idx}, attempt {attempt_num} failed: {e}\")\n",
    "                \n",
    "                # Create failed attempt\n",
    "                attempt_detail = {\n",
    "                    \"task_id\": ex.get(\"task_id\", f\"task_{task_idx}\"),\n",
    "                    \"attempt\": attempt_num,\n",
    "                    \"program\": \"\",\n",
    "                    \"program_extracted\": False,\n",
    "                    \"code_ran\": False,\n",
    "                    \"train_results\": [\n",
    "                        {\"correct\": False, \"prediction\": None, \"error\": str(e), \"timeout\": False}\n",
    "                        for _ in ex[\"train_input\"]\n",
    "                    ],\n",
    "                    \"test_results\": [\n",
    "                        {\"correct\": False, \"prediction\": None, \"error\": str(e), \"timeout\": False}\n",
    "                        for _ in ex[\"test_input\"]\n",
    "                    ],\n",
    "                    \"test_predictions\": [None for _ in ex[\"test_input\"]],\n",
    "                    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ add the two fields that voting_utils expects ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                    \"test_predicted\":  [None for _ in ex[\"test_input\"]],  # <- alias\n",
    "                    \"train_accuracy\":  0.0,                               # <- weight = 1.0\n",
    "                    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                    \"all_train_correct\": False,\n",
    "                    \"all_test_correct\":  False,\n",
    "                    \"any_timeout\":       False,\n",
    "                    \"max_length\":        False,\n",
    "                    \"response_text\":     f\"Error: {e}\",\n",
    "                    \"is_transductive\":   False,                           # <- failed attempts are not transductive\n",
    "                }\n",
    "            \n",
    "            attempt_details.append(attempt_detail)\n",
    "        \n",
    "        # Create task result\n",
    "        task_result = {\"task_data\": task_data, \"attempt_details\": attempt_details}\n",
    "        results.append(task_result)\n",
    "        \n",
    "        if debug:\n",
    "            successful_attempts = sum(1 for att in attempt_details if att[\"all_test_correct\"])\n",
    "            code_success_attempts = sum(1 for att in attempt_details if att[\"code_ran\"])\n",
    "            \n",
    "            # DEBUG: Show train accuracies for each attempt\n",
    "            train_accs = [att[\"train_accuracy\"] for att in attempt_details]\n",
    "            train_acc_summary = f\"train_accs=[{', '.join(f'{acc:.2f}' for acc in train_accs)}]\"\n",
    "            \n",
    "            print(f\"  Task {task_idx} summary: {successful_attempts}/{NUM_EVAL_ATTEMPTS} test-correct, {code_success_attempts}/{NUM_EVAL_ATTEMPTS} code-ran\")\n",
    "            print(f\"  Train accuracies: {train_acc_summary}\")\n",
    "\n",
    "    # -------------- AGGREGATE METRICS (using same logic as run_arc_tasks_soar.py) ------\n",
    "    print(\"\\nüîç DEBUG: Checking data structure for voting...\")\n",
    "    for i, result in enumerate(results[:1]):  # Just check first task\n",
    "        print(f\"\\nTask {i}:\")\n",
    "        print(f\"  task_data keys: {result['task_data'].keys()}\")\n",
    "        print(f\"  num attempts: {len(result['attempt_details'])}\")\n",
    "        \n",
    "        for j, att in enumerate(result['attempt_details'][:2]):  # First 2 attempts\n",
    "            print(f\"  Attempt {j}:\")\n",
    "            print(f\"    Keys: {list(att.keys())}\")\n",
    "            print(f\"    all_test_correct: {att.get('all_test_correct')}\")\n",
    "            print(f\"    all_train_correct: {att.get('all_train_correct')}\")\n",
    "            print(f\"    program_extracted: {att.get('program_extracted')}\")\n",
    "            print(f\"    code_ran: {att.get('code_ran')}\")\n",
    "            if att.get('test_results'):\n",
    "                print(f\"    test_results sample: {att['test_results'][0]}\")\n",
    "    \n",
    "    # DEBUG: Check what predictions look like for voting\n",
    "    print(\"\\nüîç VOTING DEBUG: Checking correct predictions for voting compatibility...\")\n",
    "    for i, result in enumerate(results[:1]):  # Just check first task  \n",
    "        correct_attempts = [att for att in result['attempt_details'] if att.get('all_test_correct')]\n",
    "        print(f\"\\nTask {i}: {len(correct_attempts)} correct attempts out of {len(result['attempt_details'])}\")\n",
    "        \n",
    "        if correct_attempts:\n",
    "            from utils.voting_utils import serialize_prediction_for_voting\n",
    "            print(f\"  Correct predictions for voting:\")\n",
    "            for j, att in enumerate(correct_attempts):\n",
    "                pred = att.get('test_predicted')\n",
    "                serialized = serialize_prediction_for_voting(pred)\n",
    "                print(f\"    Attempt {j}: type={type(pred)}, value={pred}\")\n",
    "                print(f\"    Serialized key: {serialized[:150]}...\")  # First 150 chars\n",
    "            \n",
    "            # Check if serialized keys are identical\n",
    "            serialized_keys = [serialize_prediction_for_voting(att.get('test_predicted')) for att in correct_attempts]\n",
    "            unique_keys = set(serialized_keys)\n",
    "            print(f\"  Unique serialized keys: {len(unique_keys)} (should be 1 for voting to work)\")\n",
    "            if len(unique_keys) > 1:\n",
    "                print(f\"  ‚ùå VOTING ISSUE: Different serialized keys for same task!\")\n",
    "                for k, key in enumerate(unique_keys):\n",
    "                    print(f\"    Key {k}: {key[:100]}...\")\n",
    "            \n",
    "            # DEBUG: Test voting functions directly\n",
    "            print(f\"\\n  üó≥Ô∏è  VOTING FUNCTION TESTS:\")\n",
    "            from utils.voting_utils import compute_weighted_majority_voting, compute_train_majority_voting\n",
    "            from utils.voting_utils import filter_non_transductive_attempts\n",
    "            \n",
    "            # Filter non-transductive attempts (as metrics_utils does)\n",
    "            non_trans = filter_non_transductive_attempts(result)\n",
    "            print(f\"    Non-transductive attempts: {len(non_trans)}/{len(result['attempt_details'])}\")\n",
    "            \n",
    "            if non_trans:\n",
    "                # Test weighted voting\n",
    "                weighted_results = compute_weighted_majority_voting(non_trans, top_k=2)\n",
    "                print(f\"    Weighted voting returned: {len(weighted_results)} predictions\")\n",
    "                if weighted_results:\n",
    "                    print(f\"    Weighted top prediction: {weighted_results[0]}\")\n",
    "                \n",
    "                # Test train majority voting  \n",
    "                train_maj_results = compute_train_majority_voting(non_trans, top_k=2)\n",
    "                print(f\"    Train majority voting returned: {len(train_maj_results)} predictions\")\n",
    "                if train_maj_results:\n",
    "                    print(f\"    Train majority top prediction: {train_maj_results[0]}\")\n",
    "                \n",
    "                # Show ground truth for comparison\n",
    "                gt = tuple(t[\"output\"] for t in result[\"task_data\"][\"test\"])\n",
    "                print(f\"    Ground truth: {gt}\")\n",
    "                \n",
    "                # Show how comparison works\n",
    "                if weighted_results:\n",
    "                    from utils.metrics_utils import _to_tuple\n",
    "                    # Handle both single test (raw grid) and multi-test (tuple of grids) cases\n",
    "                    for j, pred in enumerate(weighted_results):\n",
    "                        if pred is None:\n",
    "                            continue\n",
    "                        # If it's already a tuple (multi-test), keep as is\n",
    "                        # If it's a single grid, convert to tuple to match gt format\n",
    "                        if len(gt) == 1:\n",
    "                            # Single test case: pred should be raw grid, wrap in tuple\n",
    "                            normalized_pred = _to_tuple([pred])\n",
    "                        else:\n",
    "                            # Multi test case: pred should already be tuple\n",
    "                            normalized_pred = _to_tuple(pred)\n",
    "                        \n",
    "                        matches = (normalized_pred == gt)\n",
    "                        print(f\"    Weighted pred {j}: {normalized_pred} == {gt} ? {matches}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"    ‚ùå No non-transductive attempts to vote on!\")\n",
    "    \n",
    "    # DEBUG: Check transduction filtering before calling calculate_task_metrics\n",
    "    print(\"\\nüîç DEBUG: Checking transduction filtering...\")\n",
    "    for i, result in enumerate(results[:2]):  # Check first 2 tasks\n",
    "        attempts = result[\"attempt_details\"]\n",
    "        print(f\"\\nTask {i}: {len(attempts)} total attempts\")\n",
    "        \n",
    "        # Check if attempts have is_transductive flag\n",
    "        has_flag = any('is_transductive' in att for att in attempts)\n",
    "        print(f\"  Has is_transductive flag: {has_flag}\")\n",
    "        \n",
    "        # Test transduction filtering\n",
    "        from utils.voting_utils import filter_non_transductive_attempts\n",
    "        non_trans = filter_non_transductive_attempts(result)\n",
    "        print(f\"  Non-transductive attempts: {len(non_trans)}/{len(attempts)}\")\n",
    "        \n",
    "        if len(non_trans) == 0 and len(attempts) > 0:\n",
    "            print(\"  ‚ö†Ô∏è  All attempts filtered out! Testing transduction detection...\")\n",
    "            from utils.transduction import is_transduction_cheating\n",
    "            for j, att in enumerate(attempts[:3]):  # Check first 3 attempts\n",
    "                if att.get('program'):\n",
    "                    is_cheat, reason = is_transduction_cheating(att['program'], result['task_data'], debug=True)\n",
    "                    print(f\"    Attempt {j}: is_transductive={is_cheat}, reason='{reason}'\")\n",
    "                    if is_cheat:\n",
    "                        print(f\"    Program preview: {att['program'][:200]}...\")\n",
    "\n",
    "    metrics = calculate_task_metrics(results, max_tokens=MAX_NEW_TOKENS)\n",
    "    \n",
    "    tot = max(1, metrics[\"total\"])\n",
    "    tresp = max(1, metrics[\"total_responses\"])\n",
    "\n",
    "    # Return metrics compatible with trainer expectations  \n",
    "    final_metrics = {\n",
    "        \"all_test_correct\": metrics[\"all_test_correct\"] / tot,           # Oracle (best attempt)\n",
    "        \"all_train_correct\": metrics[\"all_train_correct\"] / tot,         # Perfect train performance\n",
    "        \"min1_train_correct\": metrics[\"min1_train_correct\"] / tot,       # At least some train success\n",
    "        \"min1_code_success\": metrics[\"min1_code_success\"] / tot,         # At least one working program\n",
    "        \"weighted_voting_pass2\": metrics.get(\"weighted_pass2\", 0) / tot,    # Voting metrics\n",
    "        \"train_majority_pass2\": metrics.get(\"train_majority_pass2\", 0) / tot,      # Train majority voting\n",
    "        \"max_length_rate\": metrics[\"max_length_responses\"] / tresp,      # Max length hit rate\n",
    "        \"timeout_rate\": metrics[\"timeout_responses\"] / tresp,            # Timeout rate\n",
    "        \"total_tasks\": tot,\n",
    "        \"total_responses\": tresp,\n",
    "        \"total_attempts\": tot * NUM_EVAL_ATTEMPTS,\n",
    "    }\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nüéØ FINAL MULTI-ATTEMPT METRICS:\")\n",
    "        for k, v in final_metrics.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    \n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94185a12ad84dc699fa63b8d0f2118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f30eec6807468b94d55e2b6dbc78d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update the trainer configuration to use the fixed custom metrics\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# make sure the attr exists so Unsloth can safely delete it\n",
    "setattr(model, \"_flag_for_generation\", True)\n",
    "\n",
    "trainer = VllmSFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"validation\"],\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size = batch_size_global,\n",
    "        per_device_eval_batch_size = len(data[\"validation\"]),\n",
    "        # per_device_eval_batch_size = batch_size_global,\n",
    "        gradient_accumulation_steps=int(32 / batch_size_global),\n",
    "        warmup_steps=5,\n",
    "        eval_steps=0.1,\n",
    "        do_eval=True,\n",
    "        eval_strategy=\"steps\",\n",
    "        num_train_epochs=3,\n",
    "        # max_steps=3,\n",
    "        learning_rate=1e-4,\n",
    "        logging_steps=0.05,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"constant\",\n",
    "        seed=3407,\n",
    "        report_to=\"tensorboard\",\n",
    "        logging_dir=f\"./logs/{run_name}\",\n",
    "        remove_unused_columns=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.2,\n",
    "        save_total_limit=3,\n",
    "        prediction_loss_only=False\n",
    "    ),\n",
    "    compute_metrics=compute_arc_metrics,\n",
    "    # callbacks=[VllmMemoryCallback()], # best not to mess with vllm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Evaluation Metrics and Functions Testing\n",
    "Now that the trainer is set up, let's test all evaluation components to ensure they work correctly with the actual training setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING EVALUATION METRICS AND FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "üìã Running existing tests from utils/tests...\n",
      "\n",
      "üêç Testing extract_python_code (from utils/tests)...\n",
      "  ‚úÖ extract_python_code tests - PASSED\n",
      "\n",
      "üìà Testing calculate_task_metrics (from utils/tests)...\n",
      "  ‚úÖ calculate_task_metrics tests - PASSED\n",
      "\n",
      "üìä Testing GridScorer (basic validation)...\n",
      "  ‚úÖ GridScorer basic tests - PASSED\n",
      "\n",
      "‚öôÔ∏è Testing ProgramExecutor (basic validation)...\n",
      "  ‚úÖ ProgramExecutor basic tests - PASSED\n"
     ]
    }
   ],
   "source": [
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "# Import existing tests from utils/tests instead of duplicating logic\n",
    "# Note: Assumes we're running from the llm_python directory structure\n",
    "\n",
    "# Test Configuration\n",
    "print(\"üß™ TESTING EVALUATION METRICS AND FUNCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def run_existing_tests():\n",
    "    \"\"\"Run existing tests from utils/tests to validate core functionality\"\"\"\n",
    "    print(\"\\nüìã Running existing tests from utils/tests...\")\n",
    "    \n",
    "    test_results = {}\n",
    "    \n",
    "    # Test extract_python_code using existing tests\n",
    "    print(\"\\nüêç Testing extract_python_code (from utils/tests)...\")\n",
    "    try:\n",
    "        from utils.tests.test_prompt_utils import TestPromptUtils\n",
    "        import unittest\n",
    "        \n",
    "        # Create test suite and run extract_python_code tests\n",
    "        suite = unittest.TestLoader().loadTestsFromTestCase(TestPromptUtils)\n",
    "        # Suppress test output by redirecting to null device\n",
    "        import os\n",
    "        result = unittest.TextTestRunner(stream=open(os.devnull, 'w')).run(suite)\n",
    "        \n",
    "        if result.wasSuccessful():\n",
    "            print(\"  ‚úÖ extract_python_code tests - PASSED\")\n",
    "            test_results['extract_python_code'] = True\n",
    "        else:\n",
    "            print(\"  ‚ùå extract_python_code tests - FAILED\")\n",
    "            print(f\"     Failures: {len(result.failures)}, Errors: {len(result.errors)}\")\n",
    "            test_results['extract_python_code'] = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå extract_python_code tests - ERROR: {e}\")\n",
    "        test_results['extract_python_code'] = False\n",
    "    \n",
    "    # Test calculate_task_metrics using existing tests\n",
    "    print(\"\\nüìà Testing calculate_task_metrics (from utils/tests)...\")\n",
    "    try:\n",
    "        from utils.tests.test_metrics_voting_integration import TestMetricsVotingIntegration\n",
    "        \n",
    "        # Run a specific test to validate metrics calculation\n",
    "        test_instance = TestMetricsVotingIntegration()\n",
    "        test_instance.test_single_test_case_voting_success()\n",
    "        test_instance.test_edge_cases()\n",
    "        \n",
    "        print(\"  ‚úÖ calculate_task_metrics tests - PASSED\")\n",
    "        test_results['calculate_task_metrics'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå calculate_task_metrics tests - ERROR: {e}\")\n",
    "        test_results['calculate_task_metrics'] = False\n",
    "    \n",
    "    # Test basic grid scoring logic (simple inline test since no dedicated test exists)\n",
    "    print(\"\\nüìä Testing GridScorer (basic validation)...\")\n",
    "    try:\n",
    "        scorer = GridScorer()\n",
    "        \n",
    "        # Test perfect match\n",
    "        result1 = scorer.score_grid([[1, 2], [3, 4]], [[1, 2], [3, 4]])\n",
    "        assert result1[\"correct\"] == True, \"Perfect match should be correct\"\n",
    "        \n",
    "        # Test mismatch\n",
    "        result2 = scorer.score_grid([[1, 2], [3, 4]], [[1, 2], [3, 5]])\n",
    "        assert result2[\"correct\"] == False, \"Mismatch should be incorrect\"\n",
    "        \n",
    "        print(\"  ‚úÖ GridScorer basic tests - PASSED\")\n",
    "        test_results['grid_scorer'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå GridScorer basic tests - ERROR: {e}\")\n",
    "        test_results['grid_scorer'] = False\n",
    "    \n",
    "    # Test basic program execution (simple inline test)\n",
    "    print(\"\\n‚öôÔ∏è Testing ProgramExecutor (basic validation)...\")\n",
    "    try:\n",
    "        executor = ProgramExecutor(timeout=1.0, executor_type=\"unrestricted\")\n",
    "        \n",
    "        # Test working code\n",
    "        working_code = \"def transform(grid): return [[c+1 for c in r] for r in grid]\"\n",
    "        result, error, timed_out = executor.execute_program_with_timeout(working_code, [[1, 2]])\n",
    "        assert result == [[2, 3]], f\"Expected [[2, 3]], got {result}\"\n",
    "        \n",
    "        # Test broken code\n",
    "        broken_code = \"def transform(grid): return grid[999]\"  # Index error\n",
    "        result, error, timed_out = executor.execute_program_with_timeout(broken_code, [[1, 2]])\n",
    "        assert result is None, \"Broken code should return None\"\n",
    "        \n",
    "        print(\"  ‚úÖ ProgramExecutor basic tests - PASSED\")\n",
    "        test_results['program_executor'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå ProgramExecutor basic tests - ERROR: {e}\")\n",
    "        test_results['program_executor'] = False\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Run the existing tests\n",
    "existing_test_results = run_existing_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "\n",
      "üîß Testing trainer integration...\n",
      "  ‚úÖ Trainer integration - PASSED\n",
      "     Eval dataset size: 32\n",
      "     Tokenizer vocab size: 151669\n",
      "\n",
      "üéØ Testing MULTI-ATTEMPT compute_arc_metrics with REAL trainer data...\n",
      "üîç DEBUG: Checking eval dataset structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Available keys: ['reasoning', 'code', 'correct_train_input', 'train_input', 'train_output', 'predicted_train_output', 'correct_test_input', 'test_input', 'test_output', 'predicted_test_output', 'task_id', 'model', 'generation', 'messages', 'text', 'prompt', 'input_ids', 'attention_mask']\n",
      "  Converted 32 examples to list\n",
      "  Actually generating 8 attempts per task using the model...\n",
      "  Input shape: torch.Size([32, 15051])\n",
      "  Calling VllmSFTTrainer.prediction_step...\n",
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084daea8e7ab485086b94eda0b4421e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca164cec66cc434888608e43daf31062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfadceafb034eadbbbbd07f7f77ad1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289bc6bedb6148cebac7ccc16ab8f678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04492bfc9b8a4f5098e08888e523ed6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80d1ad5ff6f428992a7437088bf19fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51148297fd74d1cbcb81be88ac810cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d0c72598a24f57a9b70f00b40f0164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f07a981edfe40a792a8933cda76d537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5793831cdd45f2a5e402ec4840a848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffad0ad32bc04d84842481a7711a944c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4538ee5cc80c429e89560f7fd822f12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c45fce6fb4b45be9d68ae74d92a14ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b268164aba6543468ab1f90be5a5bb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0aa7146ddc34b4a87cb881caacf89c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e04c0b5b237454bba7d73e9ee4dcb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generated predictions shape: torch.Size([256, 1000])\n",
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "\n",
      "=== ARC task 0 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input grid size\n",
      "    # For 2x2 input, the output is 6x6, so the scaling factor is 3\n",
      "    scale = 3\n",
      "    rows, cols =...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input grid size\n",
      "    # For...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transformation rule: Replace 8 with 2, 0 with 0, 1 with 0, 3 with 3, 7 with 7, 2 with 2, 4 with 4, 5 with 5, 6 with 6, 9 with 9\n",
      "    # The transformation seems to...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transformation rule: Replace 8 with 2, 0 with 0, 1 with 0, 3 with 3, 7 wi...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 2:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 0:\n",
      "                n...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation involves replacing certain values based on patterns observed in the input-output pairs.\n",
      "    # The transformation is complex and requires ident...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation involves replacing certain values based on patterns ob...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Replace all values with 0 except for specific values that need to be preserved\n",
      "    # Based on the observed patterns in the input-output pairs, it appears that:\n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Replace all values with 0 except for specific values that need to be pres...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    output = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Iterate over each cell in the input grid\n",
      "    for i in ra...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    output = [[0 for _ in range(9)...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            # The transformatio...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in i...\n",
      "    Program extracted: True\n",
      "  Task 0 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 1 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(0)\n",
      "            elif num == 6:...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Convert grid to a list of lists of integers\n",
      "    # Apply transformation: take every 10th element in each row, then take every 10th element in each column\n",
      "    # Th...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Convert grid to a list of lists of integers\n",
      "    # Apply transformation: t...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # This transformation rule appears to propagate values in a way that spreads the value 4 to adjacent cells,\n",
      "    # and replaces 4 with 1 in some cases. However, bas...\n",
      "    Extracted code: def transform(grid):\n",
      "    # This transformation rule appears to propagate values in a way that spread...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to take the value at the center of the grid\n",
      "    # and use it to determine the output grid. However, based on the given inputs and outp...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "        1: 1,   # Blue\n",
      "        2: 2,   # Red\n",
      "        3: 3,   # Green\n",
      "        4: 4,   # Yellow\n",
      "...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "      ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 0:\n",
      "                new_row.append(0)\n",
      "            elif val ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # The transformation rule appears to involve selecting specific cells from the input grid\n",
      "    # based on their position and value. After analyzing the input-...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # The transformation rule appears to involve selecting specific cells...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(4)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 1 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 2 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the transformation based on the pattern observed\n",
      "    # The transformation seems to be: repeat each row twice, and each column twice\n",
      "    # So, for...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the transformation based on the pattern observed\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for i in range(4):\n",
      "            count = 0\n",
      "            for j in range(4):\n",
      "                if row[j...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for i in...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # The transformation seems to involve replacing certain values with a pattern of 1s and expa...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in range(len(new_grid)...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [row[:] for row...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. For each cell in the grid, if the value is 0, it remains 0.\n",
      "    # 2. For each cell with a value greater than 0, i...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(3)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to propagate values from the top-left to the right and down\n",
      "    # For each cell, if it is not zero, it will be copied to the cell belo...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to propagate values from the top-left to the r...\n",
      "    Program extracted: True\n",
      "  Task 2 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 3 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule observed is:\n",
      "    # 1. For each row in the input grid, we take every third element (starting from index 0).\n",
      "    # 2. We then group these e...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule observed is:\n",
      "    # 1. For each row in the input g...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 3,\n",
      "        2: 2,\n",
      "        3: 3,\n",
      "        4: 4,\n",
      "        5: 5,\n",
      "        6: 6,\n",
      "        7: 7,\n",
      "      ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 3,\n",
      "  ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation appears to involve mapping numbers to specific colors and then\n",
      "    # reshaping the grid. However, based on the given examples, the transformat...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation appears to involve mapping numbers to specific colors ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all 0s with 4s in the first row.\n",
      "    # 2. Replace all 0s with 3s in the second row.\n",
      "    # 3. Replace all ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all 0s with 4s in...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 0:\n",
      "                new_row.append(1)\n",
      "            elif val ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 8:\n",
      "                n...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the grid\n",
      "    # based on the following mapping:\n",
      "    # 4 -> 2\n",
      "    # 5 -> 2 (in some cases, but no...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the gri...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace the value 7 with 6 in the grid\n",
      "    # and replace the value 6 with 7 in the grid, but this is not the correct transformation...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace the value 7 with 6 in the grid\n",
      "    ...\n",
      "    Program extracted: True\n",
      "  Task 3 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 4 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    output_size = 6\n",
      "    # Initialize the output grid\n",
      "    output_grid = [[0 for _ in range(output_size)] for _ in rang...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    output_size = 6\n",
      "    # Ini...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Mapping from input values to output values based on the observed transformations\n",
      "    # 0 -> 0, 1 -> 0, 2 -> 0, 3 -> 0, 4 -> 0, 5 -> 0, 6 -> 0, 7 -> 0, 8 -> 2, 9 ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Mapping from input values to output values based on the observed transfor...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in r...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "         ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Check if the grid is empty\n",
      "    if not grid or not grid[0]:\n",
      "        return grid\n",
      "    \n",
      "    # Initialize the result grid\n",
      "    result = [[0 for _ in range(len(grid[0])...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Check if the grid is empty\n",
      "    if not grid or not grid[0]:\n",
      "        return...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace all values except 0 with 0\n",
      "    # This is inferred from the input-output pairs where non-zero values are replaced with 0\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace all values except 0 with 0\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    result = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Fill the result grid based on the input grid\n",
      "    for i in rang...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    result = [[0 for _ in range(9)] for ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 4 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 5 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(row))] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to be taking the first row of the input grid and using it as the first row of the output grid\n",
      "    # Similarly, it's taking the first col...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to be taking the first row of the input grid and...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on the observed pattern\n",
      "    # The transformation appears to involve propagating values to the right and up, and replacing...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on the observed pattern\n",
      "    # The...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to take the value at position (i, j) in the input grid\n",
      "    # and map it to the corresponding value in the output grid based on the pos...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 0:\n",
      "                new_row.append(0)\n",
      "            elif val ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in the g...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 5 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 6 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    new_grid = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Mapping based on the given color codes\n",
      "            # 0: Black, 1: Blu...\n",
      "    Extracted code: def transform(grid):\n",
      "    new_grid = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule\n",
      "    # This rule is based on the observation that the output grids are derived by\n",
      "    # grouping cells in the input grid and replac...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rule\n",
      "    # This rule is based on the observatio...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule seems to be: for each cell in the grid, if the value is 0, leave it as is.\n",
      "    # If the value is 1, change it to 1.\n",
      "    # If the value is...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Define the color mapping\n",
      "    co...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate through each cell in the grid\n",
      "    for i i...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 0:\n",
      "                new_row.append(0)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(0)  # 3 -> 0\n",
      "           ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule seems to be: for each row, if the row index is even (0-based), \n",
      "    # then the row is kept as is. If the row index is odd, then the row i...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule seems to be: for each row, if the row index is ev...\n",
      "    Program extracted: True\n",
      "  Task 6 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 7 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the transformation based on the patterns observed\n",
      "    # This transformation seems to involve grouping adjacent numbers and replacing them with a ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the transformation based on the patterns observed\n",
      "    # T...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 1:\n",
      "                new_row.append(3)  # Blue -> Green\n",
      "    ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # The transformation seems to involve:\n",
      "    # 1. Reshaping the grid from (rows x cols) to (cols x rows)\n",
      "    #...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # The transformation...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is:\n",
      "    # 1. Replace all 0s with 4s in the first row.\n",
      "    # 2. Replace all 0s with 3s in the second row.\n",
      "    # 3. Replace all 0s with 2s ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(row))] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Replace 4 with 2 in the grid\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 4:\n",
      "                new_...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Replace 4 with 2 in the grid\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "  ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace the value 7 with 3 in the grid\n",
      "    # and replace the value 6 with 1 in the grid\n",
      "    # This is inferred from the pattern obs...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace the value 7 with 3 in the grid\n",
      "    ...\n",
      "    Program extracted: True\n",
      "  Task 7 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 8 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    rows, cols = len(input_grid), len(input_grid[0])\n",
      "    output_rows = 6\n",
      "    output_cols = 6\n",
      "    \n",
      "    # Create the ou...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    rows, cols = len(input_gr...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 2,\n",
      "        2: 2,\n",
      "        3: 2,\n",
      "        4: 2,\n",
      "        5: 2,\n",
      "        6: 2,\n",
      "        7: 7,\n",
      "      ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 2,\n",
      "  ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[cell for cell in row] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in ran...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[cell for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transformation rule: Replace each cell with the corresponding color code\n",
      "    # The transformation is based on the given input-output pairs and observed patterns\n",
      "...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace each cell value with its corresponding color code\n",
      "    # The color code is determined by the value in the grid: 0:Black; 1:B...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace each cell value with its correspond...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "    # Based on the input-output pairs, it seems that values 3, 5, 7, 9, and 1 are being rep...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat each number in the original grid 3 times in the new grid\n",
      "       ...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 8 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 9 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(row))] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be selecting specific positions from the input grid\n",
      "    # based on their row and column indices. For each output cell, we are ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be selecting specific positions from t...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to its neighbors and replace 1 with 4 where possible\n",
      "    # This is a simplified version of the transformation...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to its neighbors and ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to involve extracting specific values from the grid\n",
      "    # Based on the input-output examples, it appears the transformation is to extrac...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to involve extracting specific values from the g...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,  # Black\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    rows = len(input_grid)\n",
      "    cols = len(input_grid[0]) if rows > 0 else 0\n",
      "    result = [[0 for _ in range(cols...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    rows = len(input_gri...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(4)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 9 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 10 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Mapping based on the given color codes\n",
      "            if num == 0:\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transformation logic based on observed patterns\n",
      "    # This is a simplified version that maps certain values to specific patterns\n",
      "    # Note: The exact transforma...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Apply the transformation rule\n",
      "    # This rule seems to be: replace 0 with 0, 1 with 1, 2 with 1, 3 with 1, 4 with 1, 5 with 1, 6 with 1, 7 with 1, 8 with 1...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in r...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in the g...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[cell for cell in row] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in ran...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[cell for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(3)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on observed patterns\n",
      "    # The transformation seems to propagate values in a certain pattern\n",
      "    # For this solution, we ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on observed patterns\n",
      "    # The tr...\n",
      "    Program extracted: True\n",
      "  Task 10 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 11 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # This transformation appears to be grouping adjacent numbers and replacing them with the first number in the group, repeated for the length of the group.\n",
      "  ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # This transformation appears to be grouping adjacent numbers and rep...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 1:\n",
      "                new_row.append(3)  # 1 (Blue) -> 3 (Gre...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Initialize the output grid with zeros\n",
      "    rows = len(input_grid)\n",
      "    cols = len(input_grid[0]) if rows > 0 else 0\n",
      "    output = [[0 for _ in range(cols)] fo...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Initialize the output grid with zeros\n",
      "    rows = len(input_grid)\n",
      "  ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in r...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 8:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 2 in the grid\n",
      "    # and replace the value 5 with 2 in the grid where the value is 5 and the value to the l...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule observed is that certain cells in the grid are being replaced with specific values.\n",
      "    # From the input-output pairs, it appears that th...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule observed is that certain cells in the grid are be...\n",
      "    Program extracted: True\n",
      "  Task 11 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 12 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replicating each element in the grid\n",
      "    # in a pattern that alternates between the original element and the element\n",
      "    # ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replicating each element in the gri...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate through each cell in the grid\n",
      "    for i i...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    # This is a simplified rule based on observing the patterns in the outputs\n",
      "    # For the...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation involves several steps:\n",
      "    # 1. Replace 0 with 0\n",
      "    # 2. Replace 1 with 0\n",
      "    # 3. Replace 2 with 0\n",
      "    # 4. Replace 3 with 3\n",
      "    # 5. Repla...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "    # Specifically, values 3, 6, 7, 8, 9 are being replaced with 0\n",
      "    # However, based on ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    output = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Iterate over each cell in the input grid\n",
      "    for i in ra...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    output = [[0 for _ in range(9)...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # - For each cell in the grid, if the value is 0, keep it as 0.\n",
      "    # - If the value is 2, replace it with 2.\n",
      "    # - ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "  Task 12 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 13 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Initialize the transformed grid with zeros\n",
      "    transformed = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in th...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Initialize the transformed grid with zeros\n",
      "    transformed = [[0 for _ in...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the unique elements from the grid\n",
      "    unique_elements = set()\n",
      "    for row in grid:\n",
      "        for element in row:\n",
      "            unique_elements.add(element)\n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the unique elements from the grid\n",
      "    unique_elements = set()\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule\n",
      "    # This transformation replaces certain values with new values based on the pattern observed in the input-output pairs\n",
      "    #...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule\n",
      "    # This transformation replaces cert...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to take the value at the center of the grid and use it as the value for the output grid\n",
      "    # For a 30x30 grid, the center is at (14,1...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the transformation logic based on the observed patterns\n",
      "    # The transformation involves selecting specific cells from the input grid\n",
      "    # and arr...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the transformation logic based on the observed patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(4)\n",
      "         ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "  Task 13 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 14 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation involves duplicating each row and shifting columns\n",
      "    # For each row in the input grid, we create two rows in the output\n",
      "    # The columns ar...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation involves duplicating each row and shifting columns\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation logic based on observed patterns\n",
      "    # This is a simplified example; the actual logic may vary based on the task\n",
      "    # This code is a p...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation logic based on observed patterns\n",
      "    # This is ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implementation of the transformation rule\n",
      "    # This function checks the neighboring cells to determine the transformation\n",
      "    # Based on the given examples, it ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implementation of the transformation rule\n",
      "    # This function checks the ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 1,\n",
      "        2: 5,\n",
      "        3: 5,\n",
      "        4: 5,\n",
      "        5: 5,\n",
      "        6: 5,\n",
      "        7: 5,\n",
      "      ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 1,\n",
      "  ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    output_grid = [[0 for _ in range(15)] for _ in range(15)]\n",
      "    \n",
      "    # Iterate over each cell in the input gri...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    output_grid = [[0 fo...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(5)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(5)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 14 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 15 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions as the input\n",
      "    new_grid = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "        ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions as the input\n",
      "    new_gri...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 3,\n",
      "        2: 2,\n",
      "        3: 3,\n",
      "        4: 4,\n",
      "        5: 5,\n",
      "        6: 6,\n",
      "        7: 7,\n",
      "...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1:...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transpose the grid and apply the transformation\n",
      "    transformed = []\n",
      "    for col in range(len(grid[0])):\n",
      "        new_row = []\n",
      "        for row in range(len(grid))...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transpose the grid and apply the transformation\n",
      "    transformed = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to spread the value 4 to the left and right of the 4s, and spread the value 3 to the left and right of the 3s, and spread the value 2 ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,\n",
      "        1: 2,\n",
      "        2: 2,\n",
      "        3: 2,\n",
      "        4: 2,\n",
      "        5: 1,\n",
      "        6: 2,\n",
      "        7: 2,\n",
      "...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,\n",
      "        1:...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 8:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 2 in the grid\n",
      "    # and replace the value 5 with 2 in the grid where the original value is 5 and the cell ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 2 in the grid\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the grid based on specific patterns.\n",
      "    # Based on the input-output pairs, it seems that the t...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the gri...\n",
      "    Program extracted: True\n",
      "  Task 15 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 16 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(input_grid)\n",
      "    output_size = original_size * 3  # Each original cell is expanded to 3 rows a...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(input...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {0: 0, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2, 8: 2, 9: 2}\n",
      "    \n",
      "    # Apply the transformation\n",
      "    transformed = []\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {0: 0, 1: 2, 2: 2, 3: 2, 4: 2, 5...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    # The transformation seems to be replacing certain values with others in a specific pattern\n",
      "  ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is not explicitly defined, but based on the patterns in the examples,\n",
      "    # it appears that the transformation involves propagating value...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is not explicitly defined, but based on the patte...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation involves changing certain values in the grid based on the observed patterns\n",
      "    # From the input-output pairs, it appears that certain values ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation involves changing certain values in the grid based on ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "    # based on the input-output pairs. From the given examples, it seems that\n",
      "    # values ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat the number 3 times and add to the new row\n",
      "            new_row.ex...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "    output_grid = [row[:] for row in input_grid]\n",
      "    \n",
      "    # Iterate over each cell in the g...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "   ...\n",
      "    Program extracted: True\n",
      "  Task 16 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 17 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all cells with value 0 with 0.\n",
      "    # 2. For cells with value 5, 3, or 2, expand them to fill a certain pa...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all cells with va...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to involve taking the first element of each row and the last element of each row,\n",
      "    # and then creating a new grid where each cell is ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # This transformation rule expands certain values in the grid based on their neighbors\n",
      "    # Specifically, it propagates values to adjacent cells if they are...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # This transformation rule expands certain values in the grid based o...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to take the value at the center of the grid and use it as the value for the output grid\n",
      "    # For the given examples, the output grid ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to take the value at the center of the grid an...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      "     ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "       ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[cell for cell in row] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in ran...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[cell for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    rows = len(input_grid)\n",
      "    cols = len(input_grid[0]) if rows > 0 else 0\n",
      "    output = [[0 for _ in range(cols...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    rows = len(input_gri...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(4)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 17 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 18 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation involves repeating each row twice and shifting the columns\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        # Repeat each element in the row ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation involves repeating each row twice and shifting the col...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(8)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    # This rule seems to involve replacing certain values with adjacent values\n",
      "    # For example, in Input 1, the value 2 is replac...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    # This rule seems to involve replacing ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 1,\n",
      "        2: 5,\n",
      "        3: 5,\n",
      "        4: 5,\n",
      "        5: 5,\n",
      "        6: 5,\n",
      "        7: 5,\n",
      "      ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,\n",
      "        1: 1,\n",
      "  ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in r...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    for i in range(len(grid)):\n",
      "        for j in range(len(grid[i])):\n",
      "            if grid[i][j] == 8:\n",
      "                grid[i][j] = 2...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    for i in range(len(grid)):\n",
      "        for ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(3)\n",
      "         ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on observed patterns\n",
      "    # The transformation appears to propagate values in a certain pattern\n",
      "    # For each row, we che...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on observed patterns\n",
      "    # The tr...\n",
      "    Program extracted: True\n",
      "  Task 18 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 19 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to involve grouping adjacent numbers and replacing them with the first number in the group\n",
      "    # For example, in Input 1, the sequence [...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to involve grouping adjacent numbers and replaci...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 1:\n",
      "                new_row.append(3)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # This transformation is based on the analysis of the input-output pairs\n",
      "    # The transformation seems to i...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # This transformatio...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to be spreading values in a certain pattern.\n",
      "    # From the examples, it appears that values are expanding outward from their original p...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,  # Black -> 1 (assuming 1 is the new value for black)\n",
      "        1: 2,  # Blue -> 2\n",
      "        2: 3,  # Red ->...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,  # Black -> 1 (a...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 8:\n",
      "                new_row.append(1)  # Orange\n",
      "           ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 2 in the grid\n",
      "    # and replace the value 5 with 2 in the grid where the value is 5 and the value to the l...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 2 in the grid\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with others based on patterns\n",
      "    # From the given input-output pairs, it seems that:\n",
      "    # - 1 is...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "  Task 19 summary: 0/8 test-correct, 5/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 20 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    output_size = 6\n",
      "    # Initialize the output grid\n",
      "    output_grid = [[0 for _ in range(output_size)] for _ in rang...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    output_size = 6\n",
      "    # Ini...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "        1: 2,   # Blue -> 2\n",
      "        2: 2,   # Red -> 2\n",
      "        3: 2,   # Green -> 2\n",
      "        4:...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "      ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 2:\n",
      "                new_row.append(2)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation logic based on observed patterns\n",
      "    # This is a hypothetical transformation based on the given examples\n",
      "    # The transformation seems...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation logic based on observed patterns\n",
      "    # This is ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to involve replacing certain values based on patterns\n",
      "    # We'll implement a transformation that replaces 0 with 0, 1 with 1, etc., but...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to involve replacing certain values based on pat...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values based on patterns\n",
      "    # Observing the input-output pairs, it seems that:\n",
      "    # - 0 remains 0\n",
      "    #...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values based on p...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Expand each number to 3 columns and 3 rows\n",
      "            # Create a 3x3 g...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to spread the value 2 to adjacent cells and replace 3 with 2 in some cases\n",
      "    # This is a simplified version based on observed patter...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to spread the value 2 to adjacent cells and re...\n",
      "    Program extracted: True\n",
      "  Task 20 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 21 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Initialize the result grid with zeros\n",
      "    result = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate through each cell in the input...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Initialize the result grid with zeros\n",
      "    result = [[0 for _ in range(len...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Convert the grid to a list of lists of integers\n",
      "    # Apply the transformation rule to each cell\n",
      "    # The transformation rule is to take the value modulo 10 and...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Convert the grid to a list of lists of integers\n",
      "    # Apply the transform...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # This transformation replaces certain values in the grid based on the input-output pairs\n",
      "  ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # This transformation rule is based on the observation that the output grids are derived by taking specific values from the input grids.\n",
      "    # For example, the fir...\n",
      "    Extracted code: def transform(grid):\n",
      "    # This transformation rule is based on the observation that the output grid...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      "     ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "       ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Extract the dimensions of the input grid\n",
      "    rows = len(input_grid)\n",
      "    cols = len(input_grid[0]) if rows > 0 else 0\n",
      "    \n",
      "    # Create a new grid with the ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Extract the dimensions of the input grid\n",
      "    rows = len(input_grid)...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    # The transformation seems to involve replacing certain values based on their position or value\n",
      "    # Observing the input-outpu...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    # The transformation seems to involve r...\n",
      "    Program extracted: True\n",
      "  Task 21 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 22 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Each cell in the input grid is expanded into a 2x2 block in the output grid\n",
      "    # The value of the cell is repeated in the 2x2 block\n",
      "    result = []\n",
      "    for row ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Each cell in the input grid is expanded into a 2x2 block in the output gr...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 0:\n",
      "                new_row.append(8)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace each 0 with 0, 1 with 1, 2 with 2, 3 with 3, 4 with 4, 5 with 5, 6 with 6, 7 with 7, 8 with 8, 9 with 9.\n",
      "    # However, bas...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace each 0 with 0, 1 with 1, 2 with 2, ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Define the color mapping\n",
      "    co...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    for i in range(len(grid)):\n",
      "        for j in range(len(grid[i])):\n",
      "            if grid[i][j] == 0:\n",
      "                grid[i][j] = 6  # 0 maps to 6 (Pink)\n",
      "            e...\n",
      "    Extracted code: def transform(grid):\n",
      "    for i in range(len(grid)):\n",
      "        for j in range(len(grid[i])):\n",
      "          ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # The transformation seems to replace certain values with others based on their position\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(3)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(5)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 22 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 23 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # The transformation rule is to group adjacent numbers and replace them with the first number in the group,\n",
      "    # with the number of groups equal to the numb...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # The transformation rule is to group adjacent numbers and replace th...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "    output_grid = [row[:] for row in input_grid]\n",
      "    \n",
      "    # Define the color mapping\n",
      "    co...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # The transformation rule is not explicitly defined, but based on the input-output examples,\n",
      "    # it appears that the transformation involves converting num...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # The transformation rule is not explicitly defined, but based on the...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule observed from the examples is:\n",
      "    # 1. The value 5 in the input grid is replaced by 4 in the output grid.\n",
      "    # 2. The value 0 in the in...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule observed from the examples is:\n",
      "    # 1. The value...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,  # Black -> 1 (blue)\n",
      "        1: 2,  # Blue -> 2 (red)\n",
      "        2: 3,  # Red -> 3 (green)\n",
      "        3: 4,  #...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,  # Black -> 1 (b...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 8:\n",
      "                new_row.append(1)  # Orange\n",
      "           ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the grid\n",
      "    # based on the given input-output pairs. From the examples, it seems that:\n",
      "    # -...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the gri...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to replace certain values with others based on patterns.\n",
      "    # Observing the input-output pairs, it appears that the transformation invo...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to replace certain values with others based on p...\n",
      "    Program extracted: True\n",
      "  Task 23 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 24 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(input_grid)\n",
      "    output_size = original_size * 3  # Each original cell is repeated 3 times in ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(input...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,\n",
      "        1: 2,\n",
      "        2: 2,\n",
      "        3: 2,\n",
      "        4: 2,\n",
      "        5: 2,\n",
      "        6: 2,\n",
      "        7: 7,\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,\n",
      "        1: 2...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    # This is a simplified version based on observed patterns in the examples\n",
      "    # This rul...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Replace all values with 0 except for specific values that need to be preserved\n",
      "    # Based on the observed patterns in the input-output pairs, it seems that valu...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Replace all values with 0 except for specific values that need to be pres...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat each number in the input grid 3 times in the output grid\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Check if the grid is 20x30 or 10x20 or 20x20\n",
      "    if len(grid) == 20 and len(grid[0]) == 30:\n",
      "        # For 20x30 grid\n",
      "        for i in range(20):\n",
      "            for ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "  Task 24 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 25 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(0)\n",
      "            elif num == 6:...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the coordinates of the corners of the input grid\n",
      "    # The input grid is 30x30, so the corners are at (0,0), (0,29), (29,0), (29,29)\n",
      "    # The output gri...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the coordinates of the corners of the input grid\n",
      "    # The input ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # This transformation appears to involve propagating values to the right and expanding certain values\n",
      "    # Based on the input-output examples, it seems that...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # This transformation appears to involve propagating values to the ri...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # This transformation function is based on the observation that the output grids are formed by taking specific values from the input grid\n",
      "    # The exact transform...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Mapping of colors based on the given color codes\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "        1: 1,   # Blue\n",
      "        2: 2,   # Red\n",
      "        3: 3,   # Green\n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Mapping of colors based on the given color codes\n",
      "    color_map = {\n",
      "      ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule: replace 0 with 0, 1 with 1, 2 with 2, 3 with 3, 4 with 4, 5 with 5, 6 with 6, 7 with 7, 8 with 8, 9 with 9\n",
      "    # The transformatio...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule: replace 0 with 0, 1 with 1, 2 with 2, 3 wi...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    # This is a simplified version that maps specific numbers to their positions in the output\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    # This...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 25 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 26 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the transformation rule based on the given examples\n",
      "    # The transformation seems to be: each cell in the input grid is expanded into a 2x2 bloc...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the transformation rule based on the given examples\n",
      "    #...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 0:\n",
      "                new_row.append(8)\n",
      "            elif val ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # This transformation seems to involve propagating values from the left and top\n",
      "    # to fill in missing val...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # This transformatio...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Define the color mapping\n",
      "    co...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in the g...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "         ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 3:\n",
      "                new_row.append(3)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 26 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 27 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # This function applies a transformation where each row is split into segments of the same value,\n",
      "    # and each segment is replaced by the value followed by...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # This function applies a transformation where each row is split into...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {0: 0, 1: 3, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "    \n",
      "    # Create a new grid with the transformed values\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {0: 0, 1: 3, 2: 2, 3: 3, 4: 4, 5...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transpose the grid to change rows to columns and vice versa\n",
      "    transposed = list(zip(*grid))\n",
      "    # Convert tuples to lists\n",
      "    transformed = [list(row) for row ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transpose the grid to change rows to columns and vice versa\n",
      "    transpose...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to expand the values in the grid by spreading them to adjacent cells.\n",
      "    # This is a simple diffusion-like process where each non-zer...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to expand the values in the grid by spreading ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 8:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace 4 with 2 in the grid\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace 4 with 2 in the grid\n",
      "    transforme...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule observed is that certain numbers in the grid are replaced based on their position.\n",
      "    # Specifically, it seems that the number 7 in the ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule observed is that certain numbers in the grid are ...\n",
      "    Program extracted: True\n",
      "  Task 27 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 28 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Determine the size of the new grid\n",
      "    original_size = len(grid)\n",
      "    new_size = original_size * 3  # Each original cell is repeated 3 times in each dimension\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Determine the size of the new grid\n",
      "    original_size = len(grid)\n",
      "    new_...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping based on the given color codes\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 2,  # Blue -> 2\n",
      "        2: 2,  # Red -> 2\n",
      "        3: ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping based on the given color codes\n",
      "    color_map = {...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    # This rule is based on the observation that 2 is replaced with 8 in certain regions\n",
      "   ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rules\n",
      "    # The transformation seems to be replacing certain values with others based on some pattern\n",
      "    # Based on the given examples...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rules\n",
      "    # The transformation seems to be repl...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Check if the grid is empty\n",
      "    if not grid or not grid[0]:\n",
      "        return grid\n",
      "    \n",
      "    # Initialize the result grid\n",
      "    result = [[0 for _ in range(len(grid[0])...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Check if the grid is empty\n",
      "    if not grid or not grid[0]:\n",
      "        return...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Replace all values with 0 except for specific values that need to be preserved\n",
      "    # Based on the patterns observed in the input-output pairs, it appears that va...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    output = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Iterate over each cell in the input grid\n",
      "    for i in ra...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Initialize a 9x9 grid with zeros\n",
      "    output = [[0 for _ in range(9)...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in range(len(new_grid)...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [row[:] for row...\n",
      "    Program extracted: True\n",
      "  Task 28 summary: 0/8 test-correct, 6/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 29 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in input_grid]\n",
      "    \n",
      "    # Iterate through each cell in th...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      "    for row in grid:\n",
      "        for val in row:\n",
      "            unique_values.add(val)\n",
      "    \n",
      "    ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace values in the grid based on the following rules:\n",
      "    # - 1 becomes 1\n",
      "    # - 2 becomes 3\n",
      "    # - 3 becomes 4\n",
      "    # - 4 beco...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace values in the grid based on the fol...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation based on the observed patterns\n",
      "    # This is a placeholder implementation; the actual logic needs to be derived from the input-outpu...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation based on the observed patterns\n",
      "    # This is...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      "        5...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the transformed values\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 0:\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the transformed values\n",
      "    transformed = []\n",
      "    fo...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transformation rule: Replace 9 with 8, 7 with 3, 6 with 4, 5 with 7, and 0 remains 0\n",
      "    # This rule is based on observing the pattern in the input-output pairs\n",
      "...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transformation rule: Replace 9 with 8, 7 with 3, 6 with 4, 5 with 7, and ...\n",
      "    Program extracted: True\n",
      "  Task 29 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 30 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation appears to be a pattern where each input row is repeated twice in the output\n",
      "    # and each input column is expanded into two columns in the o...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation appears to be a pattern where each input row is repeat...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for i in range(4):\n",
      "            if i % 2 == 0:\n",
      "                new_row.append(8 if row[i] == 0 el...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for i in...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule seems to be:\n",
      "    # - Replace all 0s with 0s\n",
      "    # - Replace all 1s with 1s\n",
      "    # - Replace all 2s with 1s\n",
      "    # - Replace all 3s with 0s\n",
      "...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping based on the given numbers\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping based on the given numbers\n",
      "    color_map = {\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate through each cell in the grid\n",
      "    for i i...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # The transformation seems to involve replacing certain numbers with others based on their p...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on the observed patterns\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 3:\n",
      "                new_row.append(3)\n",
      "       ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(5)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "  Task 30 summary: 0/8 test-correct, 7/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "=== ARC task 31 - processing 8 pre-generated attempts ===\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # The transformation rule seems to be grouping adjacent numbers and replacing them with the first number in the group\n",
      "    # For example, in Input 1, the numb...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # The transformation rule seems to be grouping adjacent numbers and r...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {0: 0, 1: 3, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "    \n",
      "    # Create a new grid with the transformed values\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {0: 0, 1: 3, 2: 2, 3: 3, 4: 4, 5...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation logic based on observed patterns\n",
      "    # The transformation seems to be:\n",
      "    # 1. Transpose the grid (rows become columns and vice versa)...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation logic based on observed patterns\n",
      "    # The tran...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in input_grid]\n",
      "    \n",
      "    # Iterate through each cell in th...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,  # Black -> 1 (as per the output, it seems 1 is used for some black regions)\n",
      "        1: 2,  # Blue -> 2\n",
      "...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 1,  # Black -> 1 (a...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all instances of 8 with 1\n",
      "    # 2. Replace all instances of 1 with 2\n",
      "    # 3. Replace all instances of 3 ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all instances of ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace 4 with 2 in the grid\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = [cell if cell != 4 else 2 for cell in row]...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace 4 with 2 in the grid\n",
      "    transforme...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation appears to be replacing certain values with others based on patterns\n",
      "    # From the input-output pairs, it seems that some values are being re...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation appears to be replacing certain values with others bas...\n",
      "    Program extracted: True\n",
      "  Task 31 summary: 0/8 test-correct, 8/8 code-ran\n",
      "  Train accuracies: train_accs=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 3, 3, 2, 2, 2], [3, 3, 3, 2, 2, 2], [3, 3, 3, 2, 2, 2], [7, 7, 7, 8, 8, 8], [7, 7, 7, 8, 8, 8], [7, 7, 7, 8, 8, 8]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 2], [7, 2]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "üéØ FINAL MULTI-ATTEMPT METRICS:\n",
      "  all_test_correct: 0.0\n",
      "  all_train_correct: 0.0\n",
      "  min1_train_correct: 0.0\n",
      "  min1_code_success: 1.0\n",
      "  weighted_voting_pass2: 0.0\n",
      "  train_majority_pass2: 0.0\n",
      "  max_length_rate: 0.0\n",
      "  timeout_rate: 0.0\n",
      "  total_tasks: 32\n",
      "  total_responses: 256\n",
      "  total_attempts: 256\n",
      "  ‚úÖ compute_arc_metrics with real data - PASSED\n",
      "     Multi-attempt metrics:\n",
      "       Oracle (best): 0.000\n",
      "       Code success: 1.000\n",
      "       Voting pass@2: 0.000\n",
      "       Total attempts: 256 (8 per task)\n"
     ]
    }
   ],
   "source": [
    "def test_compute_arc_metrics_with_real_data():\n",
    "    \"\"\"Test the multi-attempt compute_arc_metrics function using real trainer and data\"\"\"\n",
    "    print(\"\\nüéØ Testing MULTI-ATTEMPT compute_arc_metrics with REAL trainer data...\")\n",
    "    \n",
    "    # DEBUG: Check what's actually in the eval dataset\n",
    "    print(\"üîç DEBUG: Checking eval dataset structure...\")\n",
    "    sample = trainer.eval_dataset[0]\n",
    "    print(f\"  Available keys: {list(sample.keys())}\")\n",
    "    \n",
    "    # Convert dataset to list to avoid indexing issues\n",
    "    eval_data_list = [trainer.eval_dataset[i] for i in range(len(trainer.eval_dataset))]\n",
    "    print(f\"  Converted {len(eval_data_list)} examples to list\")\n",
    "    \n",
    "    # Use REAL validation data from the trainer (all tasks)\n",
    "    real_eval_data = eval_data_list\n",
    "    \n",
    "    # Temporarily replace eval_dataset for testing\n",
    "    original_eval_dataset = trainer.eval_dataset\n",
    "    trainer.eval_dataset = real_eval_data\n",
    "    \n",
    "    try:\n",
    "        print(f\"  Actually generating {NUM_EVAL_ATTEMPTS} attempts per task using the model...\")\n",
    "        \n",
    "        # Extract input_ids from the converted list\n",
    "        input_ids_list = []\n",
    "        for sample in eval_data_list:\n",
    "            # Convert list to tensor if needed\n",
    "            if isinstance(sample['input_ids'], list):\n",
    "                input_ids = torch.tensor(sample['input_ids'])\n",
    "            else:\n",
    "                input_ids = sample['input_ids']\n",
    "            input_ids_list.append(input_ids)\n",
    "        \n",
    "        # Stack and pad if necessary\n",
    "        max_len = max(len(ids) for ids in input_ids_list)\n",
    "        padded_input_ids = []\n",
    "        for ids in input_ids_list:\n",
    "            if len(ids) < max_len:\n",
    "                # Pad with tokenizer pad token\n",
    "                padding = torch.full((max_len - len(ids),), tokenizer.pad_token_id)\n",
    "                ids = torch.cat([ids, padding])\n",
    "            padded_input_ids.append(ids)\n",
    "        \n",
    "        # Create inputs tensor\n",
    "        inputs = {\n",
    "            'input_ids': torch.stack(padded_input_ids).to(trainer.model.device)\n",
    "        }\n",
    "        \n",
    "        print(f\"  Input shape: {inputs['input_ids'].shape}\")\n",
    "        \n",
    "        # Actually call VllmSFTTrainer.prediction_step to get REAL generations\n",
    "        print(\"  Calling VllmSFTTrainer.prediction_step...\")\n",
    "        _, real_predictions, _ = trainer.prediction_step(\n",
    "            model=trainer.model,\n",
    "            inputs=inputs,\n",
    "            prediction_loss_only=False\n",
    "        )\n",
    "        \n",
    "        print(f\"  Generated predictions shape: {real_predictions.shape}\")\n",
    "        \n",
    "        # Create EvalPrediction object with REAL predictions\n",
    "        eval_pred = EvalPrediction(\n",
    "            predictions=real_predictions,\n",
    "            label_ids=None\n",
    "        )\n",
    "        \n",
    "        # Test the compute_arc_metrics function with real predictions\n",
    "        metrics = compute_arc_metrics(eval_pred, debug=True)\n",
    "        \n",
    "        # Rest of validation code...\n",
    "        \n",
    "        # Verify expected structure for multi-attempt metrics\n",
    "        expected_keys = [\n",
    "            \"all_test_correct\", \"all_train_correct\", \"min1_train_correct\",\n",
    "            \"min1_code_success\", \"weighted_voting_pass2\", \"train_majority_pass2\",\n",
    "            \"max_length_rate\", \"timeout_rate\", \"total_tasks\", \"total_responses\", \"total_attempts\"\n",
    "        ]\n",
    "        \n",
    "        passed = True\n",
    "        for key in expected_keys:\n",
    "            if key not in metrics:\n",
    "                print(f\"  ‚ùå Missing metric: {key}\")\n",
    "                passed = False\n",
    "            elif not isinstance(metrics[key], (int, float)):\n",
    "                print(f\"  ‚ùå Metric {key} has wrong type: {type(metrics[key])}\")\n",
    "                passed = False\n",
    "        \n",
    "        # Check that we have reasonable values for multi-attempt setup\n",
    "        if metrics[\"total_tasks\"] != len(trainer.eval_dataset):\n",
    "            print(f\"  ‚ùå Expected 8 tasks, got {metrics['total_tasks']}\")\n",
    "            passed = False\n",
    "        \n",
    "        expected_total_attempts = len(trainer.eval_dataset) * NUM_EVAL_ATTEMPTS  # len(trainer.eval_dataset) tasks √ó attempts each\n",
    "        if metrics[\"total_attempts\"] != expected_total_attempts:\n",
    "            print(f\"  ‚ùå Expected {expected_total_attempts} total attempts, got {metrics['total_attempts']}\")\n",
    "            passed = False\n",
    "        \n",
    "        # Check that voting metrics are present (even if 0)\n",
    "        if \"weighted_voting_pass2\" not in metrics:\n",
    "            print(f\"  ‚ùå Missing weighted_voting_pass2 metric (multi-attempt feature)\")\n",
    "            passed = False\n",
    "        \n",
    "        if \"train_majority_pass2\" not in metrics:\n",
    "            print(f\"  ‚ùå Missing train_majority_pass2 metric (multi-attempt feature)\")\n",
    "            passed = False\n",
    "        \n",
    "        # Verify sampling parameters are working (basic check)\n",
    "        if metrics[\"min1_code_success\"] < 0 or metrics[\"min1_code_success\"] > 1:\n",
    "            print(f\"  ‚ùå Invalid min1_code_success: {metrics['min1_code_success']} (should be 0-1)\")\n",
    "            passed = False\n",
    "        \n",
    "        if passed:\n",
    "            print(\"  ‚úÖ compute_arc_metrics with real data - PASSED\")\n",
    "            print(f\"     Multi-attempt metrics:\")\n",
    "            print(f\"       Oracle (best): {metrics['all_test_correct']:.3f}\")\n",
    "            print(f\"       Code success: {metrics['min1_code_success']:.3f}\")\n",
    "            print(f\"       Voting pass@2: {metrics['weighted_voting_pass2']:.3f}\")\n",
    "            print(f\"       Total attempts: {metrics['total_attempts']} ({NUM_EVAL_ATTEMPTS} per task)\")\n",
    "        else:\n",
    "            print(\"  ‚ùå compute_arc_metrics with real data - FAILED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå compute_arc_metrics real data test - ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        passed = False\n",
    "    \n",
    "    finally:\n",
    "        # Restore original settings\n",
    "        trainer.eval_dataset = original_eval_dataset\n",
    "    \n",
    "    return passed\n",
    "\n",
    "def test_trainer_integration():\n",
    "    \"\"\"Test that trainer is properly set up and integrated\"\"\"\n",
    "    print(\"\\nüîß Testing trainer integration...\")\n",
    "    \n",
    "    passed = True\n",
    "    \n",
    "    # Test trainer setup\n",
    "    try:\n",
    "        assert hasattr(trainer, 'model'), \"Trainer missing model\"\n",
    "        assert hasattr(trainer, 'tokenizer'), \"Trainer missing tokenizer\"  \n",
    "        assert hasattr(trainer, 'eval_dataset'), \"Trainer missing eval_dataset\"\n",
    "        assert hasattr(trainer, 'compute_metrics'), \"Trainer missing compute_metrics\"\n",
    "        \n",
    "        # Test eval dataset structure\n",
    "        eval_sample = trainer.eval_dataset[0]\n",
    "        required_fields = ['train_input', 'train_output', 'test_input', 'test_output']\n",
    "        for field in required_fields:\n",
    "            if field not in eval_sample:\n",
    "                print(f\"  ‚ùå Missing field in eval dataset: {field}\")\n",
    "                passed = False\n",
    "        \n",
    "        # Test that compute_metrics is our function\n",
    "        if trainer.compute_metrics != compute_arc_metrics:\n",
    "            print(f\"  ‚ùå Wrong compute_metrics function\")\n",
    "            passed = False\n",
    "            \n",
    "        # Test tokenizer compatibility\n",
    "        if trainer.tokenizer != tokenizer:\n",
    "            print(f\"  ‚ùå Trainer tokenizer mismatch\")\n",
    "            passed = False\n",
    "            \n",
    "        print(f\"  ‚úÖ Trainer integration - PASSED\")\n",
    "        print(f\"     Eval dataset size: {len(trainer.eval_dataset)}\")\n",
    "        print(f\"     Tokenizer vocab size: {len(tokenizer.get_vocab())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Trainer integration - ERROR: {e}\")\n",
    "        passed = False\n",
    "    \n",
    "    return passed\n",
    "\n",
    "# Run trainer-specific tests\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "trainer_integration_passed = test_trainer_integration()\n",
    "compute_metrics_real_passed = test_compute_arc_metrics_with_real_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÅ FINAL EVALUATION SYSTEM TEST SUMMARY\n",
      "============================================================\n",
      "\n",
      "üìä TEST RESULTS:\n",
      "  extract_python_code            ‚úÖ PASSED\n",
      "  calculate_task_metrics         ‚úÖ PASSED\n",
      "  GridScorer                     ‚úÖ PASSED\n",
      "  ProgramExecutor                ‚úÖ PASSED\n",
      "  trainer_integration            ‚úÖ PASSED\n",
      "  compute_arc_metrics (multi-attempt) ‚úÖ PASSED\n",
      "\n",
      "üéØ OVERALL RESULTS:\n",
      "  Tests passed: 6/6 (100.0%)\n",
      "  üéâ ALL EVALUATION FUNCTIONS ARE WORKING CORRECTLY!\n",
      "  ‚úÖ Multi-attempt evaluation system ready for training!\n",
      "  üî¢ Training will use 8 attempts per task with temp=1.0, min_p=0.05\n",
      "\n",
      "üîß WHAT THESE TESTS VALIDATED:\n",
      "  ‚Ä¢ Grid comparison logic (exact matching)\n",
      "  ‚Ä¢ Code execution with timeout handling\n",
      "  ‚Ä¢ Python code extraction from model outputs\n",
      "  ‚Ä¢ Multi-attempt generation with proper sampling (temp=1.0, min_p=0.05)\n",
      "  ‚Ä¢ Voting and best-attempt metrics across multiple attempts\n",
      "  ‚Ä¢ Training evaluation pipeline integration (compatible with run_arc_tasks_soar.py)\n",
      "  ‚Ä¢ Core utility functions (leveraging existing test suite)\n",
      "\n",
      "üìà MULTI-ATTEMPT EVALUATION METRICS:\n",
      "  ‚Ä¢ all_test_correct: Oracle (best attempt) - whether best attempt solves all test grids\n",
      "  ‚Ä¢ all_train_correct: Perfect training performance across attempts\n",
      "  ‚Ä¢ min1_train_correct: Tasks with at least some training success\n",
      "  ‚Ä¢ min1_code_success: Tasks where at least one attempt generated working code\n",
      "  ‚Ä¢ weighted_voting_pass2: Pass@2 using weighted voting across attempts\n",
      "  ‚Ä¢ train_majority_pass2: Pass@2 using training majority voting\n",
      "  ‚Ä¢ timeout_rate: Fraction of attempts that timed out\n",
      "  ‚Ä¢ max_length_rate: Fraction of attempts that hit max length\n",
      "\n",
      "üöÄ MULTI-ATTEMPT TRAINING BENEFITS:\n",
      "  ‚Ä¢ Each validation task generates 8 attempts during evaluation\n",
      "  ‚Ä¢ Uses same sampling parameters as run_arc_tasks_soar.py (temp=1.0, min_p=0.05)\n",
      "  ‚Ä¢ Comprehensive metrics: oracle, voting, code success rates\n",
      "  ‚Ä¢ Better signal during training - can track improvement across multiple attempts\n",
      "  ‚Ä¢ Direct compatibility with existing ARC evaluation pipelines\n",
      "\n",
      "üöÄ READY TO PROCEED WITH TRAINING!\n",
      "   ‚úÖ Multi-attempt evaluation system validated\n",
      "   üìä Will generate 8 attempts per validation task\n",
      "   üéØ Metrics include voting, oracle (best), and code success rates\n",
      "   üîÑ Sampling: temperature=1.0, min_p=0.05 (aligned with run_arc_tasks_soar.py)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of all test results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÅ FINAL EVALUATION SYSTEM TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine results from existing tests and trainer-specific tests\n",
    "all_tests = [\n",
    "    (\"extract_python_code\", existing_test_results.get('extract_python_code', False)),\n",
    "    (\"calculate_task_metrics\", existing_test_results.get('calculate_task_metrics', False)),\n",
    "    (\"GridScorer\", existing_test_results.get('grid_scorer', False)),\n",
    "    (\"ProgramExecutor\", existing_test_results.get('program_executor', False)),\n",
    "    (\"trainer_integration\", trainer_integration_passed),\n",
    "    (\"compute_arc_metrics (multi-attempt)\", compute_metrics_real_passed),\n",
    "]\n",
    "\n",
    "passed_count = sum(1 for _, passed in all_tests if passed)\n",
    "total_count = len(all_tests)\n",
    "\n",
    "print(f\"\\nüìä TEST RESULTS:\")\n",
    "for test_name, passed in all_tests:\n",
    "    status = \"‚úÖ PASSED\" if passed else \"‚ùå FAILED\"\n",
    "    print(f\"  {test_name:<30} {status}\")\n",
    "\n",
    "print(f\"\\nüéØ OVERALL RESULTS:\")\n",
    "print(f\"  Tests passed: {passed_count}/{total_count} ({passed_count/total_count:.1%})\")\n",
    "\n",
    "if passed_count == total_count:\n",
    "    print(\"  üéâ ALL EVALUATION FUNCTIONS ARE WORKING CORRECTLY!\")\n",
    "    print(\"  ‚úÖ Multi-attempt evaluation system ready for training!\")\n",
    "    print(f\"  üî¢ Training will use {NUM_EVAL_ATTEMPTS} attempts per task with temp=1.0, min_p=0.05\")\n",
    "elif passed_count >= total_count * 0.8:\n",
    "    print(\"  ‚úÖ Most evaluation functions are working correctly.\")\n",
    "    print(\"  ‚ö†Ô∏è  Review the failed tests before proceeding with training.\")\n",
    "else:\n",
    "    print(\"  ‚ùå Multiple evaluation functions have issues.\")\n",
    "    print(\"  üö® STRONGLY RECOMMEND fixing these before training!\")\n",
    "\n",
    "print(f\"\\nüîß WHAT THESE TESTS VALIDATED:\")\n",
    "print(\"  ‚Ä¢ Grid comparison logic (exact matching)\")\n",
    "print(\"  ‚Ä¢ Code execution with timeout handling\")\n",
    "print(\"  ‚Ä¢ Python code extraction from model outputs\")\n",
    "print(\"  ‚Ä¢ Multi-attempt generation with proper sampling (temp=1.0, min_p=0.05)\")\n",
    "print(\"  ‚Ä¢ Voting and best-attempt metrics across multiple attempts\")\n",
    "print(\"  ‚Ä¢ Training evaluation pipeline integration (compatible with run_arc_tasks_soar.py)\")\n",
    "print(\"  ‚Ä¢ Core utility functions (leveraging existing test suite)\")\n",
    "\n",
    "print(f\"\\nüìà MULTI-ATTEMPT EVALUATION METRICS:\")\n",
    "print(f\"  ‚Ä¢ all_test_correct: Oracle (best attempt) - whether best attempt solves all test grids\")\n",
    "print(f\"  ‚Ä¢ all_train_correct: Perfect training performance across attempts\") \n",
    "print(f\"  ‚Ä¢ min1_train_correct: Tasks with at least some training success\")\n",
    "print(f\"  ‚Ä¢ min1_code_success: Tasks where at least one attempt generated working code\")\n",
    "print(f\"  ‚Ä¢ weighted_voting_pass2: Pass@2 using weighted voting across attempts\")\n",
    "print(f\"  ‚Ä¢ train_majority_pass2: Pass@2 using training majority voting\") \n",
    "print(f\"  ‚Ä¢ timeout_rate: Fraction of attempts that timed out\")\n",
    "print(f\"  ‚Ä¢ max_length_rate: Fraction of attempts that hit max length\")\n",
    "\n",
    "print(f\"\\nüöÄ MULTI-ATTEMPT TRAINING BENEFITS:\")\n",
    "print(f\"  ‚Ä¢ Each validation task generates {NUM_EVAL_ATTEMPTS} attempts during evaluation\")\n",
    "print(f\"  ‚Ä¢ Uses same sampling parameters as run_arc_tasks_soar.py (temp=1.0, min_p=0.05)\")\n",
    "print(f\"  ‚Ä¢ Comprehensive metrics: oracle, voting, code success rates\")\n",
    "print(f\"  ‚Ä¢ Better signal during training - can track improvement across multiple attempts\")\n",
    "print(f\"  ‚Ä¢ Direct compatibility with existing ARC evaluation pipelines\")\n",
    "\n",
    "if passed_count == total_count:\n",
    "    print(f\"\\nüöÄ READY TO PROCEED WITH TRAINING!\")\n",
    "    print(f\"   ‚úÖ Multi-attempt evaluation system validated\")\n",
    "    print(f\"   üìä Will generate {NUM_EVAL_ATTEMPTS} attempts per validation task\")\n",
    "    print(f\"   üéØ Metrics include voting, oracle (best), and code success rates\")\n",
    "    print(f\"   üîÑ Sampling: temperature=1.0, min_p=0.05 (aligned with run_arc_tasks_soar.py)\")\n",
    "else:\n",
    "    failed_tests = [name for name, passed in all_tests if not passed]\n",
    "    print(f\"\\n‚ö†Ô∏è  ISSUES TO INVESTIGATE:\")\n",
    "    for test_name in failed_tests:\n",
    "        print(f\"   ‚Ä¢ {test_name}\")\n",
    "    print(f\"\\nüí° RECOMMENDATION: Fix the failed tests before training to ensure accurate evaluation.\")\n",
    "    print(f\"   üí° TIP: Run utils/tests/ directly for more detailed debugging of core functions.\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "2ejIt2xSNKKp",
    "outputId": "344c14cb-0138-4981-9d85-b1e8856093ec",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H200. Max memory = 139.719 GB.\n",
      "43.455 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We should consider training on completions only!!! which means the response part for the xentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75c0d4b83654eff8fb8d9515e45f794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=192):   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815c999bbfb0488d9a3da23c06e0100f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only # or run the code above if not using unsloth\n",
    "\n",
    "# TO SUPPORT REASONING, WE NEED TO DYNAMICALLY APPLY THE RIGHT MASKING, NOT YET IMPLEMENTED\n",
    "# masks everything between the instruction_part and response_part\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = instruction_tag,\n",
    "    response_part = response_tag,\n",
    "    # force_match=False # comment out to set true for a cleaner masking\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by reasoning and generating Python code.<|im_end|>\\n<|im_start|>user\\nYou are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by generating Python code.\\nYour goal is to analyze input-output grid pairs. The outputs were produced by applying a transformation rule to the inputs. Implement the transformation rules as a Python function.\\nYou should only write the implemented the transformation in code.\\nYou must write code in triple backticks (```python and then ```). You must write a function called 'transform' which takes a single argument, the input grid as 'list[list[int]]', and returns the transformed grid (also as 'list[list[int]]').\\nYou should make sure that you implement a version of the transformation which works in general (at least for all given input-output pairs and test input pairs).\\nThe number in the input grid can be mapped to the following colors: 0:Black; 1:Blue; 2:Red; 3:Green; 4:Yellow; 5:Grey; 6:Pink; 7:Orange; 8:Purple; 9:Brown\\nNow, solve the following ARC-AGI task:\\n# Task to solve:\\n## Input 1 (grid shape: 3 by 3):\\n[[0 7 7] [7 7 7] [0 7 7]]\\n## Output 1 (grid shape: 9 by 9):\\n[[0 0 0 0 7 7 0 7 7] [0 0 0 7 7 7 7 7 7] [0 0 0 0 7 7 0 7 7] [0 7 7 0 7 7 0 7 7] [7 7 7 7 7 7 7 7 7] [0 7 7 0 7 7 0 7 7] [0 0 0 0 7 7 0 7 7] [0 0 0 7 7 7 7 7 7] [0 0 0 0 7 7 0 7 7]]\\n\\n## Input 2 (grid shape: 3 by 3):\\n[[4 0 4] [0 0 0] [0 4 0]]\\n## Output 2 (grid shape: 9 by 9):\\n[[4 0 4 0 0 0 4 0 4] [0 0 0 0 0 0 0 0 0] [0 4 0 0 0 0 0 4 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 4 0 4 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 4 0 0 0 0]]\\n\\n## Input 3 (grid shape: 3 by 3):\\n[[0 0 0] [0 0 2] [2 0 2]]\\n## Output 3 (grid shape: 9 by 9):\\n[[0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 2] [0 0 0 0 0 0 2 0 2] [0 0 0 0 0 0 0 0 0] [0 0 2 0 0 0 0 0 2] [2 0 2 0 0 0 2 0 2]]\\n\\n## Input 4 (grid shape: 3 by 3):\\n[[6 6 0] [6 0 0] [0 6 6]]\\n## Output 4 (grid shape: 9 by 9):\\n[[6 6 0 6 6 0 0 0 0] [6 0 0 6 0 0 0 0 0] [0 6 6 0 6 6 0 0 0] [6 6 0 0 0 0 0 0 0] [6 0 0 0 0 0 0 0 0] [0 6 6 0 0 0 0 0 0] [0 0 0 6 6 0 6 6 0] [0 0 0 6 0 0 6 0 0] [0 0 0 0 6 6 0 6 6]]\\n\\n## Input 5 (grid shape: 3 by 3):\\n[[2 2 2] [0 0 0] [0 2 2]]\\n## Output 5 (grid shape: 9 by 9):\\n[[2 2 2 2 2 2 2 2 2] [0 0 0 0 0 0 0 0 0] [0 2 2 0 2 2 0 2 2] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 0 0] [0 0 0 2 2 2 2 2 2] [0 0 0 0 0 0 0 0 0] [0 0 0 0 2 2 0 2 2]]\\n\\n## Test Input 1 (grid shape: 3 by 3):\\n[[7 0 7] [7 0 7] [7 7 0]]\\n## Expected Test Output 1 (grid shape: 9 by 9):\\n[[7 0 7 0 0 0 7 0 7] [7 0 7 0 0 0 7 0 7] [7 7 0 0 0 0 7 7 0] [7 0 7 0 0 0 7 0 7] [7 0 7 0 0 0 7 0 7] [7 7 0 0 0 0 7 7 0] [7 0 7 7 0 7 0 0 0] [7 0 7 7 0 7 0 0 0] [7 7 0 7 7 0 0 0 0]]\\n<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n```python\\ndef transform(input_grid):\\n    output_grid = []\\n    for i in range(3):\\n        for j in range(3):\\n            row = []\\n            for k in range(3):\\n                for l in range(3):\\n                    row.append(input_grid[i][k] if input_grid[i][k] == input_grid[j][l] else 0)\\n            output_grid.append(row)\\n    return output_grid\\n```<|im_end|>\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ```python\\ndef transform(input_grid):\\n    output_grid = []\\n    for i in range(3):\\n        for j in range(3):\\n            row = []\\n            for k in range(3):\\n                for l in range(3):\\n                    row.append(input_grid[i][k] if input_grid[i][k] == input_grid[j][l] else 0)\\n            output_grid.append(row)\\n    return output_grid\\n```<|im_end|>\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[0][\"labels\"]]).replace(tokenizer.pad_token, \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "M9fa371ShyhB",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's train the model! To resume a training run, set `trainer.train(resume_from_checkpoint = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "yqxqAZ7KJ4oL",
    "outputId": "4b644b12-626b-45c7-fb11-89825ae13bd2",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,600 | Num Epochs = 3 | Total steps = 150\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 264,241,152 of 4,286,709,248 (6.16% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/150 34:22 < 09:51, 0.06 it/s, Epoch 2.32/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>All Test Correct</th>\n",
       "      <th>All Train Correct</th>\n",
       "      <th>Min1 Train Correct</th>\n",
       "      <th>Min1 Code Success</th>\n",
       "      <th>Weighted Voting Pass2</th>\n",
       "      <th>Train Majority Pass2</th>\n",
       "      <th>Max Length Rate</th>\n",
       "      <th>Timeout Rate</th>\n",
       "      <th>Total Tasks</th>\n",
       "      <th>Total Responses</th>\n",
       "      <th>Total Attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e6350c3b8848ef98feab568cbf0386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5563b3c7c9554dbea1a21fe6ce0197f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340f836d98ae469486fb702f75631755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff285fffba4f479189fee4581a5b2747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8c7a294bd64b72a32488aa980300de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61574b59b19b455ea62dfa87bf50bc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5f039324a149eda8bf5934e4123c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531ff53211d94c9b93e52f7cf5b71a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11a32872030430796a685dc76c37a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42814e2fcae482f9d3561665e2786ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3fd04e6db94037975dd7ec5b11ff2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa035234be2489db376902bae6eee6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ed81c677764d41a37af4d32a2a2353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774fa3d686854a44bae6d42065dd7d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7d27cfae74434d8cf33e1398f822b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bd1dd25d4c4a3b9484991300bbc569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the expansion factor based on the input grid size\n",
      "    # The output grid is 6 times larger in each dimension\n",
      "    expansion_factor = 6\n",
      "    rows, co...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the expansion factor based on the input grid size\n",
      "    # T...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "      ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rules based on observed patterns\n",
      "    # In the given examples, the transformation seems to replace certain values with others in a speci...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rules based on observed patterns\n",
      "    # In the g...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule seems to be that each cell with value 2 is replaced with 3, and each cell with value 4 is replaced with 3.\n",
      "    # Additionally, some cells...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule seems to be that each cell with value 2 is replac...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "    # based on their position in the grid. Specifically, it seems that values\n",
      "    # that ar...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with 0\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    output = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat each number in the input grid 3 times in the output ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    output = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        f...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 2:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace all cells with value 0 with 0,\n",
      "    # replace all cells with value 1 with 0,\n",
      "    # replace all cells with value 2 with 0,\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace all cells with value 0 with 0,\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Convert each cell value to the corresponding color code\n",
      "    color_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "    transformed = []\n",
      "    for...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Convert each cell value to the corresponding color code\n",
      "    color_map = {...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to adjacent cells and replace 1 with 4 in certain patterns.\n",
      "    # This is a simplified version that works for...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to adjacent cells and...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to take the sum of the row and column indices of each cell\n",
      "    # and use that sum to determine the new value. However, based on the gi...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to take the sum of the row and column indices ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(1)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        transformed_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                transformed_row.app...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        transformed_row =...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2], [7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 2], [7, 7]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf97daa48e5f45d49e40a0100fd9d65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a3cbeabb724b4581bcf3b0822330c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d0a82bfb154fb98db3ce6a5ede9c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c31dc20930b460b88c251327f70c8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f7f27568144a10ae5d3ab2dd7b2869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac541c36e8744128f1ff21def4f300f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b0b4cb7e7d4634bae64b9cb949a4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4433b128d940ee80857f1aac60f9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e8e3cb71b44790a149443b12d7b9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd24ffdf0c245cfadb624ecdff4bac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b798424e40264bb3973338aee4f4c7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddcea7455054e96b30c5e13d767a572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad45b9a9cbb46ecade7ea98f9ed47c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c40e7dc8704ba9a87e122ce504da5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8220a6be859c4b17af7dfec3008d4fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7444a71b26c48cf8ab300a8581cccab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(grid)\n",
      "    output_size = original_size * 3  # Each cell is repeated 3 times in each dimension\n",
      "    \n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(grid)\n",
      "    o...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Mapping from original numbers to new numbers based on the given transformations\n",
      "    # The mapping is determined by observing the input-output pairs\n",
      "    # 0 -> 0,...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Mapping from original numbers to new numbers based on the given transform...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain positions\n",
      "    # The rule appears to be: replace 2 with 8 in a pattern that forms a ring around the ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain positions\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Apply the transformation rule\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to be:\n",
      "    # 1. Convert all 0s to 0s\n",
      "    # 2. Convert all 2s to 2s\n",
      "    # 3. Convert all 4s to 3s\n",
      "    # 4. Convert all 8s to 2s\n",
      "    # 5. ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to be:\n",
      "    # 1. Convert all 0s to 0s\n",
      "    # 2. Co...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Replace values based on the transformation rule\n",
      "    # 0 remains 0, 1 becomes 2, 2 becomes 3, 3 becomes 1, 4 becomes 4, 5 becomes 5, 6 becomes 7, 7 becomes 8, 8 b...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Replace values based on the transformation rule\n",
      "    # 0 remains 0, 1 beco...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat each number in the input grid 3 times in the output grid\n",
      "       ...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # The transformation rule is: for each cell in the grid, if the value is 2, 3, or 8, \n",
      "    # it is replaced with a sequence of values that spread outward from...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # The transformation rule is: for each cell in the grid, if the value...\n",
      "    Program extracted: True\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(0)\n",
      "            elif num == 6:...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to be taking the first occurrence of each color in each row and column\n",
      "    # and then creating a new grid based on those values. However...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to be taking the first occurrence of each color ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # This transformation involves propagating values to the right and down, and replacing certain values with others\n",
      "    # The exact transformation is complex and not...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation involves taking the sum of the digits in each row and column,\n",
      "    # then mapping the sum to a specific number based on the output patterns.\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation involves taking the sum of the digits in each row and ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "        1: 1,   # Blue\n",
      "        2: 2,   # Red\n",
      "        3: 3,   # Green\n",
      "        4: 4,   # Yellow\n",
      "    ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "        1:...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    # This function is a general implementation that maps the input grid to the output grid\n",
      "...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(4)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 3, 2, 2, 0, 0], [3, 3, 2, 2, 0, 0], [7, 7, 8, 8, 0, 0], [7, 7, 8, 8, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 2], [7, 2]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4bdb0470cb44d18ad1be916efd33b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe2b71d55984f38bd2bfd7b9dcc90b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbaec29631b4ca283964f77566702c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a6fd53f7f448ec9281c48bc0fe09c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2951e597e0ce456ab592ac3c1c0519c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84019fde9b0040189ede4095dc121c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10f5c10a8f04912ad4d354aa265a747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b324a4fbc6431d82c053a1da03fe4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c3ef8bfa7d4217a93cf6f935fb1fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5312c7bcc382433aba2b95dab1cbef4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12db7ff2fe9f4b6c9b7b5a351baf2175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d698226c3a5a47a6882ce6b86598c815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fba8e221a6b42418c01e4e05e59d7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ccd7c488c047409a672bba5e5ccf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2710440c0724472a840379555fd24a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc678105e9d0437e913b04eb5764b798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input size\n",
      "    # Since the input is 2x2 and output is 6x6, the scaling factor is 3\n",
      "    scale = 3\n",
      "    # Create the...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input size\n",
      "    # Since th...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    # This is a simplified version based on observing the patterns in the examples\n",
      "    # The...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rule: replace 2 with 8 in certain patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Transformation rule: Replace each cell with the value from the corresponding row in the output grid\n",
      "    # This is a placeholder for the actual transformati...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Transformation rule: Replace each cell with the value from the corr...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 0:\n",
      "                new_row.append(0)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace all values except 0 with 0\n",
      "    # This is based on observing that in all input-output pairs, non-zero values are replaced wi...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace all values except 0 with 0\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new 9x9 grid filled with 0s\n",
      "    result = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Iterate over each cell in the input grid\n",
      "    for i in rang...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new 9x9 grid filled with 0s\n",
      "    result = [[0 for _ in range(9)] ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    new_grid = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in rang...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    new_grid = ...\n",
      "    Program extracted: True\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Initialize the result grid with zeros\n",
      "    result = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in the input gr...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Initialize the result grid with zeros\n",
      "    result = [[0 for _ in range(len...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the corners of the grid\n",
      "    top_left = grid[0][0]\n",
      "    top_right = grid[0][-1]\n",
      "    bottom_left = grid[-1][0]\n",
      "    bottom_right = grid[-1][-1]\n",
      "    \n",
      "    # Cr...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the corners of the grid\n",
      "    top_left = grid[0][0]\n",
      "    top_right =...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 8, 1 with 3, and 2 with 4 in the grid.\n",
      "    # This is based on the observed patterns in the input-output pa...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace the value 4 with 8, 1 with 3, and 2...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      "    for row in grid:\n",
      "        for val in row:\n",
      "            unique_values.add(val)\n",
      "    \n",
      "    ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Ye...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,  # Bla...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Extract the dimensions of the input grid\n",
      "    rows = len(input_grid)\n",
      "    cols = len(input_grid[0]) if rows > 0 else 0\n",
      "    \n",
      "    # Create a new grid with the ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Extract the dimensions of the input grid\n",
      "    rows = len(input_grid)...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 3, 3, 2, 2, 2], [7, 7, 7, 8, 8, 8]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 2], [7, 2]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84482b274a6a49899a98165bcd99f11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc3002f70984a209d5e0e364efae7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cba877abdc24b61b3571720239808e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d127d9a1205e4e36bc118284c0e4d593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93087aa19f4d4f24bc5b4c8a7ea9b1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46207686c9c409ca40333035b0eeb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef97c9e78334b19878cde68ce94949e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0728e1318b43489e0c3740927c776b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f561c1877974c3f9c69470514e2953a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d43d6468434909a2faa1657cfa3de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6171aab13b4d6383f65c34cb661124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5641e82d8f4549dd987ac88e0296ce0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcefd00dbd6147fbb76a772b7b66d67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c810791fb33d4a9d9c3b4178446693bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa710a2cbea458ca48295f80de9f04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cd316af2e145b6a818283473c7f4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    rows, cols = len(input_grid), len(input_grid[0])\n",
      "    new_rows = 6\n",
      "    new_cols = 6\n",
      "    transformed = [[0 for _ in range(new_cols)] for _ in range(new_rows)]\n",
      "...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    rows, cols = len(input_grid), len(input_grid[0])\n",
      "    new_rows = 6\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "        1: 2,   # Blue -> 2\n",
      "        2: 2,   # Red -> 2\n",
      "        3: 2,   # Green -> 2\n",
      "        4:...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,   # Black\n",
      "      ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in r...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 4:\n",
      "                new_row.append(1)\n",
      "       ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 0:\n",
      "                new_row.append(0)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Replace all values with 0 except for 2, 3, 8, and 9, which are kept as is\n",
      "    # This transformation is based on the observed patterns in the input-output pairs\n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Replace all values with 0 except for 2, 3, 8, and 9, which are kept as is...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat each number in the original grid 3 times in the new grid\n",
      "       ...\n",
      "    Extracted code: def transform(grid):\n",
      "    result = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in ro...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to spread the value 2 to adjacent cells in all directions\n",
      "    # and to spread the value 3 to adjacent cells in all directions\n",
      "    # Ad...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(row))] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the coordinates of the corners of the input grid\n",
      "    # The input grid is 30x30, so the corners are at (0,0), (0,29), (29,0), (29,29)\n",
      "    # The output gri...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the coordinates of the corners of the input grid\n",
      "    # The input ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to neighboring cells\n",
      "    # and replace 1 with 4 in certain contexts, but the general rule is to propagate 4 t...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to neighboring cells\n",
      "...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      "    for row in grid:\n",
      "        for val in row:\n",
      "            unique_values.add(val)\n",
      "    \n",
      "    ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      " ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,  # Black\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with specific values based on their positions.\n",
      "    # From the input-output pairs, it seems that th...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values with speci...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    # The transformation seems to involve selecting specific cells from the input grid\n",
      "    #...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[8, 3, 8, 3, 8, 3], [3, 8, 3, 8, 3, 8], [8, 3, 8, 3, 8, 3], [3, 8, 3, 8, 3, 8], [8, 3, 8, 3, 8, 3], [3, 8, 3, 8, 3, 8]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[2, 2], [2, 2]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76778913e12a4390bf0ce195f6ec5c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ed2cd5a7b446c1b620975a9e3741ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2275979040c42fa87f18c9252e9cc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577a707038c2432f8df524704f8475c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16f830585dc47da850cf725f815c40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efe2902568f48de8569e49443403b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef756ea7957d4e1bb7c437b9b380d7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152af0f0faf64c319fbc224d1646943b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1ec490d03b4600b69a32c01f1c5738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76bb99442b74af980539facf72b6d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a7e98919b34e2992f9f59482d1f0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dad7fe3f1b44d2a9c0d8bb498a4cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c7e23ef324d87b7a96454917ebccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740e5c4c66bb4532a1b72b6cab066ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25fc13879ed46a78e894d6866c1fb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031713fd4ac64f9283e071872af57924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input grid size\n",
      "    # Since the output is 6x6 for 2x2 input, the scaling factor is 3\n",
      "    scale = 3\n",
      "    rows, cols...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input grid size\n",
      "    # Sin...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 2,  # Blue -> 2\n",
      "        2: 2,  # Red -> 2\n",
      "        3: 3,  # Green\n",
      "        4: 7,  # Ye...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "       ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace certain values with specific numbers:\n",
      "    # 0: remains 0\n",
      "    # 1: remains 1\n",
      "    # 2: remains 2\n",
      "    # 3: remains 3\n",
      "    # 4: ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace certain values with specific number...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implementation of the transformation rule\n",
      "    # This is a hypothetical transformation based on observed patterns\n",
      "    # The actual rule might involve color propag...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation based on observed patterns\n",
      "    # The transformation appears to involve replacing certain colors with others\n",
      "    # and expanding or m...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation based on observed patterns\n",
      "    # The transfo...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to replace all values except 0 with 0\n",
      "    # This is based on the observed pattern in the input-output pairs where non-zero values are ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to replace all values except 0 with 0\n",
      "    # Th...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Initialize the output grid with zeros\n",
      "    output = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Iterate over each cell in the input grid\n",
      "    for i ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Initialize the output grid with zeros\n",
      "    output = [[0 for _ in ran...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 2:\n",
      "                new_row.append(2)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Initialize the result grid with zeros\n",
      "    result = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Initialize the result grid with zeros\n",
      "    result = [[0 for _ in range(len...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Convert the grid to a list of lists of integers\n",
      "    # The transformation rule is to take the first row of the input grid as the first row of the output,\n",
      "    # an...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Convert the grid to a list of lists of integers\n",
      "    # The transformation ...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to neighboring cells and replace 1 with 4 where possible\n",
      "    # This is a simplified version that works for th...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to propagate the value 4 to neighboring cells ...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implementation of the transformation rule based on observed patterns\n",
      "    # This is a placeholder implementation; the actual rule needs to be derived from the giv...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implementation of the transformation rule based on observed patterns\n",
      "    ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      "        5...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the grid\n",
      "    # based on their positions. From the input-output examples, it seems that:\n",
      "    # -...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    transformed = []\n",
      "    for row in input_grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            # Appl...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    transformed = []\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(2)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2], [7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 2], [7, 7]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400bddd96a634dcf873253ec68543e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14adb9acaf5d4aa88cb604f4014329c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f517b857f54284bf2efbcbe8372e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b9854a69d46ab8bb12875d92ca824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afdccf766d343619e194c3e7fc8bae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955b7484a9e4417188d9b60bb6769df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c738621e75c64cbcbca0bbd634795c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640b5a98951c4bc7827b2297dd720f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1504d95dc8024b61855eb8b5531f672f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a88041311734ebbbfcb34f25994e283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68145a25b8644250a1cde1e0e5128b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d5a9b3911c49d19ae29b432d373384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff881c453de4907891332a6e7b2954b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9559c337610747acb1f80c6a23a05cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a17f6f746f4d708264d1f25b876b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c8f900cf2a466f8255e443c1171eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input grid size\n",
      "    # For 2x2 input, the output is 6x6, so the scaling factor is 3\n",
      "    scale = 3\n",
      "    # Create a n...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the scaling factor based on the input grid size\n",
      "    # For...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "      ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed = [row[:] for row in grid]\n",
      "    \n",
      "    # Iterate over each cell in the grid\n",
      "    for i in r...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a copy of the grid to avoid modifying the original\n",
      "    transformed...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rule: replace 0 with 1, 1 with 2, 2 with 3, 3 with 4, 4 with 5, 5 with 6, 6 with 7, 7 with 8, 8 with 9, 9 with 0\n",
      "    # This is a cyclic...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the transformation rule: replace 0 with 1, 1 with 2, 2 with 3, 3 w...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Check if the grid is empty\n",
      "    if not grid or not grid[0]:\n",
      "        return grid\n",
      "    \n",
      "    # Initialize the result grid\n",
      "    result = [[0 for _ in range(len(grid[0])...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Check if the grid is empty\n",
      "    if not grid or not grid[0]:\n",
      "        return...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be replacing certain values in the grid\n",
      "    # based on their positions. Specifically, it seems that values 3, 8, and 9 are\n",
      "   ...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            # Repeat each number in the input grid 3 times in the output grid\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "    result = [row[:] for row in input_grid]\n",
      "    \n",
      "    # Iterate through each cell in the gri...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Create a copy of the input grid to avoid modifying the original\n",
      "   ...\n",
      "    Program extracted: True\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # The transformation seems to involve spreading values to neighboring cells\n",
      "    # and replacing 0s with the ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Transform the grid based on the observed pattern\n",
      "    # The transformation...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Convert each cell value to its corresponding color code\n",
      "    # The color code is determined by the value in the grid: 0-9 map to 0-9 respectively\n",
      "    # We then ap...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Convert each cell value to its corresponding color code\n",
      "    # The color c...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # This transformation rule seems to be propagating values from adjacent cells and replacing certain values with others.\n",
      "    # Based on the input-output pairs, it a...\n",
      "    Extracted code: def transform(grid):\n",
      "    # This transformation rule seems to be propagating values from adjacent cel...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      "    for row in grid:\n",
      "        for val in row:\n",
      "            unique_values.add(val)\n",
      "    \n",
      "    ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Extract the unique values from the input grid\n",
      "    unique_values = set()\n",
      " ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,\n",
      "        1: 1,\n",
      "        2: 2,\n",
      "        3: 3,\n",
      "        4: 4,\n",
      "        5: 5,\n",
      "        6: 6,\n",
      "        7: 7,\n",
      "  ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_mapping = {\n",
      "        0: 0,\n",
      "        1: 1...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 0:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the transformation rules based on the observed patterns\n",
      "    # The transformation seems to involve:\n",
      "    # 1. Keeping the same number in the grid\n",
      "    # 2. C...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(4)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 3, 3, 2, 2, 2], [3, 3, 3, 2, 2, 2], [3, 3, 3, 2, 2, 2], [7, 7, 7, 8, 8, 8], [7, 7, 7, 8, 8, 8], [7, 7, 7, 8, 8, 8]], 'error': '', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[2, 2], [2, 2]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vLLM predict] batch size = 32, generating 8 attempts per task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4721cd88824dc1af857cee4fc65af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30466288cd3428499c9618ed1baf863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32204960b2d485a92dfcf98adcf7ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdfca0d01ee494681a36e773a4ad533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d2afb311414d0d81d1cd388bc5e060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd554dd67dc4469bc51f6e92e58fb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52733dba1c5d4233a311d92d59d2d01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8585ff4c504d420bb998b6144b7b4273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7116b5f946a940c3b5d22807a5c296a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278976605b0d42a192f100c9d8b90c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce903ca484b4a048878d1de91cd45f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7aca26a1e54200b3db8636134eca31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da40be49aad045b0aaeb091f22544d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef2368d95d34692ad4f76c85f4197f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3368b19a1634bc68fc5fc9a7dc17d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836f51920dd0458e8894b9d5aec1cc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MULTI-ATTEMPT EVALUATION: 8 attempts per task from trainer prediction_step\n",
      "üìä Processing 256 predictions for 32 tasks (8 attempts each)\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(input_grid)\n",
      "    output_size = original_size * 3  # Each original cell is repeated 3 times in ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Determine the size of the output grid\n",
      "    original_size = len(input...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping based on the given color codes\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 2,  # Blue -> 2\n",
      "        2: 2,  # Red -> 2\n",
      "        3: ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping based on the given color codes\n",
      "    color_map = {...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell in row:\n",
      "            if cell == 2:\n",
      "                new_row.append(8)\n",
      "            elif ce...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for cell...\n",
      "    Program extracted: True\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all 0s with the value from the first non-zero cell in the first row.\n",
      "    # 2. Replace all other cells wit...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be:\n",
      "    # 1. Replace all 0s with the v...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implement the transformation rule based on observed patterns\n",
      "    # This is a simplified example; the actual transformation might be more complex\n",
      "    # This solut...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Implement the transformation rule based on observed patterns\n",
      "    # This i...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule appears to be: replace all values that are not 0 with 0\n",
      "    # This is evident from the input-output pairs where non-zero values are repla...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule appears to be: replace all values that are not 0 ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # Initialize the output grid with zeros\n",
      "    output = [[0 for _ in range(9)] for _ in range(9)]\n",
      "    \n",
      "    # Fill the output grid based on the input grid\n",
      "    fo...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # Initialize the output grid with zeros\n",
      "    output = [[0 for _ in ran...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(input_grid):\n",
      "    # The transformation rule appears to be: for each cell in the grid, if the value is 2, 3, 7, or 8, \n",
      "    # we replace it with the same value but propagate it ...\n",
      "    Extracted code: def transform(input_grid):\n",
      "    # The transformation rule appears to be: for each cell in the grid, i...\n",
      "    Program extracted: True\n",
      "    Attempt 0: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 5:\n",
      "                new_row.append(0)\n",
      "            elif num ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "    Attempt 1: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation rule is to take the first element of each row in the input grid and use it as the value for the corresponding position in the output grid.\n",
      "   ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation rule is to take the first element of each row in the i...\n",
      "    Program extracted: True\n",
      "    Attempt 2: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Implementation of the transformation rule\n",
      "    # This transformation replaces certain values based on the given input-output pairs\n",
      "    # The transformation involv...\n",
      "    Extracted code: None...\n",
      "    Program extracted: False\n",
      "    Attempt 3: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # The transformation seems to involve taking the sum of the row and column indices\n",
      "    # and using that to determine the value in the new grid. However, based on t...\n",
      "    Extracted code: def transform(grid):\n",
      "    # The transformation seems to involve taking the sum of the row and column ...\n",
      "    Program extracted: True\n",
      "    Attempt 4: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "        1: 1,  # Blue\n",
      "        2: 2,  # Red\n",
      "        3: 3,  # Green\n",
      "        4: 4,  # Yellow\n",
      "     ...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Define the color mapping\n",
      "    color_map = {\n",
      "        0: 0,  # Black\n",
      "       ...\n",
      "    Program extracted: True\n",
      "    Attempt 5: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val in row:\n",
      "            if val == 0:\n",
      "                new_row.append(0)\n",
      "            elif val ...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for val ...\n",
      "    Program extracted: True\n",
      "    Attempt 6: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    \n",
      "    # Iterate over each cell in the g...\n",
      "    Extracted code: def transform(grid):\n",
      "    # Create a new grid with the same dimensions\n",
      "    new_grid = [[0 for _ in ra...\n",
      "    Program extracted: True\n",
      "    Attempt 7: Generated text preview: \n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num in row:\n",
      "            if num == 4:\n",
      "                new_row.append(3)  # 4 (Yellow) becomes...\n",
      "    Extracted code: def transform(grid):\n",
      "    transformed = []\n",
      "    for row in grid:\n",
      "        new_row = []\n",
      "        for num ...\n",
      "    Program extracted: True\n",
      "\n",
      "üîç DEBUG: Checking data structure for voting...\n",
      "\n",
      "Task 0:\n",
      "  task_data keys: dict_keys(['task_id', 'train', 'test'])\n",
      "  num attempts: 8\n",
      "  Attempt 0:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: False\n",
      "    test_results sample: {'correct': False, 'prediction': None, 'error': 'list index out of range', 'timeout': False}\n",
      "  Attempt 1:\n",
      "    Keys: ['task_id', 'attempt', 'program', 'program_extracted', 'code_ran', 'train_results', 'test_results', 'test_predicted', 'all_train_correct', 'all_test_correct', 'any_timeout', 'max_length', 'response_text', 'train_accuracy', 'is_transductive']\n",
      "    all_test_correct: False\n",
      "    all_train_correct: False\n",
      "    program_extracted: True\n",
      "    code_ran: True\n",
      "    test_results sample: {'correct': False, 'prediction': [[3, 2], [7, 5]], 'error': '', 'timeout': False}\n",
      "\n",
      "üîç VOTING DEBUG: Checking correct predictions for voting compatibility...\n",
      "\n",
      "Task 0: 0 correct attempts out of 8\n",
      "\n",
      "üîç DEBUG: Checking transduction filtering...\n",
      "\n",
      "Task 0: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 8/8\n",
      "\n",
      "Task 1: 8 total attempts\n",
      "  Has is_transductive flag: True\n",
      "  Non-transductive attempts: 7/8\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "pCqnaKmlO1U9",
    "outputId": "3e2fcdf8-501c-4707-fcbb-7c1b4700bb9d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a few examples\n",
    "for i in range(2):\n",
    "    example = data[\"train\"][i]\n",
    "    print(f\"\\nExample {i} text length: {len(example['text'])}\")\n",
    "    print(f\"Last 200 chars: {example['text'][-200:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "ekOmTR1hSNcr",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model via Unsloth native inference! According to the `Qwen-3` team, the recommended settings for reasoning inference are `temperature = 0.6, top_p = 0.95, top_k = 20`\n",
    "\n",
    "For normal chat based inference, `temperature = 0.7, top_p = 0.8, top_k = 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR3gIAX-SM2q",
    "outputId": "b813e560-8e4c-4491-c8be-18067bc07639"
   },
   "outputs": [],
   "source": [
    "# Legacy inference testing example - replaced by actual test in cell 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"validation\"]['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j873RMcEi9uq",
    "outputId": "3b358da9-aedd-48e3-a345-1ed0ca0bd3fa"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\" : \"system\", \"content\" : \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n",
    "    {\"role\" : \"user\", \"content\" : \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation  \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\n```python\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n```\\n\"}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = False, # Disable thinking\n",
    ")\n",
    "\n",
    "# from transformers import TextStreamer\n",
    "# _ = model.generate(\n",
    "#     **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "#     max_new_tokens = 8000, # Increase for longer outputs!\n",
    "#     # temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "#     temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "#     # temperature = 0.01,\n",
    "#     streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "# )\n",
    "\n",
    "# text = data[\"validation\"]['prompt'][0]\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "input_ids = inputs[\"input_ids\"]  # Extract for convenience\n",
    "\n",
    "output_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    # temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "    # temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "    temperature=0.1, # BEST FOR SINGLE ATTEMPTS\n",
    ")\n",
    "\n",
    "# Slice to skip the prompt portion in output\n",
    "generated_tokens = output_ids[0][input_ids.shape[-1]:]\n",
    "generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use extract_python_code from utils (SOAR approach)\n",
    "code = extract_python_code(generated_text)\n",
    "\n",
    "if code:\n",
    "    print(code)\n",
    "    exec(code, globals())  # Defines `transform()` in global scope\n",
    "else:\n",
    "    raise ValueError(\"Could not extract Python code from generated text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative transform implementations commented out - using model generated version above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------- helper --------------------\n",
    "def safe_transform(grid):\n",
    "    grid = grid.copy()        # <‚Äë‚Äë clone so the original stays unchanged\n",
    "    try:\n",
    "        return transform(grid)\n",
    "    except Exception as err:\n",
    "        print(f\"[safe_transform] transform() failed ‚Äì {err}\")\n",
    "        return np.zeros_like(grid)\n",
    "\n",
    "# -------------------- test case -----------------\n",
    "test_case = {\n",
    "    \"input\": np.array([  # convert to np.array for convenience\n",
    "        [5, 0, 5, 5, 0, 0, 5, 0, 5, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5]\n",
    "    ]),\n",
    "    \"output\": np.array([\n",
    "        [5, 0, 5, 5, 0, 0, 5, 0, 5, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "        [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [2, 0, 2, 2, 0, 0, 2, 0, 2, 5]\n",
    "    ])\n",
    "}\n",
    "\n",
    "# -------------------- run & plot ----------------\n",
    "predicted_output = safe_transform(test_case[\"input\"])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "titles = [\"Input\", \"Predicted Output\", \"Ground Truth Output\"]\n",
    "grids  = [test_case[\"input\"], predicted_output, test_case[\"output\"]]\n",
    "\n",
    "for ax, grid, title in zip(axs, grids, titles):\n",
    "    im = ax.imshow(grid, cmap=\"viridis\", vmin=0, vmax=5)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference testing section ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving, loading finetuned models\n",
    "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
    "\n",
    "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upcOlWe7A1vc",
    "outputId": "0a9c6608-d1f5-4779-8ad4-7e3a46e2258d"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "You can use this also to load a checkpoint!!! i.e. an intermediate checkpoint from training, so you can then push it to hub.\n",
    "\n",
    "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKX_XKs_BNZR"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        # max_seq_length = 30000,\n",
    "        load_in_4bit = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f422JgM9sdVT"
   },
   "source": [
    "### Saving to float16 for VLLM\n",
    "\n",
    "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder, login\n",
    "\n",
    "# Call this at the top of your script / notebook\n",
    "if HfFolder.get_token() is None:   # no token cached or in $HF_TOKEN\n",
    "    login()                        # interactive prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = \"Qwen2.5-Coder-7B-Instruct-gemini_synth_50_random_split_1_training-20250723-113848\"\n",
    "print(f\"Pushing to Trelis/{run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "model.push_to_hub(f\"Trelis/{run_name}\")\n",
    "tokenizer.push_to_hub(f\"Trelis/{run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHjt_SMYsd3P"
   },
   "outputs": [],
   "source": [
    "# # Merge to 16bit\n",
    "# if False:\n",
    "#     model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "# if True: # Pushing to HF Hub\n",
    "#     model.push_to_hub_merged(f\"Trelis/{run_name}\", tokenizer, save_method = \"merged_16bit\")\n",
    "\n",
    "# # Merge to 4bit\n",
    "# if False:\n",
    "#     model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
    "# if False: # Pushing to HF Hub\n",
    "#     model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
    "\n",
    "# # Just LoRA adapters\n",
    "# if False:\n",
    "#     model.save_pretrained(\"model\")\n",
    "#     tokenizer.save_pretrained(\"model\")\n",
    "# if False: # Pushing to HF Hub\n",
    "#     model.push_to_hub(\"hf/model\", token = \"\")\n",
    "#     tokenizer.push_to_hub(\"hf/model\", token = \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCv4vXHd61i7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GGUF / llama.cpp Conversion\n",
    "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
    "\n",
    "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
    "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
    "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
    "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
    "\n",
    "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqfebeAdT073"
   },
   "outputs": [],
   "source": [
    "# Save to 8bit Q8_0\n",
    "if False:\n",
    "    model.save_pretrained_gguf(\"model\", tokenizer,)\n",
    "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
    "# And change hf to your username!\n",
    "if False:\n",
    "    model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# Save to 16bit GGUF\n",
    "if False:\n",
    "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "if False: # Pushing to HF Hub\n",
    "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# Save to q4_k_m GGUF\n",
    "if False:\n",
    "    model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if False: # Pushing to HF Hub\n",
    "    model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
    "\n",
    "# Save to multiple GGUF options - much faster if you want multiple!\n",
    "if False:\n",
    "    model.push_to_hub_gguf(\n",
    "        \"hf/model\", # Change hf to your username!\n",
    "        tokenizer,\n",
    "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOfJSxs_VJjz"
   },
   "source": [
    "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
    "\n",
    "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
    "\n",
    "Some other links:\n",
    "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
    "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
    "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
    "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
    "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
    "\n",
    "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00d671d686af43c38b12a9448c5bbf06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0340990c29e64f8d9a9ba37f09c55659": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05997290010e49259742f1a560a6aac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_140760e267d84afc852df8cb470d86d5",
       "IPY_MODEL_b22bcb2a7b24497581994b71b02f755d",
       "IPY_MODEL_3c5c945a8daf4b3f83741ecbc26804b2"
      ],
      "layout": "IPY_MODEL_2170ab68e5724b4b9c77c039c57f8e0a"
     }
    },
    "062f278ab1c94d8099e06074e0cd360c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06c646d514b448628424dc8c772994de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8be1618a9f8840af8d89103c37ef02ef",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f0b8a9e00c0d4cc1aff1e3a748a8f039",
      "value": "chat_template.jinja:‚Äá100%"
     }
    },
    "0940df31fc9047ccae4870b7d2c89b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09cd31746a174e96bb346e1afc7b3c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64eb3128b25448b48268ec61cac289d1",
      "max": 237,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc277d60ad4a419a94ded28a1c27a9f4",
      "value": 237
     }
    },
    "09ce664a0a404087a9fe53a5c2d5316e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d254a8222d42b093ff8f229a6fe503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ab824fcbf0e46f7bbe75af9f662c31a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b3d64dd05f841d68ad472ce933e36d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d0852d9ebb2409ea51650f538dd1621": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_062f278ab1c94d8099e06074e0cd360c",
      "max": 707,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ad57df96bec4267a220a739cfc72bc1",
      "value": 707
     }
    },
    "0e112f4ad6974529a4c4f583e6a73950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e997f45717c44e1944d510ae6c51fb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f195b35b0a7416c8d395c17dea7fafa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fab32e1222f4431a255a36df0a22a35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "100a0b5f637b4dc1a1da400e8f363678": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "109c736c8b99496e8721f9595c54eb6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f89daea726144ded892113a161649b64",
       "IPY_MODEL_9f0108d9201f40599facfccf668a6e84",
       "IPY_MODEL_927c60cd1f0d4a32a1ff9427a96a3246"
      ],
      "layout": "IPY_MODEL_fb6f38d9dd1e49ec8fdfb7ca7ea363a2"
     }
    },
    "12d7229f7d81488e93689d4269ee48ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d7cac449954aafa26c6b5bcb6e031f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26dbcdc380e1404687020cbd9bf38513",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2abd7191bff846198b2fb033da32f8c8",
      "value": "‚Äá11.4M/11.4M‚Äá[00:00&lt;00:00,‚Äá33.3MB/s]"
     }
    },
    "132dbcd182314c10a906d16f43f94896": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_231a411ab9c241a3b9b8a98617ff8ad4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c688c828118f41859a3d71c54b62354a",
      "value": "README.md:‚Äá100%"
     }
    },
    "13779546fa624d448862777f344bb2a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "140760e267d84afc852df8cb470d86d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0340990c29e64f8d9a9ba37f09c55659",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5deffaef73d14116a8b1bcf8d46df2fc",
      "value": "Generating‚Äácot‚Äásplit:‚Äá100%"
     }
    },
    "145cc80490fa42258fe6e5a643b57dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c3887400b6d34c30a54c6af94c2b612d",
       "IPY_MODEL_7efa9f507c8546bb9b0b5d47be527c25",
       "IPY_MODEL_74267e9cd64d44b58bdbd7dad03b681d"
      ],
      "layout": "IPY_MODEL_dd2adf3e30304398b8340253dbd4489a"
     }
    },
    "153259764d2b45e0bc02938d6909d40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d9deebcb56f40e3ace1f52e862c1c31",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_100a0b5f637b4dc1a1da400e8f363678",
      "value": "‚Äá100000/100000‚Äá[00:04&lt;00:00,‚Äá6952.47‚Äáexamples/s]"
     }
    },
    "179e343762ba440cbc094e0e85b4ee84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cb88502cb1643a8927049baf40d56b7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c37a4b08afa84b64b40ebbe08cbfb018",
      "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
     }
    },
    "196f35f21b97476a9814acd96dbec717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ad6055d2ba2481c83b1b136e5898986",
       "IPY_MODEL_8147cc77ce3941c290982d21c42f9f66",
       "IPY_MODEL_f1af17f7a7ee405dabd07f41b6b786d7"
      ],
      "layout": "IPY_MODEL_aeb720eea25149deb34e6844a8bdd2c5"
     }
    },
    "1a09813436c24b5ea68e652254288ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b2a213c48f04667a243cc6dc6c43b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afb3e794edf046a9b594fcbb99acb8ea",
      "max": 982,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1a6d94a50aa4ac29965cb1693c9c5c3",
      "value": 982
     }
    },
    "1c2573a314d94fc1a2f414adfa9d259a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d31954fe1804140bcac71e3d4102fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f9eba179bf847dcb47dbda34611459a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8f15be1afc44472bff560ca7316873a",
      "max": 10534,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a40e10f372644d80b2830d0f42fcde6c",
      "value": 10534
     }
    },
    "2068eb23121440ec83d8cd117b4c6ba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7054b1bcb73e4515afd29b42a32b20c5",
       "IPY_MODEL_09cd31746a174e96bb346e1afc7b3c8b",
       "IPY_MODEL_802bdf3c4293448bb00b625722f1a9f6"
      ],
      "layout": "IPY_MODEL_f7c27321d53047479c1ed45b5d5109f6"
     }
    },
    "2167f3dc7050467a9f19f3f885cfb09b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2170ab68e5724b4b9c77c039c57f8e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "231a411ab9c241a3b9b8a98617ff8ad4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23791684cb5349c4853cffb4e72ebe1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aefab33f6f345869c19899ca2952df1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_881919ffdd7940839c8b40edba7f8c01",
      "value": "‚Äá1.56G/1.56G‚Äá[00:16&lt;00:00,‚Äá730MB/s]"
     }
    },
    "247ee0a6f4e64e5ca0a435d243690d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c1c1bc584cb456c9d07f4ac267cf2c5",
       "IPY_MODEL_cc9479fb190742fd865613680e87e535",
       "IPY_MODEL_ae9317b34ba341c4ac40797da3ac2478"
      ],
      "layout": "IPY_MODEL_5012456fc82e47aca5a69f52a36cb8f5"
     }
    },
    "247f2a4074cc4fb0956ef06b10b5e5da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26dbcdc380e1404687020cbd9bf38513": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2857e876d47a49bbadf3494b1864c1bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b9748337a1c4291ac882194b16eb032",
      "max": 19252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1b000b08af549689d1be5f0289bf2c3",
      "value": 19252
     }
    },
    "28d439d23bf54688963517fbdb482339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0940df31fc9047ccae4870b7d2c89b3d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0b3d64dd05f841d68ad472ce933e36d7",
      "value": "‚Äá3/3‚Äá[00:45&lt;00:00,‚Äá13.54s/it]"
     }
    },
    "2abd7191bff846198b2fb033da32f8c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aefab33f6f345869c19899ca2952df1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b72ac21d79c459395682f6692c4325f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b9748337a1c4291ac882194b16eb032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c04e534215f4d40b103be09e300b744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cfa55ba5d3345cda1cf83cde925a7fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6367d6b72c37406cafa63daa77263ca2",
       "IPY_MODEL_8f14d9c07bf846a682c1c44f4a2d2410",
       "IPY_MODEL_6e020b0421e84d9a9a8f0b68aa10cbee"
      ],
      "layout": "IPY_MODEL_13779546fa624d448862777f344bb2a6"
     }
    },
    "2de7e147b2e14db38243c7656a29f0e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dff2433978a477582b995bc6abafe68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b998e55dd17b44d7a8c23ac427619036",
       "IPY_MODEL_5210d369018a44d4ad2fbd26190aca9b",
       "IPY_MODEL_64b00e376bb142c88a690757f27b8294"
      ],
      "layout": "IPY_MODEL_09ce664a0a404087a9fe53a5c2d5316e"
     }
    },
    "2f4608614780453a826e3ad59817d7ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d4fb1807bc4ec0840d63ef0bf2e0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32000eaf412840388188523be1033cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34b0ab119eab40eda8b7a551642e0e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71c37d1f12294e858ceb337d2e37e375",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_00d671d686af43c38b12a9448c5bbf06",
      "value": "special_tokens_map.json:‚Äá100%"
     }
    },
    "36eed804652e4c6fb7fe2e969228decd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ad57df96bec4267a220a739cfc72bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ad6055d2ba2481c83b1b136e5898986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d574f195dfc4bc4b1ca86863d97e597",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c8faa5be5b88425298b5655a8f507a2a",
      "value": "merges.txt:‚Äá100%"
     }
    },
    "3c2e07218b764906a278d6a367153548": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db172381abdf4bb0a84417882fc462be",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0ab824fcbf0e46f7bbe75af9f662c31a",
      "value": "‚Äá4.67k/4.67k‚Äá[00:00&lt;00:00,‚Äá312kB/s]"
     }
    },
    "3c5c945a8daf4b3f83741ecbc26804b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df721834c3de4656909069aed0670d36",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4015d6ed6b9d4c1394850ff0ad704149",
      "value": "‚Äá19252/19252‚Äá[00:01&lt;00:00,‚Äá13745.17‚Äáexamples/s]"
     }
    },
    "3cb88502cb1643a8927049baf40d56b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d9deebcb56f40e3ace1f52e862c1c31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ddcfbdbb0fc49b0b53a296cdb2348b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e3384d811f94fb9a2d065ffdffaf731": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4015d6ed6b9d4c1394850ff0ad704149": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40b0b562564b4e969c02902b1bbea6e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42724261ea1a440c8ca92a32df1e52d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "455c651682fd42eda5a25ce06560893f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46b625ee9ac041338432f548ee3ab51a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b19bb0b66b248fdbcd01b6264e2ff02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ba6022d4efc4c2ebfdf87b288ed9fd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c1c1bc584cb456c9d07f4ac267cf2c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e84a5ae6c71d42ea8187ebbdcdb4791e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2c04e534215f4d40b103be09e300b744",
      "value": "model-00001-of-00003.safetensors:‚Äá100%"
     }
    },
    "5012456fc82e47aca5a69f52a36cb8f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "502b4fc680b248079121ec2a51062b8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_132dbcd182314c10a906d16f43f94896",
       "IPY_MODEL_1b2a213c48f04667a243cc6dc6c43b0e",
       "IPY_MODEL_eeb29e4ed2ae401f9d21cbe941d6cb1d"
      ],
      "layout": "IPY_MODEL_dcffa04c1de94d3691a14d10df2ee24b"
     }
    },
    "50524c8582eb4814a598654901c35a82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50ad501db7af4ef394540eaf36e1793b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5132d82c92ac41d2b592bf6eebf92c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5210d369018a44d4ad2fbd26190aca9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36eed804652e4c6fb7fe2e969228decd",
      "max": 4589082716,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b8c883b15d84ca2a12bfd3f7a87101d",
      "value": 4589082279
     }
    },
    "528e29551b7a4f77aed08c653e49ee57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_247f2a4074cc4fb0956ef06b10b5e5da",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d760efb7d31a4bbbb29c7af2478e1cbd",
      "value": 100000
     }
    },
    "53f8155387394238b443d54cffe9a363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09d254a8222d42b093ff8f229a6fe503",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_daa8753d49d7458cab39dd1524b20356",
      "value": "Unsloth:‚ÄáStandardizing‚Äáformats‚Äá(num_proc=2):‚Äá100%"
     }
    },
    "5496d2ce66584dc3aed8ca0a31e10463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55a9f6bcb83d4a98a9efcf18253b5091": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b26ab90b1043cb8ed36aab316a45ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "569ad7b2350d46549b2f385a126426d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57ae3d07d1244ba495573895ff11e28e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2c1801935444f2a807b2d483c91ad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a7feb07c0124b9ab00900eb25efa616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b3081e536ac4a258fe5db59bb927ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acbef56d18ae4b86ad0d4b79210db204",
       "IPY_MODEL_2857e876d47a49bbadf3494b1864c1bf",
       "IPY_MODEL_87ca88b487414767af6533125e688186"
      ],
      "layout": "IPY_MODEL_b1e286de944749ec8f5b4ce03df7b7e5"
     }
    },
    "5d66a72e82e54d9e8367ca8a2469dd0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5deffaef73d14116a8b1bcf8d46df2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e18861f3fa24666869822349d1de377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e276c9e2cf14d38ab5971a32b4e369d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60c6d4d43a6445e78051c96a462d7c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06c646d514b448628424dc8c772994de",
       "IPY_MODEL_7c33f0f45eca43cb8015416999b884a1",
       "IPY_MODEL_3c2e07218b764906a278d6a367153548"
      ],
      "layout": "IPY_MODEL_bf94cc1837ba486b895656b41c1e9c99"
     }
    },
    "6303ec778b1d49dd980542a191261961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6367d6b72c37406cafa63daa77263ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96d0f3f2bbc8468fb34e0b61454f8ce8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5496d2ce66584dc3aed8ca0a31e10463",
      "value": "0000.parquet:‚Äá100%"
     }
    },
    "6379559e06cd4668b8c2322cb7dc7f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63abaade8f464ed6bbd51d77014dfe66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644f70a125854e418fbb8469d287edd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca910f4f81547b1afdb9a27eb3f4819",
      "max": 116531415,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42724261ea1a440c8ca92a32df1e52d5",
      "value": 116531404
     }
    },
    "64b00e376bb142c88a690757f27b8294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7afd9c01f68473387f009b05d829b3b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f34c9b4f069f4fb281f4e0145f0e818e",
      "value": "‚Äá4.59G/4.59G‚Äá[00:34&lt;00:00,‚Äá384MB/s]"
     }
    },
    "64eb3128b25448b48268ec61cac289d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65fa509db52047b791159e65ce9108a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e276c9e2cf14d38ab5971a32b4e369d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_eed62b35a7974086b8d27d9c3e459a91",
      "value": "‚Äá117M/117M‚Äá[00:01&lt;00:00,‚Äá100MB/s]"
     }
    },
    "6769817deaaf45fc8a0efb945570f412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67a67c8affbe4ec38f99cbb0a3c52dcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a86e54867d5141dfb1e31ed2d706434f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9864096e9bb54228bf1d9e581b8485bc",
      "value": "added_tokens.json:‚Äá100%"
     }
    },
    "67e43763f2f7457487d8b5bfca51b8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "689f645af24947e8920b631d2aa7c3ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6910d714dc854e959839e57b5123af86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77f86f331a19461d94e4840213b256f6",
       "IPY_MODEL_fcd0ee642395431e92a681ba8d829b20",
       "IPY_MODEL_12d7cac449954aafa26c6b5bcb6e031f"
      ],
      "layout": "IPY_MODEL_4ba6022d4efc4c2ebfdf87b288ed9fd4"
     }
    },
    "691a8c5c682a4b32b19c7e71c1672189": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6be394c3849a41a3937322325836d604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e020b0421e84d9a9a8f0b68aa10cbee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f195b35b0a7416c8d395c17dea7fafa",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_32000eaf412840388188523be1033cab",
      "value": "‚Äá106M/106M‚Äá[00:01&lt;00:00,‚Äá41.8MB/s]"
     }
    },
    "6ec851dec2af487b93f0a626cacba0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3cb03ec368f40fb965beb086b78fb78",
       "IPY_MODEL_bc1b4decb2154b8fb66347408d419ce3",
       "IPY_MODEL_942778de9f014522a928a1408cfcfb05"
      ],
      "layout": "IPY_MODEL_847e20d244014914a420c20b660c99cf"
     }
    },
    "7013b9ae0d8a4bbfa744a5a3e3c18a1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7054b1bcb73e4515afd29b42a32b20c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55a9f6bcb83d4a98a9efcf18253b5091",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5e18861f3fa24666869822349d1de377",
      "value": "generation_config.json:‚Äá100%"
     }
    },
    "71c37d1f12294e858ceb337d2e37e375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73d6e9b4704f40aab25fecd24154f9bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74267e9cd64d44b58bdbd7dad03b681d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a151688c648045f399e32dc55dd9a1b3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_55b26ab90b1043cb8ed36aab316a45ad",
      "value": "‚Äá168k/168k‚Äá[00:00&lt;00:00,‚Äá2.48MB/s]"
     }
    },
    "77f86f331a19461d94e4840213b256f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fab32e1222f4431a255a36df0a22a35",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7013b9ae0d8a4bbfa744a5a3e3c18a1e",
      "value": "tokenizer.json:‚Äá100%"
     }
    },
    "7a3a67547e2043a0ac74b49c47009954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b21ad18c43d4509810204b8a4787b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b34f538a42f4a9ba9de379ae57f0134": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_968919dd5d5f41ce91da5cdea02b438b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_31d4fb1807bc4ec0840d63ef0bf2e0f9",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "7b8c883b15d84ca2a12bfd3f7a87101d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c33f0f45eca43cb8015416999b884a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1cd702821234a9f87933d099ef5273c",
      "max": 4673,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6be394c3849a41a3937322325836d604",
      "value": 4673
     }
    },
    "7c6caf15c5de4a2fb699d034a6ab776c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d574f195dfc4bc4b1ca86863d97e597": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e7ac790b8af4cfb978bfe8ac8499900": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7efa9f507c8546bb9b0b5d47be527c25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46b625ee9ac041338432f548ee3ab51a",
      "max": 167747,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fea4c81baaf84d9b806c1853216c89e2",
      "value": 167747
     }
    },
    "802bdf3c4293448bb00b625722f1a9f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57ae3d07d1244ba495573895ff11e28e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0e997f45717c44e1944d510ae6c51fb9",
      "value": "‚Äá237/237‚Äá[00:00&lt;00:00,‚Äá20.7kB/s]"
     }
    },
    "8147cc77ce3941c290982d21c42f9f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93a91db5fd6147c5a7982496f09c5b8b",
      "max": 1671853,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5132d82c92ac41d2b592bf6eebf92c19",
      "value": 1671853
     }
    },
    "844cd70bf80d40f79c520caf1d7e2a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f4608614780453a826e3ad59817d7ae",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c89e5721ed7e48b295ccc74b841ec61e",
      "value": "‚Äá10.5k/10.5k‚Äá[00:00&lt;00:00,‚Äá704kB/s]"
     }
    },
    "8450b0ecd0934facbc4f16fc471f778b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "847e20d244014914a420c20b660c99cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "852a10d472ad48a19203ded79cf30662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d8db7e564a40499d58f0d9c11b01a7",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a7feb07c0124b9ab00900eb25efa616",
      "value": 100000
     }
    },
    "87ca88b487414767af6533125e688186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1e4e03e40b2480388b67dcb7d2120c3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8bf8b1e60de142a6845aaadbe64fcb85",
      "value": "‚Äá19252/19252‚Äá[00:01&lt;00:00,‚Äá10429.75‚Äáexamples/s]"
     }
    },
    "881919ffdd7940839c8b40edba7f8c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8be1618a9f8840af8d89103c37ef02ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bf8b1e60de142a6845aaadbe64fcb85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cdf258cb0554d64a4aceed488b6361b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53f8155387394238b443d54cffe9a363",
       "IPY_MODEL_852a10d472ad48a19203ded79cf30662",
       "IPY_MODEL_9ced22ec1fc54b4e9e7b7ab1aae0c940"
      ],
      "layout": "IPY_MODEL_a6a8ff65be444bc3999c28f53d9b46f4"
     }
    },
    "8f14d9c07bf846a682c1c44f4a2d2410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b72d23e8d05449a8bf8a7511ada49704",
      "max": 105878062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6379559e06cd4668b8c2322cb7dc7f53",
      "value": 105878052
     }
    },
    "904f626a367745979ac664f4d2ea6409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e976be66ed774ce880463df39d0c25ce",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_67e43763f2f7457487d8b5bfca51b8e4",
      "value": "‚Äá707/707‚Äá[00:00&lt;00:00,‚Äá70.0kB/s]"
     }
    },
    "911bd3f394ce4394be92e50782d6ae39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd1b79ecec114d28ace8c1b8b1fd4d5d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d4b3982b73d046478f7c9b561ed42298",
      "value": "vocab.json:‚Äá100%"
     }
    },
    "927c60cd1f0d4a32a1ff9427a96a3246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7077f3352b246ddbbca391c08c48b4a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a1c374126fb144e68060e4fedab51046",
      "value": "‚Äá25669/25669‚Äá[03:35&lt;00:00,‚Äá157.21‚Äáexamples/s]"
     }
    },
    "92be8fd7a814466c983d689bd5d6e1a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93a91db5fd6147c5a7982496f09c5b8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "942778de9f014522a928a1408cfcfb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50ad501db7af4ef394540eaf36e1793b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8450b0ecd0934facbc4f16fc471f778b",
      "value": "‚Äá603/603‚Äá[00:00&lt;00:00,‚Äá24.5kB/s]"
     }
    },
    "968919dd5d5f41ce91da5cdea02b438b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d0f3f2bbc8468fb34e0b61454f8ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9864096e9bb54228bf1d9e581b8485bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c35626d415d4468a30e0513cc7a5234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9b22a85e2049089b2194770637c91e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ced22ec1fc54b4e9e7b7ab1aae0c940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_455c651682fd42eda5a25ce06560893f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a56f6c918e064278a0217c53e8cc2f6e",
      "value": "‚Äá100000/100000‚Äá[00:04&lt;00:00,‚Äá30077.54‚Äáexamples/s]"
     }
    },
    "9d02fcd7882345dea97be6decb5293a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b34f538a42f4a9ba9de379ae57f0134",
       "IPY_MODEL_1f9eba179bf847dcb47dbda34611459a",
       "IPY_MODEL_844cd70bf80d40f79c520caf1d7e2a5b"
      ],
      "layout": "IPY_MODEL_fa8721e596b74611945a1d76e9deff8f"
     }
    },
    "9f0108d9201f40599facfccf668a6e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e17016c458a14736bd56ba55d7168f32",
      "max": 25669,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d31954fe1804140bcac71e3d4102fdc",
      "value": 25669
     }
    },
    "9f6ddb6a1c264fc79f907c54078bb769": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a151688c648045f399e32dc55dd9a1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1c374126fb144e68060e4fedab51046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1e4e03e40b2480388b67dcb7d2120c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a40e10f372644d80b2830d0f42fcde6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a469a1af99124ff6974265f45563deea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a48262b1d98a427ab79d589907521d88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a56f6c918e064278a0217c53e8cc2f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a68cbb7211b448c78cd418a90b908037": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a8ff65be444bc3999c28f53d9b46f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7077f3352b246ddbbca391c08c48b4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7078409a02740cbbd6d59b61a4a8c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_691a8c5c682a4b32b19c7e71c1672189",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5a2c1801935444f2a807b2d483c91ad7",
      "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
     }
    },
    "a81ef4374fde4d10a1cdc5daeec34dda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a86e54867d5141dfb1e31ed2d706434f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a99b117d78a8493c9f6ae80f5bf6ea5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b74e4e5971684b00b40ca42cf2aebb9e",
       "IPY_MODEL_d9dcda48a37e41f7808a933cfd939ded",
       "IPY_MODEL_23791684cb5349c4853cffb4e72ebe1d"
      ],
      "layout": "IPY_MODEL_c6514d1ee44141d3bf83fde032d39a46"
     }
    },
    "a9e3708d145c4bedaa07e5347019fd01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca910f4f81547b1afdb9a27eb3f4819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acbef56d18ae4b86ad0d4b79210db204": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cde3541ff2444f55a1651b8992e53da1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7b21ad18c43d4509810204b8a4787b64",
      "value": "Map:‚Äá100%"
     }
    },
    "ae9317b34ba341c4ac40797da3ac2478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c9b22a85e2049089b2194770637c91e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fb2ce6370b1d4d5d9dbdb98aa236da71",
      "value": "‚Äá4.97G/4.97G‚Äá[00:54&lt;00:00,‚Äá151MB/s]"
     }
    },
    "aeb720eea25149deb34e6844a8bdd2c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afb3e794edf046a9b594fcbb99acb8ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1542f5b57f14b98be813e6b2540bb80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34b0ab119eab40eda8b7a551642e0e31",
       "IPY_MODEL_c519c7b69d70467c875a3d228e6b6fd2",
       "IPY_MODEL_cd8774e4577a4652863469d3cb75f2ee"
      ],
      "layout": "IPY_MODEL_40b0b562564b4e969c02902b1bbea6e8"
     }
    },
    "b1a6d94a50aa4ac29965cb1693c9c5c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1cd702821234a9f87933d099ef5273c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1e286de944749ec8f5b4ce03df7b7e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b22bcb2a7b24497581994b71b02f755d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0969d7420e541229f1e0a9de683c367",
      "max": 19252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c2573a314d94fc1a2f414adfa9d259a",
      "value": 19252
     }
    },
    "b25399bf6ae4414ba2836733f59e4ab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92be8fd7a814466c983d689bd5d6e1a9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7a3a67547e2043a0ac74b49c47009954",
      "value": "‚Äá2.78M/2.78M‚Äá[00:00&lt;00:00,‚Äá7.66MB/s]"
     }
    },
    "b72d23e8d05449a8bf8a7511ada49704": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b74e4e5971684b00b40ca42cf2aebb9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6769817deaaf45fc8a0efb945570f412",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d7465d2830f64de996d4d3a306b97c82",
      "value": "model-00003-of-00003.safetensors:‚Äá100%"
     }
    },
    "b8c184cdaa6b4d72ad28a604d1a8fa39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_179e343762ba440cbc094e0e85b4ee84",
       "IPY_MODEL_ecd44b2e03794d5783ffbf07d8b8619f",
       "IPY_MODEL_28d439d23bf54688963517fbdb482339"
      ],
      "layout": "IPY_MODEL_7e7ac790b8af4cfb978bfe8ac8499900"
     }
    },
    "b998e55dd17b44d7a8c23ac427619036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a09813436c24b5ea68e652254288ee0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a469a1af99124ff6974265f45563deea",
      "value": "model-00002-of-00003.safetensors:‚Äá100%"
     }
    },
    "bc1b4decb2154b8fb66347408d419ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e3384d811f94fb9a2d065ffdffaf731",
      "max": 603,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca410b0da67a466abd7c94ebd0762872",
      "value": 603
     }
    },
    "bc277d60ad4a419a94ded28a1c27a9f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bce369933ce540d7b6ec670b04d7f1a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf94cc1837ba486b895656b41c1e9c99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2d8db7e564a40499d58f0d9c11b01a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c37a4b08afa84b64b40ebbe08cbfb018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3887400b6d34c30a54c6af94c2b612d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c6caf15c5de4a2fb699d034a6ab776c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ebe9490475bc437c92ebc03187e53382",
      "value": "model.safetensors.index.json:‚Äá100%"
     }
    },
    "c519c7b69d70467c875a3d228e6b6fd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f85353b1b37342859c9aa71442781e95",
      "max": 614,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73d6e9b4704f40aab25fecd24154f9bc",
      "value": 614
     }
    },
    "c6514d1ee44141d3bf83fde032d39a46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c688c828118f41859a3d71c54b62354a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c89e5721ed7e48b295ccc74b841ec61e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8faa5be5b88425298b5655a8f507a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca410b0da67a466abd7c94ebd0762872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc9479fb190742fd865613680e87e535": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7ae6535329c45009bf5664fbd30bbf5",
      "max": 4974351586,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e112f4ad6974529a4c4f583e6a73950",
      "value": 4974351112
     }
    },
    "cd8774e4577a4652863469d3cb75f2ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2167f3dc7050467a9f19f3f885cfb09b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_569ad7b2350d46549b2f385a126426d5",
      "value": "‚Äá614/614‚Äá[00:00&lt;00:00,‚Äá37.3kB/s]"
     }
    },
    "cde3541ff2444f55a1651b8992e53da1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce05df3e26834837b2db818657a9d175": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63abaade8f464ed6bbd51d77014dfe66",
      "max": 2776833,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef69f52b4c7a485b8708f171bb6acbd6",
      "value": 2776833
     }
    },
    "d127b4248d7e4114a38df6961b0f28c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dcb04c84d5854f878555a92bcda62550",
       "IPY_MODEL_644f70a125854e418fbb8469d287edd2",
       "IPY_MODEL_65fa509db52047b791159e65ce9108a4"
      ],
      "layout": "IPY_MODEL_50524c8582eb4814a598654901c35a82"
     }
    },
    "d1b000b08af549689d1be5f0289bf2c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3da0aa9fb884983b6554f3563b05eeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4b3982b73d046478f7c9b561ed42298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7465d2830f64de996d4d3a306b97c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d760efb7d31a4bbbb29c7af2478e1cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7ae6535329c45009bf5664fbd30bbf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7afd9c01f68473387f009b05d829b3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9c143d31e494981b188be41bd52118f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67a67c8affbe4ec38f99cbb0a3c52dcc",
       "IPY_MODEL_0d0852d9ebb2409ea51650f538dd1621",
       "IPY_MODEL_904f626a367745979ac664f4d2ea6409"
      ],
      "layout": "IPY_MODEL_e0260495036b406fbf462b3c387205d2"
     }
    },
    "d9dcda48a37e41f7808a933cfd939ded": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68cbb7211b448c78cd418a90b908037",
      "max": 1555824768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb052cc7147d474597529c462497b731",
      "value": 1555824620
     }
    },
    "daa8753d49d7458cab39dd1524b20356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db172381abdf4bb0a84417882fc462be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcb04c84d5854f878555a92bcda62550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f6ddb6a1c264fc79f907c54078bb769",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a9e3708d145c4bedaa07e5347019fd01",
      "value": "train-00000-of-00001.parquet:‚Äá100%"
     }
    },
    "dcffa04c1de94d3691a14d10df2ee24b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd1b79ecec114d28ace8c1b8b1fd4d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2adf3e30304398b8340253dbd4489a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de968455db9840f09ced1a8443f4beae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df721834c3de4656909069aed0670d36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0260495036b406fbf462b3c387205d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0969d7420e541229f1e0a9de683c367": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e17016c458a14736bd56ba55d7168f32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3ecd73a9b86479e8596d8bb1ef5791d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_911bd3f394ce4394be92e50782d6ae39",
       "IPY_MODEL_ce05df3e26834837b2db818657a9d175",
       "IPY_MODEL_b25399bf6ae4414ba2836733f59e4ab0"
      ],
      "layout": "IPY_MODEL_a81ef4374fde4d10a1cdc5daeec34dda"
     }
    },
    "e84a5ae6c71d42ea8187ebbdcdb4791e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e976be66ed774ce880463df39d0c25ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea7c149f9c274f8a94970880d99edbab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7078409a02740cbbd6d59b61a4a8c6b",
       "IPY_MODEL_528e29551b7a4f77aed08c653e49ee57",
       "IPY_MODEL_153259764d2b45e0bc02938d6909d40a"
      ],
      "layout": "IPY_MODEL_9c35626d415d4468a30e0513cc7a5234"
     }
    },
    "eb052cc7147d474597529c462497b731": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ebe9490475bc437c92ebc03187e53382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecd44b2e03794d5783ffbf07d8b8619f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2de7e147b2e14db38243c7656a29f0e4",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bce369933ce540d7b6ec670b04d7f1a4",
      "value": 3
     }
    },
    "eeb29e4ed2ae401f9d21cbe941d6cb1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12d7229f7d81488e93689d4269ee48ac",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d3da0aa9fb884983b6554f3563b05eeb",
      "value": "‚Äá982/982‚Äá[00:00&lt;00:00,‚Äá27.1kB/s]"
     }
    },
    "eed62b35a7974086b8d27d9c3e459a91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef69f52b4c7a485b8708f171bb6acbd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0b8a9e00c0d4cc1aff1e3a748a8f039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1af17f7a7ee405dabd07f41b6b786d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b19bb0b66b248fdbcd01b6264e2ff02",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_689f645af24947e8920b631d2aa7c3ad",
      "value": "‚Äá1.67M/1.67M‚Äá[00:00&lt;00:00,‚Äá11.7MB/s]"
     }
    },
    "f34c9b4f069f4fb281f4e0145f0e818e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3cb03ec368f40fb965beb086b78fb78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a48262b1d98a427ab79d589907521d88",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_de968455db9840f09ced1a8443f4beae",
      "value": "README.md:‚Äá100%"
     }
    },
    "f7c27321d53047479c1ed45b5d5109f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f85353b1b37342859c9aa71442781e95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f89daea726144ded892113a161649b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6303ec778b1d49dd980542a191261961",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5d66a72e82e54d9e8367ca8a2469dd0a",
      "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=2):‚Äá100%"
     }
    },
    "f8f15be1afc44472bff560ca7316873a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa8721e596b74611945a1d76e9deff8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb2ce6370b1d4d5d9dbdb98aa236da71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb6f38d9dd1e49ec8fdfb7ca7ea363a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcd0ee642395431e92a681ba8d829b20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ddcfbdbb0fc49b0b53a296cdb2348b8",
      "max": 11422654,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b72ac21d79c459395682f6692c4325f",
      "value": 11422654
     }
    },
    "fea4c81baaf84d9b806c1853216c89e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
