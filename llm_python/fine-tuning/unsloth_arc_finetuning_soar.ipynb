{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3 Tuning\n",
    "for ARC AGI 2\n",
    "\n",
    "**Updates**\n",
    "-Sept 10th 2025-\n",
    "* The validation set is now selected at random from the training dataset. A max of 32 rows.\n",
    "\n",
    "**WARNINGs!**\n",
    "1. This notebook will grab the last numbered checkpoints (i.e. if there are 1, 2, 3, then it will grab 3 and 2.). This can pose issues if you train the same model twice for a similar number of steps, as you may push wrong checkpoints the second time! Ideally we would fix this by writing to a subfolder inside trainer_output called {run_name} or similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Reinstall for OSS with unsloth\n",
    "# !uv pip uninstall unsloth_zoo unsloth\n",
    "# !uv pip install --upgrade --force-reinstall --no-deps --no-cache-dir \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo.git\" -q\n",
    "# !uv pip install --upgrade --force-reinstall --no-deps --no-cache-dir \"unsloth[base] @ git+https://github.com/unslothai/unsloth.git\" -q\n",
    "\n",
    "import os \n",
    "# to avoid lots of forking notifications with OSS\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
    "\n",
    "# !uv pip show transformers unsloth unsloth-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded config from: config.yaml\n",
      "ğŸ“Š Data source: huggingface (Trelis/arc-agi-2-reasoning-5)\n",
      "Config loaded:\n",
      "  config_path: config.yaml\n",
      "  test_run: False\n",
      "  execution_mode: full\n",
      "  data_source: huggingface\n",
      "  model_slug: Qwen/Qwen3-4B-Thinking-2507\n",
      "  batch_size_global: 4\n",
      "  max_rows: None\n",
      "  model_save_dir: /workspace/arc-agi-2025/llm_python/fine-tuning/merged\n",
      "  train_slug: Trelis/arc-agi-2-reasoning-5\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Config (loaded from YAML with environment variable overrides)\n",
    "# ---------------------------------------------------------------------\n",
    "import yaml\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def load_config_from_yaml(config_path=\"config.yaml\"):\n",
    "  \"\"\"Load configuration from YAML file with environment variable overrides.\"\"\"\n",
    "  if not Path(config_path).exists():\n",
    "      print(f\"Config file {config_path} not found! Using default values.\")\n",
    "      return {}\n",
    "\n",
    "  with open(config_path, 'r') as f:\n",
    "      config = yaml.safe_load(f)\n",
    "\n",
    "  print(f\"âœ… Loaded config from: {config_path}\")\n",
    "  return config\n",
    "\n",
    "# Detect if we're running as script vs notebook and handle config path accordingly\n",
    "if '__file__' in globals():\n",
    "    # Script mode - use argparse for --config parameter\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', default='config.yaml', help='Path to config file')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    config_path = args.config\n",
    "else:\n",
    "    # Notebook mode - use default config file\n",
    "    config_path = \"config.yaml\"\n",
    "\n",
    "# Load configuration\n",
    "config = load_config_from_yaml(config_path)\n",
    "\n",
    "# Extract values with fallbacks and environment variable overrides\n",
    "test_run = config.get('test_run', False)\n",
    "is_kaggle = config.get('is_kaggle', False)\n",
    "\n",
    "# Override if running on Kaggle\n",
    "if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") is not None:\n",
    "    is_kaggle = True\n",
    "\n",
    "# Environment variable overrides\n",
    "model_save_dir = os.environ.get('MODEL_SAVE_DIR', \n",
    "                              os.environ.get('LOCAL_MODEL_DIR',\n",
    "                                            config.get('model_save_dir', \"/kaggle/working/\")))\n",
    "\n",
    "execution_mode = os.environ.get('FINE_TUNING_MODE', config.get('execution_mode', 'full'))\n",
    "\n",
    "# Data source configuration\n",
    "data_config = config.get('data', {})\n",
    "data_source = os.environ.get('DATA_SOURCE', data_config.get('source', 'huggingface'))\n",
    "parquet_path = os.environ.get('ARC_PROGRAMS_PARQUET',\n",
    "                              data_config.get('parquet', {}).get('path', '../datasets/inference/'))\n",
    "\n",
    "# Dataset configuration\n",
    "train_slug = data_config.get('dataset_slug', None)\n",
    "if data_source == 'parquet' or train_slug is None:\n",
    "    data_source = 'parquet'  # Default to parquet now\n",
    "    train_slug = None\n",
    "    print(f\"ğŸ“Š Data source: parquet ({parquet_path})\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š Data source: huggingface ({train_slug})\")\n",
    "\n",
    "# Model configuration with environment override\n",
    "model_config = config.get('model', {})\n",
    "model_slug = os.environ.get('MODEL_SLUG', model_config.get('slug', \"Qwen/Qwen3-4B\"))\n",
    "model_max_length = model_config.get('max_length', 32768)\n",
    "lora_rank = model_config.get('lora_rank', 128)\n",
    "\n",
    "# Training configuration\n",
    "training_config = config.get('training', {})\n",
    "batch_size_global = 1 if is_kaggle else training_config.get('batch_size_global', 4)\n",
    "enable_thinking = training_config.get('enable_thinking', False)\n",
    "\n",
    "# Handle max_rows with test_run override\n",
    "if test_run:\n",
    "  overrides = config.get('overrides', {})\n",
    "  max_rows = overrides.get('test_run_max_rows', 128)\n",
    "else:\n",
    "  max_rows = training_config.get('max_rows')  # None for all rows\n",
    "\n",
    "# Print loaded configuration\n",
    "print(f\"Config loaded:\")\n",
    "print(f\"  config_path: {config_path}\")\n",
    "print(f\"  test_run: {test_run}\")\n",
    "print(f\"  execution_mode: {execution_mode}\")\n",
    "print(f\"  data_source: {data_source}\")\n",
    "print(f\"  model_slug: {model_slug}\")\n",
    "print(f\"  batch_size_global: {batch_size_global}\")\n",
    "print(f\"  max_rows: {max_rows}\")\n",
    "print(f\"  model_save_dir: {model_save_dir}\")\n",
    "if train_slug:\n",
    "    print(f\"  train_slug: {train_slug}\")\n",
    "else:\n",
    "    print(f\"  parquet_path: {parquet_path}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report to: ['wandb']\n"
     ]
    }
   ],
   "source": [
    "# Check if env variable exists\n",
    "if is_kaggle:\n",
    "    report_to = \"none\"\n",
    "else:\n",
    "    report_to = [\"wandb\"]\n",
    "\n",
    "print(f\"Report to: {report_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.get(\"training\", {}).get(\"multi_gpu\", False):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"    # single GPU\n",
    "\n",
    "if not is_kaggle:\n",
    "    os.environ[\"HF_HOME\"] = \"/workspace\"\n",
    "    os.environ[\"HF_HUB_CACHE\"] = \"/workspace/hub\" # (recommended) override just the repo cache\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = \"/workspace/transformers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGuJWXIFu44v"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder, login\n",
    "\n",
    "if not is_kaggle:\n",
    "    # Call this at the top of your script / notebook\n",
    "    if HfFolder.get_token() is None:   # no token cached or in $HF_TOKEN\n",
    "        login()                        # interactive prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "iajq1W8ipjyK",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573,
     "referenced_widgets": [
      "145cc80490fa42258fe6e5a643b57dd5",
      "c3887400b6d34c30a54c6af94c2b612d",
      "7efa9f507c8546bb9b0b5d47be527c25",
      "74267e9cd64d44b58bdbd7dad03b681d",
      "dd2adf3e30304398b8340253dbd4489a",
      "7c6caf15c5de4a2fb699d034a6ab776c",
      "ebe9490475bc437c92ebc03187e53382",
      "46b625ee9ac041338432f548ee3ab51a",
      "fea4c81baaf84d9b806c1853216c89e2",
      "a151688c648045f399e32dc55dd9a1b3",
      "55b26ab90b1043cb8ed36aab316a45ad",
      "247ee0a6f4e64e5ca0a435d243690d0a",
      "4c1c1bc584cb456c9d07f4ac267cf2c5",
      "cc9479fb190742fd865613680e87e535",
      "ae9317b34ba341c4ac40797da3ac2478",
      "5012456fc82e47aca5a69f52a36cb8f5",
      "e84a5ae6c71d42ea8187ebbdcdb4791e",
      "2c04e534215f4d40b103be09e300b744",
      "d7ae6535329c45009bf5664fbd30bbf5",
      "0e112f4ad6974529a4c4f583e6a73950",
      "9c9b22a85e2049089b2194770637c91e",
      "fb2ce6370b1d4d5d9dbdb98aa236da71",
      "2dff2433978a477582b995bc6abafe68",
      "b998e55dd17b44d7a8c23ac427619036",
      "5210d369018a44d4ad2fbd26190aca9b",
      "64b00e376bb142c88a690757f27b8294",
      "09ce664a0a404087a9fe53a5c2d5316e",
      "1a09813436c24b5ea68e652254288ee0",
      "a469a1af99124ff6974265f45563deea",
      "36eed804652e4c6fb7fe2e969228decd",
      "7b8c883b15d84ca2a12bfd3f7a87101d",
      "d7afd9c01f68473387f009b05d829b3b",
      "f34c9b4f069f4fb281f4e0145f0e818e",
      "a99b117d78a8493c9f6ae80f5bf6ea5a",
      "b74e4e5971684b00b40ca42cf2aebb9e",
      "d9dcda48a37e41f7808a933cfd939ded",
      "23791684cb5349c4853cffb4e72ebe1d",
      "c6514d1ee44141d3bf83fde032d39a46",
      "6769817deaaf45fc8a0efb945570f412",
      "d7465d2830f64de996d4d3a306b97c82",
      "a68cbb7211b448c78cd418a90b908037",
      "eb052cc7147d474597529c462497b731",
      "2aefab33f6f345869c19899ca2952df1",
      "881919ffdd7940839c8b40edba7f8c01",
      "b8c184cdaa6b4d72ad28a604d1a8fa39",
      "179e343762ba440cbc094e0e85b4ee84",
      "ecd44b2e03794d5783ffbf07d8b8619f",
      "28d439d23bf54688963517fbdb482339",
      "7e7ac790b8af4cfb978bfe8ac8499900",
      "3cb88502cb1643a8927049baf40d56b7",
      "c37a4b08afa84b64b40ebbe08cbfb018",
      "2de7e147b2e14db38243c7656a29f0e4",
      "bce369933ce540d7b6ec670b04d7f1a4",
      "0940df31fc9047ccae4870b7d2c89b3d",
      "0b3d64dd05f841d68ad472ce933e36d7",
      "2068eb23121440ec83d8cd117b4c6ba5",
      "7054b1bcb73e4515afd29b42a32b20c5",
      "09cd31746a174e96bb346e1afc7b3c8b",
      "802bdf3c4293448bb00b625722f1a9f6",
      "f7c27321d53047479c1ed45b5d5109f6",
      "55a9f6bcb83d4a98a9efcf18253b5091",
      "5e18861f3fa24666869822349d1de377",
      "64eb3128b25448b48268ec61cac289d1",
      "bc277d60ad4a419a94ded28a1c27a9f4",
      "57ae3d07d1244ba495573895ff11e28e",
      "0e997f45717c44e1944d510ae6c51fb9",
      "9d02fcd7882345dea97be6decb5293a5",
      "7b34f538a42f4a9ba9de379ae57f0134",
      "1f9eba179bf847dcb47dbda34611459a",
      "844cd70bf80d40f79c520caf1d7e2a5b",
      "fa8721e596b74611945a1d76e9deff8f",
      "968919dd5d5f41ce91da5cdea02b438b",
      "31d4fb1807bc4ec0840d63ef0bf2e0f9",
      "f8f15be1afc44472bff560ca7316873a",
      "a40e10f372644d80b2830d0f42fcde6c",
      "2f4608614780453a826e3ad59817d7ae",
      "c89e5721ed7e48b295ccc74b841ec61e",
      "e3ecd73a9b86479e8596d8bb1ef5791d",
      "911bd3f394ce4394be92e50782d6ae39",
      "ce05df3e26834837b2db818657a9d175",
      "b25399bf6ae4414ba2836733f59e4ab0",
      "a81ef4374fde4d10a1cdc5daeec34dda",
      "dd1b79ecec114d28ace8c1b8b1fd4d5d",
      "d4b3982b73d046478f7c9b561ed42298",
      "63abaade8f464ed6bbd51d77014dfe66",
      "ef69f52b4c7a485b8708f171bb6acbd6",
      "92be8fd7a814466c983d689bd5d6e1a9",
      "7a3a67547e2043a0ac74b49c47009954",
      "196f35f21b97476a9814acd96dbec717",
      "3ad6055d2ba2481c83b1b136e5898986",
      "8147cc77ce3941c290982d21c42f9f66",
      "f1af17f7a7ee405dabd07f41b6b786d7",
      "aeb720eea25149deb34e6844a8bdd2c5",
      "7d574f195dfc4bc4b1ca86863d97e597",
      "c8faa5be5b88425298b5655a8f507a2a",
      "93a91db5fd6147c5a7982496f09c5b8b",
      "5132d82c92ac41d2b592bf6eebf92c19",
      "4b19bb0b66b248fdbcd01b6264e2ff02",
      "689f645af24947e8920b631d2aa7c3ad",
      "d9c143d31e494981b188be41bd52118f",
      "67a67c8affbe4ec38f99cbb0a3c52dcc",
      "0d0852d9ebb2409ea51650f538dd1621",
      "904f626a367745979ac664f4d2ea6409",
      "e0260495036b406fbf462b3c387205d2",
      "a86e54867d5141dfb1e31ed2d706434f",
      "9864096e9bb54228bf1d9e581b8485bc",
      "062f278ab1c94d8099e06074e0cd360c",
      "3ad57df96bec4267a220a739cfc72bc1",
      "e976be66ed774ce880463df39d0c25ce",
      "67e43763f2f7457487d8b5bfca51b8e4",
      "b1542f5b57f14b98be813e6b2540bb80",
      "34b0ab119eab40eda8b7a551642e0e31",
      "c519c7b69d70467c875a3d228e6b6fd2",
      "cd8774e4577a4652863469d3cb75f2ee",
      "40b0b562564b4e969c02902b1bbea6e8",
      "71c37d1f12294e858ceb337d2e37e375",
      "00d671d686af43c38b12a9448c5bbf06",
      "f85353b1b37342859c9aa71442781e95",
      "73d6e9b4704f40aab25fecd24154f9bc",
      "2167f3dc7050467a9f19f3f885cfb09b",
      "569ad7b2350d46549b2f385a126426d5",
      "6910d714dc854e959839e57b5123af86",
      "77f86f331a19461d94e4840213b256f6",
      "fcd0ee642395431e92a681ba8d829b20",
      "12d7cac449954aafa26c6b5bcb6e031f",
      "4ba6022d4efc4c2ebfdf87b288ed9fd4",
      "0fab32e1222f4431a255a36df0a22a35",
      "7013b9ae0d8a4bbfa744a5a3e3c18a1e",
      "3ddcfbdbb0fc49b0b53a296cdb2348b8",
      "2b72ac21d79c459395682f6692c4325f",
      "26dbcdc380e1404687020cbd9bf38513",
      "2abd7191bff846198b2fb033da32f8c8",
      "60c6d4d43a6445e78051c96a462d7c20",
      "06c646d514b448628424dc8c772994de",
      "7c33f0f45eca43cb8015416999b884a1",
      "3c2e07218b764906a278d6a367153548",
      "bf94cc1837ba486b895656b41c1e9c99",
      "8be1618a9f8840af8d89103c37ef02ef",
      "f0b8a9e00c0d4cc1aff1e3a748a8f039",
      "b1cd702821234a9f87933d099ef5273c",
      "6be394c3849a41a3937322325836d604",
      "db172381abdf4bb0a84417882fc462be",
      "0ab824fcbf0e46f7bbe75af9f662c31a"
     ]
    },
    "editable": true,
    "id": "QmUBVEnvCDJv",
    "outputId": "ad27d22a-d0a6-4659-be63-60bf3b3561b7",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Qwen3 patching. Transformers: 4.55.2.\n",
      "   \\\\   /|    NVIDIA H200. Num GPUs = 1. Max memory: 139.812 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "import os\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_slug,\n",
    "    max_seq_length = model_max_length,   # Context length - can be longer, but uses more memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.max_seq_length: 32768\n"
     ]
    }
   ],
   "source": [
    "print(f\"model.max_seq_length: {model.max_seq_length}\")\n",
    "# print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Print a summary of the transformer layers and key dimensions\n",
    "# for i, block in enumerate(model.model.layers):\n",
    "#     attn = block.self_attn\n",
    "#     mlp = block.mlp\n",
    "\n",
    "#     print(f\"Layer {i}:\")\n",
    "#     print(f\"  Attention:\")\n",
    "#     print(f\"    q_proj: {attn.q_proj.weight.shape}\")\n",
    "#     print(f\"    k_proj: {attn.k_proj.weight.shape}\")\n",
    "#     print(f\"    v_proj: {attn.v_proj.weight.shape}\")\n",
    "#     print(f\"    out_proj: {attn.o_proj.weight.shape}\")\n",
    "#     print(f\"  MLP:\")\n",
    "#     print(f\"    fc1: {mlp.gate_proj.weight.shape}\")\n",
    "#     print(f\"    fc2: {mlp.up_proj.weight.shape}\")\n",
    "#     print(f\"    fc3: {mlp.down_proj.weight.shape}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "SXd9bTZd1aaL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "6bZsfBuZDeCL",
    "outputId": "d50f06c8-4905-4f4e-c6da-980145c41e29",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.8.9 patched 36 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128. could consider 128.\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                     ],\n",
    "    lora_alpha = 64,  # Best to choose alpha = rank or rank*2. EXCEPT if using rslora, in which case set it as sqrt(max matrix dimension). 64 is good for Qwen 4B\n",
    "    lora_dropout = 0.05, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    # use_gradient_checkpointing = False, # Hard to know if this really turns it off.\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.padding_side: right\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(f\"tokenizer.padding_side: {tokenizer.padding_side}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Project root: /workspace/arc-agi-2025\n",
      "âœ… Utils imported and initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Import utils using standard project root detection\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if not is_kaggle:\n",
    "    # Find project root by looking for pyproject.toml\n",
    "    project_root = next(\n",
    "      (parent for parent in [Path.cwd()] + list(Path.cwd().parents)\n",
    "       if (parent / \"pyproject.toml\").exists()),\n",
    "      Path.cwd()\n",
    "    )\n",
    "    \n",
    "    # Add project root to path for consistent imports\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "    print(f\"ğŸ“ Project root: {project_root}\")\n",
    "\n",
    "# Import from llm_python with consistent root-level imports\n",
    "from llm_python.utils.task_loader import TaskLoader\n",
    "from llm_python.utils.scoring import GridScorer\n",
    "from llm_python.utils.arc_tester import ArcTester\n",
    "from llm_python.utils.prompt_utils import create_arc_prompt, extract_python_code\n",
    "from llm_python.utils.metrics_utils import calculate_task_metrics, format_metrics_display, metrics_to_percentages\n",
    "from llm_python.utils.timeout_utils import execute_with_timeout\n",
    "from llm_python.utils.prompt_loader import PromptLoader\n",
    "\n",
    "# Initialize utility instances\n",
    "prompt_loader = PromptLoader()\n",
    "scorer = GridScorer()\n",
    "print(\"âœ… Utils imported and initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "vITh0KVJ10qX",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added code cleaning and filtering functions\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_multiple_newlines(code: str) -> str:\n",
    "    \"\"\"Remove multiple consecutive newlines and replace with at most one empty line.\"\"\"\n",
    "    # Pattern to match multiple consecutive newlines with optional whitespace\n",
    "    # This handles cases like \\n\\n\\n, \\n  \\n\\n, \\n\\t\\n\\n\\n etc.\n",
    "    pattern = r'\\n(\\s*\\n)+'\n",
    "    # Replace with at most one empty line (two newlines)\n",
    "    cleaned = re.sub(pattern, '\\n\\n', code)\n",
    "    return cleaned\n",
    "\n",
    "def count_tokens(text: str, tokenizer) -> int:\n",
    "    \"\"\"Count tokens in text using the provided tokenizer.\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def should_filter_code(code: str, tokenizer, max_tokens: int = 2000) -> bool:\n",
    "    \"\"\"Check if code should be filtered based on token count.\"\"\"\n",
    "    return count_tokens(code, tokenizer) > max_tokens\n",
    "\n",
    "print(\"âœ… Added code cleaning and filtering functions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL CODE:\n",
      "'def solve(grid):\\n  # First comment\\n\\n\\n  # Second comment after multiple empty lines\\n  rows = len(grid)\\n  cols = len(grid[0])\\n\\n  # Another comment\\n\\n\\n  return grid'\n",
      "\n",
      "ORIGINAL CODE (formatted):\n",
      "def solve(grid):\n",
      "  # First comment\n",
      "\n",
      "\n",
      "  # Second comment after multiple empty lines\n",
      "  rows = len(grid)\n",
      "  cols = len(grid[0])\n",
      "\n",
      "  # Another comment\n",
      "\n",
      "\n",
      "  return grid\n",
      "\n",
      "==================================================\n",
      "CLEANED CODE:\n",
      "'def solve(grid):\\n  # First comment\\n\\n  # Second comment after multiple empty lines\\n  rows = len(grid)\\n  cols = len(grid[0])\\n\\n  # Another comment\\n\\n  return grid'\n",
      "\n",
      "CLEANED CODE (formatted):\n",
      "def solve(grid):\n",
      "  # First comment\n",
      "\n",
      "  # Second comment after multiple empty lines\n",
      "  rows = len(grid)\n",
      "  cols = len(grid[0])\n",
      "\n",
      "  # Another comment\n",
      "\n",
      "  return grid\n",
      "\n",
      "==================================================\n",
      "CHANGES SUMMARY:\n",
      "Original length: 160 chars\n",
      "Cleaned length: 158 chars\n",
      "Characters removed: 2\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "test_code = \"\"\"def solve(grid):\n",
    "  # First comment\n",
    "\n",
    "\n",
    "  # Second comment after multiple empty lines\n",
    "  rows = len(grid)\n",
    "  cols = len(grid[0])\n",
    "  \n",
    "  # Another comment\n",
    "    \n",
    "    \n",
    "  return grid\"\"\"\n",
    "\n",
    "print(\"ORIGINAL CODE:\")\n",
    "print(repr(test_code))\n",
    "print(\"\\nORIGINAL CODE (formatted):\")\n",
    "print(test_code)\n",
    "\n",
    "cleaned = clean_multiple_newlines(test_code)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANED CODE:\")\n",
    "print(repr(cleaned))\n",
    "print(\"\\nCLEANED CODE (formatted):\")\n",
    "print(cleaned)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CHANGES SUMMARY:\")\n",
    "print(f\"Original length: {len(test_code)} chars\")\n",
    "print(f\"Cleaned length: {len(cleaned)} chars\")\n",
    "print(f\"Characters removed: {len(test_code) - len(cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   System prompt: 129 chars\n",
      "   Initial turn prompt: 1109 chars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre-filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2972/2972 [00:01<00:00, 1514.61 examples/s]\n",
      "build chat fields: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2972/2972 [00:02<00:00, 1010.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training data cleaning statistics:\n",
      "   Total examples (raw slice): 2972\n",
      "   Removed in pre-filter: 0\n",
      "   Examples retained: 2972\n",
      "   Examples with cleaned newlines (retained): 0\n",
      "   Examples with refinement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from llm_python.utils.task_loader import get_task_loader\n",
    "from llm_python.datasets.parquet_utils import parquet_to_dataset\n",
    "\n",
    "# Add this debug code right after building raw_ds:\n",
    "if data_source == \"parquet\":\n",
    "  raw_ds = parquet_to_dataset(parquet_path, max_rows)\n",
    "  print(\"DEBUG: Available columns in dataset:\", raw_ds.column_names)\n",
    "  if len(raw_ds) > 0:\n",
    "      print(\"DEBUG: First example keys:\", raw_ds[0].keys())\n",
    "\n",
    "SYSTEM_PROMPT = prompt_loader.get_system_message(\"soar\")\n",
    "INITIAL_TURN_PROMPT = prompt_loader.get_initial_turn_prompt(\"soar\")\n",
    "\n",
    "print(f\"   System prompt: {len(SYSTEM_PROMPT)} chars\")\n",
    "print(f\"   Initial turn prompt: {len(INITIAL_TURN_PROMPT)} chars\")\n",
    "\n",
    "def canonical_chat_mapper(example, task_loader, use_predicted_outputs=False):\n",
    "    \"\"\"\n",
    "    Converts a raw example to canonical chat format.\n",
    "    use_predicted_outputs: True for HF, False for parquet\n",
    "    \"\"\"\n",
    "    task_id = example[\"task_id\"]\n",
    "    task_data = task_loader.get_task(task_id)\n",
    "\n",
    "    raw_code = example[\"code\"]\n",
    "    cleaned_code = clean_multiple_newlines(raw_code)\n",
    "    cleaned_flag = int(cleaned_code != raw_code)\n",
    "\n",
    "    # Check if this is a refinement example\n",
    "    is_refinement = ('predicted_train_output_original' in example and\n",
    "                    example['predicted_train_output_original'] is not None and\n",
    "                    len(example.get('predicted_train_output_original', [])) > 0)\n",
    "\n",
    "    if is_refinement:\n",
    "        # REFINEMENT EXAMPLE: Use reference program's predictions as inputs\n",
    "        predicted_train_original = example['predicted_train_output_original']\n",
    "        predicted_test_original = example.get('predicted_test_output_original', [])\n",
    "\n",
    "        # Create swapped task data: reference predictions â†’ inputs, ground truth â†’ outputs\n",
    "        task_data_for_prompt = {\n",
    "            \"train\": [\n",
    "                {\n",
    "                    \"input\": predicted_train_original[i] if i < len(predicted_train_original) else ex[\"input\"],\n",
    "                    \"output\": ex[\"output\"]  # Ground truth from original task\n",
    "                }\n",
    "                for i, ex in enumerate(task_data[\"train\"])\n",
    "            ],\n",
    "            \"test\": [\n",
    "                {\n",
    "                    \"input\": predicted_test_original[i] if i < len(predicted_test_original) else ex[\"input\"],\n",
    "                    \"output\": ex[\"output\"]  # Ground truth from original task\n",
    "                }\n",
    "                for i, ex in enumerate(task_data[\"test\"])\n",
    "            ],\n",
    "            \"reasoning\": example[\"reasoning\"]\n",
    "        }\n",
    "\n",
    "        # For output tracking in the returned dict - respect use_predicted_outputs\n",
    "        if use_predicted_outputs:\n",
    "            train_outputs = example.get(\n",
    "                \"predicted_train_output\",\n",
    "                [ex[\"output\"] for ex in task_data[\"train\"]],\n",
    "            )\n",
    "            test_outputs = example.get(\n",
    "                \"predicted_test_output\",\n",
    "                [ex[\"output\"] for ex in task_data[\"test\"]],\n",
    "            )\n",
    "        else:\n",
    "            train_outputs = [ex[\"output\"] for ex in task_data[\"train\"]]\n",
    "            test_outputs = [ex[\"output\"] for ex in task_data[\"test\"]]\n",
    "\n",
    "    else:\n",
    "        # REGULAR EXAMPLE: Use original logic\n",
    "        if use_predicted_outputs:\n",
    "            train_outputs = example.get(\n",
    "                \"predicted_train_output\",\n",
    "                [ex[\"output\"] for ex in task_data[\"train\"]],\n",
    "            )\n",
    "            test_outputs = example.get(\n",
    "                \"predicted_test_output\",\n",
    "                [ex[\"output\"] for ex in task_data[\"test\"]],\n",
    "            )\n",
    "        else:\n",
    "            train_outputs = [ex[\"output\"] for ex in task_data[\"train\"]]\n",
    "            test_outputs = [ex[\"output\"] for ex in task_data[\"test\"]]\n",
    "\n",
    "        task_data_for_prompt = {\n",
    "            \"train\": [\n",
    "                {\"input\": ex[\"input\"], \"output\": out}\n",
    "                for ex, out in zip(task_data[\"train\"], train_outputs)\n",
    "            ],\n",
    "            \"test\": [\n",
    "                {\"input\": ex[\"input\"], \"output\": out}\n",
    "                for ex, out in zip(task_data[\"test\"], test_outputs)\n",
    "            ],\n",
    "            \"reasoning\": example[\"reasoning\"]\n",
    "        }\n",
    "\n",
    "    # Use standard SOAR prompt for both regular and refinement examples\n",
    "    system_content, user_content, reasoning = create_arc_prompt(task_data_for_prompt, prompt_loader, \"soar\")\n",
    "\n",
    "    if reasoning is not None:\n",
    "        if 'oss' in model_slug:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "                {\"role\": \"assistant\", \"content\": f\"```python\\n{cleaned_code}\\n```\", \"thinking\": reasoning},\n",
    "            ]\n",
    "        else:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "                {\"role\": \"assistant\", \"content\": f\"```python\\n{cleaned_code}\\n```\", \"reasoning_content\": reasoning},\n",
    "            ]\n",
    "    else:\n",
    "        if test_run:\n",
    "            print(\"Warning: Reasoning is None. Ensure this is expected!\")\n",
    "            \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": f\"```python\\n{cleaned_code}\\n```\"},\n",
    "        ]\n",
    "\n",
    "    extra_kwargs = {}\n",
    "    if \"qwen\" in model_slug.lower():\n",
    "        # only Qwen tokenizers understand this\n",
    "        extra_kwargs[\"enable_thinking\"] = enable_thinking\n",
    "    elif \"oss\" in model_slug.lower() or \"gpt-oss\" in model_slug.lower():\n",
    "        # GPT-OSS expects reasoning_effort\n",
    "        extra_kwargs[\"reasoning_effort\"] = \"medium\"\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False,\n",
    "        **extra_kwargs,\n",
    "    )\n",
    "    \n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages[:-1],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        **extra_kwargs,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"text\": text,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"train_input\": [ex[\"input\"] for ex in task_data_for_prompt[\"train\"]],\n",
    "        \"train_output\": train_outputs,\n",
    "        \"test_input\": [ex[\"input\"] for ex in task_data_for_prompt[\"test\"]],\n",
    "        \"test_output\": test_outputs,\n",
    "        \"task_id\": task_id,\n",
    "        \"cleaned_newlines\": cleaned_flag,\n",
    "        \"is_refinement_example\": is_refinement\n",
    "    }\n",
    "\n",
    "def build_canonical_dataset(\n",
    "    data_source, train_slug=None, parquet_path=None, max_rows=None, data_config=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build dataset from either HuggingFace or parquet source using canonical mapping.\n",
    "    \"\"\"\n",
    "    task_loader = get_task_loader()\n",
    "    use_predicted_outputs = data_source != \"parquet\"\n",
    "\n",
    "    if data_source == \"parquet\":\n",
    "        raw_ds = parquet_to_dataset(parquet_path, max_rows)\n",
    "    else:\n",
    "        effective_split = f\"train[:{max_rows}]\" if max_rows else \"train\"\n",
    "        raw_ds = load_dataset(train_slug, split=effective_split)\n",
    "\n",
    "    def keep_example(ex):\n",
    "        try:\n",
    "            task_loader.get_task(ex[\"task_id\"])\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "        cleaned = clean_multiple_newlines(ex[\"code\"])\n",
    "        if should_filter_code(cleaned, tokenizer, max_tokens=2000):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    ds_kept = raw_ds.filter(keep_example, desc=\"pre-filter\", load_from_cache_file=False)\n",
    "    train_ds = ds_kept.map(\n",
    "        lambda ex: canonical_chat_mapper(\n",
    "            ex, task_loader, use_predicted_outputs=use_predicted_outputs\n",
    "        ),\n",
    "        desc=\"build chat fields\",\n",
    "        load_from_cache_file=False,\n",
    "    )\n",
    "\n",
    "    total_raw = raw_ds.num_rows\n",
    "    kept = ds_kept.num_rows\n",
    "    retained = train_ds.num_rows\n",
    "    cleaned_count = (\n",
    "        sum(train_ds[\"cleaned_newlines\"])\n",
    "        if \"cleaned_newlines\" in train_ds.column_names\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    print(\"\\nğŸ“Š Training data cleaning statistics:\")\n",
    "    print(f\"   Total examples (raw slice): {total_raw}\")\n",
    "    print(f\"   Removed in pre-filter: {total_raw - kept}\")\n",
    "    print(f\"   Examples retained: {retained}\")\n",
    "    print(f\"   Examples with cleaned newlines (retained): {cleaned_count}\")\n",
    "    print(f\"   Examples with refinement: {sum(train_ds['is_refinement_example'])}\")\n",
    "\n",
    "    return DatasetDict(train=train_ds)\n",
    "# ---------------------------------------------------------------------\n",
    "# Build the dataset\n",
    "# ---------------------------------------------------------------------\n",
    "data = build_canonical_dataset(\n",
    "    data_source=data_source,\n",
    "    train_slug=train_slug,\n",
    "    parquet_path=parquet_path,\n",
    "    max_rows=max_rows,\n",
    "    data_config=data_config,\n",
    ")\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Calculate validation size: min(32, 10% of train set)\n",
    "val_size = min(32, int(0.1 * len(data[\"train\"])))\n",
    "\n",
    "# Train/val split\n",
    "train_size = len(data[\"train\"]) - val_size\n",
    "train_data = data[\"train\"].select(range(train_size))\n",
    "val_data = data[\"train\"].select(range(train_size, len(data[\"train\"])))\n",
    "\n",
    "# Replace with new DatasetDict\n",
    "data = DatasetDict({\n",
    "    \"train\": train_data,\n",
    "    \"validation\": val_data,\n",
    "})\n",
    "\n",
    "# # WARNING - really we should be doing this, to shuffle\n",
    "# data = data[\"train\"].train_test_split(\n",
    "#     test_size=val_size,\n",
    "#     seed=42,       # fixes randomness\n",
    "#     shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['row_id', 'task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input', 'predicted_train_output', 'predicted_test_output', 'model', 'is_transductive', 'refined_from_id', 'compound_inspiration_id', 'messages', 'text', 'prompt', 'train_input', 'train_output', 'test_input', 'test_output', 'cleaned_newlines', 'is_refinement_example'],\n",
      "    num_rows: 2940\n",
      "})\n",
      "Dataset({\n",
      "    features: ['row_id', 'task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input', 'predicted_train_output', 'predicted_test_output', 'model', 'is_transductive', 'refined_from_id', 'compound_inspiration_id', 'messages', 'text', 'prompt', 'train_input', 'train_output', 'test_input', 'test_output', 'cleaned_newlines', 'is_refinement_example'],\n",
      "    num_rows: 32\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"])\n",
    "print(data[\"validation\"])\n",
    "\n",
    "# print(data[\"train\"][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "PTZICZtie3lQ",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's see the structure of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true,
    "id": "jfV47_SXgXH4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2940/2940 [00:24<00:00, 119.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train:  min= 861  median=5494  max=31223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 107.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " validation:  min=1405  median=6569  max=13392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2940/2940 [00:24<00:00, 118.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by reasoning and generating Python code.<|im_end|>\n",
      "<|im_start|>user\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by generating Python code.\n",
      "Your goal is to analyze input-output grid pairs. The outputs were produced by applying a transformation rule to the inputs. Implement the transformation rules as a Python function.\n",
      "\n",
      "You must write code in triple backticks (```python and then ```). You must write a function called 'transform' which takes a single argument, the input grid as 'list[list[int]]', and returns the transformed grid (also as 'list[list[int]]').\n",
      "\n",
      "You should make sure that you implement a version of the transformation which works in general (at least for all given input-output pairs and test input pairs). The code should NOT hardcode specific predicted outputs.\n",
      "\n",
      "The number in the input grid can be mapped to the following colors: 0:Black; 1:Blue; 2:Red; 3:Green; 4:Yellow; 5:Grey; 6:Pink; 7:Orange; 8:Purple; 9:Brown\n",
      "\n",
      "IMPORTANT: Your response must end with a Python code block containing the transform function. Do not add any text after the closing ``` of your final code block.\n",
      "\n",
      "# Task to solve:\n",
      "## Input 1 (grid shape: 3 by 3):\n",
      "[[8 8 8] [5 5 8] [8 5 5]]\n",
      "## Output 1 (grid shape: 3 by 3):\n",
      "[[5 5 8] [8 5 5] [8 8 8]]\n",
      "\n",
      "## Input 2 (grid shape: 3 by 3):\n",
      "[[9 2 4] [2 4 4] [2 9 2]]\n",
      "## Output 2 (grid shape: 3 by 3):\n",
      "[[2 9 2] [4 4 2] [4 2 9]]\n",
      "\n",
      "## Input 3 (grid shape: 3 by 3):\n",
      "[[3 2 9] [9 9 9] [2 3 3]]\n",
      "## Output 3 (grid shape: 3 by 3):\n",
      "[[3 3 2] [9 9 9] [9 2 3]]\n",
      "\n",
      "## Input 4 (grid shape: 3 by 3):\n",
      "[[2 2 1] [2 1 2] [2 8 1]]\n",
      "## Output 4 (grid shape: 3 by 3):\n",
      "[[1 8 2] [2 1 2] [1 2 2]]\n",
      "\n",
      "## Test Input 1 (grid shape: 3 by 3):\n",
      "[[6 4 4] [6 6 4] [4 6 7]]\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "**Analyzing matrix rotations**\n",
      "\n",
      "I'm checking if the matrices are sorted by columns, but it seems that's not the case. The output appears to be transposed and reversed. So, Iâ€™ll compare the input and output matrices. \n",
      "\n",
      "For the first matrix, rotating it 180 degrees gives me the expected output. Then I try the second matrix: the rotations turn out to match perfectly as well. Everything checks out great!**Testing matrix rotations**\n",
      "\n",
      "I'm testing Input3, a 3x3 matrix, to see if a 180-degree rotation gives me the expected output. For this matrix, reversing the rows and then each row separately yields the correct transformation. \n",
      "\n",
      "Next, I move on to Input4. After reversing the order and each row for the 180 rotation, the results match Output4 perfectly. Great, everything's working well! Now Iâ€™ll write a function named `transform(grid)` that implements this logic for a 180-degree rotation of a 3x3 matrix.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "def transform(grid: list[list[int]]) -> list[list[int]]:\n",
      "\n",
      "    if not grid:\n",
      "        return []\n",
      "    return [row[::-1] for row in grid[::-1]]\n",
      "```<|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "def length_stats(dataset, name=\"\"):\n",
    "    \"\"\"\n",
    "    Return min / median / max tokenised length for a ğŸ¤— Dataset split that has a\n",
    "    single 'text' column. Uses the same tokenizer already in memory.\n",
    "    \"\"\"\n",
    "    # Tokenise in batches â†’ list of list[int] â†’ list[int] lengths\n",
    "    lengths = dataset.map(\n",
    "        lambda batch: {\n",
    "            \"len\": [len(ids) for ids in tokenizer(batch[\"text\"],\n",
    "                                                  add_special_tokens=False\n",
    "                                                 )[\"input_ids\"]]\n",
    "        },\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,   # drop 'text'\n",
    "        keep_in_memory=True,\n",
    "    )[\"len\"]\n",
    "\n",
    "    print(f\"{name:>11}:  min={min(lengths):>4}  \"\n",
    "          f\"median={int(median(lengths)):>4}  max={max(lengths):>4}\")\n",
    "\n",
    "# â”€â”€ run for both splits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "length_stats(data[\"train\"],       \"train\")\n",
    "\n",
    "# â”€â”€ run for both splits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "length_stats(data[\"validation\"],       \"validation\")\n",
    "\n",
    "# # shortest-by tokenized length\n",
    "# train = data[\"train\"]\n",
    "\n",
    "# tok_lengths = train.map(\n",
    "#     lambda batch: {\n",
    "#         \"len\": [len(ids) for ids in tokenizer(batch[\"text\"], add_special_tokens=False)[\"input_ids\"]]\n",
    "#     },\n",
    "#     batched=True,\n",
    "#     keep_in_memory=True,\n",
    "#     remove_columns=[],  # don't drop columns; original dataset is unchanged anyway\n",
    "# )[\"len\"]\n",
    "\n",
    "# min_idx = int(np.argmin(tok_lengths))\n",
    "# shortest_row = train[min_idx]\n",
    "\n",
    "# print(train[min_idx][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Pre-Training Data Integrity Tests\n",
    "Before training, let's test the ground-truth code on a random sample of training examples to validate dataset quality and establish baseline performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Running Pre-Training Data Integrity Tests\n",
      "ğŸ“Š Testing 32 random examples from train split\n",
      "============================================================\n",
      "\n",
      "ğŸ” Testing 32 examples...\n",
      "\n",
      "[1/32] Testing 21f83797\n",
      "  âœ… Train: 2/2 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[2/32] Testing e48d4e1a\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[3/32] Testing 25ff71a9\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  2/2 (100.0%)\n",
      "\n",
      "[4/32] Testing e4941b18\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[5/32] Testing 03560426\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[6/32] Testing e9bb6954\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[7/32] Testing ae4f1146\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[8/32] Testing 22208ba4\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[9/32] Testing 025d127b\n",
      "  âœ… Train: 2/2 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[10/32] Testing 4c5c2cf0\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[11/32] Testing 1a2e2828\n",
      "  âœ… Train: 5/5 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[12/32] Testing e41c6fd3\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[13/32] Testing 834ec97d\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[14/32] Testing 53b68214\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  2/2 (100.0%)\n",
      "\n",
      "[15/32] Testing f18ec8cc\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  2/2 (100.0%)\n",
      "\n",
      "[16/32] Testing 23b5c85d\n",
      "  âœ… Train: 5/5 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[17/32] Testing 0a938d79\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[18/32] Testing f5b8619d\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[19/32] Testing d4a91cb9\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[20/32] Testing ca8f78db\n",
      "  âœ… Train: 0/3 (0.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[21/32] Testing 5d588b4d\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  2/2 (100.0%)\n",
      "\n",
      "[22/32] Testing 6855a6e4\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[23/32] Testing 91413438\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[24/32] Testing 070dd51e\n",
      "  âœ… Train: 2/2 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[25/32] Testing 551d5bf1\n",
      "  âœ… Train: 2/2 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[26/32] Testing 8eb1be9a\n",
      "  âœ… Train: 2/2 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[27/32] Testing 4c5c2cf0\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[28/32] Testing 963e52fc\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[29/32] Testing 855e0971\n",
      "  âœ… Train: 4/4 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[30/32] Testing 1cf80156\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[31/32] Testing 18419cfa\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n",
      "[32/32] Testing 4364c1c4\n",
      "  âœ… Train: 3/3 (100.0%)\n",
      "  âœ… Test:  1/1 (100.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Configuration for pre-training tests\n",
    "NUM_TEST_EXAMPLES = 32  # Number of random examples to test\n",
    "RANDOM_SEED = 42  # For reproducible results\n",
    "\n",
    "def run_pre_training_data_integrity_tests(dataset_split=\"train\", num_examples=NUM_TEST_EXAMPLES):\n",
    "    \"\"\"\n",
    "    Test ground-truth code from dataset on random examples to validate data quality.\n",
    "    \n",
    "    Args:\n",
    "        dataset_split: Which split to test (should be \"train\" since validation has no ground-truth code)\n",
    "        num_examples: Number of random examples to test\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ§ª Running Pre-Training Data Integrity Tests\")\n",
    "    print(f\"ğŸ“Š Testing {num_examples} random examples from {dataset_split} split\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set seed for reproducible sampling\n",
    "    random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Get the dataset split\n",
    "    dataset = data[dataset_split]\n",
    "    \n",
    "    # Randomly sample examples\n",
    "    total_examples = len(dataset)\n",
    "    if num_examples > total_examples:\n",
    "        print(f\"âš ï¸  Requested {num_examples} examples but only {total_examples} available. Testing all.\")\n",
    "        sample_indices = list(range(total_examples))\n",
    "    else:\n",
    "        sample_indices = random.sample(range(total_examples), num_examples)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    results = []\n",
    "    executor = ArcTester(timeout=5.0, executor_type=\"unrestricted\")\n",
    "    \n",
    "    print(f\"\\nğŸ” Testing {len(sample_indices)} examples...\\n\")\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        example = dataset[idx]\n",
    "        task_id = example.get(\"task_id\", f\"idx_{idx}\")\n",
    "        if \"code\" in example:\n",
    "          code = example[\"code\"]  # HuggingFace format AND parquet format\n",
    "        else:\n",
    "          code = \"\"\n",
    "        \n",
    "        print(f\"[{i+1}/{len(sample_indices)}] Testing {task_id}\")\n",
    "        \n",
    "        # Initialize results for this example\n",
    "        example_result = {\n",
    "            \"task_id\": task_id,\n",
    "            \"index\": idx,\n",
    "            \"code\": code,\n",
    "            \"train_results\": [],\n",
    "            \"test_results\": [],\n",
    "            \"train_success\": 0,\n",
    "            \"test_success\": 0,\n",
    "            \"code_executed\": False,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        \n",
    "        # Test on training examples\n",
    "        train_correct = 0\n",
    "        for t_idx, (train_in, train_out) in enumerate(zip(example[\"train_input\"], example[\"train_output\"])):\n",
    "            try:\n",
    "                predicted_output, error, timed_out = executor.execute_program_with_timeout(code, train_in)\n",
    "                \n",
    "                if predicted_output is not None:\n",
    "                    example_result[\"code_executed\"] = True\n",
    "                    score_result = scorer.score_grid(predicted_output, train_out)\n",
    "                    is_correct = score_result[\"correct\"]\n",
    "                    \n",
    "                    if is_correct:\n",
    "                        train_correct += 1\n",
    "                    \n",
    "                    example_result[\"train_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": is_correct,\n",
    "                        \"predicted\": predicted_output,\n",
    "                        \"expected\": train_out,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                else:\n",
    "                    example_result[\"train_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": False,\n",
    "                        \"error\": error,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                    if error:\n",
    "                        example_result[\"errors\"].append(f\"Train {t_idx}: {error}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                example_result[\"train_results\"].append({\n",
    "                    \"index\": t_idx,\n",
    "                    \"correct\": False,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                example_result[\"errors\"].append(f\"Train {t_idx}: {str(e)}\")\n",
    "        \n",
    "        # Test on test examples\n",
    "        test_correct = 0\n",
    "        for t_idx, (test_in, test_out) in enumerate(zip(example[\"test_input\"], example[\"test_output\"])):\n",
    "            try:\n",
    "                predicted_output, error, timed_out = executor.execute_program_with_timeout(code, test_in)\n",
    "                \n",
    "                if predicted_output is not None:\n",
    "                    example_result[\"code_executed\"] = True\n",
    "                    score_result = scorer.score_grid(predicted_output, test_out)\n",
    "                    is_correct = score_result[\"correct\"]\n",
    "                    \n",
    "                    if is_correct:\n",
    "                        test_correct += 1\n",
    "                    \n",
    "                    example_result[\"test_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": is_correct,\n",
    "                        \"predicted\": predicted_output,\n",
    "                        \"expected\": test_out,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                else:\n",
    "                    example_result[\"test_results\"].append({\n",
    "                        \"index\": t_idx,\n",
    "                        \"correct\": False,\n",
    "                        \"error\": error,\n",
    "                        \"timed_out\": timed_out\n",
    "                    })\n",
    "                    if error:\n",
    "                        example_result[\"errors\"].append(f\"Test {t_idx}: {error}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                example_result[\"test_results\"].append({\n",
    "                    \"index\": t_idx,\n",
    "                    \"correct\": False,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                example_result[\"errors\"].append(f\"Test {t_idx}: {str(e)}\")\n",
    "        \n",
    "        # Calculate success rates for this example\n",
    "        example_result[\"train_success\"] = train_correct / len(example[\"train_input\"]) if example[\"train_input\"] else 0\n",
    "        example_result[\"test_success\"] = test_correct / len(example[\"test_input\"]) if example[\"test_input\"] else 0\n",
    "        \n",
    "        # Print summary for this example\n",
    "        total_train = len(example[\"train_input\"])\n",
    "        total_test = len(example[\"test_input\"])\n",
    "        \n",
    "        print(f\"  âœ… Train: {train_correct}/{total_train} ({example_result['train_success']:.1%})\")\n",
    "        print(f\"  âœ… Test:  {test_correct}/{total_test} ({example_result['test_success']:.1%})\")\n",
    "        \n",
    "        if example_result[\"errors\"]:\n",
    "            print(f\"  âŒ Errors: {len(example_result['errors'])}\")\n",
    "        if not example_result[\"code_executed\"]:\n",
    "            print(f\"  âš ï¸  Code never executed successfully\")\n",
    "        print()\n",
    "        \n",
    "        results.append(example_result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the tests\n",
    "data_integrity_results = run_pre_training_data_integrity_tests(\"train\", NUM_TEST_EXAMPLES)\n",
    "# data_integrity_results = run_pre_training_data_integrity_tests(\"validation\", NUM_TEST_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“ˆ PRE-TRAINING DATA INTEGRITY RESULTS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ OVERALL PERFORMANCE:\n",
      "   Examples tested: 32\n",
      "   Code executable: 32/32 (100.0%)\n",
      "   Examples with errors: 0/32 (0.0%)\n",
      "\n",
      "ğŸ“Š TRAINING GRIDS PERFORMANCE:\n",
      "   Average success rate: 96.9%\n",
      "   Perfect examples (100%): 31/32 (96.9%)\n",
      "   Partial examples (>0% <100%): 0/32 (0.0%)\n",
      "   Failed examples (0%): 1/32 (3.1%)\n",
      "   Grid-level accuracy: 102/105 (97.1%)\n",
      "\n",
      "ğŸ¯ TEST GRIDS PERFORMANCE:\n",
      "   Average success rate: 100.0%\n",
      "   Perfect examples (100%): 32/32 (100.0%)\n",
      "   Partial examples (>0% <100%): 0/32 (0.0%)\n",
      "   Failed examples (0%): 0/32 (0.0%)\n",
      "   Grid-level accuracy: 36/36 (100.0%)\n",
      "\n",
      "ğŸ“‹ DETAILED BREAKDOWN BY EXAMPLE:\n",
      "------------------------------------------------------------\n",
      "[ 1] 21f83797\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 2] e48d4e1a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 3] 25ff71a9\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 4] e4941b18\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 5] 03560426\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 6] e9bb6954\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 7] ae4f1146\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 8] 22208ba4\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[ 9] 025d127b\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[10] 4c5c2cf0\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[11] 1a2e2828\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[12] e41c6fd3\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[13] 834ec97d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[14] 53b68214\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[15] f18ec8cc\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[16] 23b5c85d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[17] 0a938d79\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[18] f5b8619d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[19] d4a91cb9\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[20] ca8f78db\n",
      "     Train:  0.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[21] 5d588b4d\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[22] 6855a6e4\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[23] 91413438\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[24] 070dd51e\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[25] 551d5bf1\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[26] 8eb1be9a\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[27] 4c5c2cf0\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[28] 963e52fc\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[29] 855e0971\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[30] 1cf80156\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[31] 18419cfa\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "[32] 4364c1c4\n",
      "     Train: 100.0% | Test: 100.0% | Executed: âœ… | Errors: 0\n",
      "\n",
      "ğŸ” DATASET QUALITY ASSESSMENT:\n",
      "------------------------------------------------------------\n",
      "âœ… EXCELLENT: Ground-truth code performs very well on training examples\n",
      "âœ… EXCELLENT: Ground-truth code generalizes very well to test examples\n",
      "âœ… EXCELLENT: All ground-truth code is executable\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def analyze_data_integrity_results(results):\n",
    "    \"\"\"\n",
    "    Analyze and display comprehensive statistics from the data integrity tests.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“ˆ PRE-TRAINING DATA INTEGRITY RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"âŒ No results to analyze!\")\n",
    "        return\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_examples = len(results)\n",
    "    examples_with_executable_code = sum(1 for r in results if r[\"code_executed\"])\n",
    "    examples_with_errors = sum(1 for r in results if r[\"errors\"])\n",
    "    \n",
    "    # Training performance statistics\n",
    "    train_success_rates = [r[\"train_success\"] for r in results]\n",
    "    perfect_train = sum(1 for rate in train_success_rates if rate == 1.0)\n",
    "    partial_train = sum(1 for rate in train_success_rates if 0 < rate < 1.0)\n",
    "    failed_train = sum(1 for rate in train_success_rates if rate == 0.0)\n",
    "    \n",
    "    # Test performance statistics  \n",
    "    test_success_rates = [r[\"test_success\"] for r in results]\n",
    "    perfect_test = sum(1 for rate in test_success_rates if rate == 1.0)\n",
    "    partial_test = sum(1 for rate in test_success_rates if 0 < rate < 1.0)\n",
    "    failed_test = sum(1 for rate in test_success_rates if rate == 0.0)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    avg_train_success = sum(train_success_rates) / len(train_success_rates) if train_success_rates else 0\n",
    "    avg_test_success = sum(test_success_rates) / len(test_success_rates) if test_success_rates else 0\n",
    "    \n",
    "    # Count total grids tested\n",
    "    total_train_grids = sum(len(r[\"train_results\"]) for r in results)\n",
    "    total_test_grids = sum(len(r[\"test_results\"]) for r in results)\n",
    "    correct_train_grids = sum(sum(tr[\"correct\"] for tr in r[\"train_results\"]) for r in results)\n",
    "    correct_test_grids = sum(sum(tr[\"correct\"] for tr in r[\"test_results\"]) for r in results)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ OVERALL PERFORMANCE:\")\n",
    "    print(f\"   Examples tested: {total_examples}\")\n",
    "    print(f\"   Code executable: {examples_with_executable_code}/{total_examples} ({examples_with_executable_code/total_examples:.1%})\")\n",
    "    print(f\"   Examples with errors: {examples_with_errors}/{total_examples} ({examples_with_errors/total_examples:.1%})\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š TRAINING GRIDS PERFORMANCE:\")\n",
    "    print(f\"   Average success rate: {avg_train_success:.1%}\")\n",
    "    print(f\"   Perfect examples (100%): {perfect_train}/{total_examples} ({perfect_train/total_examples:.1%})\")\n",
    "    print(f\"   Partial examples (>0% <100%): {partial_train}/{total_examples} ({partial_train/total_examples:.1%})\")\n",
    "    print(f\"   Failed examples (0%): {failed_train}/{total_examples} ({failed_train/total_examples:.1%})\")\n",
    "    print(f\"   Grid-level accuracy: {correct_train_grids}/{total_train_grids} ({correct_train_grids/total_train_grids:.1%})\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ TEST GRIDS PERFORMANCE:\")\n",
    "    print(f\"   Average success rate: {avg_test_success:.1%}\")\n",
    "    print(f\"   Perfect examples (100%): {perfect_test}/{total_examples} ({perfect_test/total_examples:.1%})\")\n",
    "    print(f\"   Partial examples (>0% <100%): {partial_test}/{total_examples} ({partial_test/total_examples:.1%})\")\n",
    "    print(f\"   Failed examples (0%): {failed_test}/{total_examples} ({failed_test/total_examples:.1%})\")\n",
    "    print(f\"   Grid-level accuracy: {correct_test_grids}/{total_test_grids} ({correct_test_grids/total_test_grids:.1%})\")\n",
    "    \n",
    "    # Detailed breakdown by example\n",
    "    print(f\"\\nğŸ“‹ DETAILED BREAKDOWN BY EXAMPLE:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        task_id = result[\"task_id\"]\n",
    "        train_rate = result[\"train_success\"]\n",
    "        test_rate = result[\"test_success\"]\n",
    "        executed = \"âœ…\" if result[\"code_executed\"] else \"âŒ\"\n",
    "        error_count = len(result[\"errors\"])\n",
    "        \n",
    "        print(f\"[{i+1:2d}] {task_id}\")\n",
    "        print(f\"     Train: {train_rate:5.1%} | Test: {test_rate:5.1%} | Executed: {executed} | Errors: {error_count}\")\n",
    "        \n",
    "        if result[\"errors\"] and len(result[\"errors\"]) <= 3:  # Show first few errors\n",
    "            for error in result[\"errors\"][:3]:\n",
    "                print(f\"     Error: {error}\")\n",
    "        elif len(result[\"errors\"]) > 3:\n",
    "            print(f\"     Errors: {result['errors'][0]} ... (+{len(result['errors'])-1} more)\")\n",
    "    \n",
    "    # Quality assessment\n",
    "    print(f\"\\nğŸ” DATASET QUALITY ASSESSMENT:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if avg_train_success > 0.9:\n",
    "        print(\"âœ… EXCELLENT: Ground-truth code performs very well on training examples\")\n",
    "    elif avg_train_success > 0.7:\n",
    "        print(\"âœ… GOOD: Ground-truth code performs well on training examples\")\n",
    "    elif avg_train_success > 0.5:\n",
    "        print(\"âš ï¸  MODERATE: Ground-truth code has mixed performance on training examples\")\n",
    "    else:\n",
    "        print(\"âŒ POOR: Ground-truth code has low performance on training examples\")\n",
    "    \n",
    "    if avg_test_success > 0.9:\n",
    "        print(\"âœ… EXCELLENT: Ground-truth code generalizes very well to test examples\")\n",
    "    elif avg_test_success > 0.7:\n",
    "        print(\"âœ… GOOD: Ground-truth code generalizes well to test examples\")\n",
    "    elif avg_test_success > 0.5:\n",
    "        print(\"âš ï¸  MODERATE: Ground-truth code has mixed generalization to test examples\")\n",
    "    else:\n",
    "        print(\"âŒ POOR: Ground-truth code has poor generalization to test examples\")\n",
    "    \n",
    "    if examples_with_executable_code == total_examples:\n",
    "        print(\"âœ… EXCELLENT: All ground-truth code is executable\")\n",
    "    elif examples_with_executable_code / total_examples > 0.9:\n",
    "        print(\"âœ… GOOD: Most ground-truth code is executable\")\n",
    "    else:\n",
    "        print(\"âš ï¸  ISSUE: Some ground-truth code is not executable\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    return {\n",
    "        \"total_examples\": total_examples,\n",
    "        \"executable_rate\": examples_with_executable_code / total_examples,\n",
    "        \"avg_train_success\": avg_train_success,\n",
    "        \"avg_test_success\": avg_test_success,\n",
    "        \"perfect_train_rate\": perfect_train / total_examples,\n",
    "        \"perfect_test_rate\": perfect_test / total_examples,\n",
    "        \"train_grid_accuracy\": correct_train_grids / total_train_grids if total_train_grids > 0 else 0,\n",
    "        \"test_grid_accuracy\": correct_test_grids / total_test_grids if total_test_grids > 0 else 0\n",
    "    }\n",
    "\n",
    "# Analyze the results\n",
    "summary_stats = analyze_data_integrity_results(data_integrity_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” FAILING EXAMPLES SUMMARY:\n",
      "Found 1 examples with issues: [19]\n",
      "To examine a specific failure, run: examine_failure(data_integrity_results, index)\n",
      "Example: examine_failure(data_integrity_results, 0)\n",
      "\n",
      "âœ… Pre-training data integrity tests complete!\n",
      "ğŸ“‹ Summary stats saved in 'summary_stats' variable\n",
      "ğŸ“Š Detailed results saved in 'data_integrity_results' variable\n"
     ]
    }
   ],
   "source": [
    "def normalize_grid(grid):\n",
    "  \"\"\"Convert any grid format to native Python list of lists.\"\"\"\n",
    "  if hasattr(grid, 'tolist'):  # numpy or PyArrow array\n",
    "      return grid.tolist()\n",
    "  elif isinstance(grid, list):\n",
    "      return [[int(cell) for cell in row] for row in grid]\n",
    "  return grid\n",
    "\n",
    "def examine_failure(results, example_index):\n",
    "  \"\"\"Examine a specific failing example in detail with grid visualization.\"\"\"\n",
    "  if example_index >= len(results):\n",
    "      print(f\"âŒ Invalid index {example_index}. Only {len(results)} examples available.\")\n",
    "      return\n",
    "\n",
    "  result = results[example_index]\n",
    "  dataset_example = data[\"train\"][result['index']]  # Get the original dataset example\n",
    "\n",
    "  print(f\"\\nğŸ” DETAILED EXAMINATION: Example {example_index + 1}\")\n",
    "  print(f\"Task ID: {result['task_id']}\")\n",
    "  print(f\"Dataset Index: {result['index']}\")\n",
    "  print(\"=\" * 70)\n",
    "\n",
    "  print(f\"\\nğŸ“ GROUND TRUTH CODE:\")\n",
    "  print(\"-\" * 30)\n",
    "  print(result['code'])\n",
    "\n",
    "  print(f\"\\nğŸ“Š EXECUTION SUMMARY:\")\n",
    "  print(f\"Code executed successfully: {result['code_executed']}\")\n",
    "  print(f\"Train success rate: {result['train_success']:.1%}\")\n",
    "  print(f\"Test success rate: {result['test_success']:.1%}\")\n",
    "  print(f\"Number of errors: {len(result['errors'])}\")\n",
    "\n",
    "  if result['errors']:\n",
    "      print(f\"\\nâŒ ERRORS:\")\n",
    "      for i, error in enumerate(result['errors']):\n",
    "          print(f\"  {i+1}. {error}\")\n",
    "\n",
    "  # Load original task for ground truth comparison\n",
    "  task_loader = get_task_loader()\n",
    "  try:\n",
    "      original_task = task_loader.get_task(result['task_id'])\n",
    "  except Exception as e:\n",
    "      print(f\"âŒ Could not load original task: {e}\")\n",
    "      return\n",
    "\n",
    "  def print_grid(grid, title):\n",
    "      \"\"\"Helper to print a grid nicely.\"\"\"\n",
    "      print(f\"\\n{title}:\")\n",
    "      if grid is None:\n",
    "          print(\"  None\")\n",
    "          return\n",
    "      for row in grid:\n",
    "          print(\"  \" + \" \".join(f\"{cell:2d}\" for cell in row))\n",
    "\n",
    "  # Examine training examples\n",
    "  print(f\"\\nğŸ‹ï¸ TRAINING EXAMPLES:\")\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "  for i, train_result in enumerate(result['train_results']):\n",
    "      print(f\"\\nTrain Example {i + 1}: {'âœ… CORRECT' if train_result['correct'] else 'âŒ INCORRECT'}\")\n",
    "      print(\"-\" * 40)\n",
    "\n",
    "      # Input (should be same from dataset and original)\n",
    "      dataset_input = dataset_example[\"train_input\"][i]\n",
    "      original_input = original_task[\"train\"][i][\"input\"]\n",
    "      print_grid(dataset_input, \"Input (from dataset)\")\n",
    "      if normalize_grid(dataset_input) != normalize_grid(original_input):\n",
    "          print_grid(original_input, \"Input (from original) - MISMATCH!\")\n",
    "\n",
    "      # Expected output (from dataset - might be predicted)\n",
    "      dataset_expected = dataset_example[\"train_output\"][i]\n",
    "      original_expected = original_task[\"train\"][i][\"output\"]\n",
    "      print_grid(dataset_expected, \"Expected (from dataset)\")\n",
    "      if normalize_grid(dataset_expected) != normalize_grid(original_expected):\n",
    "          print_grid(original_expected, \"Expected (ground truth) - DIFFERENT!\")\n",
    "\n",
    "      # Predicted output (from code execution)\n",
    "      if 'predicted' in train_result:\n",
    "          print_grid(train_result['predicted'], \"Predicted (from code)\")\n",
    "\n",
    "      if 'error' in train_result:\n",
    "          print(f\"\\nâŒ Execution Error: {train_result['error']}\")\n",
    "\n",
    "  # Examine test examples\n",
    "  print(f\"\\nğŸ§ª TEST EXAMPLES:\")\n",
    "  print(\"=\" * 50)\n",
    "\n",
    "  for i, test_result in enumerate(result['test_results']):\n",
    "      print(f\"\\nTest Example {i + 1}: {'âœ… CORRECT' if test_result['correct'] else 'âŒ INCORRECT'}\")\n",
    "      print(\"-\" * 40)\n",
    "\n",
    "      # Input\n",
    "      dataset_input = dataset_example[\"test_input\"][i]\n",
    "      original_input = original_task[\"test\"][i][\"input\"]\n",
    "      print_grid(dataset_input, \"Input (from dataset)\")\n",
    "      if normalize_grid(dataset_input) != normalize_grid(original_input):\n",
    "          print_grid(original_input, \"Input (from original) - MISMATCH!\")\n",
    "\n",
    "      # Expected output\n",
    "      dataset_expected = dataset_example[\"test_output\"][i]\n",
    "      original_expected = original_task[\"test\"][i].get(\"output\")  # Might be None\n",
    "      print_grid(dataset_expected, \"Expected (from dataset)\")\n",
    "      if original_expected and normalize_grid(dataset_expected) != normalize_grid(original_expected):\n",
    "          print_grid(original_expected, \"Expected (ground truth) - DIFFERENT!\")\n",
    "      elif not original_expected:\n",
    "          print(\"Expected (ground truth): No ground truth available\")\n",
    "\n",
    "      # Predicted output\n",
    "      if 'predicted' in test_result:\n",
    "          print_grid(test_result['predicted'], \"Predicted (from code)\")\n",
    "\n",
    "      if 'error' in test_result:\n",
    "          print(f\"\\nâŒ Execution Error: {test_result['error']}\")\n",
    "\n",
    "# Check for failing examples\n",
    "failed_examples = [i for i, r in enumerate(data_integrity_results)\n",
    "                if r['train_success'] < 1.0 or r['test_success'] < 1.0 or not r['code_executed']]\n",
    "\n",
    "print(f\"\\nğŸ” FAILING EXAMPLES SUMMARY:\")\n",
    "if failed_examples:\n",
    "  print(f\"Found {len(failed_examples)} examples with issues: {failed_examples}\")\n",
    "  print(\"To examine a specific failure, run: examine_failure(data_integrity_results, index)\")\n",
    "  print(\"Example: examine_failure(data_integrity_results, 0)\")\n",
    "else:\n",
    "  print(\"ğŸ‰ No failing examples found! All ground-truth code works perfectly.\")\n",
    "\n",
    "print(f\"\\nâœ… Pre-training data integrity tests complete!\")\n",
    "print(f\"ğŸ“‹ Summary stats saved in 'summary_stats' variable\")\n",
    "print(f\"ğŸ“Š Detailed results saved in 'data_integrity_results' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” DETAILED EXAMINATION: Example 19\n",
      "Task ID: d4a91cb9\n",
      "Dataset Index: 2069\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ GROUND TRUTH CODE:\n",
      "------------------------------\n",
      "def transform(grid):\n",
      "\n",
      "    r8 = c8 = r2 = c2 = None\n",
      "    for r, row in enumerate(grid):\n",
      "        for c, val in enumerate(row):\n",
      "            if val == 8:\n",
      "                r8, c8 = r, c\n",
      "            elif val == 2:\n",
      "                r2, c2 = r, c\n",
      "\n",
      "    for r in range(min(r8, r2), max(r8, r2) + 1):\n",
      "        if grid[r][c8] not in (8, 2):\n",
      "            grid[r][c8] = 4\n",
      "\n",
      "    for c in range(min(c8, c2), max(c8, c2) + 1):\n",
      "        if grid[r2][c] not in (8, 2):\n",
      "            grid[r2][c] = 4\n",
      "    return grid\n",
      "\n",
      "ğŸ“Š EXECUTION SUMMARY:\n",
      "Code executed successfully: True\n",
      "Train success rate: 100.0%\n",
      "Test success rate: 100.0%\n",
      "Number of errors: 0\n",
      "\n",
      "ğŸ‹ï¸ TRAINING EXAMPLES:\n",
      "==================================================\n",
      "\n",
      "Train Example 1: âœ… CORRECT\n",
      "----------------------------------------\n",
      "\n",
      "Input (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  8  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  2  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Expected (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  8  0  0\n",
      "   0  0  0  0  0  0  0  0  4  0  0\n",
      "   0  0  0  0  0  0  0  0  4  0  0\n",
      "   0  0  0  0  0  0  0  0  4  0  0\n",
      "   0  2  4  4  4  4  4  4  4  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Predicted (from code):\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  8  0  0\n",
      "   0  0  0  0  0  0  0  0  4  0  0\n",
      "   0  0  0  0  0  0  0  0  4  0  0\n",
      "   0  0  0  0  0  0  0  0  4  0  0\n",
      "   0  2  4  4  4  4  4  4  4  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Train Example 2: âœ… CORRECT\n",
      "----------------------------------------\n",
      "\n",
      "Input (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  8  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  2  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Expected (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  8  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  4  4  4  4  4  4  4  2  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Predicted (from code):\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  8  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  0  0  0  0  0  0  0  0  0  0\n",
      "   0  4  4  4  4  4  4  4  4  2  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Train Example 3: âœ… CORRECT\n",
      "----------------------------------------\n",
      "\n",
      "Input (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  2  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  8  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Expected (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  4  4  4  4  4  4  2  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  8  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Predicted (from code):\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  4  4  4  4  4  4  2  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  4  0  0  0  0  0  0  0  0\n",
      "   0  0  8  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "ğŸ§ª TEST EXAMPLES:\n",
      "==================================================\n",
      "\n",
      "Test Example 1: âœ… CORRECT\n",
      "----------------------------------------\n",
      "\n",
      "Input (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  8  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Expected (from dataset):\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  4  4  4  4  4  4  4  2  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  8  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Predicted (from code):\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  4  4  4  4  4  4  4  2  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  8  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "examine_failure(data_integrity_results, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Training Setup\n",
    "Now we'll set up the trainer and then validate all evaluation components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract training set date and time as dataset identifiers\n",
      "Run name will be Qwen3-4B-Thinking-2507_ds-arc-agi-2-reasoning-5\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Extract date and time using regex\n",
    "print(\"Extract training set date and time as dataset identifiers\")\n",
    "\n",
    "if data_source == \"parquet\":\n",
    "    dataset_name = parquet_path.split(\"/\")[-2]\n",
    "    dataset_name = f\"{dataset_name}_rLoRA-{lora_rank}\"\n",
    "elif data_source == 'huggingface':\n",
    "    dataset_name = train_slug.split('/')[-1]  # Get name part after last slash\n",
    "else:\n",
    "    dataset_name = \"unknown\"\n",
    "\n",
    "run_name = f\"{model_slug.split('/')[-1]}_ds-{dataset_name}\"\n",
    "\n",
    "if test_run:\n",
    "    run_name = run_name + \"_test\"   # or \"-test\"\n",
    "\n",
    "    \n",
    "print(f\"Run name will be {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Legacy code extraction imports - now using utils.prompt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, subprocess, os, gc, time\n",
    "\n",
    "def _print_gpu(prefix=\"\"):\n",
    "    alloc = torch.cuda.memory_allocated() / 2**20  # MiB\n",
    "    reserved = torch.cuda.memory_reserved() / 2**20\n",
    "    print(f\"{prefix}CUDAâ€‘alloc={alloc:.0f} MiB | reserved={reserved:.0f} MiB\")\n",
    "\n",
    "def _nvidia_smi():\n",
    "    try:\n",
    "        smi = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=memory.used,memory.free\",\n",
    "             \"--format=csv,noheader,nounits\"]).decode().strip()\n",
    "        print(\"nvidia-smi (used/free MiB):\", smi)\n",
    "    except Exception:\n",
    "        pass  # nvidia-smi not always available\n",
    "\n",
    "\n",
    "TEMPLATES = {\n",
    "    \"llama\": (\n",
    "        \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "    ),\n",
    "    \"gemma\": (\n",
    "        \"<start_of_turn>user\\n\",\n",
    "        \"<start_of_turn>model\\n\",\n",
    "    ),\n",
    "    \"qwen-coder\": (\n",
    "        \"<|im_start|>user\\n\",\n",
    "        \"<|im_start|>assistant\\n\", # this is actually how you properly allow the model to keep reasoning!\n",
    "    ),\n",
    "    \"qwen-thinking\": (\n",
    "        \"<|im_start|>user\\n\",\n",
    "        \"<|im_start|>assistant\\n\", # this is actually how you properly allow the model to keep reasoning!\n",
    "    ),\n",
    "    \"qwen\": (\n",
    "        \"<|im_start|>user\\n\",\n",
    "        \"<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\", # this is actually how you properly allow the model to keep reasoning!\n",
    "    ),\n",
    "    \"mistral\": (\n",
    "        \"[INST]\",\n",
    "        \"[/INST]\",\n",
    "    ),\n",
    "    \"oss\": (\n",
    "        \"<|start|>user<|message|>\",\n",
    "        \"<|start|>assistant\",\n",
    "    )\n",
    "    \n",
    "}\n",
    "\n",
    "# instruction_tag, response_tag = TEMPLATES[\"qwen-coder\"]   # â† change if needed and comment out below\n",
    "\n",
    "model_slug_lower = model_slug.lower()\n",
    "\n",
    "if \"qwen\" in model_slug_lower:\n",
    "    if \"coder\" in model_slug_lower:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen-coder\"]\n",
    "    if \"thinking\" in model_slug_lower:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen-thinking\"]\n",
    "    elif \"soar-qwen\" in model_slug_lower:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen-coder\"]\n",
    "    else:\n",
    "        instruction_tag, response_tag = TEMPLATES[\"qwen\"]\n",
    "elif \"oss\" in model_slug_lower:\n",
    "    instruction_tag, response_tag = TEMPLATES[\"oss\"]\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model slug for Qwen template: {model_slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response tag selected: <|im_start|>assistant\n",
      " for Qwen/Qwen3-4B-Thinking-2507\n"
     ]
    }
   ],
   "source": [
    "print(f\"Response tag selected: {response_tag} for {model_slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mronankmcgovern\u001b[0m (\u001b[33mtrelis\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/arc-agi-2025/llm_python/fine-tuning/wandb/run-20250919_105917-b58juutq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trelis/arc-agi-2025/runs/b58juutq' target=\"_blank\">Qwen3-4B-Thinking-2507_ds-arc-agi-2-reasoning-5</a></strong> to <a href='https://wandb.ai/trelis/arc-agi-2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trelis/arc-agi-2025' target=\"_blank\">https://wandb.ai/trelis/arc-agi-2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trelis/arc-agi-2025/runs/b58juutq' target=\"_blank\">https://wandb.ai/trelis/arc-agi-2025/runs/b58juutq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not is_kaggle:\n",
    "    import wandb\n",
    "\n",
    "    # 1. Log in (will prompt for your API key in notebook)\n",
    "    wandb.login()\n",
    "\n",
    "    # 2. Initialize a run and set the project\n",
    "    wandb.init(\n",
    "        project=\"arc-agi-2025\",   # set your project name\n",
    "        entity=\"trelis\",  # optional: your W&B username or team\n",
    "        name=run_name  # optional: custom run name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs used: 1, per_device: 4, grad_accum: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2940/2940 [00:15<00:00, 188.19 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 39.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_steps(raw)=0.5 output_dir=trainer_output\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "import math\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "setattr(model, \"_flag_for_generation\", True)\n",
    "\n",
    "if config.get(\"training\", {}).get(\"multi_gpu\", False):\n",
    "    num_gpus = max(1, torch.cuda.device_count())\n",
    "else:\n",
    "    num_gpus = 1\n",
    "\n",
    "target_batch_size = 32  # already int\n",
    "per_device_batch_size = int(batch_size_global)  # ensure int from config\n",
    "grad_accum = int(target_batch_size // (per_device_batch_size * num_gpus))  # ensure int division result\n",
    "print(f\"GPUs used: {num_gpus}, per_device: {per_device_batch_size}, grad_accum: {grad_accum}\")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"validation\"],\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size=per_device_batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        num_train_epochs=2,\n",
    "        learning_rate=1e-4,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=0.0125,         # keep as FRACTION of an epoch\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_ratio=0.05,\n",
    "        seed=3407,\n",
    "        report_to=report_to,\n",
    "        logging_dir=f\"./logs/{run_name}\",\n",
    "        remove_unused_columns=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.5,              # keep as FRACTION of an epoch\n",
    "        save_total_limit=4,\n",
    "        prediction_loss_only=False,\n",
    "        hub_model_id=f\"Trelis/{run_name}-trainer\",  # â† this sets the repo to push to\n",
    "        hub_strategy=\"all_checkpoints\",         # when to push (end, every_save, checkpoint, all_checkpoints)\n",
    "        hub_private_repo=True,             # optional: make it private\n",
    "        push_to_hub=not is_kaggle,\n",
    "        do_eval=True,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "      f\"save_steps(raw)={trainer.args.save_steps} \"\n",
    "      f\"output_dir={trainer.args.output_dir}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "2ejIt2xSNKKp",
    "outputId": "344c14cb-0138-4981-9d85-b1e8856093ec",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA H200. Max memory = 139.812 GB.\n",
      "3.816 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We should consider training on completions only!!! which means the response part for the xentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=192): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2940/2940 [00:01<00:00, 2471.98 examples/s]\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "WARNING:datasets.arrow_dataset:num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 111.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only # or run the code above if not using unsloth\n",
    "\n",
    "# TO SUPPORT REASONING, WE NEED TO DYNAMICALLY APPLY THE RIGHT MASKING, NOT YET IMPLEMENTED\n",
    "# masks everything between the instruction_part and response_part\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = instruction_tag,\n",
    "    response_part = response_tag,\n",
    "    # force_match=False # comment out to set true for a cleaner masking\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13724\n"
     ]
    }
   ],
   "source": [
    "print(len(trainer.train_dataset[0][\"input_ids\"]))\n",
    "\n",
    "# print(tokenizer.decode(trainer.train_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            <think>\n",
      "We need to infer transformation rule from examples.\n",
      "\n",
      "Observations: Input grids contain 0 (background) and 2 (red). Output grids are 3x3 containing 1s and 0s (blue and black). So transformation reduces to a 3x3 pattern derived from arrangement of 2-blocks (2x2 squares) maybe? Input seems to have multiple 2x2 squares of red (value 2). They are possibly placed at various positions. Output likely encodes which quadrants (of a 3x3) contain at least one red 2x2 block? Let's examine.\n",
      "\n",
      "Example 1 Input 6x6: pattern includes two 2x2 squares: one at (1,1)-(2,2) top-left, and another at (4,2)-(5,3) bottom middle. Output 3x3:\n",
      "[[1 0 1],\n",
      " [0 0 0],\n",
      " [0 0 0]]\n",
      "So 1's at positions (0,0) and (0,2). Maybe correspond to presence of red squares in top row left and right? Let's map input positions to 3x3 grid cells. Input size 6x6 can be divided into 3x3 blocks each of size 2x2. Indeed 6/2 =3. So each 2x2 block corresponds to a cell in 3x3 output. The rule: For each 2x2 block, if it contains any red (2) cells, output 1 else 0? Let's test.\n",
      "\n",
      "Divide 6x6 into 3x3 cells each 2x2:\n",
      "\n",
      "Indices: block row 0 corresponds rows 0-1, block col0 cols0-1: in Input1, rows0-1 cols0-1 are all 0 => output (0,0) should be 0 but actual is 1. Wait maybe we need to consider presence of a full 2x2 red block? In Input1, the red block is at rows1-2, cols1-2 (i.e., block row 0? Let's compute: rows1-2 -> which block? rows 0-1 is block0, rows2-3 block1, rows4-5 block2. Actually 2x2 blocks boundaries: rows 0-1,2-3,4-5. So red block rows1-2 spans rows1 (block0) and row2 (block1) across boundary -> not aligned to 2x2 grid. Hmm.\n",
      "\n",
      "But maybe they consider each 2x2 red square as a \"object\" and map its centroid to a 3x3 coordinate based on which quadrant of the overall grid its center lies. The output 3x3 shows pattern of which quadrants contain a red square.\n",
      "\n",
      "Let's compute centers: First red square occupies rows1-2, cols1-2. Its center approx at (1.5,1.5). Overall grid 6x6, divide into 3x3 cells each of size 2. The cell indices: row index floor(y/2), col floor(x/2). With 0-index, center (1.5,1.5) falls into cell (0,0) (since floor(1.5/2)=0). That matches output 1 at (0,0). Second red square rows4-5 cols2-3 center (4.5,2.5) floor/2 => row 2, col 1 => output at (2,1) would be 1 but actual output has 0 there. Wait output has 1 at (0,2) not (2,1). Let's double-check coordinates: rows index vertical. second square rows4-5 (indices 4,5), cols2-3 (2,3). Center (4.5,2.5). floor(4.5/2)=2 row block, floor(2.5/2)=1 col block => cell (2,1). But output shows 1 at (0,2). So maybe orientation transposed? Let's check maybe they map x coordinate to column index; we did that. So not matching.\n",
      "\n",
      "Alternatively maybe they rotate or reflect. Let's test other examples.\n",
      "\n",
      "Example 2 Input 7x7; output 3x3 pattern with 1s at corners and center (0,0),(0,2),(1,1),(2,0),(2,2). Input contains multiple red squares (2x2). Let's locate them.\n",
      "\n",
      "I'll quickly compute using reasoning: Input2 grid 7x7 with 2's forming several 2x2 blocks: Top-left region rows1-2 cols1-2 is a 2x2 block. Also rows0-1? Actually row0 has \"0 0 0 0 2 2 0\". So rows0-1 cols4-5 is a block? Row0 col4-5 =2, row1 col4-5 =2 (since row1 = [0 2 2 0 2 2 0]), yes that forms a 2x2 block at top right. Additional block at rows3-4? Row3 \"0 0 0 0 0 2 2\", row4 \"2 2 0 0 0 2 2\". So there is block at rows3-4 cols5-6? rows3 col5-6 =2,2; rows4 col5-6 =2,2 => yes block bottom right. Also block at rows4-5 cols0-1 (rows4:2 2 ; rows5:2 2) bottom left. And maybe block at rows5-6 col3-4? rows5: \"2 2 0 2 2 0 0\" col3-4 =2,2 ; rows6: \"0 0 0 2 2 0 0\" col3-4 =2,2 => block middle right? Actually rows5-6 col3-4 =2,2;2,2 forms block. So there are many blocks.\n",
      "\n",
      "Now output shows 1 at (0,0) (top-left), (0,2) top-right, (1,1) center, (2,0) bottom-left, (2,2) bottom-right. So corresponds to presence of block in each of those 5 positions of 3x3 grid. So mapping seems to be: divide the original grid into 3x3 larger cells, each cell size maybe varies because original size 7 not divisible by 3. Could be they compress by detecting whether there is any red (2) in each of the 3x3 quadrants defined by dividing both dimensions into three equal (or nearly equal) parts.\n",
      "\n",
      "For 7x7, dividing into 3 parts gives sizes 2,2,3 (since 7 = 2+2+3). So cells: rows 0-1,2-3,4-6; cols similar 0-1,2-3,4-6. Let's test: Top-left cell rows0-1 cols0-1 contains any 2? rows0 col0-1 are 0 0, row1 col0-1 are 0 2? row1 col1 is 2 (since row1 = [0 2 2 0 2 2 0]) yes there is 2 at (1,1) inside top-left cell => output (0,0)=1 matches.\n",
      "\n",
      "Top-right cell rows0-1 cols4-6: rows0 col4-6 =2 2 0; row1 col4-6 =2 2 0 => contains 2 => output (0,2)=1 matches.\n",
      "\n",
      "Center cell rows2-3 cols2-3: rows2 (index2) = [0 2 2 0 0 0 0]; cols2-3 = (2,3) values 2,0 ; rows3 = [0 0 0 0 0 2 2]; cols2-3 =0,0 => contains 2 => output (1,1)=1 matches.\n",
      "\n",
      "Bottom-left cell rows4-6 cols0-1: rows4 = [2 2 0 0 0 2 2]; cols0-1 =2,2 => yes => output (2,0)=1.\n",
      "\n",
      "Bottom-right cell rows4-6 cols4-6: rows4 cols4-6 =0,2,2 ; rows5 cols4-6 =2,0,0 ; rows6 cols4-6 =2,0,0 . Contains 2 => output (2,2)=1.\n",
      "\n",
      "Thus rule: Partition grid into 3x3 blocks (by dividing rows and columns into three contiguous segments as equal as possible: floor(N/3) for first two, remainder for last). For each block, if any cell with value 2 present, set output cell to 1 else 0.\n",
      "\n",
      "Check Example1: 6x6 => N=6, divide into 3 equal parts each size 2. So blocks 2x2. Blocks containing 2? top-left block rows0-1 cols0-1 none => would be 0 but output has 1 at (0,0). Wait but earlier we found red block spanned rows1-2 cols1-2 crossing boundary, meaning it touches both top-left and top-middle blocks? Actually rows1-2 includes row1 (top block) and row2 (middle block). Since block size 2, rows 0-1 (block0), rows2-3 (block1). The red square rows1-2 includes row1 (top block) and row2 (middle block). So the block detection for top-left block (rows0-1 cols0-1) includes row1 col1 (since col1 within cols0-1). That's a 2 value? Input top-left 2x2 region rows0-1 cols0-1 = all 0. But the red square includes cell (1,1) which is within that block (row1 col1). Indeed (1,1) is in rows0-1 (since row1) and cols0-1 (col1). So block (0,0) contains a 2. Wait earlier we thought block rows0-1 cols0-1 all zero, but we mis-copied input. Let's verify Input1 grid rows:\n",
      "\n",
      "Row0: 0 0 0 0 0 0\n",
      "Row1: 0 2 2 0 0 0\n",
      "Row2: 0 2 2 0 0 0\n",
      "Row3: 0 0 0 0 0 0\n",
      "Row4: 0 0 2 2 0 0\n",
      "Row5: 0 0 2 2 0 0\n",
      "\n",
      "Thus block (0,0) rows0-1 cols0-1 includes (0,0)=0, (0,1)=0, (1,0)=0, (1,1)=2 -> contains 2, so output 1 matches.\n",
      "\n",
      "Block (0,2) rows0-1 cols4-5 includes (0,4)=0,(0,5)=0,(1,4)=0,(1,5)=0 -> no 2, but output (0,2)=1. Hmm discrepancy. Wait output has 1 at (0,2). Let's check if there is any 2 in that block: rows0-1 cols4-5 indeed all zeros. So why output 1? Maybe we misinterpret column indices: For 6 columns divided into 3 parts each of size 2: col groups: 0-1,2-3,4-5. The second block (0,1) would be cols2-3. Output at (0,2) corresponds to cols4-5. There is no 2 there. So rule not simply any 2.\n",
      "\n",
      "Let's examine where 2s are: Another red square at rows4-5 cols2-3. This lies in block row index 2 (rows4-5) and col index 1 (cols2-3). So that would be output cell (2,1). But output (2,1) is 0. So maybe rule is different: maybe they consider presence of a full 2x2 red block that is completely inside a 3x3 cell (i.e., not overlapping boundaries). In Input1, the top-left red block is a 2x2 square occupying rows1-2 cols1-2. This spans rows1 (block0) and row2 (block1) thus overlaps two row partitions. So maybe they assign this block to the top-left cell of the 3x3 output? Actually they might consider the top-left corner of the 2x2 block (its minimal row, col) and map that to a 3x3 cell via integer division by 2? The top-left corner of block at (1,1) maps to cell (0,0). The second block top-left corner at (4,2) maps to cell (2,1). But output shows 1 at (0,2) not (2,1). So maybe they consider bottom-right corner? Bottom-right of first block (2,2) maps to cell (1,1) (since floor(2/2)=1). Not output.\n",
      "\n",
      "Thus maybe output pattern is derived not from blocks but from connectivity of 2s forming larger shapes? Let's compute for Input1, the output pattern has 1 at top-left and top-right corners. Maybe they encode whether there is a red block in the same row region (top half) but left/right side presence? Actually there are red blocks in top region (rows0-2) left side only, and bottom region (rows4-5) middle. Output 1 at (0,2) maybe indicates presence of red block in bottom region? Not.\n",
      "\n",
      "Let's analyze other examples to clarify.\n",
      "\n",
      "Example4 Input 3x3: [[0 0 0],[0 2 2],[0 2 2]]. Output 3x3: [[1 0 0],[0 0 0],[0 0 0]]. Input is a 2x2 red block occupying bottom right of the 3x3 grid? Actually rows1-2 cols1-2 are 2. Output has 1 at (0,0) only. So mapping: The red block located in lower-right corner maps to output top-left corner. That's like rotating 180 degrees? Let's test: If we rotate positions 180Â°, bottom-right (2,2) maps to top-left (0,0). Indeed 3x3 indices: (2,2) -> (0,0). So maybe they map the location of the red block's centroid after rotating 180 degrees.\n",
      "\n",
      "Check Example1: red block at top-left region (center near (1.5,1.5)) would map to bottom-right (2,2) after 180 deg, but output has 1 at (0,0) and (0,2). Not matching.\n",
      "\n",
      "Maybe they reflect across vertical axis? Bottom-right block would reflect to bottom-left (2,0) but output top-left (0,0). Not.\n",
      "\n",
      "Let's examine Example5 Input 5x5: pattern includes two 2x2 blocks: top-left (rows1-2 cols1-2) and bottom-right (rows3-4 cols3-4). Output 3x3: [[1 0 1],[0 0 0],[0 0 0]]. So 1 at top-left and top-right corners. This mirrors earlier Example1 output. The two blocks are at opposite corners (top-left and bottom-right). Output shows top-left and top-right. So mapping maybe based on whether block is on main diagonal? Actually top-left block corresponds to output (0,0). Bottom-right block corresponds to output (0,2). So mapping of bottom-right block to top-right cell. That's like taking the block's row position (top vs bottom) and mapping to output row 0 always? Not.\n",
      "\n",
      "Let's compute using the 3x3 partition rule again for 5x5 grid. Divide rows into sizes floor(5/3)=1 for first two, remainder 3 for last? Actually 5 = 1+1+3? But we may allocate as 2,2,1? Need to decide. The typical ARC approach: split into three equal parts if possible; when not divisible, they may split into roughly equal, maybe using integer division and remainder added to last part. For 5, we could have parts of size 2,2,1 (since 5 = 2+2+1). Let's test that. Row groups: rows0-1, rows2-3, row4. Column groups similarly. Then block (0,0) rows0-1 cols0-1 includes rows0-1 (row0 all zeros, row1 has 2 at col1). So contains 2 => output (0,0)=1 matches. Block (0,2) rows0-1 cols4? Actually col groups: 0-1,2-3,4. So block (0,2) rows0-1 col4 includes row0 col4=0, row1 col4=0 => no 2, but output (0,2)=1 (due to bottom-right block). Bottom-right block rows3-4 cols3-4? rows3 (index3) = [0 0 0 2 2] includes cols3-4 =2,2; rows4 all zeros. This block falls into row group rows2-3 (group index1) and col group col3-4 (group index2?) Wait col groups: 0-1 group0, 2-3 group1, 4 group2. The block's columns are 3 and 4, spanning groups1 and2. So not fully within a single block. So simple block detection fails.\n",
      "\n",
      "Thus rule maybe based on counting red 2x2 squares and mapping their positions to output pattern using some transformation like compressing by factor 2, but also maybe using morphological operation: take the original grid, downscale by factor 2 using max pooling (if any 2 present in 2x2 region, output 1). For Input5 5x5, downscale by factor? Not uniform.\n",
      "\n",
      "Let's consider downscaling by factor 2 (ceil). For 5x5, output size would be ceil(5/2)=3. So each output cell corresponds to a 2x2 region of original, using maybe top-left corner anchored (i.e., output[i][j] corresponds to original rows 2i to 2i+1, cols 2j to 2j+1). For 5x5, indices: output (0,0) covers rows0-1 cols0-1 includes 2 => 1. output (0,1) rows0-1 cols2-3 includes rows0-1 col2-3 all zeros => 0. output (0,2) rows0-1 cols4-5 (col5 out of range) maybe just col4? Use padding zero. rows0-1 col4 includes zeros => 0. But output expects 1 at (0,2). So not.\n",
      "\n",
      "Alternative: maybe downscale using max pooling but overlapping stride 2 (non-overlapping) but with offset? Not.\n",
      "\n",
      "Let's analyze pattern of outputs across examples: The outputs often have 1s at positions where there is a 2x2 block in the input that is oriented diagonally opposite? Example5 bottom-right block gave output top-right.\n",
      "\n",
      "Maybe rule: take each 2x2 red block, compute its relative position to the center of the grid, and map to output quadrants based on sign of displacement: top-left block => output top-left; bottom-right block => output top-right (i.e., reflect across vertical axis). Example1 second block bottom-middle gave output top-right? Actually bottom-middle block (center lower middle) gave output top-right (0,2). Yes matches: bottom-middle maps to top-right. So maybe transformation: reflect vertically (flip rows) and keep columns same? Let's test: Input1 block positions: first block at top-left (row index ~1, col~1). Flip rows vertically (mirror top-bottom) in 3x3 output: top-left becomes bottom-left? Wait output (0,0) is top-left, not bottom-left. So not simple flip.\n",
      "\n",
      "Maybe they rotate 90 degrees? Let's test mapping: Top-left block maps to top-left (unchanged). Bottom-right block maps to top-right (different). Bottom-middle block maps to top-right as well. So mapping not consistent.\n",
      "\n",
      "Let's compute for each example the positions of blocks (their top-left coordinates) and output 1 positions.\n",
      "\n",
      "We'll write quick mental but maybe easier to code, but offline.\n",
      "\n",
      "Let's list coordinates (row, col) of each 2x2 block (top-left corner) for each example.\n",
      "\n",
      "Example1: blocks at (1,1) and (4,2). Output 1s at (0,0) and (0,2). Mapping: (1,1) -> (0,0). (4,2) -> (0,2). So mapping seems to ignore row coordinate (output row always 0) and column mapped to 0 if col<2? Actually col1 maps to 0, col2 maps to 2. So perhaps output row corresponds to whether block is in top half? Both blocks are in top half? Actually second block rows4-5 is bottom half, but output row 0 still. So output row maybe based on whether block's column is left/right? Not.\n",
      "\n",
      "Maybe they project blocks onto a single row based on some property like \"blocks that are aligned vertically produce same output row\"? Not.\n",
      "\n",
      "Let's examine Example2: blocks positions? Many blocks. Let's compute approximate top-left corners:\n",
      "- (0,4) top-right block.\n",
      "- (1,1) top-left block.\n",
      "- (3,5) bottom-right block.\n",
      "- (4,0) bottom-left block.\n",
      "- (5,3) middle-right block? Actually block at rows5-6 cols3-4 top-left (5,3).\n",
      "Thus output 1s at (0,0) top-left, (0,2) top-right, (1,1) center, (2,0) bottom-left, (2,2) bottom-right. So mapping: block (1,1) -> (0,0) (top-left). block (0,4) -> (0,2) (top-right). block (5,3) maybe maps to (2,2) bottom-right? Actually (5,3) row index 5 (bottom), col 3 (right) -> output bottom-right (2,2). block (4,0) maps to bottom-left (2,0). block (3,5) maps to center? Wait (3,5) is bottom-right region maybe maps to center (1,1). Not.\n",
      "\n",
      "Seems mapping may be based on which quadrant of the original grid the block resides in (3x3 grid of quadrants). But earlier we tried partitioning into 3 rows/cols, and that gave correct mapping for Example2. Let's re-evaluate Example1 with that partition rule: For 6x6, partitions rows0-1,2-3,4-5; cols same. Determine which blocks intersect each partition cell. For each cell, if any red present, output 1. Let's compute cells containing reds:\n",
      "\n",
      "- Cell (0,0): rows0-1 cols0-1 includes red at (1,1) => 1.\n",
      "- Cell (0,1): rows0-1 cols2-3 includes red at (1,2) maybe? (1,2) is 2 (since row1 col2 =2). Yes there is red also at (1,2) which lies in column group 2-3, row group 0-1. So cell (0,1) also has red. Output (0,1) is 0 though. So rule fails.\n",
      "\n",
      "But note red at (1,2) is part of same 2x2 block overlapping cells (0,0) and (0,1). Perhaps they consider each 2x2 block as a whole and assign it to a single cell based on its top-left corner (as earlier). The top-left corner (1,1) falls into cell (0,0). So block counted only for cell (0,0), not also for (0,1). Similarly second block top-left (4,2) falls into cell (2,1) (since rows4-5 group2, cols2-3 group1). That would set output (2,1)=1, but actual output (0,2)=1. So not.\n",
      "\n",
      "Maybe they assign block based on its centroid (average of its four cells) and then round to nearest cell? The centroid of block (1,1)-(2,2) is (1.5,1.5) which maps to cell (0,0) (as before). The second block (4,2)-(5,3) centroid (4.5,2.5) maps to cell (2,1). Output (0,2) not matching.\n",
      "\n",
      "Thus maybe they treat each red cell individually, not blocks, and map each red cell to output cell via floor division by 2, then take logical OR across cells. Let's compute for Input1: list of red cells coordinates: (1,1),(1,2),(2,1),(2,2),(4,2),(4,3),(5,2),(5,3). Compute floor division by 2: (0,0),(0,1),(1,0),(1,1),(2,1),(2,1),(2,1),(2,1). Then OR across results gives cells (0,0),(0,1),(1,0),(1,1),(2,1). Output should have 1s at those positions, but actual output only at (0,0) and (0,2). So not.\n",
      "\n",
      "Thus maybe they are compressing by factor 3? Since output is 3x3 regardless of input size. Maybe they rescale entire grid to 3x3 by downsampling (e.g., using average or majority) and then threshold to produce 1 if any red present. For Input1 6x6 downsample to 3x3 via 2x2 pooling (non-overlapping). Let's compute each 2x2 region:\n",
      "\n",
      "Region (0,0): rows0-1 cols0-1 includes red (1,1) => 1.\n",
      "Region (0,1): rows0-1 cols2-3 includes red (1,2) => 1.\n",
      "Region (0,2): rows0-1 cols4-5 includes none => 0.\n",
      "Region (1,0): rows2-3 cols0-1 includes red (2,1)?? row2 col1=2 yes => 1.\n",
      "Region (1,1): rows2-3 cols2-3 includes red (2,2) =>1.\n",
      "Region (1,2): rows2-3 cols4-5 none =>0.\n",
      "Region (2,0): rows4-5 cols0-1 none =>0.\n",
      "Region (2,1): rows4-5 cols2-3 includes reds =>1.\n",
      "Region (2,2): rows4-5 cols4-5 none =>0.\n",
      "\n",
      "Resulting 3x3 matrix would have many 1s, not match.\n",
      "\n",
      "So maybe they are performing some operation like \"find the pattern of 2x2 blocks, then produce a 3x3 representation where a 1 indicates presence of a block in that relative position within the set of blocks considered as a shape.\" For example, they might take the minimal bounding rectangle that contains all 2s, then normalize its shape to 3x3 by scaling the coordinates of block centers relative to that bounding rectangle.\n",
      "\n",
      "Let's compute bounding box of all red cells in Input1: rows 1-5, cols1-3? Actually reds at cols1-3? maximum col 3. So bbox rows 1-5 (height 5), cols1-3 (width 3). If we scale to 3x3 grid by dividing row range into 3 equal intervals (height 5 -> intervals size ~1.67) and col range width 3 -> intervals size 1. So block centers positions (1.5,1.5) maps to row interval 0 (since 1.5-1=0.5 <1.67) column interval 0 (since 1.5-1=0.5 <1). So output (0,0). Second block center (4.5,2.5) row offset 4.5-1=3.5; 3.5/1.67â‰ˆ2.09 => row interval 2, col offset 2.5-1=1.5; 1.5/1=1.5 => col interval 1 (or 2 after rounding). Output (2,1) not match.\n",
      "\n",
      "Thus not.\n",
      "\n",
      "Observe outputs often have pattern symmetric: corners often 1 if there is a block in corresponding corner of input (top-left, top-right, bottom-left, bottom-right). The center sometimes 1 if there is a block in middle region. However output row 0 corresponds to top row of output, but in many cases both top-left and top-right are 1 even when blocks are at opposite corners (top-left and bottom-right). So maybe they ignore vertical position and only consider horizontal position? For Input5, blocks at top-left and bottom-right gave output top-left and top-right (both top row). So vertical info collapsed.\n",
      "\n",
      "Similarly Input1 blocks top-left and bottom-middle gave output top-left and top-right (both top row). Input6 output pattern: top row has 1 0 1, middle row 0 1 0, bottom row all 0. Let's examine Input6 blocks positions: Input6 grid 7x7 includes 2x2 blocks at (1,1) top-left, (2,4) top-right? Actually rows2-3 cols4-5 contain 2's, also block at (3,4) maybe overlapping? Let's list: rows1-2 cols1-2 block (1,1). rows2-3 cols4-5 block (2,4). rows4-5 cols2-3 block (4,2). So three blocks: top-left, top-right, bottom-middle. Output shows top-left, top-right, and center (1,1) =1. So bottom-middle block maps to center. So mapping: bottom row block maps to center (row 1). So vertical collapsed to three possible output rows: top row corresponds to blocks whose row index is in top two rows? bottom row maybe maps to center? Hmm.\n",
      "\n",
      "Let's compute block row groups: using three vertical sections of the input (top, middle, bottom). For 7 rows, sections sizes maybe 2,2,3. Blocks top-left (rows1-2) lies in top section (rows0-1? Actually block rows1-2 includes row1 (top) and row2 (middle). So block straddles top and middle. Yet output placed at top row.\n",
      "\n",
      "Block top-right (rows2-3) also straddles middle and bottom? rows2-3 includes row2 (middle) and row3 (bottom). Output placed at top row also.\n",
      "\n",
      "Block bottom-middle (rows4-5) lies in bottom section (rows4-5) both bottom. Output placed at center row (1). So rule may be: if block is fully within bottom section, map to middle row; else map to top row. Not consistent.\n",
      "\n",
      "Let's analyze Example7 Input7: output pattern corners (0,0)=1, (0,2)=1, (1,1)=1, (2,0)=1, (2,2)=0? Actually output given [[1 0 1],[0 1 0],[1 0 0]]. So corners top-left, top-right, bottom-left are 1; bottom-right 0; center 1.\n",
      "\n",
      "Input7 blocks: I need to locate. Input7 grid 7x7: pattern includes many 2x2 blocks: top-right block at rows0-1 cols4-5, top-left? rows2-3 cols1-2? Actually rows2-3 have [0 2 2 0 0 0 0] and [0 2 2 0 2 2 0] => block at (2,1) and another at (3,4). Also bottom-left block at rows5-6 cols1-2? rows5: [0 2 2 0 0 0 0]; rows6 same. So blocks: (0,4) top-right, (2,1) middle-left, (3,4) middle-right, (5,1) bottom-left. Output has 1 at top-left, top-right, center, bottom-left. So mapping: block (0,4) -> top-right (matches). block (5,1) bottom-left -> bottom-left (matches). block (2,1) middle-left -> maybe maps to center? Indeed output center (1,1)=1. block (3,4) middle-right -> maps to top-left? Not.\n",
      "\n",
      "But output also has top-left 1 maybe from block (2,1) or (3,4) etc.\n",
      "\n",
      "Thus maybe rule is: For each block, take its row modulo 3 and column modulo 3? Since output size 3, maybe compute row %3 and col %3 of block's top-left coordinate, then set that cell to 1. Let's test: For Input1 block (1,1) -> (1%3=1,1%3=1) would map to (1,1) not (0,0). So not.\n",
      "\n",
      "Maybe they compute (row // something) %3? Not.\n",
      "\n",
      "Let's consider that output appears to be the pattern of where 2x2 blocks appear when we view the grid as 3x3 of 2x2 blocks, but with wrapping (toroidal) i.e., blocks that cross boundaries are assigned to the cell where their majority lies? For Input1 second block spans rows4-5 cols2-3 which is within cell (2,1). Output shows (0,2). So maybe they wrap rows modulo 3 (i.e., row index 2 maps to 0) and column index 1 maps to 2? That is a rotation 180 degrees? If we rotate cell (2,1) by 90 deg clockwise: (2,1) -> (1,0) not (0,2). 180 deg: (2,1) -> (0,1). Not.\n",
      "\n",
      "But maybe they transpose? (2,1) transposed -> (1,2). Not.\n",
      "\n",
      "If we reflect both axes: (2,1) -> (0,1). Not.\n",
      "\n",
      "If we reflect rows only: (2,1) -> (0,1). Not.\n",
      "\n",
      "If we reflect columns only: (2,1) -> (2,1). Not.\n",
      "\n",
      "Thus not.\n",
      "\n",
      "Let's compute mapping of cell indices for each block in Example2 using simple partition cell (by floor division of top-left coordinate by size) and compare to output.\n",
      "\n",
      "We'll compute quickly using mental: Input2 size 7 => row group sizes 2,2,3. Determine cell index for each block top-left coordinate:\n",
      "\n",
      "Blocks:\n",
      "A at (0,4): row 0 belongs to group0, col4 belongs to group2 (since cols0-1 group0,2-3 group1,4-6 group2) => cell (0,2) output 1 matches.\n",
      "B at (1,1): row1 group0, col1 group0 => cell (0,0) matches.\n",
      "C at (3,5): row3 group1 (rows2-3), col5 group2 => cell (1,2) output? there is no 1 at (1,2) (output (1,2)=0). So maybe this block not counted because it's not a full 2x2? Let's verify block at (3,5) is rows3-4 cols5-6: rows3 col5-6 =2,2; row4 col5-6 =2,2 -> yes full block. So cell (1,2) would be 1 but output not. So maybe they ignore blocks that are partially overlapping row group boundaries? However block (0,4) also straddles groups? row0 only group0, col4-5 within group2 (since group2 includes col4-6). So fine.\n",
      "\n",
      "Block (4,0): row4 group2 (rows4-6), col0 group0 => cell (2,0) output 1 matches.\n",
      "Block (5,3): row5 group2, col3 group1 => cell (2,1) output? output (2,1)=0. So not counted.\n",
      "\n",
      "Thus some blocks counted, some not. Which ones counted? The ones where both rows of block are within same row group? For block (0,4): rows0-1 both within group0 (since group0 rows0-1). Good. Block (1,1): rows1-2 spans groups0 and1 (since row2 is in group1). Yet counted. So not.\n",
      "\n",
      "Maybe they count blocks whose columns are within same column group but rows may span? Not.\n",
      "\n",
      "Block (3,5): rows3-4 -> rows3 in group1, row4 in group2 (spans two groups) -> not counted. Block (5,3): rows5-6 both in group2, columns3-4 span groups1 and2 (col3 in group1, col4 in group2) -> not counted. So rule: block must be entirely within a single column group AND a single row group (i.e., not crossing group boundaries). That holds for blocks A (rows0-1 within group0, cols4-5 within group2) yes. Block B (rows1-2 cross groups) actually rows1-2 cross groups (row1 group0, row2 group1) -> violates but still counted. So maybe they treat block B differently because its top-left at (1,1) but block occupies rows1-2, cols1-2 which cross both row and column groups (since col2 in group1). Yet output includes (0,0). So contradictory.\n",
      "\n",
      "Thus maybe they are not using block concept but rather looking at positions of individual 2 cells and mapping via some function that produces exactly those output cells.\n",
      "\n",
      "Let's compute set of positions of any 2 cell, map via floor division by 2 (i.e., compress by factor 2 rounding up?) For 7x7, we can map each cell to output 3x3 by integer division by 2 (i // 2, j // 2). Let's test for Example2: any 2 at (0,4) -> (0,2) yes output. (0,5)-> (0,2). (1,1)-> (0,0) output. (1,2)-> (0,1) would cause output (0,1)=1 but output has 0. However there is a 2 at (1,2) indeed. So fails.\n",
      "\n",
      "Maybe they use ceiling division: (i+1)//2? For i=1 gives 1, not 0.\n",
      "\n",
      "Thus not.\n",
      "\n",
      "Maybe they use modulo 3 mapping: (i % 3, j % 3). For (1,2) -> (1,2) output (1,2)=0 but there is a 2. So not.\n",
      "\n",
      "Let's step back. Perhaps the transformation is to detect the pattern of where 2x2 squares appear relative to each other forming a shape, then output a 3x3 pattern representing the shape's convex hull or something.\n",
      "\n",
      "Observe that outputs often have exactly the same number of 1s as number of distinct 2x2 blocks? Example1 has 2 blocks, output has 2 ones. Example2 has 5 blocks, output has 5 ones. Example3 has 4 blocks? Let's count: Output3 has 4 ones (positions corners and center). Input3 likely has 4 blocks. Example4 has 1 block, output 1 one. Example5 has 2 blocks, output 2 ones. Example6 has 3 blocks, output 3 ones. Example7 has 4 blocks, output 4 ones. Example8 has 1 block, output 1 one. So indeed number of 1s equals number of 2x2 blocks (full red squares). So mapping is one-to-one.\n",
      "\n",
      "Thus each 2x2 block maps to a distinct output cell (3x3). So we need a deterministic mapping from block position to output cell such that each block maps to unique cell, and the mapping yields positions as seen.\n",
      "\n",
      "We need to find mapping function f(row, col) where (row, col) are top-left coordinates of block, yielding output (r,c) in {0,1,2}. For each example, the mapping seems to be based on something like (row // something) mod 3 etc but with some rule to ensure uniqueness.\n",
      "\n",
      "Let's compute for each example block top-left and output cell.\n",
      "\n",
      "We'll enumerate:\n",
      "\n",
      "Example1:\n",
      "Block1 TL (1,1) -> out (0,0)\n",
      "Block2 TL (4,2) -> out (0,2)\n",
      "\n",
      "Example2 blocks TL:\n",
      "(0,4) -> (0,2)\n",
      "(1,1) -> (0,0)\n",
      "(3,5) -> not counted? Actually there are 5 output ones, need 5 blocks; we have list of 5 blocks: also (4,0) -> (2,0); (5,3) -> (2,2). That accounts for 5 ones. So mapping:\n",
      "(3,5) not a block? Wait maybe there is not a full 2x2 block at (3,5). Let's verify grid rows3-4 cols5-6: rows3: [0 0 0 0 0 2 2]; rows4: [2 2 0 0 0 2 2]; yes both rows have 2 at cols5-6. So it's a block. But output includes only 5 ones; we have 6 blocks? Let's recount blocks: In Input2 we have blocks at positions:\n",
      "A (0,4)\n",
      "B (1,1)\n",
      "C (3,5)\n",
      "D (4,0)\n",
      "E (5,3)\n",
      "Also maybe block at (2,2)? Actually rows2-3 cols2-3: rows2 = [0 2 2 0 0 0 0]; rows3 = [0 0 0 0 0 2 2]; columns2-3 are (2,0) and (0,0) not both 2. So not.\n",
      "Thus 5 blocks? Wait that's 5 blocks: A,B,D,E plus maybe one more? Let's double-check C: rows3-4 col5-6: row3 col5-6 =2,2 ; row4 col5-6 =2,2 => yes block. So that is 5th block, giving total 5. But output also 5 ones. So which mapping corresponds to which output cell? Output cells: (0,0),(0,2),(1,1),(2,0),(2,2). So need to map each block to one of those cells.\n",
      "\n",
      "We can assign:\n",
      "A (0,4) -> (0,2)\n",
      "B (1,1) -> (0,0)\n",
      "C (3,5) -> (1,1) maybe? center\n",
      "D (4,0) -> (2,0)\n",
      "E (5,3) -> (2,2)\n",
      "\n",
      "Check: Does C's location map to center? top-left (3,5) is near bottom-right; mapping to center plausible.\n",
      "\n",
      "Now Example3 Input: we need blocks and output positions (1s at corners except bottom-right? output pattern [[1 0 1],[0 1 0],[1 0 0]] -> ones at (0,0),(0,2),(1,1),(2,0). So 4 blocks.\n",
      "\n",
      "Let's list blocks in Input3 grid 7x7:\n",
      "\n",
      "Rows0-1 cols2-3? Actually rows0: [0 0 2 2 0 2 2]; rows1 same. So block at (0,2) top-left (0,2) (covers cols2-3 rows0-1). Also block at (0,5) top-right (0,5). That's two.\n",
      "\n",
      "Rows2-3: rows2 [2 2 0 0 0 0 0]; rows3 [2 2 0 2 2 0 0]; There is block at (2,0) rows2-3 cols0-1. Also block at (3,3)? rows3 cols3-4 =2,2 but rows4 (row4) is [0 0 0 2 2 0 0]; need rows3-4 for block at (3,3) would need row4 col3-4 =2,2 yes forms block at (3,3). That's fourth block.\n",
      "\n",
      "Thus blocks TL: (0,2), (0,5), (2,0), (3,3). Output ones at (0,0),(0,2),(1,1),(2,0). Mapping possibilities:\n",
      "(0,2) -> (0,0) maybe? (0,5) -> (0,2). (2,0) -> (2,0). (3,3) -> (1,1). Works! So mapping seems to be: take block TL coordinates, then compress by dividing by 2? Let's test: (0,2) //2 = (0,1) not (0,0). (0,5)//2 = (0,2) matches (0,2). (2,0)//2 = (1,0) not (2,0). (3,3)//2 = (1,1) matches center. So not consistent.\n",
      "\n",
      "Maybe mapping is (row // something, col // something) where row division factor varies based on row range. For size 7, maybe rows groups of size 2,2,3 as earlier. Compute group index: row 0-1 ->0, 2-3 ->1, 4-6 ->2. col groups same. Then mapping:\n",
      "(0,2) row group0, col group1 => (0,1) but output (0,0). So shift left.\n",
      "\n",
      "(0,5) row0 col group2 => (0,2) matches output (0,2). Good.\n",
      "\n",
      "(2,0) row group1 col0 => (1,0) but output (2,0). So shifted down.\n",
      "\n",
      "(3,3) row group1 col group1 => (1,1) matches output (1,1).\n",
      "\n",
      "Thus mapping seems to sometimes map group index to output index but with some transformation like row index may be mapped to output row = (2 - group) for some? Let's compute: For block (0,2) group row 0 maps to output row 0 (no change). For block (2,0) group row 1 maps to output row 2 (inverse). So maybe output row = (group * 2) mod 3? Not.\n",
      "\n",
      "Observation: Blocks in leftmost column (col group0) map to output column 0 regardless of row group. That's true for (0,2) which is col group1 but output col 0, contradicts. Actually (0,2) col group1 but output col0. So not.\n",
      "\n",
      "Maybe mapping uses parity of block position: If block's column index (top-left) modulo 4? Let's compute: (0,2) col2 -> output col0 (subtract 2). (0,5) col5 -> output col2 (subtract 3). Not.\n",
      "\n",
      "Let's examine pattern across examples: The output seems to reflect positions of blocks after rotating the whole input 90 degrees clockwise and then compressing to 3x3? Let's test for Example1: rotate input 90 deg clockwise, the block at (1,1) moves to (1,4?) Hard.\n",
      "\n",
      "Alternative: Maybe they take the positions of blocks and map them to output based on ordering: first block maps to (0,0), second to (0,2), third to (2,0), fourth to (2,2), fifth to (1,1) etc? But order not defined.\n",
      "\n",
      "Let's see Example2: blocks order maybe scanning rows top to bottom left to right: B (1,1) first -> (0,0); A (0,4) second -> (0,2); D (4,0) third -> (2,0); E (5,3) fourth -> (2,2); C (3,5) fifth -> (1,1). This matches output positions if we assign based on order. That could be the rule: Sort blocks by something like top-left row then column, map to predefined pattern order: corners then center. But Example1 only two blocks, they map to (0,0) and (0,2) (first corner top-left, second top-right). Example5 two blocks top-left and bottom-right map to (0,0) and (0,2) again (same order). So order scanning left-to-right top-to-bottom would encounter top-left block first, then bottom-right later (since bottom rows later). That yields (0,0) then (0,2). Works.\n",
      "\n",
      "Example6 three blocks: order scanning: (1,1) top-left, (2,4) top-right, (4,2) bottom-middle. Output order: (0,0), (0,2), (1,1). Indeed matches: third block mapped to center.\n",
      "\n",
      "Thus rule could be: Identify all 2x2 red blocks. Sort them by top-left coordinate (row then col). Then map each block to a unique cell in output according to a fixed mapping sequence: the first block to (0,0), second to (0,2), third to (1,1), fourth to (2,0), fifth to (2,2), sixth maybe? This seems to follow a pattern of positions in a \"X\" shape: corners then center, maybe in order of reading? Let's list order of mapping positions as per examples with number of blocks:\n",
      "\n",
      "- 1 block -> (0,0)\n",
      "- 2 blocks -> (0,0), (0,2)\n",
      "- 3 blocks -> (0,0), (0,2), (1,1)\n",
      "- 4 blocks -> (0,0), (0,2), (1,1), (2,0) (example7 output includes (2,0) but not (2,2) because maybe 4th block maps to (2,0). Indeed example7 has blocks: order scanning: (0,4) top-right (first), (2,1) middle-left (second), (3,4) middle-right (third), (5,1) bottom-left (fourth). According to mapping sequence, first -> (0,0) but output has (0,0)=1 yes, second -> (0,2) output (0,2)=1 yes, third -> (1,1) output (1,1)=1 yes, fourth -> (2,0) output (2,0)=1 yes. So matches! The ordering of blocks (by top-left row then col) gave (0,4) first (row0), (2,1) second (row2), (3,4) third (row3), (5,1) fourth (row5). That maps to sequence corners left->right? Actually mapping positions predetermined independent of block location.\n",
      "\n",
      "Thus algorithm: detect all 2x2 red squares (blocks). Sort them by top-left row then column. Then assign them to output cells in the order of a predefined list of positions: [(0,0), (0,2), (1,1), (2,0), (2,2)] maybe also (0,1) etc? But we haven't seen more than 5 blocks. Max maybe 5. The list seems to follow a pattern of traversing output positions in a \"Z\" shape? Actually order: top-left, top-right, center, bottom-left, bottom-right. That's like reading order of positions of a 3x3 cross shape. Good.\n",
      "\n",
      "Check Example2 with 5 blocks: mapping order produced (0,0),(0,2),(1,1),(2,0),(2,2) which matches output.\n",
      "\n",
      "Example3 with 4 blocks: mapping gave (0,0),(0,2),(1,1),(2,0) matches output.\n",
      "\n",
      "Example6 with 3 blocks: mapping gave (0,0),(0,2),(1,1) matches output.\n",
      "\n",
      "Example8 with 1 block: (0,0) matches output (top-left 1). Yes.\n",
      "\n",
      "Thus rule seems consistent.\n",
      "\n",
      "Now need to implement detection of 2x2 red blocks: find all positions (i,j) such that grid[i][j]==2 and grid[i+1][j]==2 and grid[i][j+1]==2 and grid[i+1][j+1]==2. Ensure within bounds.\n",
      "\n",
      "Potential overlapping blocks? In examples blocks are non-overlapping. Should be fine.\n",
      "\n",
      "Sort by (i,j). Then create 3x3 output initialized zeros. Define mapping order list as above. For each block index k, if k < len(order), set output[order[k]] = 1.\n",
      "\n",
      "Edge cases: If more than 5 blocks, maybe ignore extra? Not needed.\n",
      "\n",
      "Implement transform(grid): compute rows, cols; find blocks; sort; define order = [(0,0),(0,2),(1,1),(2,0),(2,2)]; create out 3x3 zeros; for idx, (r,c) in enumerate(blocks): if idx < len(order): out[order[idx][0]][order[idx][1]] = 1; return out.\n",
      "\n",
      "Test with given examples mentally: Works.\n",
      "\n",
      "Let's test Example4: Input 3x3 contains a 2x2 block at (1,1) (rows1-2 cols1-2). Blocks list length 1 -> output set (0,0)=1 matches.\n",
      "\n",
      "Example5: blocks at (1,1) and (3,3). Sorted: (1,1) first, (3,3) second. Output set (0,0)=1 and (0,2)=1 matches.\n",
      "\n",
      "Example6: blocks at (1,1), (2,4), (4,2). Sorted: (1,1) first, (2,4) second, (4,2) third. Output set (0,0)=1, (0,2)=1, (1,1)=1 matches.\n",
      "\n",
      "Example7: blocks at (0,4),(2,1),(3,4),(5,1). Sorted order as earlier yields mapping matches.\n",
      "\n",
      "Example8: block at (0,0) first -> (0,0)=1 matches.\n",
      "\n",
      "Thus rule solved.\n",
      "\n",
      "Implement code accordingly.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "def transform(grid):\n",
      "\n",
      "    h = len(grid)\n",
      "    w = len(grid[0]) if h else 0\n",
      "\n",
      "    squares = []\n",
      "    for r in range(h - 1):\n",
      "        for c in range(w - 1):\n",
      "            if (grid[r][c] == 2 and grid[r + 1][c] == 2 and\n",
      "                grid[r][c + 1] == 2 and grid[r + 1][c + 1] == 2):\n",
      "                squares.append((r, c))\n",
      "\n",
      "    squares.sort()\n",
      "\n",
      "    out = [[0 for _ in range(3)] for _ in range(3)]\n",
      "\n",
      "    order = [(0, 0), (0, 2), (1, 1), (2, 0), (2, 2)]\n",
      "\n",
      "    for idx, _ in enumerate(squares):\n",
      "        if idx >= len(order):\n",
      "            break          \n",
      "        r_out, c_out = order[idx]\n",
      "        out[r_out][c_out] = 1\n",
      "\n",
      "    return out\n",
      "```<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[0][\"labels\"]]).replace(tokenizer.pad_token, \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "M9fa371ShyhB",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's train the model! To resume a training run, set `trainer.train(resume_from_checkpoint = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "yqxqAZ7KJ4oL",
    "outputId": "4b644b12-626b-45c7-fb11-89825ae13bd2",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,940 | Num Epochs = 2 | Total steps = 184\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 132,120,576 of 4,154,588,672 (3.18% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/184 01:00 < 1:30:05, 0.03 it/s, Epoch 0.03/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer_stats = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/transformers/trainer.py:2229\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2226\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2227\u001b[39m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[32m   2228\u001b[39m     hf_hub_utils.disable_progress_bars()\n\u001b[32m-> \u001b[39m\u001b[32m2229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2230\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2234\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2235\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2236\u001b[39m     hf_hub_utils.enable_progress_bars()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/accelerate/utils/memory.py:174\u001b[39m, in \u001b[36mfind_executable_batch_size.<locals>.decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo executable batch size found, reached zero.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:325\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/unsloth_compiled_cache/UnslothSFTTrainer.py:936\u001b[39m, in \u001b[36m_UnslothSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    935\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:34\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/unsloth_compiled_cache/UnslothSFTTrainer.py:925\u001b[39m, in \u001b[36m_UnslothSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs = \u001b[38;5;28;01mFalse\u001b[39;00m, num_items_in_batch = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/models/_utils.py:1243\u001b[39m, in \u001b[36m_unsloth_pre_compute_loss\u001b[39m\u001b[34m(self, model, inputs, *args, **kwargs)\u001b[39m\n\u001b[32m   1237\u001b[39m     logger.warning_once(\n\u001b[32m   1238\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Not an error, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept `num_items_in_batch`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\\\n\u001b[32m   1239\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing gradient accumulation will be very slightly less accurate.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\\\n\u001b[32m   1240\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/transformers/trainer.py:3884\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3882\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3883\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3885\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3886\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:818\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:806\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:929\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    927\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    931\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/models/llama.py:1372\u001b[39m, in \u001b[36mPeftModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base_model(\n\u001b[32m   1362\u001b[39m         input_ids = input_ids,\n\u001b[32m   1363\u001b[39m         attention_mask = attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1369\u001b[39m         **kwargs,\n\u001b[32m   1370\u001b[39m     )\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:222\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/models/llama.py:1183\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1181\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1183\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1196\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/models/llama.py:995\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    992\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1006\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         message = message.rstrip(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gradient_checkpointing_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:929\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    927\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    931\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:488\u001b[39m, in \u001b[36mcheckpoint\u001b[39m\u001b[34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    484\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    485\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muse_reentrant=False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    490\u001b[39m     gen = _checkpoint_without_reentrant_generator(\n\u001b[32m    491\u001b[39m         function, preserve, context_fn, determinism_check, debug, *args, **kwargs\n\u001b[32m    492\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/autograd/function.py:576\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    574\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    575\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    584\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth_zoo/gradient_checkpointing.py:475\u001b[39m, in \u001b[36mUnslothCheckpointFunction.forward\u001b[39m\u001b[34m(ctx, run_function, preserve_rng_state, *args)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx._requires_gradient: ctx.save_for_backward(*tensor_inputs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     outputs = \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_gpu_buffer: MAIN_STREAM.wait_stream(EXTRA_STREAM)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/models/llama.py:667\u001b[39m, in \u001b[36mLlamaDecoderLayer_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    665\u001b[39m residual = hidden_states\n\u001b[32m    666\u001b[39m hidden_states = fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m.input_layernorm, hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    678\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    680\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/models/qwen3.py:121\u001b[39m, in \u001b[36mQwen3Attention_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    120\u001b[39m         cos, sin = rotary_emb.get_cached(kv_seq_len, device_index)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m Q, K = \u001b[43mfast_rope_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     K = torch.cat([past_key_value[\u001b[32m0\u001b[39m], K], dim = \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:929\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    927\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    931\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/unsloth/kernels/rope_embedding.py:159\u001b[39m, in \u001b[36mfast_rope_embedding\u001b[39m\u001b[34m(Q, K, cos, sin)\u001b[39m\n\u001b[32m    157\u001b[39m K = Fast_RoPE_Embedding.apply(K.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m), cos, sin).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# synchronize before cat to avoid race condition\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Q, K\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/arc-agi-2025/.venv/lib/python3.11/site-packages/torch/cuda/streams.py:102\u001b[39m, in \u001b[36mStream.synchronize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msynchronize\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     97\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Wait for all the kernels in this stream to complete.\u001b[39;00m\n\u001b[32m     98\u001b[39m \n\u001b[32m     99\u001b[39m \u001b[33;03m    .. note:: This is a wrapper around ``cudaStreamSynchronize()``: see\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m       `CUDA Stream documentation`_ for more info.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "pCqnaKmlO1U9",
    "outputId": "3e2fcdf8-501c-4707-fcbb-7c1b4700bb9d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(trainer_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_mode == \"full\":\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Trainer output dir: {trainer.args.output_dir}\")\n",
    "    print(f\"Checkpoints exist: {os.listdir(trainer.args.output_dir)}\")\n",
    "    trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR3gIAX-SM2q",
    "outputId": "b813e560-8e4c-4491-c8be-18067bc07639"
   },
   "outputs": [],
   "source": [
    "# Way to push the final model (lora)\n",
    "# trainer.push_to_hub(dataset_name=train_slug)\n",
    "# stop\n",
    "\n",
    "# print(parquet_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "ekOmTR1hSNcr",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model via Unsloth native inference! According to the `Qwen-3` team, the recommended settings for reasoning inference are `temperature = 0.6, top_p = 0.95, top_k = 20`\n",
    "\n",
    "For normal chat based inference, `temperature = 0.7, top_p = 0.8, top_k = 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"validation\"]['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j873RMcEi9uq",
    "outputId": "3b358da9-aedd-48e3-a345-1ed0ca0bd3fa"
   },
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\" : \"system\", \"content\" : \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n",
    "#     {\"role\" : \"user\", \"content\" : \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation  \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\n```python\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n```\\n\"}\n",
    "# ]\n",
    "# text = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize = False,\n",
    "#     add_generation_prompt = True, # Must add for generation\n",
    "#     enable_thinking = False, # Disable thinking\n",
    "# )\n",
    "\n",
    "# # from transformers import TextStreamer\n",
    "# # _ = model.generate(\n",
    "# #     **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "# #     max_new_tokens = 8000, # Increase for longer outputs!\n",
    "# #     # temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "# #     temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "# #     # temperature = 0.01,\n",
    "# #     streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "# # )\n",
    "\n",
    "# # text = data[\"validation\"]['prompt'][0]\n",
    "\n",
    "# from transformers import TextStreamer\n",
    "\n",
    "# inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "# input_ids = inputs[\"input_ids\"]  # Extract for convenience\n",
    "\n",
    "# output_ids = model.generate(\n",
    "#     **inputs,\n",
    "#     max_new_tokens=2000,\n",
    "#     # temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "#     # temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking\n",
    "#     temperature=0.1, # BEST FOR SINGLE ATTEMPTS\n",
    "# )\n",
    "\n",
    "# # Slice to skip the prompt portion in output\n",
    "# generated_tokens = output_ids[0][input_ids.shape[-1]:]\n",
    "# generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use extract_python_code from utils (SOAR approach)\n",
    "# code = extract_python_code(generated_text)\n",
    "\n",
    "# if code:\n",
    "#     print(code)\n",
    "#     exec(code, globals())  # Defines `transform()` in global scope\n",
    "# else:\n",
    "#     raise ValueError(\"Could not extract Python code from generated text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative transform implementations commented out - using model generated version above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # -------------------- helper --------------------\n",
    "# def safe_transform(grid):\n",
    "#     grid = grid.copy()        # <â€‘â€‘ clone so the original stays unchanged\n",
    "#     try:\n",
    "#         return transform(grid)\n",
    "#     except Exception as err:\n",
    "#         print(f\"[safe_transform] transform() failed â€“ {err}\")\n",
    "#         return np.zeros_like(grid)\n",
    "\n",
    "# # -------------------- test case -----------------\n",
    "# test_case = {\n",
    "#     \"input\": np.array([  # convert to np.array for convenience\n",
    "#         [5, 0, 5, 5, 0, 0, 5, 0, 5, 0],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 5]\n",
    "#     ]),\n",
    "#     \"output\": np.array([\n",
    "#         [5, 0, 5, 5, 0, 0, 5, 0, 5, 0],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "#         [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [2, 0, 2, 2, 0, 0, 2, 0, 2, 5],\n",
    "#         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#         [2, 0, 2, 2, 0, 0, 2, 0, 2, 5]\n",
    "#     ])\n",
    "# }\n",
    "\n",
    "# # -------------------- run & plot ----------------\n",
    "# predicted_output = safe_transform(test_case[\"input\"])\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "# titles = [\"Input\", \"Predicted Output\", \"Ground Truth Output\"]\n",
    "# grids  = [test_case[\"input\"], predicted_output, test_case[\"output\"]]\n",
    "\n",
    "# for ax, grid, title in zip(axs, grids, titles):\n",
    "#     im = ax.imshow(grid, cmap=\"viridis\", vmin=0, vmax=5)\n",
    "#     ax.set_title(title)\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference testing section ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "<a name=\"Save\"></a>\n",
    "### Saving, loading finetuned models\n",
    "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
    "\n",
    "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "You can use this also to load a checkpoint!!! i.e. an intermediate checkpoint from training, so you can then push it to hub.\n",
    "\n",
    "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKX_XKs_BNZR"
   },
   "outputs": [],
   "source": [
    "# if False:\n",
    "#     # TO MANUALLY LOAD A LORA AND THEN MERGE AND PUSH\n",
    "#     import os\n",
    "#     import unsloth\n",
    "#     from unsloth import FastLanguageModel\n",
    "#     import torch\n",
    "    \n",
    "#     checkpoint = 44\n",
    "\n",
    "#     from unsloth import FastLanguageModel\n",
    "#     model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#         # model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "#         model_name = f\"trainer_output/checkpoint-{checkpoint}\",\n",
    "#         # max_seq_length = 30000,\n",
    "#         # load_in_4bit = False,\n",
    "#     )\n",
    "#     # run_name = \"Qwen3-4B_dsarc-programs-50-full-200-partial_20250807-211749\"\n",
    "#     # lora_run_name = run_name + f\"-c{checkpoint}\"\n",
    "#     # print(f\"Pushing to Trelis/{lora_run_name}\")\n",
    "#     # model = model.merge_and_unload()\n",
    "#     # model.push_to_hub(f\"Trelis/{lora_run_name}\")\n",
    "#     # tokenizer.push_to_hub(f\"Trelis/{lora_run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint processing based on execution mode\n",
    "import os, re, torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# # if re-running\n",
    "# run_name = \"test-oss\"\n",
    "# execution_mode = \"final\"\n",
    "# is_kaggle = False\n",
    "\n",
    "ROOT = \"trainer_output\"\n",
    "RUN_NAME = run_name\n",
    "\n",
    "if \"model\" in locals() or \"model\" in globals():\n",
    "    del model\n",
    "if \"tokenizer\" in locals() or \"tokenizer\" in globals():\n",
    "    del tokenizer\n",
    "\n",
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if execution_mode == \"final_only\":\n",
    "    print(\"ğŸ”§ Final-only mode: Only processing the last checkpoint\")\n",
    "    \n",
    "    # Find all checkpoints and get the latest one\n",
    "    ckpts = []\n",
    "    for d in os.listdir(ROOT):\n",
    "        m = re.fullmatch(r\"checkpoint-(\\d+)\", d)\n",
    "        if m and os.path.isdir(os.path.join(ROOT, d)):\n",
    "            ckpts.append((int(m.group(1)), os.path.join(ROOT, d)))\n",
    "    \n",
    "    if not ckpts:\n",
    "        print(\"âŒ No checkpoints found!\")\n",
    "    else:\n",
    "        # Sort and get the last checkpoint\n",
    "        ckpts.sort(key=lambda x: x[0])\n",
    "        final_step, final_path = ckpts[-1]\n",
    "        \n",
    "        print(f\"ğŸ“¦ Processing final checkpoint: {final_step}\")\n",
    "        \n",
    "        try:\n",
    "            model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "                model_name=final_path,\n",
    "                load_in_4bit=False,\n",
    "            )\n",
    "\n",
    "            final_model_path = os.path.join(model_save_dir, f\"{RUN_NAME}-final\")\n",
    "            print(f\"ğŸ’¾ Saving final model to: {final_model_path}\")\n",
    "\n",
    "            # # UNSLOTH - Merge and Save Locally\n",
    "            if 'oss' in final_model_path:\n",
    "                model.save_pretrained_merged(final_model_path, tokenizer, save_method=\"mxfp4\")\n",
    "                # model.save_pretrained_merged(final_model_path, tokenizer, save_method=\"merged_16bit\")\n",
    "            else:\n",
    "                model.save_pretrained_merged(final_model_path, tokenizer, save_method=\"merged_16bit\")\n",
    "            \n",
    "            # # TRANSFORMERS - Merge and save locally\n",
    "            # merged_model = model.merge_and_unload()\n",
    "            # merged_model.save_pretrained(final_model_path)\n",
    "            # tokenizer.save_pretrained(final_model_path)\n",
    "            # del merged_model\n",
    "            \n",
    "            print(f\"âœ… Final model saved successfully\")\n",
    "            \n",
    "            # Clean up\n",
    "            del model, tokenizer\n",
    "            try:\n",
    "                torch.cuda.empty_cache()\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing final checkpoint: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ”„ Full mode: Processing all checkpoints\")\n",
    "    \n",
    "    # Original behavior - process all checkpoints\n",
    "    ckpts = []\n",
    "    for d in os.listdir(ROOT):\n",
    "        m = re.fullmatch(r\"checkpoint-(\\d+)\", d)\n",
    "        if m and os.path.isdir(os.path.join(ROOT, d)):\n",
    "            ckpts.append((int(m.group(1)), os.path.join(ROOT, d)))\n",
    "    ckpts.sort(key=lambda x: x[0])  # ascending; use reverse=True for newest first\n",
    "    \n",
    "    # ğŸ‘‡ keep only the last 2 checkpoints\n",
    "    checkpoints_to_push = ckpts[-2:]\n",
    "    print(f\"Found {len(checkpoints_to_push)} checkpoints:\", [s for s, _ in checkpoints_to_push])\n",
    "    \n",
    "    for step, path in checkpoints_to_push:\n",
    "        try:\n",
    "            print(f\"\\n=== STEP {step} === Loading {path}\")\n",
    "            model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "                model_name = path,\n",
    "                load_in_4bit = False,\n",
    "                # device_map = \"auto\",   # uncomment if you have GPU available\n",
    "            )\n",
    "            repo_id = f\"Trelis/{RUN_NAME}-c{step}\"\n",
    "            \n",
    "            if is_kaggle:\n",
    "                # Save locally when running locally\n",
    "                local_path = os.path.join(model_save_dir, f\"{RUN_NAME}-c{step}\")\n",
    "                print(f\"Saving locally at {local_path}\")\n",
    "\n",
    "                if 'oss' in local_path:\n",
    "                    # # UNSLOTH - Merge and Save Locally\n",
    "                    model.save_pretrained_merged(local_path, tokenizer, save_method=\"mxfp4\")\n",
    "                    # model.save_pretrained_merged(local_path, tokenizer, save_method=\"merged_16bit\")\n",
    "                else:\n",
    "                    model.save_pretrained_merged(local_path, tokenizer, save_method=\"merged_16bit\")\n",
    "            \n",
    "                # ## TRANSFORMERS\n",
    "                # merged_model = model.merge_and_unload()\n",
    "                # merged_model.save_pretrained(local_path)\n",
    "                # tokenizer.save_pretrained(local_path)\n",
    "                # del merged_model\n",
    "                \n",
    "            else:\n",
    "                print(f\"Pushing to {repo_id} â€¦\")\n",
    "\n",
    "                # # UNSLOTH - Merge and Push\n",
    "                if 'oss' in repo_id:\n",
    "                    # model.push_to_hub_merged(repo_id, tokenizer, save_method=\"merged_16bit\")\n",
    "                    model.push_to_hub_merged(repo_id, tokenizer, save_method=\"mxfp4\")\n",
    "                else:\n",
    "                    model.push_to_hub_merged(repo_id, tokenizer, save_method=\"merged_16bit\")\n",
    "                \n",
    "                # ## TRANSFORMERS\n",
    "                # # If you trained with LoRA, keep merge_and_unload(); if full-finetune, drop this line.\n",
    "                # model = model.merge_and_unload()\n",
    "                # model.push_to_hub(repo_id,private=True)\n",
    "                # tokenizer.push_to_hub(repo_id)\n",
    "\n",
    "            # tidy up between checkpoints\n",
    "            del model\n",
    "            del tokenizer\n",
    "            try:\n",
    "                torch.cuda.empty_cache()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping checkpoint {step}: {e}\")\n",
    "            \n",
    "print(f\"\\nâœ… Checkpoint processing complete for {execution_mode} mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MANUAL MERGE AFTER THE FACT.\n",
    "# # pip install -U huggingface_hub transformers peft\n",
    "# import re, gc, torch\n",
    "# from huggingface_hub import HfApi\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from peft import PeftModel\n",
    "\n",
    "# BASE_ID  = \"Qwen/Qwen3-4B\"\n",
    "# SRC_REPO = \"Trelis/Qwen3-4B_dsarc-programs-50-full-200-incorrect_20250808-134330-trainer\"\n",
    "# REVISION = \"main\"\n",
    "# OUT_NS   = \"Trelis\"\n",
    "# PRIVATE  = True\n",
    "\n",
    "# api = HfApi()  # uses HF_TOKEN if set\n",
    "\n",
    "# def find_checkpoints(repo_id: str, revision: str = \"main\"):\n",
    "#     files = api.list_repo_files(repo_id=repo_id, repo_type=\"model\", revision=revision)\n",
    "#     steps = sorted({int(m.group(1)) for p in files if (m := re.match(r\"^checkpoint-(\\d+)/\", p))})\n",
    "#     return [f\"checkpoint-{s}\" for s in steps], files\n",
    "\n",
    "# def load_tokenizer_for_checkpoint(repo_id: str, subfolder: str):\n",
    "#     # Try subfolder tokenizer -> repo root tokenizer -> base tokenizer\n",
    "#     try:\n",
    "#         return AutoTokenizer.from_pretrained(\n",
    "#             repo_id, subfolder=subfolder, revision=REVISION, trust_remote_code=True, use_fast=True\n",
    "#         )\n",
    "#     except Exception:\n",
    "#         try:\n",
    "#             return AutoTokenizer.from_pretrained(\n",
    "#                 repo_id, revision=REVISION, trust_remote_code=True, use_fast=True\n",
    "#             )\n",
    "#         except Exception:\n",
    "#             return AutoTokenizer.from_pretrained(BASE_ID, trust_remote_code=True, use_fast=True)\n",
    "\n",
    "# ckpt_dirs, files = find_checkpoints(SRC_REPO, REVISION)\n",
    "# print(\"Found checkpoints:\", ckpt_dirs)\n",
    "# if not ckpt_dirs:\n",
    "#     print(\"[DEBUG] sample files:\", files[:20])\n",
    "\n",
    "# for sub in ckpt_dirs:\n",
    "#     step = int(sub.split(\"-\")[1])\n",
    "#     out_repo = f\"{OUT_NS}/{SRC_REPO.split('/',1)[1].replace('-trainer','')}-c{step}\"\n",
    "#     print(f\"\\n=== {SRC_REPO}/{sub} -> {out_repo} ===\")\n",
    "\n",
    "#     # Load base each time (avoid stacking adapters)\n",
    "#     base = AutoModelForCausalLM.from_pretrained(\n",
    "#         BASE_ID, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True, low_cpu_mem_usage=True\n",
    "#     )\n",
    "\n",
    "#     # Attach LoRA from checkpoint subfolder\n",
    "#     peft = PeftModel.from_pretrained(\n",
    "#         base, model_id=SRC_REPO, subfolder=sub, adapter_name=f\"ckpt{step}\"\n",
    "#     )\n",
    "#     peft.set_adapter(f\"ckpt{step}\")\n",
    "\n",
    "#     # Load tokenizer *for this checkpoint*\n",
    "#     tok = load_tokenizer_for_checkpoint(SRC_REPO, sub)\n",
    "\n",
    "#     # Optional safety: warn if tokenizer size > embeddings size\n",
    "#     try:\n",
    "#         vocab = len(tok)\n",
    "#         emb = peft.base_model.get_input_embeddings().weight.shape[0]\n",
    "#         if vocab > emb:\n",
    "#             print(f\"[WARN] tokenizer {vocab} > embeddings {emb} â€” consider resize or base tokenizer\")\n",
    "#         else:\n",
    "#             print(f\"[OK] tokenizer {vocab} <= embeddings {emb} (padding: {emb - vocab})\")\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "#     # Bake LoRA into base\n",
    "#     merged = peft.merge_and_unload()  # returns plain Transformers model\n",
    "\n",
    "#     # Push baked model + that checkpoint's tokenizer\n",
    "#     merged.push_to_hub(out_repo, private=PRIVATE)\n",
    "#     tok.push_to_hub(out_repo)\n",
    "#     print(f\"Pushed {out_repo}\")\n",
    "\n",
    "#     del merged, peft, base, tok\n",
    "#     gc.collect()\n",
    "#     try: torch.cuda.empty_cache()\n",
    "#     except: pass\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "arc-agi-2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00d671d686af43c38b12a9448c5bbf06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0340990c29e64f8d9a9ba37f09c55659": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05997290010e49259742f1a560a6aac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_140760e267d84afc852df8cb470d86d5",
       "IPY_MODEL_b22bcb2a7b24497581994b71b02f755d",
       "IPY_MODEL_3c5c945a8daf4b3f83741ecbc26804b2"
      ],
      "layout": "IPY_MODEL_2170ab68e5724b4b9c77c039c57f8e0a"
     }
    },
    "062f278ab1c94d8099e06074e0cd360c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06c646d514b448628424dc8c772994de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8be1618a9f8840af8d89103c37ef02ef",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f0b8a9e00c0d4cc1aff1e3a748a8f039",
      "value": "chat_template.jinja:â€‡100%"
     }
    },
    "0940df31fc9047ccae4870b7d2c89b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09cd31746a174e96bb346e1afc7b3c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64eb3128b25448b48268ec61cac289d1",
      "max": 237,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc277d60ad4a419a94ded28a1c27a9f4",
      "value": 237
     }
    },
    "09ce664a0a404087a9fe53a5c2d5316e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d254a8222d42b093ff8f229a6fe503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ab824fcbf0e46f7bbe75af9f662c31a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b3d64dd05f841d68ad472ce933e36d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d0852d9ebb2409ea51650f538dd1621": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_062f278ab1c94d8099e06074e0cd360c",
      "max": 707,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ad57df96bec4267a220a739cfc72bc1",
      "value": 707
     }
    },
    "0e112f4ad6974529a4c4f583e6a73950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e997f45717c44e1944d510ae6c51fb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f195b35b0a7416c8d395c17dea7fafa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fab32e1222f4431a255a36df0a22a35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "100a0b5f637b4dc1a1da400e8f363678": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "109c736c8b99496e8721f9595c54eb6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f89daea726144ded892113a161649b64",
       "IPY_MODEL_9f0108d9201f40599facfccf668a6e84",
       "IPY_MODEL_927c60cd1f0d4a32a1ff9427a96a3246"
      ],
      "layout": "IPY_MODEL_fb6f38d9dd1e49ec8fdfb7ca7ea363a2"
     }
    },
    "12d7229f7d81488e93689d4269ee48ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d7cac449954aafa26c6b5bcb6e031f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26dbcdc380e1404687020cbd9bf38513",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2abd7191bff846198b2fb033da32f8c8",
      "value": "â€‡11.4M/11.4Mâ€‡[00:00&lt;00:00,â€‡33.3MB/s]"
     }
    },
    "132dbcd182314c10a906d16f43f94896": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_231a411ab9c241a3b9b8a98617ff8ad4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c688c828118f41859a3d71c54b62354a",
      "value": "README.md:â€‡100%"
     }
    },
    "13779546fa624d448862777f344bb2a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "140760e267d84afc852df8cb470d86d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0340990c29e64f8d9a9ba37f09c55659",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5deffaef73d14116a8b1bcf8d46df2fc",
      "value": "Generatingâ€‡cotâ€‡split:â€‡100%"
     }
    },
    "145cc80490fa42258fe6e5a643b57dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c3887400b6d34c30a54c6af94c2b612d",
       "IPY_MODEL_7efa9f507c8546bb9b0b5d47be527c25",
       "IPY_MODEL_74267e9cd64d44b58bdbd7dad03b681d"
      ],
      "layout": "IPY_MODEL_dd2adf3e30304398b8340253dbd4489a"
     }
    },
    "153259764d2b45e0bc02938d6909d40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d9deebcb56f40e3ace1f52e862c1c31",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_100a0b5f637b4dc1a1da400e8f363678",
      "value": "â€‡100000/100000â€‡[00:04&lt;00:00,â€‡6952.47â€‡examples/s]"
     }
    },
    "179e343762ba440cbc094e0e85b4ee84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cb88502cb1643a8927049baf40d56b7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c37a4b08afa84b64b40ebbe08cbfb018",
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    },
    "196f35f21b97476a9814acd96dbec717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ad6055d2ba2481c83b1b136e5898986",
       "IPY_MODEL_8147cc77ce3941c290982d21c42f9f66",
       "IPY_MODEL_f1af17f7a7ee405dabd07f41b6b786d7"
      ],
      "layout": "IPY_MODEL_aeb720eea25149deb34e6844a8bdd2c5"
     }
    },
    "1a09813436c24b5ea68e652254288ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b2a213c48f04667a243cc6dc6c43b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afb3e794edf046a9b594fcbb99acb8ea",
      "max": 982,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1a6d94a50aa4ac29965cb1693c9c5c3",
      "value": 982
     }
    },
    "1c2573a314d94fc1a2f414adfa9d259a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d31954fe1804140bcac71e3d4102fdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f9eba179bf847dcb47dbda34611459a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8f15be1afc44472bff560ca7316873a",
      "max": 10534,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a40e10f372644d80b2830d0f42fcde6c",
      "value": 10534
     }
    },
    "2068eb23121440ec83d8cd117b4c6ba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7054b1bcb73e4515afd29b42a32b20c5",
       "IPY_MODEL_09cd31746a174e96bb346e1afc7b3c8b",
       "IPY_MODEL_802bdf3c4293448bb00b625722f1a9f6"
      ],
      "layout": "IPY_MODEL_f7c27321d53047479c1ed45b5d5109f6"
     }
    },
    "2167f3dc7050467a9f19f3f885cfb09b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2170ab68e5724b4b9c77c039c57f8e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "231a411ab9c241a3b9b8a98617ff8ad4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23791684cb5349c4853cffb4e72ebe1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aefab33f6f345869c19899ca2952df1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_881919ffdd7940839c8b40edba7f8c01",
      "value": "â€‡1.56G/1.56Gâ€‡[00:16&lt;00:00,â€‡730MB/s]"
     }
    },
    "247ee0a6f4e64e5ca0a435d243690d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c1c1bc584cb456c9d07f4ac267cf2c5",
       "IPY_MODEL_cc9479fb190742fd865613680e87e535",
       "IPY_MODEL_ae9317b34ba341c4ac40797da3ac2478"
      ],
      "layout": "IPY_MODEL_5012456fc82e47aca5a69f52a36cb8f5"
     }
    },
    "247f2a4074cc4fb0956ef06b10b5e5da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26dbcdc380e1404687020cbd9bf38513": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2857e876d47a49bbadf3494b1864c1bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b9748337a1c4291ac882194b16eb032",
      "max": 19252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1b000b08af549689d1be5f0289bf2c3",
      "value": 19252
     }
    },
    "28d439d23bf54688963517fbdb482339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0940df31fc9047ccae4870b7d2c89b3d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0b3d64dd05f841d68ad472ce933e36d7",
      "value": "â€‡3/3â€‡[00:45&lt;00:00,â€‡13.54s/it]"
     }
    },
    "2abd7191bff846198b2fb033da32f8c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aefab33f6f345869c19899ca2952df1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b72ac21d79c459395682f6692c4325f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b9748337a1c4291ac882194b16eb032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c04e534215f4d40b103be09e300b744": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cfa55ba5d3345cda1cf83cde925a7fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6367d6b72c37406cafa63daa77263ca2",
       "IPY_MODEL_8f14d9c07bf846a682c1c44f4a2d2410",
       "IPY_MODEL_6e020b0421e84d9a9a8f0b68aa10cbee"
      ],
      "layout": "IPY_MODEL_13779546fa624d448862777f344bb2a6"
     }
    },
    "2de7e147b2e14db38243c7656a29f0e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dff2433978a477582b995bc6abafe68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b998e55dd17b44d7a8c23ac427619036",
       "IPY_MODEL_5210d369018a44d4ad2fbd26190aca9b",
       "IPY_MODEL_64b00e376bb142c88a690757f27b8294"
      ],
      "layout": "IPY_MODEL_09ce664a0a404087a9fe53a5c2d5316e"
     }
    },
    "2f4608614780453a826e3ad59817d7ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d4fb1807bc4ec0840d63ef0bf2e0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32000eaf412840388188523be1033cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34b0ab119eab40eda8b7a551642e0e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71c37d1f12294e858ceb337d2e37e375",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_00d671d686af43c38b12a9448c5bbf06",
      "value": "special_tokens_map.json:â€‡100%"
     }
    },
    "36eed804652e4c6fb7fe2e969228decd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ad57df96bec4267a220a739cfc72bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ad6055d2ba2481c83b1b136e5898986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d574f195dfc4bc4b1ca86863d97e597",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c8faa5be5b88425298b5655a8f507a2a",
      "value": "merges.txt:â€‡100%"
     }
    },
    "3c2e07218b764906a278d6a367153548": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db172381abdf4bb0a84417882fc462be",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0ab824fcbf0e46f7bbe75af9f662c31a",
      "value": "â€‡4.67k/4.67kâ€‡[00:00&lt;00:00,â€‡312kB/s]"
     }
    },
    "3c5c945a8daf4b3f83741ecbc26804b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df721834c3de4656909069aed0670d36",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4015d6ed6b9d4c1394850ff0ad704149",
      "value": "â€‡19252/19252â€‡[00:01&lt;00:00,â€‡13745.17â€‡examples/s]"
     }
    },
    "3cb88502cb1643a8927049baf40d56b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d9deebcb56f40e3ace1f52e862c1c31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ddcfbdbb0fc49b0b53a296cdb2348b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e3384d811f94fb9a2d065ffdffaf731": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4015d6ed6b9d4c1394850ff0ad704149": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40b0b562564b4e969c02902b1bbea6e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42724261ea1a440c8ca92a32df1e52d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "455c651682fd42eda5a25ce06560893f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46b625ee9ac041338432f548ee3ab51a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b19bb0b66b248fdbcd01b6264e2ff02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ba6022d4efc4c2ebfdf87b288ed9fd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c1c1bc584cb456c9d07f4ac267cf2c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e84a5ae6c71d42ea8187ebbdcdb4791e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2c04e534215f4d40b103be09e300b744",
      "value": "model-00001-of-00003.safetensors:â€‡100%"
     }
    },
    "5012456fc82e47aca5a69f52a36cb8f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "502b4fc680b248079121ec2a51062b8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_132dbcd182314c10a906d16f43f94896",
       "IPY_MODEL_1b2a213c48f04667a243cc6dc6c43b0e",
       "IPY_MODEL_eeb29e4ed2ae401f9d21cbe941d6cb1d"
      ],
      "layout": "IPY_MODEL_dcffa04c1de94d3691a14d10df2ee24b"
     }
    },
    "50524c8582eb4814a598654901c35a82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50ad501db7af4ef394540eaf36e1793b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5132d82c92ac41d2b592bf6eebf92c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5210d369018a44d4ad2fbd26190aca9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36eed804652e4c6fb7fe2e969228decd",
      "max": 4589082716,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b8c883b15d84ca2a12bfd3f7a87101d",
      "value": 4589082279
     }
    },
    "528e29551b7a4f77aed08c653e49ee57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_247f2a4074cc4fb0956ef06b10b5e5da",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d760efb7d31a4bbbb29c7af2478e1cbd",
      "value": 100000
     }
    },
    "53f8155387394238b443d54cffe9a363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09d254a8222d42b093ff8f229a6fe503",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_daa8753d49d7458cab39dd1524b20356",
      "value": "Unsloth:â€‡Standardizingâ€‡formatsâ€‡(num_proc=2):â€‡100%"
     }
    },
    "5496d2ce66584dc3aed8ca0a31e10463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55a9f6bcb83d4a98a9efcf18253b5091": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b26ab90b1043cb8ed36aab316a45ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "569ad7b2350d46549b2f385a126426d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57ae3d07d1244ba495573895ff11e28e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2c1801935444f2a807b2d483c91ad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a7feb07c0124b9ab00900eb25efa616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b3081e536ac4a258fe5db59bb927ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acbef56d18ae4b86ad0d4b79210db204",
       "IPY_MODEL_2857e876d47a49bbadf3494b1864c1bf",
       "IPY_MODEL_87ca88b487414767af6533125e688186"
      ],
      "layout": "IPY_MODEL_b1e286de944749ec8f5b4ce03df7b7e5"
     }
    },
    "5d66a72e82e54d9e8367ca8a2469dd0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5deffaef73d14116a8b1bcf8d46df2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e18861f3fa24666869822349d1de377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e276c9e2cf14d38ab5971a32b4e369d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60c6d4d43a6445e78051c96a462d7c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06c646d514b448628424dc8c772994de",
       "IPY_MODEL_7c33f0f45eca43cb8015416999b884a1",
       "IPY_MODEL_3c2e07218b764906a278d6a367153548"
      ],
      "layout": "IPY_MODEL_bf94cc1837ba486b895656b41c1e9c99"
     }
    },
    "6303ec778b1d49dd980542a191261961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6367d6b72c37406cafa63daa77263ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96d0f3f2bbc8468fb34e0b61454f8ce8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5496d2ce66584dc3aed8ca0a31e10463",
      "value": "0000.parquet:â€‡100%"
     }
    },
    "6379559e06cd4668b8c2322cb7dc7f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63abaade8f464ed6bbd51d77014dfe66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644f70a125854e418fbb8469d287edd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca910f4f81547b1afdb9a27eb3f4819",
      "max": 116531415,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42724261ea1a440c8ca92a32df1e52d5",
      "value": 116531404
     }
    },
    "64b00e376bb142c88a690757f27b8294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7afd9c01f68473387f009b05d829b3b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f34c9b4f069f4fb281f4e0145f0e818e",
      "value": "â€‡4.59G/4.59Gâ€‡[00:34&lt;00:00,â€‡384MB/s]"
     }
    },
    "64eb3128b25448b48268ec61cac289d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65fa509db52047b791159e65ce9108a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e276c9e2cf14d38ab5971a32b4e369d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_eed62b35a7974086b8d27d9c3e459a91",
      "value": "â€‡117M/117Mâ€‡[00:01&lt;00:00,â€‡100MB/s]"
     }
    },
    "6769817deaaf45fc8a0efb945570f412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67a67c8affbe4ec38f99cbb0a3c52dcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a86e54867d5141dfb1e31ed2d706434f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9864096e9bb54228bf1d9e581b8485bc",
      "value": "added_tokens.json:â€‡100%"
     }
    },
    "67e43763f2f7457487d8b5bfca51b8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "689f645af24947e8920b631d2aa7c3ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6910d714dc854e959839e57b5123af86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77f86f331a19461d94e4840213b256f6",
       "IPY_MODEL_fcd0ee642395431e92a681ba8d829b20",
       "IPY_MODEL_12d7cac449954aafa26c6b5bcb6e031f"
      ],
      "layout": "IPY_MODEL_4ba6022d4efc4c2ebfdf87b288ed9fd4"
     }
    },
    "691a8c5c682a4b32b19c7e71c1672189": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6be394c3849a41a3937322325836d604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e020b0421e84d9a9a8f0b68aa10cbee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f195b35b0a7416c8d395c17dea7fafa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_32000eaf412840388188523be1033cab",
      "value": "â€‡106M/106Mâ€‡[00:01&lt;00:00,â€‡41.8MB/s]"
     }
    },
    "6ec851dec2af487b93f0a626cacba0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3cb03ec368f40fb965beb086b78fb78",
       "IPY_MODEL_bc1b4decb2154b8fb66347408d419ce3",
       "IPY_MODEL_942778de9f014522a928a1408cfcfb05"
      ],
      "layout": "IPY_MODEL_847e20d244014914a420c20b660c99cf"
     }
    },
    "7013b9ae0d8a4bbfa744a5a3e3c18a1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7054b1bcb73e4515afd29b42a32b20c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55a9f6bcb83d4a98a9efcf18253b5091",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e18861f3fa24666869822349d1de377",
      "value": "generation_config.json:â€‡100%"
     }
    },
    "71c37d1f12294e858ceb337d2e37e375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73d6e9b4704f40aab25fecd24154f9bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74267e9cd64d44b58bdbd7dad03b681d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a151688c648045f399e32dc55dd9a1b3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_55b26ab90b1043cb8ed36aab316a45ad",
      "value": "â€‡168k/168kâ€‡[00:00&lt;00:00,â€‡2.48MB/s]"
     }
    },
    "77f86f331a19461d94e4840213b256f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fab32e1222f4431a255a36df0a22a35",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7013b9ae0d8a4bbfa744a5a3e3c18a1e",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "7a3a67547e2043a0ac74b49c47009954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b21ad18c43d4509810204b8a4787b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b34f538a42f4a9ba9de379ae57f0134": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_968919dd5d5f41ce91da5cdea02b438b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_31d4fb1807bc4ec0840d63ef0bf2e0f9",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "7b8c883b15d84ca2a12bfd3f7a87101d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c33f0f45eca43cb8015416999b884a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1cd702821234a9f87933d099ef5273c",
      "max": 4673,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6be394c3849a41a3937322325836d604",
      "value": 4673
     }
    },
    "7c6caf15c5de4a2fb699d034a6ab776c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d574f195dfc4bc4b1ca86863d97e597": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e7ac790b8af4cfb978bfe8ac8499900": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7efa9f507c8546bb9b0b5d47be527c25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46b625ee9ac041338432f548ee3ab51a",
      "max": 167747,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fea4c81baaf84d9b806c1853216c89e2",
      "value": 167747
     }
    },
    "802bdf3c4293448bb00b625722f1a9f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57ae3d07d1244ba495573895ff11e28e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0e997f45717c44e1944d510ae6c51fb9",
      "value": "â€‡237/237â€‡[00:00&lt;00:00,â€‡20.7kB/s]"
     }
    },
    "8147cc77ce3941c290982d21c42f9f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93a91db5fd6147c5a7982496f09c5b8b",
      "max": 1671853,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5132d82c92ac41d2b592bf6eebf92c19",
      "value": 1671853
     }
    },
    "844cd70bf80d40f79c520caf1d7e2a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f4608614780453a826e3ad59817d7ae",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c89e5721ed7e48b295ccc74b841ec61e",
      "value": "â€‡10.5k/10.5kâ€‡[00:00&lt;00:00,â€‡704kB/s]"
     }
    },
    "8450b0ecd0934facbc4f16fc471f778b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "847e20d244014914a420c20b660c99cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "852a10d472ad48a19203ded79cf30662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d8db7e564a40499d58f0d9c11b01a7",
      "max": 100000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a7feb07c0124b9ab00900eb25efa616",
      "value": 100000
     }
    },
    "87ca88b487414767af6533125e688186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1e4e03e40b2480388b67dcb7d2120c3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8bf8b1e60de142a6845aaadbe64fcb85",
      "value": "â€‡19252/19252â€‡[00:01&lt;00:00,â€‡10429.75â€‡examples/s]"
     }
    },
    "881919ffdd7940839c8b40edba7f8c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8be1618a9f8840af8d89103c37ef02ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bf8b1e60de142a6845aaadbe64fcb85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cdf258cb0554d64a4aceed488b6361b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53f8155387394238b443d54cffe9a363",
       "IPY_MODEL_852a10d472ad48a19203ded79cf30662",
       "IPY_MODEL_9ced22ec1fc54b4e9e7b7ab1aae0c940"
      ],
      "layout": "IPY_MODEL_a6a8ff65be444bc3999c28f53d9b46f4"
     }
    },
    "8f14d9c07bf846a682c1c44f4a2d2410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b72d23e8d05449a8bf8a7511ada49704",
      "max": 105878062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6379559e06cd4668b8c2322cb7dc7f53",
      "value": 105878052
     }
    },
    "904f626a367745979ac664f4d2ea6409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e976be66ed774ce880463df39d0c25ce",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_67e43763f2f7457487d8b5bfca51b8e4",
      "value": "â€‡707/707â€‡[00:00&lt;00:00,â€‡70.0kB/s]"
     }
    },
    "911bd3f394ce4394be92e50782d6ae39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd1b79ecec114d28ace8c1b8b1fd4d5d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d4b3982b73d046478f7c9b561ed42298",
      "value": "vocab.json:â€‡100%"
     }
    },
    "927c60cd1f0d4a32a1ff9427a96a3246": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7077f3352b246ddbbca391c08c48b4a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a1c374126fb144e68060e4fedab51046",
      "value": "â€‡25669/25669â€‡[03:35&lt;00:00,â€‡157.21â€‡examples/s]"
     }
    },
    "92be8fd7a814466c983d689bd5d6e1a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93a91db5fd6147c5a7982496f09c5b8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "942778de9f014522a928a1408cfcfb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50ad501db7af4ef394540eaf36e1793b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8450b0ecd0934facbc4f16fc471f778b",
      "value": "â€‡603/603â€‡[00:00&lt;00:00,â€‡24.5kB/s]"
     }
    },
    "968919dd5d5f41ce91da5cdea02b438b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d0f3f2bbc8468fb34e0b61454f8ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9864096e9bb54228bf1d9e581b8485bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c35626d415d4468a30e0513cc7a5234": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9b22a85e2049089b2194770637c91e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ced22ec1fc54b4e9e7b7ab1aae0c940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_455c651682fd42eda5a25ce06560893f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a56f6c918e064278a0217c53e8cc2f6e",
      "value": "â€‡100000/100000â€‡[00:04&lt;00:00,â€‡30077.54â€‡examples/s]"
     }
    },
    "9d02fcd7882345dea97be6decb5293a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b34f538a42f4a9ba9de379ae57f0134",
       "IPY_MODEL_1f9eba179bf847dcb47dbda34611459a",
       "IPY_MODEL_844cd70bf80d40f79c520caf1d7e2a5b"
      ],
      "layout": "IPY_MODEL_fa8721e596b74611945a1d76e9deff8f"
     }
    },
    "9f0108d9201f40599facfccf668a6e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e17016c458a14736bd56ba55d7168f32",
      "max": 25669,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d31954fe1804140bcac71e3d4102fdc",
      "value": 25669
     }
    },
    "9f6ddb6a1c264fc79f907c54078bb769": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a151688c648045f399e32dc55dd9a1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1c374126fb144e68060e4fedab51046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1e4e03e40b2480388b67dcb7d2120c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a40e10f372644d80b2830d0f42fcde6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a469a1af99124ff6974265f45563deea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a48262b1d98a427ab79d589907521d88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a56f6c918e064278a0217c53e8cc2f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a68cbb7211b448c78cd418a90b908037": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a8ff65be444bc3999c28f53d9b46f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7077f3352b246ddbbca391c08c48b4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7078409a02740cbbd6d59b61a4a8c6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_691a8c5c682a4b32b19c7e71c1672189",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5a2c1801935444f2a807b2d483c91ad7",
      "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
     }
    },
    "a81ef4374fde4d10a1cdc5daeec34dda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a86e54867d5141dfb1e31ed2d706434f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a99b117d78a8493c9f6ae80f5bf6ea5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b74e4e5971684b00b40ca42cf2aebb9e",
       "IPY_MODEL_d9dcda48a37e41f7808a933cfd939ded",
       "IPY_MODEL_23791684cb5349c4853cffb4e72ebe1d"
      ],
      "layout": "IPY_MODEL_c6514d1ee44141d3bf83fde032d39a46"
     }
    },
    "a9e3708d145c4bedaa07e5347019fd01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca910f4f81547b1afdb9a27eb3f4819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acbef56d18ae4b86ad0d4b79210db204": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cde3541ff2444f55a1651b8992e53da1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7b21ad18c43d4509810204b8a4787b64",
      "value": "Map:â€‡100%"
     }
    },
    "ae9317b34ba341c4ac40797da3ac2478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c9b22a85e2049089b2194770637c91e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fb2ce6370b1d4d5d9dbdb98aa236da71",
      "value": "â€‡4.97G/4.97Gâ€‡[00:54&lt;00:00,â€‡151MB/s]"
     }
    },
    "aeb720eea25149deb34e6844a8bdd2c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afb3e794edf046a9b594fcbb99acb8ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1542f5b57f14b98be813e6b2540bb80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34b0ab119eab40eda8b7a551642e0e31",
       "IPY_MODEL_c519c7b69d70467c875a3d228e6b6fd2",
       "IPY_MODEL_cd8774e4577a4652863469d3cb75f2ee"
      ],
      "layout": "IPY_MODEL_40b0b562564b4e969c02902b1bbea6e8"
     }
    },
    "b1a6d94a50aa4ac29965cb1693c9c5c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1cd702821234a9f87933d099ef5273c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1e286de944749ec8f5b4ce03df7b7e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b22bcb2a7b24497581994b71b02f755d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0969d7420e541229f1e0a9de683c367",
      "max": 19252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c2573a314d94fc1a2f414adfa9d259a",
      "value": 19252
     }
    },
    "b25399bf6ae4414ba2836733f59e4ab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92be8fd7a814466c983d689bd5d6e1a9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7a3a67547e2043a0ac74b49c47009954",
      "value": "â€‡2.78M/2.78Mâ€‡[00:00&lt;00:00,â€‡7.66MB/s]"
     }
    },
    "b72d23e8d05449a8bf8a7511ada49704": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b74e4e5971684b00b40ca42cf2aebb9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6769817deaaf45fc8a0efb945570f412",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d7465d2830f64de996d4d3a306b97c82",
      "value": "model-00003-of-00003.safetensors:â€‡100%"
     }
    },
    "b8c184cdaa6b4d72ad28a604d1a8fa39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_179e343762ba440cbc094e0e85b4ee84",
       "IPY_MODEL_ecd44b2e03794d5783ffbf07d8b8619f",
       "IPY_MODEL_28d439d23bf54688963517fbdb482339"
      ],
      "layout": "IPY_MODEL_7e7ac790b8af4cfb978bfe8ac8499900"
     }
    },
    "b998e55dd17b44d7a8c23ac427619036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a09813436c24b5ea68e652254288ee0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a469a1af99124ff6974265f45563deea",
      "value": "model-00002-of-00003.safetensors:â€‡100%"
     }
    },
    "bc1b4decb2154b8fb66347408d419ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e3384d811f94fb9a2d065ffdffaf731",
      "max": 603,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca410b0da67a466abd7c94ebd0762872",
      "value": 603
     }
    },
    "bc277d60ad4a419a94ded28a1c27a9f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bce369933ce540d7b6ec670b04d7f1a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf94cc1837ba486b895656b41c1e9c99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2d8db7e564a40499d58f0d9c11b01a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c37a4b08afa84b64b40ebbe08cbfb018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3887400b6d34c30a54c6af94c2b612d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c6caf15c5de4a2fb699d034a6ab776c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ebe9490475bc437c92ebc03187e53382",
      "value": "model.safetensors.index.json:â€‡100%"
     }
    },
    "c519c7b69d70467c875a3d228e6b6fd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f85353b1b37342859c9aa71442781e95",
      "max": 614,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73d6e9b4704f40aab25fecd24154f9bc",
      "value": 614
     }
    },
    "c6514d1ee44141d3bf83fde032d39a46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c688c828118f41859a3d71c54b62354a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c89e5721ed7e48b295ccc74b841ec61e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8faa5be5b88425298b5655a8f507a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca410b0da67a466abd7c94ebd0762872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc9479fb190742fd865613680e87e535": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7ae6535329c45009bf5664fbd30bbf5",
      "max": 4974351586,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e112f4ad6974529a4c4f583e6a73950",
      "value": 4974351112
     }
    },
    "cd8774e4577a4652863469d3cb75f2ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2167f3dc7050467a9f19f3f885cfb09b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_569ad7b2350d46549b2f385a126426d5",
      "value": "â€‡614/614â€‡[00:00&lt;00:00,â€‡37.3kB/s]"
     }
    },
    "cde3541ff2444f55a1651b8992e53da1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce05df3e26834837b2db818657a9d175": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63abaade8f464ed6bbd51d77014dfe66",
      "max": 2776833,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef69f52b4c7a485b8708f171bb6acbd6",
      "value": 2776833
     }
    },
    "d127b4248d7e4114a38df6961b0f28c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dcb04c84d5854f878555a92bcda62550",
       "IPY_MODEL_644f70a125854e418fbb8469d287edd2",
       "IPY_MODEL_65fa509db52047b791159e65ce9108a4"
      ],
      "layout": "IPY_MODEL_50524c8582eb4814a598654901c35a82"
     }
    },
    "d1b000b08af549689d1be5f0289bf2c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3da0aa9fb884983b6554f3563b05eeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4b3982b73d046478f7c9b561ed42298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7465d2830f64de996d4d3a306b97c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d760efb7d31a4bbbb29c7af2478e1cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7ae6535329c45009bf5664fbd30bbf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7afd9c01f68473387f009b05d829b3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9c143d31e494981b188be41bd52118f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67a67c8affbe4ec38f99cbb0a3c52dcc",
       "IPY_MODEL_0d0852d9ebb2409ea51650f538dd1621",
       "IPY_MODEL_904f626a367745979ac664f4d2ea6409"
      ],
      "layout": "IPY_MODEL_e0260495036b406fbf462b3c387205d2"
     }
    },
    "d9dcda48a37e41f7808a933cfd939ded": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68cbb7211b448c78cd418a90b908037",
      "max": 1555824768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb052cc7147d474597529c462497b731",
      "value": 1555824620
     }
    },
    "daa8753d49d7458cab39dd1524b20356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db172381abdf4bb0a84417882fc462be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcb04c84d5854f878555a92bcda62550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f6ddb6a1c264fc79f907c54078bb769",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a9e3708d145c4bedaa07e5347019fd01",
      "value": "train-00000-of-00001.parquet:â€‡100%"
     }
    },
    "dcffa04c1de94d3691a14d10df2ee24b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd1b79ecec114d28ace8c1b8b1fd4d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2adf3e30304398b8340253dbd4489a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de968455db9840f09ced1a8443f4beae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df721834c3de4656909069aed0670d36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0260495036b406fbf462b3c387205d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0969d7420e541229f1e0a9de683c367": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e17016c458a14736bd56ba55d7168f32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3ecd73a9b86479e8596d8bb1ef5791d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_911bd3f394ce4394be92e50782d6ae39",
       "IPY_MODEL_ce05df3e26834837b2db818657a9d175",
       "IPY_MODEL_b25399bf6ae4414ba2836733f59e4ab0"
      ],
      "layout": "IPY_MODEL_a81ef4374fde4d10a1cdc5daeec34dda"
     }
    },
    "e84a5ae6c71d42ea8187ebbdcdb4791e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e976be66ed774ce880463df39d0c25ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea7c149f9c274f8a94970880d99edbab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7078409a02740cbbd6d59b61a4a8c6b",
       "IPY_MODEL_528e29551b7a4f77aed08c653e49ee57",
       "IPY_MODEL_153259764d2b45e0bc02938d6909d40a"
      ],
      "layout": "IPY_MODEL_9c35626d415d4468a30e0513cc7a5234"
     }
    },
    "eb052cc7147d474597529c462497b731": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ebe9490475bc437c92ebc03187e53382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecd44b2e03794d5783ffbf07d8b8619f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2de7e147b2e14db38243c7656a29f0e4",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bce369933ce540d7b6ec670b04d7f1a4",
      "value": 3
     }
    },
    "eeb29e4ed2ae401f9d21cbe941d6cb1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12d7229f7d81488e93689d4269ee48ac",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d3da0aa9fb884983b6554f3563b05eeb",
      "value": "â€‡982/982â€‡[00:00&lt;00:00,â€‡27.1kB/s]"
     }
    },
    "eed62b35a7974086b8d27d9c3e459a91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef69f52b4c7a485b8708f171bb6acbd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0b8a9e00c0d4cc1aff1e3a748a8f039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1af17f7a7ee405dabd07f41b6b786d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b19bb0b66b248fdbcd01b6264e2ff02",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_689f645af24947e8920b631d2aa7c3ad",
      "value": "â€‡1.67M/1.67Mâ€‡[00:00&lt;00:00,â€‡11.7MB/s]"
     }
    },
    "f34c9b4f069f4fb281f4e0145f0e818e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3cb03ec368f40fb965beb086b78fb78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a48262b1d98a427ab79d589907521d88",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_de968455db9840f09ced1a8443f4beae",
      "value": "README.md:â€‡100%"
     }
    },
    "f7c27321d53047479c1ed45b5d5109f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f85353b1b37342859c9aa71442781e95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f89daea726144ded892113a161649b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6303ec778b1d49dd980542a191261961",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5d66a72e82e54d9e8367ca8a2469dd0a",
      "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=2):â€‡100%"
     }
    },
    "f8f15be1afc44472bff560ca7316873a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa8721e596b74611945a1d76e9deff8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb2ce6370b1d4d5d9dbdb98aa236da71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb6f38d9dd1e49ec8fdfb7ca7ea363a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcd0ee642395431e92a681ba8d829b20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ddcfbdbb0fc49b0b53a296cdb2348b8",
      "max": 11422654,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b72ac21d79c459395682f6692c4325f",
      "value": 11422654
     }
    },
    "fea4c81baaf84d9b806c1853216c89e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
