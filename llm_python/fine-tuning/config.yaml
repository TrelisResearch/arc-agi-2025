# Fine-tuning configuration for ARC-AGI model
# This file can be modified for different experiment runs

# Test mode - set to true for quick test runs with only 128 rows of data.
test_run: false

# Data source configuration
data:
  # Dataset source: "huggingface" or "parquet"  
  # If source is "parquet", will load from parquet files
  source: "huggingface"  # can be overridden by DATA_SOURCE env variable
  # source: "parquet"  # can be overridden by DATA_SOURCE env variable
  
  # Parquet configuration (used when source is "parquet")
  parquet:
    path: "../datasets/"  # overridden by ARC_PROGRAMS_PARQUET env variable if set
    # Filter for non-transductive programs (when loading from parquet)
    filters:
      is_transductive: false  # Only load non-transductive programs for fine-tuning
      
  # # HuggingFace dataset (used when source is "huggingface" and dataset_slug is provided)
  dataset_slug: "Trelis/arc-agi-2-reasoning-5"

# Execution mode - controls checkpoint behavior
# "full": save all intermediate checkpoints and optionally push to hub (controlled by PUSH_TO_HUB)
# "final_only": only save and merge final checkpoint (TTT mode) and optionally push (controlled by PUSH_TO_HUB)
# execution_mode: "final_only"  # overridden by FINE_TUNING_MODE env variable
execution_mode: "full"  # overridden by FINE_TUNING_MODE env variable

# Hub pushing configuration
# Controls whether models are pushed to HuggingFace Hub after saving locally
# push_to_hub: true  # overridden by PUSH_TO_HUB env variable
push_to_hub: true  # overridden by PUSH_TO_HUB env variable (false on Kaggle, true elsewhere)

# Model configuration
model:
  # slug: "Qwen/Qwen3-4B"
  # slug: "Qwen/Qwen3-8B"
  # slug: "unsloth/gpt-oss-20b-BF16"
  slug: "unsloth/gpt-oss-20b"
  # slug: "Qwen/Qwen3-4B-Thinking-2507"

  # Alternative models:
  # slug: "Trelis/Qwen3-4B_ds-arc-agi-2-partial-100-c2806"
  # slug: "julien31/Soar-qwen-7b"
  # slug: "Qwen/Qwen2.5-Coder-7B-Instruct"
  # slug: "Qwen/Qwen3-30B-A3B"
  # slug: "Qwen/Qwen3-Coder-30B-A3B-Instruct"  # overridden by MODEL_SLUG env variable if set

  train_in_4bit: true
  
  max_length: 32768  # Max eval set ~19,400 tokens + headroom
  lora_rank: 32

# Training configuration
training:
  use_unsloth: true
  do_eval: false
  multi_gpu: false  # Set to true to use multi-gpu training, NOT YET SUPPORTED!
  batch_size_global: 4 # Per-device batch size (effective batch size will be 32, grad accum will be set based on number of GPUs, if using multi-gpu training)
  max_rows: null  # Set to integer to limit training data, null for all
  enable_thinking: true  # Must set true to include thinking traces

# Override max_rows when in test mode
overrides:
  test_run_max_rows: 32  # 32*4 rows for test runs