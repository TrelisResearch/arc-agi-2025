{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c913ef65",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-14T19:17:30.008793Z",
     "iopub.status.busy": "2025-09-14T19:17:30.008490Z",
     "iopub.status.idle": "2025-09-14T19:17:30.039704Z",
     "shell.execute_reply": "2025-09-14T19:17:30.038968Z"
    },
    "papermill": {
     "duration": 0.037384,
     "end_time": "2025-09-14T19:17:30.040804",
     "exception": false,
     "start_time": "2025-09-14T19:17:30.003420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Searching for models in Kaggle environment...\n",
      "   Looking for initial model dataset: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset\n",
      "   âœ… Found initial model at: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "      Contents: ['model.safetensors.index.json', 'model-00003-of-00004.safetensors', 'config.json', 'merges.txt', '.cache']\n",
      "   Looking for refinement base dataset: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset\n",
      "   âœ… Found refinement base at: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "      Contents: ['model.safetensors.index.json', 'model-00003-of-00004.safetensors', 'config.json', 'merges.txt', '.cache']\n",
      "\n",
      "ðŸ“¦ Final model paths:\n",
      "   Initial model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "   Refinement base: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "ðŸ”§ Development run â€” setting short 412s timeout for testing\n",
      "ðŸ§ª ENABLE_REFINEMENT ENABLED\n",
      "   â†’ Will run: First inference â†’ Second inference\n",
      "   â†’ First inference: 4 attempts, 64 workers\n",
      "   â†’ Second inference: 4 attempts, 64 workers\n",
      "Mode summary â†’ IS_KAGGLE=True | IS_RERUN=False | ENABLE_REFINEMENT=True |\n",
      "TEST_INFERENCE=True | SCORE=True | SUBMIT=true | INITIAL_MODEL=/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic | REFINEMENT_MODEL=/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# Model Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# # Model for initial inference (path for Kaggle, slug for local/RunPod)\n",
    "INITIAL_MODEL_HF = \"Trelis/Soar-qwen-14b-FP8-Dynamic\"  # For local/RunPod\n",
    "INITIAL_MODEL_KAGGLE = \"arc-1-fake-ttt-blended-c802-dataset\"  # Kaggle dataset name\n",
    "\n",
    "# # Model for Refinement\n",
    "REFINEMENT_MODEL_HF = \"Trelis/Soar-qwen-14b-FP8-Dynamic\"  # For local/RunPod\n",
    "REFINEMENT_MODEL_KAGGLE = \"arc-1-fake-ttt-blended-c802-dataset\"  # Kaggle dataset name\n",
    "\n",
    "# ============================================================================\n",
    "# Inference Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Test Attempts (used for first and second/refinement)\n",
    "TEST_ATTEMPTS = 4\n",
    "KAGGLE_TIMEOUT = 3600*11 # Allow only 11 hours for inference, one hour buffer. NOT USED AT PRESENT!\n",
    "\n",
    "# First inference settings\n",
    "FIRST_ATTEMPTS = 128     # Number of attempts for first inference\n",
    "FIRST_WORKERS = 64       # Number of workers for first inference\n",
    "\n",
    "# Second inference settings\n",
    "SECOND_ATTEMPTS = 64     # Number of attempts for second inference\n",
    "SECOND_WORKERS = 64      # Number of workers for second inference\n",
    "\n",
    "# ============================================================================\n",
    "# Other Configuration\n",
    "# ============================================================================\n",
    "\n",
    "DATASET = \"arc-prize-2025\"\n",
    "\n",
    "# ---- Config flags (single source of truth) ----\n",
    "START_SERVER = True\n",
    "TEST_INFERENCE = True\n",
    "SCORE = True                   # default; overridden below, depending on flags\n",
    "\n",
    "# Refinement mode?\n",
    "ENABLE_REFINEMENT=True\n",
    "\n",
    "# Env-backed flags\n",
    "IS_KAGGLE = bool(os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"))\n",
    "IS_RERUN  = IS_KAGGLE and os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\", \"\").lower() == \"true\"\n",
    "\n",
    "# String env flag for external tools\n",
    "os.environ[\"SUBMIT\"] = \"true\"\n",
    "\n",
    "# ---- Paths ----\n",
    "if IS_KAGGLE:\n",
    "    ARC_DATA_ROOT   = Path(\"/kaggle/input\")\n",
    "    MODEL_SAVE_DIR = Path(\"/kaggle/working\")\n",
    "    SUBMIT_DIR      = Path(\"/kaggle/working\")\n",
    "    ARC_PROGRAMS_PARQUET = SUBMIT_DIR\n",
    "\n",
    "    print(\"ðŸ” Searching for models in Kaggle environment...\")\n",
    "\n",
    "    # Auto-find initial model path in Kaggle's dataset structure\n",
    "    model_dataset_path = ARC_DATA_ROOT / INITIAL_MODEL_KAGGLE\n",
    "    print(f\"   Looking for initial model dataset: {model_dataset_path}\")\n",
    "\n",
    "    if model_dataset_path.exists() and model_dataset_path.is_dir():\n",
    "        # Kaggle datasets have version folders, find the first subdirectory\n",
    "        subdirs = [d for d in model_dataset_path.iterdir() if d.is_dir()]\n",
    "        if subdirs:\n",
    "            MODEL_PATH = subdirs[0]  # Use the first (usually only) version folder\n",
    "            print(f\"   âœ… Found initial model at: {MODEL_PATH}\")\n",
    "            # List what's inside to confirm it's right\n",
    "            model_contents = list(MODEL_PATH.iterdir())[:5]  # Show first 5 items\n",
    "            print(f\"      Contents: {[f.name for f in model_contents]}\")\n",
    "        else:\n",
    "            # Fallback if no subdirectory found\n",
    "            MODEL_PATH = model_dataset_path\n",
    "            print(f\"   âš ï¸ No version folder found for initial model, using: {MODEL_PATH}\")\n",
    "    else:\n",
    "        MODEL_PATH = model_dataset_path\n",
    "        print(f\"   âŒ Initial model dataset not found at: {MODEL_PATH}\")\n",
    "        print(f\"      Available datasets: {[d.name for d in ARC_DATA_ROOT.iterdir() if d.is_dir()][:10]}\")\n",
    "\n",
    "    # Auto-find refinement base model path\n",
    "    refinement_dataset_path = ARC_DATA_ROOT / REFINEMENT_MODEL_KAGGLE\n",
    "    print(f\"   Looking for refinement base dataset: {refinement_dataset_path}\")\n",
    "\n",
    "    if refinement_dataset_path.exists() and refinement_dataset_path.is_dir():\n",
    "        subdirs = [d for d in refinement_dataset_path.iterdir() if d.is_dir()]\n",
    "        if subdirs:\n",
    "            REFINEMENT_MODEL_PATH = subdirs[0]\n",
    "            print(f\"   âœ… Found refinement base at: {REFINEMENT_MODEL_PATH}\")\n",
    "            # List what's inside to confirm it's right\n",
    "            finetune_contents = list(REFINEMENT_MODEL_PATH.iterdir())[:5]  # Show first 5 items\n",
    "            print(f\"      Contents: {[f.name for f in finetune_contents]}\")\n",
    "        else:\n",
    "            REFINEMENT_MODEL_PATH = refinement_dataset_path\n",
    "            print(f\"   âš ï¸ No version folder found for refinement base, using: {REFINEMENT_MODEL_PATH}\")\n",
    "    else:\n",
    "        REFINEMENT_MODEL_PATH = refinement_dataset_path\n",
    "        print(f\"   âŒ Refinement base dataset not found at: {REFINEMENT_MODEL_PATH}\")\n",
    "\n",
    "    print(f\"\\nðŸ“¦ Final model paths:\")\n",
    "    print(f\"   Initial model: {MODEL_PATH}\")\n",
    "    print(f\"   Refinement base: {REFINEMENT_MODEL_PATH}\")\n",
    "\n",
    "else:\n",
    "    ARC_DATA_ROOT   = Path(\"/workspace/arc-agi-2025/data\")\n",
    "    MODEL_SAVE_DIR = Path(\"/workspace/arc-agi-2025/llm_python/fine-tuning\")\n",
    "    SUBMIT_DIR      = Path(\"/workspace/arc-agi-2025/llm_python/submissions\")\n",
    "    ARC_PROGRAMS_PARQUET = Path(\"/workspace/arc-agi-2025/llm_python/datasets/inference\")\n",
    "\n",
    "    # Use local/RunPod model paths\n",
    "    MODEL_PATH = INITIAL_MODEL_HF\n",
    "    REFINEMENT_MODEL_PATH = REFINEMENT_MODEL_HF\n",
    "\n",
    "    print(f\"ðŸ“¦ Local/RunPod model paths:\")\n",
    "    print(f\"   Initial model: {MODEL_PATH}\")\n",
    "    print(f\"   Refinement base: {REFINEMENT_MODEL_PATH}\")\n",
    "\n",
    "# Set up paths - parquet files are saved by task runner in different locations\n",
    "if IS_KAGGLE:\n",
    "    # On Kaggle, parquet files are saved directly in /kaggle/working by task runner\n",
    "    inference_dir = \"/kaggle/working\"\n",
    "else:\n",
    "    # On RunPod/local, parquet files are saved in llm_python/datasets/inference\n",
    "    inference_dir = \"llm_python/datasets/inference\"\n",
    "\n",
    "# Export envs for downstream processes\n",
    "os.environ[\"ARC_DATA_ROOT\"]   = str(ARC_DATA_ROOT)\n",
    "os.environ[\"MODEL_SAVE_DIR\"] = str(MODEL_SAVE_DIR)\n",
    "os.environ[\"SUBMIT_DIR\"]      = str(SUBMIT_DIR)\n",
    "os.environ[\"ARC_PROGRAMS_PARQUET\"] = str(ARC_PROGRAMS_PARQUET)\n",
    "os.environ[\"MODEL_PATH\"] = str(MODEL_PATH)\n",
    "\n",
    "# Export config flags for subprocess use\n",
    "os.environ[\"IS_KAGGLE\"] = str(IS_KAGGLE).lower()\n",
    "os.environ[\"IS_RERUN\"] = str(IS_RERUN).lower()\n",
    "os.environ[\"DATASET\"] = DATASET\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in (MODEL_SAVE_DIR, SUBMIT_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if IS_RERUN:\n",
    "    # Kaggle competition rerun\n",
    "    timeout_seconds = KAGGLE_TIMEOUT\n",
    "    print(f\"ðŸ† Competition rerun detected â€” setting FULL {timeout_seconds}s timeout for all inference\")\n",
    "    SCORE = False\n",
    "    os.environ[\"SUBMIT\"] = \"true\"\n",
    "\n",
    "elif not IS_KAGGLE:\n",
    "    # Runpod / local long run\n",
    "    timeout_seconds = None\n",
    "    print(f\"ðŸ–¥ï¸ Runpod/local long run â€” setting no timeout for inference\")\n",
    "    if os.getenv(\"SUBMIT\", \"false\").lower() == \"true\":\n",
    "        SCORE = True  # if we're generating a submission, do scoring\n",
    "\n",
    "else:\n",
    "    # Kaggle dev/testing\n",
    "    timeout_seconds = int(KAGGLE_TIMEOUT * TEST_ATTEMPTS / (2 * (FIRST_ATTEMPTS + SECOND_ATTEMPTS)))   # 1 minute\n",
    "    print(f\"ðŸ”§ Development run â€” setting short {timeout_seconds}s timeout for testing\")\n",
    "    # Safer default: don't auto-submit in dev\n",
    "    os.environ[\"SUBMIT\"] = \"true\"\n",
    "    FIRST_ATTEMPTS = TEST_ATTEMPTS\n",
    "    SECOND_ATTEMPTS = TEST_ATTEMPTS\n",
    "\n",
    "# ENABLE_REFINEMENT Mode configuration\n",
    "if ENABLE_REFINEMENT:\n",
    "    print(\"ðŸ§ª ENABLE_REFINEMENT ENABLED\")\n",
    "    print(\"   â†’ Will run: First inference â†’ Second inference\")\n",
    "    print(f\"   â†’ First inference: {FIRST_ATTEMPTS} attempts, {FIRST_WORKERS} workers\")\n",
    "    print(f\"   â†’ Second inference: {SECOND_ATTEMPTS} attempts, {SECOND_WORKERS} workers\")\n",
    "else:\n",
    "    print(\"ðŸ”„ Standard mode (ENABLE_REFINEMENT disabled)\")\n",
    "    print(f\"   â†’ Will run: First inference only ({FIRST_ATTEMPTS} attempts, {FIRST_WORKERS} workers)\")\n",
    "\n",
    "# Optional: quick summary (helps avoid accidental submits)\n",
    "print(\n",
    "    \"Mode summary â†’ \"\n",
    "    f\"IS_KAGGLE={IS_KAGGLE} | IS_RERUN={IS_RERUN} | ENABLE_REFINEMENT={ENABLE_REFINEMENT} |\\n\"\n",
    "    f\"TEST_INFERENCE={TEST_INFERENCE} | SCORE={SCORE} | SUBMIT={os.environ['SUBMIT']} | INITIAL_MODEL={MODEL_PATH} | REFINEMENT_MODEL={REFINEMENT_MODEL_PATH}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b850b6de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:17:30.048372Z",
     "iopub.status.busy": "2025-09-14T19:17:30.048051Z",
     "iopub.status.idle": "2025-09-14T19:17:42.941791Z",
     "shell.execute_reply": "2025-09-14T19:17:42.941069Z"
    },
    "papermill": {
     "duration": 12.898677,
     "end_time": "2025-09-14T19:17:42.942988",
     "exception": false,
     "start_time": "2025-09-14T19:17:30.044311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA version (PyTorch): 12.8\n",
      "CUDA available: True\n",
      "NumPy version: 1.26.4\n",
      "GPU count: 4\n",
      "GPU name: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version (PyTorch): {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "   print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "   print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eadcf6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:17:42.951278Z",
     "iopub.status.busy": "2025-09-14T19:17:42.950661Z",
     "iopub.status.idle": "2025-09-14T19:17:46.499919Z",
     "shell.execute_reply": "2025-09-14T19:17:46.499247Z"
    },
    "papermill": {
     "duration": 3.554569,
     "end_time": "2025-09-14T19:17:46.501106",
     "exception": false,
     "start_time": "2025-09-14T19:17:42.946537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang version: 0.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 19:17:45.830000 19 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W0914 19:17:45.830000 19 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashInfer version: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "import sglang\n",
    "print(\"SGLang version:\", sglang.__version__)\n",
    "\n",
    "try:\n",
    "    import flashinfer\n",
    "    print(\"FlashInfer version:\", flashinfer.__version__)\n",
    "except ImportError:\n",
    "    print(\"FlashInfer not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6fe90b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:17:46.509427Z",
     "iopub.status.busy": "2025-09-14T19:17:46.508921Z",
     "iopub.status.idle": "2025-09-14T19:17:47.227165Z",
     "shell.execute_reply": "2025-09-14T19:17:47.226432Z"
    },
    "papermill": {
     "duration": 0.723513,
     "end_time": "2025-09-14T19:17:47.228354",
     "exception": false,
     "start_time": "2025-09-14T19:17:46.504841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptxas -> ptxas: NVIDIA (R) Ptx optimizing assembler\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_02:14:54_PDT_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n"
     ]
    }
   ],
   "source": [
    "if IS_KAGGLE:\n",
    "    import os, shutil, subprocess, stat\n",
    "    \n",
    "    # 1) Where to place binaries + cache\n",
    "    WRK_BIN = \"/kaggle/working/bin\"\n",
    "    TRITON_CACHE = \"/kaggle/working/.triton\"\n",
    "    os.makedirs(WRK_BIN, exist_ok=True)\n",
    "    os.makedirs(TRITON_CACHE, exist_ok=True)\n",
    "    \n",
    "    # 2) Preferred source for ptxas/cuobjdump/nvdisasm\n",
    "    SYSTEM_CUDA_BIN = \"/usr/local/cuda/bin\"\n",
    "    FALLBACK_VENDORED = \"/kaggle/usr/lib/sglang_utility/triton/backends/nvidia/bin\"  # if you have it\n",
    "    \n",
    "    def copy_tool(name: str):\n",
    "        for src_dir in (SYSTEM_CUDA_BIN, FALLBACK_VENDORED):\n",
    "            src = os.path.join(src_dir, name)\n",
    "            if os.path.exists(src):\n",
    "                dst = os.path.join(WRK_BIN, name)\n",
    "                shutil.copy2(src, dst)\n",
    "                # ensure executable bit\n",
    "                os.chmod(dst, os.stat(dst).st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n",
    "                return dst\n",
    "        raise FileNotFoundError(f\"Could not find {name} in {SYSTEM_CUDA_BIN} or {FALLBACK_VENDORED}\")\n",
    "    \n",
    "    ptxas_path = copy_tool(\"ptxas\")\n",
    "    try:\n",
    "        cuobjdump_path = copy_tool(\"cuobjdump\")\n",
    "    except FileNotFoundError:\n",
    "        cuobjdump_path = None  # optional\n",
    "    try:\n",
    "        nvdisasm_path = copy_tool(\"nvdisasm\")\n",
    "    except FileNotFoundError:\n",
    "        nvdisasm_path = None  # optional\n",
    "    \n",
    "    # 3) Environment for Triton/JIT\n",
    "    os.environ[\"TRITON_PTXAS_PATH\"] = ptxas_path\n",
    "    os.environ[\"PATH\"] = f\"{WRK_BIN}:{os.environ.get('PATH','')}\"\n",
    "    os.environ[\"TRITON_CACHE_DIR\"] = TRITON_CACHE\n",
    "    os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n",
    "    os.environ[\"CUDA_PATH\"] = \"/usr/local/cuda\"\n",
    "    \n",
    "    # Helpful fallbacks if you still hit capture issues:\n",
    "    # os.environ[\"SGLANG_DISABLE_CUDA_GRAPH\"] = \"1\"      # skip CUDA graphs (degrades perf but avoids capture)\n",
    "    # os.environ[\"TRITON_CODEGEN_FATBIN\"] = \"0\"          # can reduce Triton fatbin steps on some setups\n",
    "    \n",
    "    # 4) Smoke test: ensure ptxas runs from the new location\n",
    "    print(\"ptxas ->\", subprocess.check_output([ptxas_path, \"--version\"]).decode().strip())\n",
    "    \n",
    "    # Now it's safe to import heavy libs that trigger Triton\n",
    "    import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fc3ab",
   "metadata": {
    "papermill": {
     "duration": 0.003372,
     "end_time": "2025-09-14T19:17:47.235475",
     "exception": false,
     "start_time": "2025-09-14T19:17:47.232103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53b2fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:17:47.244495Z",
     "iopub.status.busy": "2025-09-14T19:17:47.244295Z",
     "iopub.status.idle": "2025-09-14T19:20:47.864953Z",
     "shell.execute_reply": "2025-09-14T19:20:47.864239Z"
    },
    "papermill": {
     "duration": 180.6259,
     "end_time": "2025-09-14T19:20:47.865965",
     "exception": false,
     "start_time": "2025-09-14T19:17:47.240065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory cleared.\n",
      "ðŸ”§ Using model from /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "LOG file path: /kaggle/working/sglang_server.log\n",
      "Started sglang server PID=42 | logging to /kaggle/working/sglang_server.log\n",
      "Command: /usr/bin/python3 -m sglang.launch_server --host 0.0.0.0 --port 8080 --model-path /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic --dp 4 --kv-cache-dtype fp8_e4m3 --enable-metrics\n",
      "sglang not ready after timeout. Showing last 60 log lines:\n",
      "2025-09-14 19:18:20.041544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1757877500.300974      42 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1757877500.379904      42 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0914 19:18:53.427000 42 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "W0914 19:18:53.427000 42 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\r\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\r\n",
      "[2025-09-14 19:18:55] server_args=ServerArgs(model_path='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic', tokenizer_path='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=8080, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='fp8_e4m3', mem_fraction_static=0.871, max_running_requests=None, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=2048, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=108688317, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=4, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)\r\n",
      "[2025-09-14 19:18:56] Using default HuggingFace chat template with detected content format: string\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1757877559.252467     112 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1757877559.252627     113 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1757877559.261447     112 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1757877559.261553     113 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0914 19:20:01.946000 113 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "W0914 19:20:01.946000 113 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\r\n",
      "W0914 19:20:01.966000 112 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "W0914 19:20:01.966000 112 arc_agi_2025_aux_rewrite_refine/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\r\n",
      "Call stop_server() or full_cleanup() to shut it down gracefully.\n"
     ]
    }
   ],
   "source": [
    "if START_SERVER:\n",
    "  # Background server launcher for Kaggle with SGLang\n",
    "  import os, sys, time, subprocess, json, socket, requests\n",
    "\n",
    "  # ---------- 1) Check for existing server and cleanup ----------\n",
    "  PORT = 8080\n",
    "  HEALTH_URL = f\"http://127.0.0.1:{PORT}/v1/models\"\n",
    "\n",
    "  # Check if server already running\n",
    "  try:\n",
    "      r = requests.get(HEALTH_URL, timeout=3)\n",
    "      if r.status_code == 200:\n",
    "          print(f\"Server already running on port {PORT}. Stopping it first...\")\n",
    "          # Kill existing sglang processes\n",
    "          subprocess.run([\"pkill\", \"-f\", \"sglang.launch_server\"], capture_output=True)\n",
    "          time.sleep(3)  # Wait for cleanup\n",
    "  except:\n",
    "      pass  # No server running\n",
    "\n",
    "  # Clear CUDA memory before starting\n",
    "  try:\n",
    "      import torch\n",
    "      if torch.cuda.is_available():\n",
    "          torch.cuda.empty_cache()\n",
    "          torch.cuda.synchronize()\n",
    "          print(\"CUDA memory cleared.\")\n",
    "      num_gpus = torch.cuda.device_count()\n",
    "  except Exception:\n",
    "      num_gpus = 0\n",
    "      \n",
    "  model_path_to_use = str(MODEL_PATH)\n",
    "  print(f\"ðŸ”§ Using model from {model_path_to_use}\")\n",
    "\n",
    "  LOG = f\"{SUBMIT_DIR}/sglang_server.log\"\n",
    "  print(f\"LOG file path: {LOG}\")\n",
    "\n",
    "  SERVER_CMD = [\n",
    "      sys.executable, \"-m\", \"sglang.launch_server\",\n",
    "      \"--host\", \"0.0.0.0\",\n",
    "      \"--port\", str(PORT),\n",
    "      \"--model-path\", model_path_to_use,\n",
    "      \"--dp\", str(max(1, min(num_gpus, 4))),\n",
    "      \"--kv-cache-dtype\", \"fp8_e4m3\",\n",
    "      \"--enable-metrics\",\n",
    "  ]\n",
    "\n",
    "  # ---------- 2) Launch in background ----------\n",
    "  log_f = open(LOG, \"w\")\n",
    "  env = os.environ.copy()\n",
    "  proc = subprocess.Popen(SERVER_CMD, stdout=log_f, stderr=subprocess.STDOUT, env=env, cwd=SUBMIT_DIR)\n",
    "  print(f\"Started sglang server PID={proc.pid} | logging to {LOG}\")\n",
    "  print(\"Command:\", \" \".join(SERVER_CMD))\n",
    "\n",
    "  # ---------- 3) Wait for readiness ----------\n",
    "  def wait_ready(url, timeout_s=180):\n",
    "      t0 = time.time()\n",
    "      while time.time() - t0 < timeout_s:\n",
    "          try:\n",
    "              r = requests.get(url, timeout=3)\n",
    "              if r.status_code == 200:\n",
    "                  return True\n",
    "          except Exception:\n",
    "              pass\n",
    "          time.sleep(2)\n",
    "      return False\n",
    "\n",
    "  ready = wait_ready(HEALTH_URL)\n",
    "  log_f.flush()\n",
    "\n",
    "  if ready:\n",
    "      print(f\"sglang is READY on port {PORT}.\")\n",
    "      print(f\"- Tail logs: !tail -n 50 {LOG}\")\n",
    "      print(f\"- List models: !curl -s http://127.0.0.1:{PORT}/v1/models | jq .\")\n",
    "  else:\n",
    "      print(f\"sglang not ready after timeout. Showing last 60 log lines:\")\n",
    "      log_f.close()\n",
    "      !tail -n 60 {LOG}\n",
    "\n",
    "  # ---------- 4) Cleanup functions ----------\n",
    "  def stop_server(p=proc):\n",
    "      try:\n",
    "          p.terminate()\n",
    "          p.wait(timeout=10)\n",
    "      except Exception:\n",
    "          p.kill()\n",
    "      print(\"Server stopped.\")\n",
    "\n",
    "  def full_cleanup(p=proc):\n",
    "      # Stop server\n",
    "      try:\n",
    "          p.terminate()\n",
    "          p.wait(timeout=10)\n",
    "      except Exception:\n",
    "          p.kill()\n",
    "\n",
    "      # Also kill any lingering sglang processes\n",
    "      subprocess.run([\"pkill\", \"-f\", \"sglang.launch_server\"], capture_output=True)\n",
    "\n",
    "      # Clear CUDA memory\n",
    "      try:\n",
    "          import torch\n",
    "          if torch.cuda.is_available():\n",
    "              torch.cuda.empty_cache()\n",
    "              torch.cuda.synchronize()\n",
    "      except:\n",
    "          pass\n",
    "\n",
    "      print(\"Server stopped and CUDA memory cleared.\")\n",
    "\n",
    "  print(\"Call stop_server() or full_cleanup() to shut it down gracefully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf3bfed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:20:47.874396Z",
     "iopub.status.busy": "2025-09-14T19:20:47.874177Z",
     "iopub.status.idle": "2025-09-14T19:26:47.908692Z",
     "shell.execute_reply": "2025-09-14T19:26:47.907991Z"
    },
    "papermill": {
     "duration": 360.039986,
     "end_time": "2025-09-14T19:26:47.909828",
     "exception": false,
     "start_time": "2025-09-14T19:20:47.869842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âŒ Connection failed - server may not be ready yet\n",
      "â³ Waiting 30 seconds before retrying...\n",
      "âœ… Server is responding!\n",
      "Available models:\n",
      "  - /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "\n",
      "âœ… Found model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n"
     ]
    }
   ],
   "source": [
    "if START_SERVER:\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    def check_models():\n",
    "        url = \"http://127.0.0.1:8080/v1/models\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "    \n",
    "            print(\"âœ… Server is responding!\")\n",
    "            print(\"Available models:\")\n",
    "            for model in result['data']:\n",
    "                print(f\"  - {model['id']}\")\n",
    "    \n",
    "            return result['data'][0]['id'] if result['data'] else None\n",
    "    \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"âŒ Connection failed - server may not be ready yet\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Poll every 30 seconds until we get a model\n",
    "    model_name = None\n",
    "    while not model_name:\n",
    "        model_name = check_models()\n",
    "        if not model_name:\n",
    "            print(\"â³ Waiting 30 seconds before retrying...\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    print(f\"\\nâœ… Found model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f39f6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:26:47.920042Z",
     "iopub.status.busy": "2025-09-14T19:26:47.919737Z",
     "iopub.status.idle": "2025-09-14T19:26:58.024214Z",
     "shell.execute_reply": "2025-09-14T19:26:58.023508Z"
    },
    "papermill": {
     "duration": 10.111292,
     "end_time": "2025-09-14T19:26:58.025629",
     "exception": false,
     "start_time": "2025-09-14T19:26:47.914337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Response received:\n",
      "```python\n",
      "def transform(grid):\n",
      "    transformed_grid\n",
      "\n",
      "â± Elapsed time: 10.09 seconds\n",
      "ðŸ”¢ Estimated tokens: 12.8\n",
      "âš¡ Output tokens/sec: 1.26\n"
     ]
    }
   ],
   "source": [
    "if TEST_INFERENCE:\n",
    "    import time\n",
    "    import requests\n",
    "    \n",
    "    url = \"http://127.0.0.1:8080/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation  \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\n```python\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n```\\n\"}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,  # from your polling loop\n",
    "        \"messages\": messages,\n",
    "        # \"max_tokens\": 1000\n",
    "        \"max_tokens\": 10\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers=headers, json=payload, timeout=600)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    output_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Estimate token count (4 chars/token assumption)\n",
    "    estimated_tokens = len(output_text) / 4\n",
    "    elapsed_time = end_time - start_time\n",
    "    tokens_per_second = estimated_tokens / elapsed_time\n",
    "    \n",
    "    print(\"âœ… Response received:\")\n",
    "    print(output_text)\n",
    "    print(f\"\\nâ± Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"ðŸ”¢ Estimated tokens: {estimated_tokens:.1f}\")\n",
    "    print(f\"âš¡ Output tokens/sec: {tokens_per_second:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e45eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:26:58.043681Z",
     "iopub.status.busy": "2025-09-14T19:26:58.043362Z",
     "iopub.status.idle": "2025-09-14T19:35:43.511721Z",
     "shell.execute_reply": "2025-09-14T19:35:43.511003Z"
    },
    "papermill": {
     "duration": 525.478862,
     "end_time": "2025-09-14T19:35:43.513043",
     "exception": false,
     "start_time": "2025-09-14T19:26:58.034181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Inference â†’ dev | attempts=4 | workers=64 | subset=evaluation\n",
      "Running command: uv run python -u -m llm_python.run_arc_tasks_soar --dataset arc-prize-2025 --subset evaluation --max_workers 64 --max_attempts 4 --model /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic --base-url http://127.0.0.1:8080/v1 --unsafe-executor --max-tokens 2000 --qwen-no-think --parquet-output-dir /kaggle/working\n",
      "Running: uv run python -u -m llm_python.run_arc_tasks_soar --dataset arc-prize-2025 --subset evaluation --max_workers 64 --max_attempts 4 --model /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic --base-url http://127.0.0.1:8080/v1 --unsafe-executor --max-tokens 2000 --qwen-no-think --parquet-output-dir /kaggle/working\n",
      "\n",
      "âš ï¸  WARNING: Using unrestricted executor - generated code will run directly on your system!\r\n",
      "/kaggle/usr/lib/arc_agi_2025_aux_rewrite_refine/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\r\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\r\n",
      "  warnings.warn(\r\n",
      "â° API timeout: 600s per request (enforced by OpenAI client)\r\n",
      "ðŸ—„ï¸ Sampled programs will be logged to /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\r\n",
      "ðŸ“Š vLLM metrics monitoring enabled (http://127.0.0.1:8080/metrics)\r\n",
      "Loading subset: arc-prize-2025/evaluation\r\n",
      "ðŸ” Validating 120 tasks...\r\n",
      "âœ… Task validation complete: 120 valid tasks\r\n",
      "ðŸ“ Tasks sorted by length (shortest to longest)\r\n",
      "\r\n",
      "Running 120 tasks from arc-prize-2025/evaluation\r\n",
      "Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\r\n",
      "API: All Attempts Mode (4 attempts per task)\r\n",
      "Mode: True parallelization - 480 total attempts\r\n",
      "ðŸ”€ Training Data Splitter: DISABLED (using all training examples)\r\n",
      "Parallelization: ENABLED (64 workers)\r\n",
      "Scheduling: Batched (16 tasks Ã— 4 attempts = 64 workers used)\r\n",
      "\r\n",
      "â° API timeout: 600s per request, inactivity timeout: 600s for execution\r\n",
      "\r\n",
      "Sampling Parameters: {'max_tokens': 2000, 'temperature': 0.7, 'top_p': 0.9, 'extra_body': {'top_k': 20, 'chat_template_kwargs': {'enable_thinking': False}}}\r\n",
      "Executor: unrestricted (timeout: 15s) âš ï¸  UNSAFE MODE\r\n",
      "--------------------------------------------------\r\n",
      "ðŸ“Š Starting metrics monitoring thread for http://127.0.0.1:8080/metrics\r\n",
      "ðŸ“Š Metrics thread started, polling http://127.0.0.1:8080/metrics every 30s\r\n",
      "ðŸ“Š [19:27:10] SGLang: 1R/0Q, Cache 0.0%, Reqs 5\r\n",
      "\r\n",
      "ðŸ“ FIRST TASK REGULAR PROMPT (e8686506):\r\n",
      "================================================================================\r\n",
      "SYSTEM:\r\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by reasoning and generating Python code.\r\n",
      "\r\n",
      "USER:\r\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by generating Python code.\r\n",
      "Your goal is to analyze input-output grid pairs. The outputs were produced by applying a transformation rule to the inputs. Implement the transformation rules as a Python function.\r\n",
      "\r\n",
      "You must write code in triple backticks (```python and then ```). You must write a function called 'transform' which takes a single argument, the input grid as 'list[list[int]]', and returns the transformed grid (also as 'list[list[int]]').\r\n",
      "\r\n",
      "You should make sure that you implement a version of the transformation which works in general (at least for all given input-output pairs and test input pairs). The code should NOT hardcode specific predicted outputs.\r\n",
      "\r\n",
      "The number in the input grid can be mapped to the following colors: 0:Black; 1:Blue; 2:Red; 3:Green; 4:Yellow; 5:Grey; 6:Pink; 7:Orange; 8:Purple; 9:Brown\r\n",
      "\r\n",
      "\r\n",
      "# Task to solve:\r\n",
      "## Input 1 (grid shape: 13 by 13):\r\n",
      "[[8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 8 8 8 4 8 8 8 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 3 3 8 3 3 8 8 4 8 8 8] [8 8 3 8 8 8 3 8 8 8 8 8 8] [8 8 3 8 8 8 3 8 8 8 8 8 8] [8 8 8 3 8 3 8 8 8 8 8 4 8] [8 8 3 3 8 3 3 8 8 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 1 1 1 8 8 8 6 8 8 8 8] [8 8 1 1 1 8 8 8 6 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8]]\r\n",
      "## Output 1 (grid shape: 5 by 5):\r\n",
      "[[3 3 4 3 3] [3 1 1 1 3] [3 1 1 1 3] [4 3 6 3 4] [3 3 6 3 3]]\r\n",
      "\r\n",
      "## Input 2 (grid shape: 13 by 13):\r\n",
      "[[3 3 3 3 3 3 3 3 3 3 3 3 3] [3 6 3 3 3 3 3 3 8 8 8 3 3] [3 6 3 3 3 3 3 3 3 8 3 3 3] [3 3 3 1 1 1 3 3 3 8 3 5 3] [3 3 1 3 3 3 1 3 3 3 3 3 3] [3 3 1 1 3 1 1 3 5 3 3 3 3] [3 3 3 1 3 1 3 3 3 3 3 3 3] [3 3 3 2 3 2 3 3 3 3 4 3 3] [3 3 2 2 3 2 2 3 3 3 4 3 3] [3 3 2 3 3 3 2 3 3 4 4 4 3] [3 3 3 2 2 2 3 3 3 3 3 3 3] [3 6 3 3 3 3 3 3 3 3 5 3 3] [3 6 3 3 3 3 3 5 3 3 3 3 3]]\r\n",
      "## Output 2 (grid shape: 5 by 8):\r\n",
      "[[5 1 1 1 5] [1 8 8 8 1] [1 1 8 1 1] [6 1 8 1 6] [6 2 4 2 6] [2 2 4 2 2] [2 4 4 4 2] [5 2 2 2 5]]\r\n",
      "\r\n",
      "## Test Input 1 (grid shape: 15 by 15):\r\n",
      "[[4 1 4 4 4 4 4 4 4 4 4 4 4 4 4] [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4] [4 4 4 4 4 8 8 8 4 4 4 4 6 6 6] [4 4 3 4 8 4 4 4 8 4 4 4 4 6 4] [4 4 3 4 4 8 4 8 4 4 1 4 4 4 4] [4 4 3 4 4 8 4 8 4 4 4 4 4 4 4] [4 4 3 4 4 8 4 8 4 4 4 4 4 4 4] [4 4 4 4 4 8 4 8 4 4 4 4 4 4 4] [4 4 4 4 8 4 4 4 8 4 4 4 1 4 4] [4 4 4 4 4 8 8 8 4 4 4 4 4 4 4] [4 3 4 4 4 4 4 4 4 4 4 4 4 4 4] [4 3 4 4 4 4 4 9 4 4 4 4 4 4 4] [4 3 4 4 4 4 4 9 4 4 4 6 4 4 4] [4 3 4 4 1 4 4 4 4 4 6 6 6 4 4] [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]]\r\n",
      "\r\n",
      "================================================================================\r\n",
      "ðŸš€ Started 480 attempts with 64 workers\r\n",
      "â³ No completions in last 15s â€” 0/480 done; 480 remaining\r\n",
      "ðŸ“Š [19:27:40] SGLang: 57R/1Q, Cache 27.5%, Reqs 5, 12.7tok/s\r\n",
      "â³ No completions in last 15s â€” 0/480 done; 480 remaining\r\n",
      "â³ No completions in last 15s â€” 5/480 done; 475 remaining\r\n",
      "âœ… b0039139: 4 attempts | 3 valid outputs, 1 invalid outputs | 3 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:28:10] SGLang: 57R/0Q, Cache 54.8%, Reqs 45, 699.9tok/s\r\n",
      "â³ No completions in last 15s â€” 37/480 done; 443 remaining\r\n",
      "ðŸŒ Slow attempt: 28a6681f attempt 3 took 60.6s\r\n",
      "âœ… 28a6681f: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7b5033c1 attempt 4 took 60.8s\r\n",
      "âœ… 7b5033c1: 4 attempts | 1 valid outputs, 3 invalid outputs | 1 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: d35bdbdc attempt 3 took 60.8s\r\n",
      "ðŸŒ Slow attempt: 78332cb0 attempt 1 took 61.4s\r\n",
      "ðŸŒ Slow attempt: eee78d87 attempt 4 took 61.3s\r\n",
      "ðŸŒ Slow attempt: 136b0064 attempt 3 took 61.4s\r\n",
      "ðŸŒ Slow attempt: 97d7923e attempt 2 took 61.7s\r\n",
      "ðŸŒ Slow attempt: 3dc255db attempt 3 took 62.5s\r\n",
      "ðŸŒ Slow attempt: eee78d87 attempt 1 took 62.9s\r\n",
      "ðŸŒ Slow attempt: d35bdbdc attempt 1 took 63.5s\r\n",
      "âœ… d35bdbdc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 20270e3b attempt 2 took 65.1s\r\n",
      "ðŸŒ Slow attempt: bf45cf4b attempt 4 took 65.4s\r\n",
      "ðŸŒ Slow attempt: dd6b8c4b attempt 1 took 65.7s\r\n",
      "ðŸŒ Slow attempt: 20270e3b attempt 4 took 65.7s\r\n",
      "ðŸŒ Slow attempt: eee78d87 attempt 2 took 66.4s\r\n",
      "âœ… eee78d87: 4 attempts | 1 valid outputs, 3 execution errors | 1 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: dd6b8c4b attempt 4 took 66.5s\r\n",
      "âœ… dd6b8c4b: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 20270e3b attempt 1 took 67.2s\r\n",
      "âœ… 20270e3b: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 136b0064 attempt 2 took 67.5s\r\n",
      "ðŸŒ Slow attempt: 136b0064 attempt 4 took 67.9s\r\n",
      "ðŸŒ Slow attempt: e8686506 attempt 2 took 68.2s\r\n",
      "âœ… e8686506: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: bf45cf4b attempt 1 took 68.3s\r\n",
      "âœ… bf45cf4b: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 3dc255db attempt 4 took 69.0s\r\n",
      "âœ… 3dc255db: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: dbff022c attempt 3 took 70.7s\r\n",
      "âœ… dbff022c: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 136b0064 attempt 1 took 75.0s\r\n",
      "âœ… 136b0064: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 73/480 done; 407 remaining\r\n",
      "ðŸŒ Slow attempt: 97d7923e attempt 3 took 78.3s\r\n",
      "âœ… 97d7923e: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 78332cb0 attempt 4 took 87.3s\r\n",
      "âœ… 78332cb0: 4 attempts | 1 valid outputs, 2 execution errors, 1 invalid outputs | 1 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ“Š [19:28:40] SGLang: 56R/3Q, Cache 78.2%, Reqs 99, 664.1tok/s\r\n",
      "âœ… 31f7f899: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 92/480 done; 388 remaining\r\n",
      "ðŸŒ Slow attempt: 4c3d4a41 attempt 1 took 90.7s\r\n",
      "âœ… 4c3d4a41: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 1ae2feb7: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ¥ Health [100 attempts]: Success 92% | ExecTimeout 0% | ExecErr 8% | APITimeout 0% | AvgTime 39.98s\r\n",
      "âœ… 7491f3cf: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 16de56c4: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 1818057f: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 581f7754: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… faa9f03d: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 5545f144: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 2b83f449: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 127/480 done; 353 remaining\r\n",
      "âœ… 247ef758: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 291dc1e1: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 271d71e2: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "âœ… 7666fa5d: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:29:10] SGLang: 58R/2Q, Cache 86.2%, Reqs 155, 588.2tok/s\r\n",
      "â³ No completions in last 15s â€” 146/480 done; 334 remaining\r\n",
      "ðŸŒ Slow attempt: 6e453dd6 attempt 3 took 60.4s\r\n",
      "âœ… 6e453dd6: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8f3a5a89 attempt 3 took 61.9s\r\n",
      "âœ… 8f3a5a89: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 446ef5d2: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 332f06d7: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 169/480 done; 311 remaining\r\n",
      "âœ… 5dbc8537: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 53fb4810: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… b6f77b65: 4 attempts | 4 valid outputs | 1 train-partial, 3 train-incorrect (of which 1 trans) (best: 20.0% train)\r\n",
      "âœ… d59b0160: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 65b59efc: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 135a2760: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 58f5dbd5 attempt 1 took 61.9s\r\n",
      "âœ… 58f5dbd5: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… 6ffbe589: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 9385bd28: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: b9e38dc0 attempt 4 took 81.2s\r\n",
      "âœ… b9e38dc0: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "âœ… 7b3084d4: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:29:40] SGLang: 56R/7Q, Cache 73.2%, Reqs 203, 501.2tok/s\r\n",
      "â³ No completions in last 15s â€” 197/480 done; 283 remaining\r\n",
      "ðŸ¥ Health [200 attempts]: Success 94% | ExecTimeout 0% | ExecErr 6% | APITimeout 0% | AvgTime 38.10s\r\n",
      "ðŸŒ Slow attempt: e376de54 attempt 2 took 70.8s\r\n",
      "âœ… e376de54: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 212/480 done; 268 remaining\r\n",
      "âœ… 8698868d: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: f931b4a8 attempt 4 took 171.1s\r\n",
      "âœ… f931b4a8: 4 attempts | 4 valid outputs | 1 train-partial (of which 1 trans), 3 train-incorrect (of which 1 trans) (best: 40.0% train)\r\n",
      "âœ… 58490d8a: 4 attempts | 2 valid outputs, 1 execution errors, 1 invalid outputs | 2 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 80a900e0: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 7ed72f31: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 45a5af55 attempt 3 took 79.5s\r\n",
      "âœ… 45a5af55: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 800d221b attempt 1 took 64.5s\r\n",
      "âœ… 800d221b: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: db695cfb attempt 1 took 101.1s\r\n",
      "âœ… db695cfb: 4 attempts | 1 valid outputs, 2 execution errors, 1 execution timeouts | 1 train-incorrect (best: 40.0% train)\r\n",
      "ðŸ“Š [19:30:10] SGLang: 37R/22Q, Cache 80.0%, Reqs 241, 423.5tok/s\r\n",
      "â³ No completions in last 15s â€” 235/480 done; 245 remaining\r\n",
      "âœ… abc82100: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… edb79dae: 4 attempts | 3 valid outputs, 1 invalid outputs | 3 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 4e34c42c: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… 9bbf930d: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 898e7135 attempt 2 took 63.8s\r\n",
      "âœ… 21897d95: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "âœ… da515329: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 253/480 done; 227 remaining\r\n",
      "ðŸŒ Slow attempt: 35ab12c3 attempt 2 took 72.7s\r\n",
      "âœ… 35ab12c3: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: db0c5428 attempt 4 took 60.9s\r\n",
      "ðŸŒ Slow attempt: dfadab01 attempt 1 took 88.2s\r\n",
      "ðŸŒ Slow attempt: dfadab01 attempt 4 took 61.3s\r\n",
      "ðŸŒ Slow attempt: 71e489b6 attempt 4 took 65.9s\r\n",
      "âœ… 71e489b6: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: dfadab01 attempt 2 took 82.8s\r\n",
      "âœ… dfadab01: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 409aa875 attempt 4 took 107.3s\r\n",
      "âœ… 409aa875: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 898e7135 attempt 4 took 63.0s\r\n",
      "âœ… 898e7135: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ“Š [19:30:40] SGLang: 37R/22Q, Cache 78.8%, Reqs 277, 370.5tok/s\r\n",
      "â³ No completions in last 15s â€” 270/480 done; 210 remaining\r\n",
      "ðŸŒ Slow attempt: 38007db0 attempt 1 took 65.4s\r\n",
      "âœ… 3a25b0d8: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 89565ca0: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 1 took 67.7s\r\n",
      "â³ No completions in last 15s â€” 280/480 done; 200 remaining\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 2 took 60.0s\r\n",
      "ðŸŒ Slow attempt: 142ca369 attempt 1 took 69.8s\r\n",
      "ðŸŒ Slow attempt: f560132c attempt 3 took 60.0s\r\n",
      "ðŸŒ Slow attempt: 142ca369 attempt 2 took 61.7s\r\n",
      "ðŸŒ Slow attempt: 8e5c0c38 attempt 2 took 62.3s\r\n",
      "âœ… 8e5c0c38: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 2 took 64.8s\r\n",
      "ðŸŒ Slow attempt: 38007db0 attempt 3 took 63.6s\r\n",
      "ðŸŒ Slow attempt: db0c5428 attempt 1 took 129.9s\r\n",
      "âœ… db0c5428: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: fc7cae8d attempt 3 took 60.7s\r\n",
      "ðŸ“Š [19:31:10] SGLang: 37R/24Q, Cache 81.2%, Reqs 301, 416.8tok/s\r\n",
      "â³ No completions in last 15s â€” 294/480 done; 186 remaining\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 2 took 73.2s\r\n",
      "âœ… f560132c: 4 attempts | 2 valid outputs, 2 execution errors | 2 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: c7f57c3e attempt 3 took 117.4s\r\n",
      "âœ… c7f57c3e: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 2 took 80.7s\r\n",
      "ðŸ¥ Health [300 attempts]: Success 93% | ExecTimeout 0% | ExecErr 7% | APITimeout 0% | AvgTime 57.51s\r\n",
      "ðŸŒ Slow attempt: 7b80bb43 attempt 1 took 90.7s\r\n",
      "ðŸŒ Slow attempt: 142ca369 attempt 3 took 63.2s\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 3 took 70.5s\r\n",
      "ðŸŒ Slow attempt: de809cff attempt 2 took 89.1s\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 1 took 91.1s\r\n",
      "â³ No completions in last 15s â€” 306/480 done; 174 remaining\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 4 took 61.7s\r\n",
      "ðŸŒ Slow attempt: 88bcf3b4 attempt 3 took 84.0s\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 3 took 80.1s\r\n",
      "ðŸŒ Slow attempt: 7b80bb43 attempt 3 took 81.2s\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 1 took 60.8s\r\n",
      "ðŸŒ Slow attempt: 38007db0 attempt 4 took 75.2s\r\n",
      "âœ… 38007db0: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7b80bb43 attempt 4 took 70.5s\r\n",
      "âœ… 7b80bb43: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: de809cff attempt 4 took 78.2s\r\n",
      "âœ… de809cff: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 142ca369 attempt 4 took 66.1s\r\n",
      "âœ… 142ca369: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:31:40] SGLang: 28R/31Q, Cache 80.5%, Reqs 331, 385.8tok/s\r\n",
      "â³ No completions in last 15s â€” 322/480 done; 158 remaining\r\n",
      "ðŸŒ Slow attempt: 88bcf3b4 attempt 4 took 84.1s\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 3 took 92.9s\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 3 took 88.6s\r\n",
      "âœ… 7b0280bc: 4 attempts | 1 valid outputs, 1 execution errors, 1 execution timeouts, 1 invalid outputs | 1 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 4 took 81.7s\r\n",
      "âœ… a6f40cea: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: fc7cae8d attempt 2 took 107.8s\r\n",
      "ðŸŒ Slow attempt: 2c181942 attempt 1 took 67.8s\r\n",
      "âœ… 2d0172a1: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 2 took 64.8s\r\n",
      "ðŸŒ Slow attempt: 36a08778 attempt 2 took 65.1s\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 4 took 87.5s\r\n",
      "âœ… 4a21e3da: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 335/480 done; 145 remaining\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 1 took 83.1s\r\n",
      "âœ… a251c730: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 64efde09 attempt 1 took 78.0s\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 1 took 80.5s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 1 took 88.3s\r\n",
      "ðŸŒ Slow attempt: 6e4f6532 attempt 2 took 60.2s\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 1 took 84.5s\r\n",
      "âœ… a47bf94d: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 1 took 87.5s\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 4 took 102.7s\r\n",
      "âœ… 2ba387bc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 2 took 66.5s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 2 took 79.7s\r\n",
      "ðŸŒ Slow attempt: 36a08778 attempt 3 took 62.1s\r\n",
      "ðŸ“Š [19:32:10] SGLang: 31R/33Q, Cache 88.2%, Reqs 356, 315.7tok/s\r\n",
      "â³ No completions in last 15s â€” 351/480 done; 129 remaining\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 2 took 69.2s\r\n",
      "ðŸŒ Slow attempt: 88bcf3b4 attempt 2 took 137.8s\r\n",
      "âœ… 88bcf3b4: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 1 took 94.3s\r\n",
      "ðŸŒ Slow attempt: 88e364bc attempt 2 took 82.1s\r\n",
      "âœ… 88e364bc: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 2 took 87.3s\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 1 took 99.4s\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 2 took 78.2s\r\n",
      "âœ… 36a08778: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 3 took 70.8s\r\n",
      "âœ… 2c181942: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 366/480 done; 114 remaining\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 3 took 76.7s\r\n",
      "âœ… cb2d8a2c: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 2 took 93.5s\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 2 took 86.8s\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 3 took 73.1s\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 3 took 75.8s\r\n",
      "âœ… a395ee82: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 3 took 87.3s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 4 took 73.7s\r\n",
      "ðŸ“Š [19:32:40] SGLang: 19R/42Q, Cache 84.2%, Reqs 382, 217.9tok/s\r\n",
      "â³ No completions in last 15s â€” 377/480 done; 103 remaining\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 4 took 71.7s\r\n",
      "âœ… 4c416de3: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 3 took 80.7s\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 4 took 80.2s\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 4 took 72.1s\r\n",
      "âœ… cbebaa4b: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 3 took 103.5s\r\n",
      "âœ… 67e490f4: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8f215267 attempt 1 took 66.2s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 3 took 99.6s\r\n",
      "âœ… 8b9c3697: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: fc7cae8d attempt 4 took 149.3s\r\n",
      "âœ… fc7cae8d: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 4 took 78.4s\r\n",
      "âœ… 8b7bacbf: 4 attempts | 3 valid outputs, 1 invalid outputs | 3 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 387/480 done; 93 remaining\r\n",
      "ðŸŒ Slow attempt: 64efde09 attempt 4 took 83.3s\r\n",
      "âœ… 64efde09: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 4 took 85.1s\r\n",
      "âœ… b5ca7ac4: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 20a9e565 attempt 2 took 60.3s\r\n",
      "ðŸ“Š [19:33:10] SGLang: 21R/38Q, Cache 83.2%, Reqs 398, 240.8tok/s\r\n",
      "â³ No completions in last 15s â€” 391/480 done; 89 remaining\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 1 took 85.7s\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 1 took 82.1s\r\n",
      "ðŸŒ Slow attempt: e12f9a14 attempt 2 took 72.1s\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 1 took 92.5s\r\n",
      "ðŸŒ Slow attempt: 6e4f6532 attempt 4 took 105.0s\r\n",
      "âœ… 6e4f6532: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 269e22fb attempt 2 took 197.6s\r\n",
      "âœ… 269e22fb: 4 attempts | 3 valid outputs, 1 max length | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 1 took 95.2s\r\n",
      "ðŸ¥ Health [400 attempts]: Success 94% | ExecTimeout 0% | ExecErr 5% | APITimeout 0% | AvgTime 77.40s\r\n",
      "ðŸŒ Slow attempt: b10624e5 attempt 3 took 66.0s\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 2 took 79.2s\r\n",
      "ðŸŒ Slow attempt: c4d067a0 attempt 1 took 100.3s\r\n",
      "âœ… e87109e9: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 403/480 done; 77 remaining\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 1 took 91.0s\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 1 took 101.0s\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 3 took 78.4s\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 2 took 89.6s\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 2 took 91.0s\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 4 took 63.5s\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 1 took 102.5s\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 3 took 72.8s\r\n",
      "ðŸŒ Slow attempt: 20a9e565 attempt 3 took 73.6s\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 1 took 110.1s\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 2 took 99.2s\r\n",
      "ðŸ“Š [19:33:40] SGLang: 23R/36Q, Cache 82.5%, Reqs 421, 320.7tok/s\r\n",
      "â³ No completions in last 15s â€” 414/480 done; 66 remaining\r\n",
      "âœ… 16b78196: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 2 took 102.6s\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 2 took 94.3s\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 4 took 65.7s\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 1 took 121.9s\r\n",
      "ðŸŒ Slow attempt: e12f9a14 attempt 4 took 65.5s\r\n",
      "ðŸŒ Slow attempt: 8f215267 attempt 3 took 96.3s\r\n",
      "ðŸŒ Slow attempt: 8f215267 attempt 2 took 113.0s\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 2 took 109.6s\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 3 took 97.9s\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 2 took 110.3s\r\n",
      "â³ No completions in last 15s â€” 425/480 done; 55 remaining\r\n",
      "ðŸŒ Slow attempt: 7c66cb00 attempt 1 took 66.4s\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 3 took 100.9s\r\n",
      "ðŸŒ Slow attempt: 20a9e565 attempt 4 took 73.2s\r\n",
      "âœ… 20a9e565: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: e12f9a14 attempt 3 took 97.1s\r\n",
      "âœ… e12f9a14: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 2 took 106.2s\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 3 took 95.1s\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 3 took 101.7s\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 3 took 103.8s\r\n",
      "ðŸŒ Slow attempt: c4d067a0 attempt 4 took 88.5s\r\n",
      "ðŸŒ Slow attempt: c4d067a0 attempt 3 took 108.4s\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 4 took 86.1s\r\n",
      "âœ… 5961cc34: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 2 took 132.7s\r\n",
      "âœ… 4c7dc4dd: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 3 took 110.9s\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 4 took 90.9s\r\n",
      "âœ… 62593bfd: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:34:10] SGLang: 17R/21Q, Cache 72.2%, Reqs 446, 291.9tok/s\r\n",
      "â³ No completions in last 15s â€” 439/480 done; 41 remaining\r\n",
      "ðŸŒ Slow attempt: 8f215267 attempt 4 took 101.2s\r\n",
      "âœ… 8f215267: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 1 took 83.6s\r\n",
      "ðŸŒ Slow attempt: c4d067a0 attempt 2 took 131.3s\r\n",
      "âœ… c4d067a0: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 4 took 90.0s\r\n",
      "âœ… a25697e4: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 4 took 102.0s\r\n",
      "âœ… aa4ec2a5: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 446/480 done; 34 remaining\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 3 took 117.9s\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 2 took 72.3s\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 4 took 117.2s\r\n",
      "âœ… 13e47133: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 4 took 102.8s\r\n",
      "âœ… 3e6067c3: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 3 took 135.8sðŸŒ Slow attempt: b99e7126 attempt 1 took 97.5s\r\n",
      "\r\n",
      "âœ… 221dfab4: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 4 took 108.7s\r\n",
      "âœ… 0934a4d8: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 2 took 85.3s\r\n",
      "ðŸŒ Slow attempt: b10624e5 attempt 4 took 130.8s\r\n",
      "âœ… b10624e5: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:34:40] SGLang: 18R/2Q, Cache 64.0%, Reqs 460, 251.8tok/s\r\n",
      "â³ No completions in last 15s â€” 455/480 done; 25 remaining\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 2 took 86.2s\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 3 took 73.2s\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 3 took 80.6s\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 1 took 106.8s\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 1 took 120.2s\r\n",
      "ðŸŒ Slow attempt: 7c66cb00 attempt 2 took 101.8s\r\n",
      "â³ No completions in last 15s â€” 461/480 done; 19 remaining\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 1 took 121.1s\r\n",
      "ðŸŒ Slow attempt: 7c66cb00 attempt 4 took 82.7s\r\n",
      "âœ… 7c66cb00: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 4 took 79.8s\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 4 took 84.8s\r\n",
      "âœ… b99e7126: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 4 took 92.7s\r\n",
      "âœ… a32d8b75: 4 attempts | 2 valid outputs, 2 execution errors | 2 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 2 took 107.8s\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 1 took 113.9s\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 3 took 95.0s\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 2 took 106.7s\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 1 took 119.5s\r\n",
      "ðŸ“Š [19:35:10] SGLang: 11R/0Q, Cache 58.0%, Reqs 476, 146.8tok/s\r\n",
      "â³ No completions in last 15s â€” 471/480 done; 9 remaining\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 2 took 118.8s\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 4 took 96.7s\r\n",
      "âœ… 9aaea919: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 4 took 101.7s\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 4 took 95.8s\r\n",
      "âœ… 981571dc: 4 attempts | 4 valid outputs | 4 train-partial (best: 75.0% train)\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 3 took 112.6s\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 3 took 117.2s\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 4 took 106.7s\r\n",
      "âœ… e3721c99: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 478/480 done; 2 remaining\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 3 took 115.3s\r\n",
      "âœ… d8e07eb2: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:35:40] SGLang: 3R/0Q, Cache 22.8%, Reqs 485, 43.9tok/s\r\n",
      "â³ No completions in last 15s â€” 479/480 done; 1 remaining\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 2 took 147.5s\r\n",
      "âœ… 195c6913: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "â³ Progress: 480/480 attempts done; 0 remaining\r\n",
      "âœ… All 480 attempts completed in 511.0s\r\n",
      "ðŸ“Š Final status: 480 successful, 0 failed, 0 cancelled\r\n",
      "Converting task results to summary format...\r\n",
      "âœ… Converted results for 120/120 tasks\r\n",
      "\r\n",
      "==================================================\r\n",
      "SUBMIT MODE SUMMARY\r\n",
      "==================================================\r\n",
      "Dataset: arc-prize-2025\r\n",
      "Subset: evaluation\r\n",
      "Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\r\n",
      "Total tasks processed: 120\r\n",
      "Total time: 511.0s\r\n",
      "Successful API calls: 120/120 (100.0%)\r\n",
      "Total tokens used: 2,916,422\r\n",
      "Total cost: $0.514573\r\n",
      "\r\n",
      "ðŸ“Š RESPONSE METRICS:\r\n",
      "  Total responses: 480\r\n",
      "  Code extracted: 479/480 (99.8%)\r\n",
      "  Max length responses: 1/480 (0.2%)\r\n",
      "  Timeout responses: 0/480 (0.0%)\r\n",
      "  API failure responses: 0/480 (0.0%)\r\n",
      "  Execution timeout responses (of all attempts): 2/480 (0.4%)\r\n",
      "  Execution error responses (of all attempts): 25/480 (5.2%)\r\n",
      "\r\n",
      "ðŸ“Š TRAIN METRICS:\r\n",
      "  All train correct: 0/120 (0.0%)\r\n",
      "  Min 1 train correct: 4/120 (3.3%)\r\n",
      "\r\n",
      "âš ï¸  Note: Test accuracy metrics unavailable in SUBMIT mode (no test outputs)\r\n",
      "\r\n",
      "ðŸŽ¯ To generate submission file, run:\r\n",
      "   uv run python llm_python/generate_submission.py --dataset arc-prize-2025 --subset evaluation\r\n",
      "All sampled programs saved to /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\r\n",
      "Graceful exit starting, process will be force terminated in 10 seconds.\r\n"
     ]
    }
   ],
   "source": [
    "if not IS_KAGGLE:\n",
    "    %cd /workspace/arc-agi-2025\n",
    "\n",
    "# Use FIRST_ATTEMPTS and FIRST_WORKERS for initial inference\n",
    "MAX_ATTEMPTS = FIRST_ATTEMPTS\n",
    "MAX_WORKERS  = FIRST_WORKERS\n",
    "\n",
    "# SUBSET = \"test\" # defaulting to test to ensure there are no loading issues.\n",
    "\n",
    "# can use this instead if testing evaluation during a pre-run\n",
    "SUBSET = \"test\" if IS_RERUN else \"evaluation\"\n",
    "\n",
    "# Common env for your runner\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n",
    "\n",
    "print(f\"First Inference â†’ {'competition' if IS_RERUN else 'dev'} | attempts={MAX_ATTEMPTS} | workers={MAX_WORKERS} | subset={SUBSET}\")\n",
    "\n",
    "# Build the command\n",
    "cmd_args = [\n",
    "    \"uv\", \"run\", \"python\", \"-u\", \"-m\", \"llm_python.run_arc_tasks_soar\",\n",
    "    \"--dataset\", DATASET,\n",
    "    \"--subset\", SUBSET,\n",
    "    \"--max_workers\", str(MAX_WORKERS),\n",
    "    \"--max_attempts\", str(MAX_ATTEMPTS),\n",
    "    \"--model\", model_name,\n",
    "    \"--base-url\", \"http://127.0.0.1:8080/v1\",\n",
    "    \"--unsafe-executor\",\n",
    "    \"--max-tokens\", \"2000\",\n",
    "    \"--qwen-no-think\"\n",
    "]\n",
    "\n",
    "\n",
    "# Add parquet output directory if set\n",
    "if os.getenv(\"ARC_PROGRAMS_PARQUET\"):\n",
    "  cmd_args.extend([\"--parquet-output-dir\", os.getenv(\"ARC_PROGRAMS_PARQUET\")])\n",
    "\n",
    "print(f\"Running command: {' '.join(cmd_args)}\")\n",
    "\n",
    "# Handle output redirection properly\n",
    "if IS_RERUN or not IS_KAGGLE:\n",
    "    # For quiet mode, redirect to file using subprocess\n",
    "    import subprocess\n",
    "    log_file_path = f\"{SUBMIT_DIR}/run.log\"\n",
    "    print(f\"ðŸ“ Logging output to: {log_file_path}\")\n",
    "    \n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        process = subprocess.Popen(\n",
    "            cmd_args,\n",
    "            stdout=log_file,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            cwd=os.getcwd()\n",
    "        )\n",
    "        \n",
    "        # Wait for completion\n",
    "        print(\"â³ Running tasks (output being written to log file)...\")\n",
    "        return_code = process.wait()\n",
    "        \n",
    "    if return_code == 0:\n",
    "        print(f\"âœ… Task runner completed successfully. Check {log_file_path} for details.\")\n",
    "    else:\n",
    "        print(f\"âŒ Task runner failed with return code {return_code}\")\n",
    "        print(f\"ðŸ“ Check {log_file_path} for error details\")\n",
    "        # Show last few lines of log\n",
    "        !tail -n 20 {log_file_path}\n",
    "else:\n",
    "    # For interactive mode, show output directly\n",
    "    cmd = \" \".join(cmd_args)\n",
    "    print(f\"Running: {cmd}\\n\")\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db35af4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:35:43.548573Z",
     "iopub.status.busy": "2025-09-14T19:35:43.547968Z",
     "iopub.status.idle": "2025-09-14T19:35:43.551860Z",
     "shell.execute_reply": "2025-09-14T19:35:43.551316Z"
    },
    "papermill": {
     "duration": 0.022456,
     "end_time": "2025-09-14T19:35:43.552885",
     "exception": false,
     "start_time": "2025-09-14T19:35:43.530429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_PATH type: <class 'pathlib.PosixPath'>, value: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n"
     ]
    }
   ],
   "source": [
    "print(f\"MODEL_PATH type: {type(MODEL_PATH)}, value: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f02e48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:35:43.587506Z",
     "iopub.status.busy": "2025-09-14T19:35:43.587067Z",
     "iopub.status.idle": "2025-09-14T19:38:53.752106Z",
     "shell.execute_reply": "2025-09-14T19:38:53.751229Z"
    },
    "papermill": {
     "duration": 190.200335,
     "end_time": "2025-09-14T19:38:53.770008",
     "exception": false,
     "start_time": "2025-09-14T19:35:43.569673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Restarting inference server with updated model...\n",
      "ðŸ›‘ Gracefully stopping existing server...\n",
      "âœ… Server stopped gracefully\n",
      "âœ… CUDA memory cleared\n",
      "ðŸŽ¯ Using model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n",
      "   â†’ Refinement model\n",
      "ðŸš€ Starting server: /usr/bin/python3 -m sglang.launch_server --host 0.0.0.0 --port 8080 --model-path /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic --dp 4 --kv-cache-dtype fp8_e4m3 --enable-metrics\n",
      "âœ… Server started with PID=7341\n",
      "âœ… Server ready!\n",
      "ðŸŽ¯ Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\n"
     ]
    }
   ],
   "source": [
    "if ENABLE_REFINEMENT:\n",
    "  # Restart the server with the (potentially) new model\n",
    "  if START_SERVER:\n",
    "      print(\"ðŸ”„ Restarting inference server with updated model...\")\n",
    "\n",
    "      # Gracefully stop existing server if it exists\n",
    "      if 'proc' in locals() and proc.poll() is None:  # Check if process is still running\n",
    "          print(\"ðŸ›‘ Gracefully stopping existing server...\")\n",
    "          try:\n",
    "              proc.terminate()  # Send SIGTERM first\n",
    "              proc.wait(timeout=30)  # Wait up to 30 seconds for graceful shutdown\n",
    "              print(\"âœ… Server stopped gracefully\")\n",
    "          except subprocess.TimeoutExpired:\n",
    "              print(\"âš ï¸  Server didn't stop gracefully, force killing...\")\n",
    "              proc.kill()\n",
    "              proc.wait()\n",
    "          except Exception as e:\n",
    "              print(f\"âš ï¸  Error stopping server: {e}\")\n",
    "\n",
    "      # Wait a bit longer after graceful shutdown\n",
    "      time.sleep(5)\n",
    "\n",
    "      # Clear CUDA memory\n",
    "      try:\n",
    "          import torch\n",
    "          if torch.cuda.is_available():\n",
    "              torch.cuda.empty_cache()\n",
    "              torch.cuda.synchronize()\n",
    "              print(\"âœ… CUDA memory cleared\")\n",
    "      except Exception:\n",
    "          pass\n",
    "\n",
    "      # Get GPU count\n",
    "      try:\n",
    "          import torch\n",
    "          num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
    "      except:\n",
    "          num_gpus = 1\n",
    "\n",
    "      # Choose which model to use: refinement if available, otherwise original\n",
    "      model_to_use = REFINEMENT_MODEL_PATH if REFINEMENT_MODEL_PATH else MODEL_PATH\n",
    "      print(f\"ðŸŽ¯ Using model: {model_to_use}\")\n",
    "      print(f\"   â†’ {'Refinement' if REFINEMENT_MODEL_PATH else 'Original'} model\")\n",
    "\n",
    "      # Restart server with appropriate model\n",
    "      PORT = 8080\n",
    "      LOG = f\"{SUBMIT_DIR}/sglang_server.log\"\n",
    "      SERVER_CMD = [\n",
    "          sys.executable, \"-m\", \"sglang.launch_server\",\n",
    "          \"--host\", \"0.0.0.0\",\n",
    "          \"--port\", str(PORT),\n",
    "          \"--model-path\", str(model_to_use),\n",
    "          \"--dp\", str(max(1, min(num_gpus, 4))),\n",
    "          \"--kv-cache-dtype\", \"fp8_e4m3\",\n",
    "          \"--enable-metrics\",\n",
    "      ]\n",
    "\n",
    "      print(f\"ðŸš€ Starting server: {' '.join(SERVER_CMD)}\")\n",
    "\n",
    "      log_f = open(LOG, \"a\")\n",
    "      proc = subprocess.Popen(SERVER_CMD, stdout=log_f, stderr=subprocess.STDOUT,\n",
    "                             env=os.environ.copy(), cwd=SUBMIT_DIR)\n",
    "\n",
    "      print(f\"âœ… Server started with PID={proc.pid}\")\n",
    "\n",
    "      # Wait for readiness with better error handling\n",
    "      def wait_ready(url, timeout_s=600):\n",
    "          t0 = time.time()\n",
    "          while time.time() - t0 < timeout_s:\n",
    "              try:\n",
    "                  r = requests.get(url, timeout=5)\n",
    "                  if r.status_code == 200:\n",
    "                      return True\n",
    "              except Exception:\n",
    "                  pass\n",
    "              time.sleep(3)  # Check less frequently\n",
    "          return False\n",
    "\n",
    "      HEALTH_URL = f\"http://127.0.0.1:{PORT}/v1/models\"\n",
    "      if wait_ready(HEALTH_URL):\n",
    "          print(\"âœ… Server ready!\")\n",
    "\n",
    "          # Update model_name\n",
    "          try:\n",
    "              response = requests.get(HEALTH_URL)\n",
    "              if response.status_code == 200:\n",
    "                  models = response.json()['data']\n",
    "                  if models:\n",
    "                      model_name = models[0]['id']\n",
    "                      print(f\"ðŸŽ¯ Model: {model_name}\")\n",
    "          except Exception as e:\n",
    "              print(f\"âš ï¸  Could not get model name: {e}\")\n",
    "      else:\n",
    "          print(\"âŒ Server failed to start properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f0e37a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:38:53.805539Z",
     "iopub.status.busy": "2025-09-14T19:38:53.804996Z",
     "iopub.status.idle": "2025-09-14T19:48:09.868726Z",
     "shell.execute_reply": "2025-09-14T19:48:09.867999Z"
    },
    "papermill": {
     "duration": 556.082824,
     "end_time": "2025-09-14T19:48:09.870010",
     "exception": false,
     "start_time": "2025-09-14T19:38:53.787186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Running SECOND inference (ENABLE_REFINEMENT mode)\n",
      "ENABLE_REFINEMENT Second Run â†’ dev | attempts=4 | workers=64 | subset=evaluation\n",
      "ðŸ“‚ Using latest parquet file for refinement: /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\n",
      "Running ENABLE_REFINEMENT second inference: uv run python -u -m llm_python.run_arc_tasks_soar --dataset arc-prize-2025 --subset evaluation --max_workers 64 --max_attempts 4 --model /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic --base-url http://127.0.0.1:8080/v1 --unsafe-executor --max-tokens 2000 --qwen-no-think --refinement-ds /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet --include-outputs --parquet-output-dir /kaggle/working\n",
      "Running ENABLE_REFINEMENT second inference: uv run python -u -m llm_python.run_arc_tasks_soar --dataset arc-prize-2025 --subset evaluation --max_workers 64 --max_attempts 4 --model /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic --base-url http://127.0.0.1:8080/v1 --unsafe-executor --max-tokens 2000 --qwen-no-think --refinement-ds /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet --include-outputs --parquet-output-dir /kaggle/working\n",
      "\n",
      "âš ï¸  WARNING: Using unrestricted executor - generated code will run directly on your system!\r\n",
      "/kaggle/usr/lib/arc_agi_2025_aux_rewrite_refine/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\r\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\r\n",
      "  warnings.warn(\r\n",
      "â° API timeout: 600s per request (enforced by OpenAI client)\r\n",
      "ðŸ—„ï¸ Sampled programs will be logged to /kaggle/working/20250914_193858__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\r\n",
      "ðŸ“Š vLLM metrics monitoring enabled (http://127.0.0.1:8080/metrics)\r\n",
      "Loading subset: arc-prize-2025/evaluation\r\n",
      "Loading refinement programs from: /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\r\n",
      "ðŸ“Š Found 322 refineable programs out of 443 total programs (non-transductive, non-perfect)\r\n",
      "âœ… Successfully loaded program data for 113 tasks for refinement\r\n",
      "ðŸ“Š Loaded refinement programs for 113 tasks\r\n",
      "ðŸ“Š Found 0 all-train-correct non-transductive programs across 0 tasks for early stopping\r\n",
      "âš ï¸ 7/120 tasks have no refinement programs, will use normal prompts\r\n",
      "ðŸ” Validating 120 tasks...\r\n",
      "âœ… Task validation complete: 120 valid tasks\r\n",
      "ðŸ“ Tasks sorted by length (shortest to longest)\r\n",
      "\r\n",
      "Running 120 tasks from arc-prize-2025/evaluation\r\n",
      "Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\r\n",
      "API: All Attempts Mode (4 attempts per task)\r\n",
      "Mode: True parallelization - 480 total attempts\r\n",
      "ðŸ”€ Training Data Splitter: DISABLED (using all training examples)\r\n",
      "Parallelization: ENABLED (64 workers)\r\n",
      "Scheduling: Batched (16 tasks Ã— 4 attempts = 64 workers used)\r\n",
      "\r\n",
      "â° API timeout: 600s per request, inactivity timeout: 600s for execution\r\n",
      "\r\n",
      "Sampling Parameters: {'max_tokens': 2000, 'temperature': 0.7, 'top_p': 0.9, 'extra_body': {'top_k': 20, 'chat_template_kwargs': {'enable_thinking': False}}}\r\n",
      "Executor: unrestricted (timeout: 15s) âš ï¸  UNSAFE MODE\r\n",
      "--------------------------------------------------\r\n",
      "ðŸ“Š Starting metrics monitoring thread for http://127.0.0.1:8080/metrics\r\n",
      "ðŸ“Š Metrics thread started, polling http://127.0.0.1:8080/metrics every 30s\r\n",
      "ðŸ“Š [19:39:02] SGLang: 0R/0Q, Cache 0.0%, Reqs 4\r\n",
      "\r\n",
      "ðŸ“ FIRST TASK REFINEMENT PROMPT (e8686506):\r\n",
      "================================================================================\r\n",
      "SYSTEM:\r\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by reasoning and generating Python code.\r\n",
      "\r\n",
      "USER:\r\n",
      "You are an AI assistant specialized in solving Abstract Reasoning Corpus (ARC-AGI) tasks by generating Python code.\r\n",
      "Your goal is to analyze input-output grid pairs. The outputs were produced by applying a transformation rule to the inputs. Implement the transformation rules as a Python function.\r\n",
      "\r\n",
      "You should analyze:\r\n",
      "1. The task input-output patterns to understand the correct transformation rule\r\n",
      "2. The provided draft program to identify its errors or shortcomings\r\n",
      "3. How to correct and improve the draft to properly solve the task\r\n",
      "You must write code in triple backticks (```python and then ```). You must write a function called 'transform' which takes a single argument, the input grid as 'list[list[int]]', and returns the transformed grid (also as 'list[list[int]]').\r\n",
      "\r\n",
      "You should make sure that you implement a version of the transformation which works in general (at least for all given input-output pairs and test input pairs). The code should NOT hardcode specific predicted outputs. The code should fix bugs in the original draft.\r\n",
      "\r\n",
      "The number in the input grid can be mapped to the following colors: 0:Black; 1:Blue; 2:Red; 3:Green; 4:Yellow; 5:Grey; 6:Pink; 7:Orange; 8:Purple; 9:Brown\r\n",
      "\r\n",
      "\r\n",
      "# Draft program to refine:\r\n",
      "```python\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\r\n",
      "    grid = np.array(grid_lst)\r\n",
      "    unique_colors = np.unique(grid)\r\n",
      "    unique_colors = unique_colors[unique_colors != 0]\r\n",
      "    color_counts = {color: np.sum(grid == color) for color in unique_colors}\r\n",
      "    sorted_colors = sorted(unique_colors, key=lambda color: color_counts[color], reverse=True)\r\n",
      "    if len(sorted_colors) > 1:\r\n",
      "        main_color = sorted_colors[0]\r\n",
      "        secondary_color = sorted_colors[1]\r\n",
      "    else:\r\n",
      "        main_color = sorted_colors[0]\r\n",
      "        secondary_color = 0\r\n",
      "    main_color_coords = np.argwhere(grid == main_color)\r\n",
      "    top, left = np.min(main_color_coords, axis=0)\r\n",
      "    bottom, right = np.max(main_color_coords, axis=0)\r\n",
      "    subgrid = grid[top:bottom + 1, left:right + 1]\r\n",
      "    if len(sorted_colors) > 1:\r\n",
      "        secondary_color_coords = np.argwhere(subgrid == secondary_color)\r\n",
      "        for coord in secondary_color_coords:\r\n",
      "            subgrid[coord[0], coord[1]] = 8\r\n",
      "    subgrid[subgrid == main_color] = secondary_color\r\n",
      "    subgrid[subgrid == 8] = main_color\r\n",
      "    return subgrid.tolist()\r\n",
      "```\r\n",
      "# Task to solve:\r\n",
      "## Input 1 (grid shape: 13 by 13):\r\n",
      "[[8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 8 8 8 4 8 8 8 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 3 3 8 3 3 8 8 4 8 8 8] [8 8 3 8 8 8 3 8 8 8 8 8 8] [8 8 3 8 8 8 3 8 8 8 8 8 8] [8 8 8 3 8 3 8 8 8 8 8 4 8] [8 8 3 3 8 3 3 8 8 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8] [8 8 1 1 1 8 8 8 6 8 8 8 8] [8 8 1 1 1 8 8 8 6 8 8 8 8] [8 8 8 8 8 8 8 8 8 8 8 8 8]]\r\n",
      "## Output 1 (grid shape: 5 by 5):\r\n",
      "[[3 3 4 3 3] [3 1 1 1 3] [3 1 1 1 3] [4 3 6 3 4] [3 3 6 3 3]]\r\n",
      "\r\n",
      "## Input 2 (grid shape: 13 by 13):\r\n",
      "[[3 3 3 3 3 3 3 3 3 3 3 3 3] [3 6 3 3 3 3 3 3 8 8 8 3 3] [3 6 3 3 3 3 3 3 3 8 3 3 3] [3 3 3 1 1 1 3 3 3 8 3 5 3] [3 3 1 3 3 3 1 3 3 3 3 3 3] [3 3 1 1 3 1 1 3 5 3 3 3 3] [3 3 3 1 3 1 3 3 3 3 3 3 3] [3 3 3 2 3 2 3 3 3 3 4 3 3] [3 3 2 2 3 2 2 3 3 3 4 3 3] [3 3 2 3 3 3 2 3 3 4 4 4 3] [3 3 3 2 2 2 3 3 3 3 3 3 3] [3 6 3 3 3 3 3 3 3 3 5 3 3] [3 6 3 3 3 3 3 5 3 3 3 3 3]]\r\n",
      "## Output 2 (grid shape: 5 by 8):\r\n",
      "[[5 1 1 1 5] [1 8 8 8 1] [1 1 8 1 1] [6 1 8 1 6] [6 2 4 2 6] [2 2 4 2 2] [2 4 4 4 2] [5 2 2 2 5]]\r\n",
      "\r\n",
      "## Test Input 1 (grid shape: 15 by 15):\r\n",
      "[[4 1 4 4 4 4 4 4 4 4 4 4 4 4 4] [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4] [4 4 4 4 4 8 8 8 4 4 4 4 6 6 6] [4 4 3 4 8 4 4 4 8 4 4 4 4 6 4] [4 4 3 4 4 8 4 8 4 4 1 4 4 4 4] [4 4 3 4 4 8 4 8 4 4 4 4 4 4 4] [4 4 3 4 4 8 4 8 4 4 4 4 4 4 4] [4 4 4 4 4 8 4 8 4 4 4 4 4 4 4] [4 4 4 4 8 4 4 4 8 4 4 4 1 4 4] [4 4 4 4 4 8 8 8 4 4 4 4 4 4 4] [4 3 4 4 4 4 4 4 4 4 4 4 4 4 4] [4 3 4 4 4 4 4 9 4 4 4 4 4 4 4] [4 3 4 4 4 4 4 9 4 4 4 6 4 4 4] [4 3 4 4 1 4 4 4 4 4 6 6 6 4 4] [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]]\r\n",
      "\r\n",
      "================================================================================\r\n",
      "ðŸš€ Started 480 attempts with 64 workers\r\n",
      "â³ No completions in last 15s â€” 0/480 done; 480 remaining\r\n",
      "âœ… 7b5033c1: 4 attempts | 3 valid outputs, 1 invalid outputs | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ“Š [19:39:32] SGLang: 57R/3Q, Cache 61.8%, Reqs 23, 624.2tok/s\r\n",
      "â³ No completions in last 15s â€” 18/480 done; 462 remaining\r\n",
      "âœ… b0039139: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… d35bdbdc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 4c3d4a41: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 28a6681f: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 46/480 done; 434 remaining\r\n",
      "âœ… e8686506: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… 3dc255db: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 20270e3b: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… dd6b8c4b: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… f931b4a8: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… 97d7923e: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… dbff022c: 4 attempts | 3 valid outputs, 1 execution timeouts | 3 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 78332cb0: 4 attempts | 2 valid outputs, 2 invalid outputs | 2 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ“Š [19:40:02] SGLang: 61R/0Q, Cache 69.2%, Reqs 81, 477.6tok/s\r\n",
      "â³ No completions in last 15s â€” 75/480 done; 405 remaining\r\n",
      "ðŸŒ Slow attempt: bf45cf4b attempt 4 took 60.4s\r\n",
      "âœ… bf45cf4b: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 136b0064 attempt 4 took 62.4s\r\n",
      "âœ… 136b0064: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 1ae2feb7: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 92/480 done; 388 remaining\r\n",
      "âœ… 2b83f449: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "âœ… 31f7f899: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ¥ Health [100 attempts]: Success 97% | ExecTimeout 1% | ExecErr 2% | APITimeout 0% | AvgTime 37.05s\r\n",
      "âœ… 16de56c4: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: faa9f03d attempt 1 took 62.9s\r\n",
      "âœ… 1818057f: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 7666fa5d: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 247ef758: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: eee78d87 attempt 1 took 86.6s\r\n",
      "âœ… eee78d87: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "âœ… 7491f3cf: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ“Š [19:40:32] SGLang: 62R/0Q, Cache 71.2%, Reqs 132, 703.8tok/s\r\n",
      "â³ No completions in last 15s â€” 125/480 done; 355 remaining\r\n",
      "âœ… 271d71e2: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 291dc1e1: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… 6e453dd6: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: faa9f03d attempt 3 took 62.3s\r\n",
      "âœ… 8f3a5a89: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 146/480 done; 334 remaining\r\n",
      "âœ… 135a2760: 4 attempts | 4 valid outputs | 1 train-partial, 3 train-incorrect (best: 50.0% train)\r\n",
      "ðŸŒ Slow attempt: faa9f03d attempt 4 took 63.2s\r\n",
      "âœ… faa9f03d: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 409aa875: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: b9e38dc0 attempt 3 took 70.0s\r\n",
      "âœ… b9e38dc0: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 45a5af55 attempt 1 took 63.2s\r\n",
      "ðŸ“Š [19:41:02] SGLang: 34R/22Q, Cache 78.3%, Reqs 179, 433.4tok/s\r\n",
      "â³ No completions in last 15s â€” 171/480 done; 309 remaining\r\n",
      "âœ… 58f5dbd5: 4 attempts | 2 valid outputs, 2 execution errors | 2 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "âœ… b6f77b65: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… d59b0160: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… db695cfb: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 6ffbe589: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 7b3084d4: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "âœ… e376de54: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 581f7754 attempt 3 took 85.8s\r\n",
      "âœ… 45a5af55: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 190/480 done; 290 remaining\r\n",
      "âœ… 9385bd28: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 446ef5d2: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 53fb4810: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 332f06d7 attempt 3 took 61.9s\r\n",
      "âœ… 332f06d7: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ¥ Health [200 attempts]: Success 96% | ExecTimeout 0% | ExecErr 4% | APITimeout 0% | AvgTime 39.72s\r\n",
      "ðŸŒ Slow attempt: 65b59efc attempt 3 took 62.2s\r\n",
      "âœ… 65b59efc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:41:32] SGLang: 52R/11Q, Cache 79.5%, Reqs 206, 555.6tok/s\r\n",
      "â³ No completions in last 15s â€” 202/480 done; 278 remaining\r\n",
      "ðŸŒ Slow attempt: db0c5428 attempt 1 took 60.2s\r\n",
      "âœ… 4e34c42c: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 9bbf930d attempt 1 took 63.4s\r\n",
      "âœ… 80a900e0: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7ed72f31 attempt 1 took 64.8s\r\n",
      "ðŸŒ Slow attempt: 71e489b6 attempt 1 took 68.0s\r\n",
      "ðŸŒ Slow attempt: c7f57c3e attempt 2 took 61.0s\r\n",
      "â³ No completions in last 15s â€” 226/480 done; 254 remaining\r\n",
      "ðŸŒ Slow attempt: 581f7754 attempt 4 took 113.9s\r\n",
      "âœ… 581f7754: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 5545f144 attempt 1 took 146.6s\r\n",
      "âœ… 7ed72f31: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 9bbf930d attempt 2 took 63.3s\r\n",
      "ðŸŒ Slow attempt: 898e7135 attempt 1 took 67.7s\r\n",
      "ðŸŒ Slow attempt: 8698868d attempt 1 took 69.2s\r\n",
      "âœ… 800d221b: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… abc82100: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… edb79dae: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: da515329 attempt 1 took 75.7s\r\n",
      "ðŸ“Š [19:42:02] SGLang: 30R/30Q, Cache 80.0%, Reqs 254, 314.1tok/s\r\n",
      "â³ No completions in last 15s â€” 247/480 done; 233 remaining\r\n",
      "âœ… dfadab01: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… 9bbf930d: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 71e489b6 attempt 3 took 64.7s\r\n",
      "âœ… 71e489b6: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: c7f57c3e attempt 3 took 70.3s\r\n",
      "âœ… c7f57c3e: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: db0c5428 attempt 2 took 81.7s\r\n",
      "ðŸŒ Slow attempt: 898e7135 attempt 3 took 67.5s\r\n",
      "âœ… 21897d95: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 35ab12c3 attempt 4 took 63.3s\r\n",
      "âœ… 35ab12c3: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "âœ… da515329: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 263/480 done; 217 remaining\r\n",
      "ðŸŒ Slow attempt: 898e7135 attempt 4 took 60.4s\r\n",
      "âœ… 898e7135: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: de809cff attempt 1 took 60.5s\r\n",
      "ðŸŒ Slow attempt: 8698868d attempt 4 took 71.4s\r\n",
      "âœ… 8698868d: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 38007db0 attempt 1 took 67.4s\r\n",
      "ðŸŒ Slow attempt: db0c5428 attempt 4 took 82.9s\r\n",
      "âœ… db0c5428: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 58490d8a attempt 3 took 93.6s\r\n",
      "âœ… 58490d8a: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸ“Š [19:42:32] SGLang: 33R/22Q, Cache 73.8%, Reqs 285, 409.7tok/s\r\n",
      "â³ No completions in last 15s â€” 280/480 done; 200 remaining\r\n",
      "âœ… 7b80bb43: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 1 took 68.0s\r\n",
      "âœ… 8e5c0c38: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 89565ca0: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 1 took 62.7s\r\n",
      "âœ… f560132c: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: fc7cae8d attempt 2 took 64.0s\r\n",
      "âœ… 3a25b0d8: 4 attempts | 3 valid outputs, 1 invalid outputs | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: de809cff attempt 2 took 67.4s\r\n",
      "â³ No completions in last 15s â€” 295/480 done; 185 remaining\r\n",
      "âœ… fc7cae8d: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 38007db0 attempt 3 took 60.6s\r\n",
      "ðŸŒ Slow attempt: 38007db0 attempt 2 took 70.8s\r\n",
      "âœ… 38007db0: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ¥ Health [300 attempts]: Success 95% | ExecTimeout 0% | ExecErr 4% | APITimeout 0% | AvgTime 50.00s\r\n",
      "âœ… 269e22fb: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 1 took 77.9s\r\n",
      "ðŸŒ Slow attempt: 142ca369 attempt 2 took 69.0s\r\n",
      "âœ… 142ca369: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: de809cff attempt 3 took 70.0s\r\n",
      "âœ… de809cff: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 3 took 63.6s\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 3 took 65.9s\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 2 took 79.0s\r\n",
      "ðŸ“Š [19:43:02] SGLang: 40R/23Q, Cache 77.0%, Reqs 316, 450.0tok/s\r\n",
      "â³ No completions in last 15s â€” 308/480 done; 172 remaining\r\n",
      "ðŸŒ Slow attempt: 88bcf3b4 attempt 4 took 64.8s\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 1 took 94.0s\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 2 took 81.3s\r\n",
      "ðŸŒ Slow attempt: 5545f144 attempt 4 took 195.9s\r\n",
      "âœ… 5545f144: 4 attempts | 2 valid outputs, 1 execution errors, 1 max length | 2 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 4 took 64.5s\r\n",
      "ðŸŒ Slow attempt: 88bcf3b4 attempt 2 took 87.4s\r\n",
      "âœ… 88bcf3b4: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a6f40cea attempt 3 took 80.7s\r\n",
      "âœ… a6f40cea: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 2 took 87.3s\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 2 took 89.0s\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 3 took 83.4s\r\n",
      "â³ No completions in last 15s â€” 331/480 done; 149 remaining\r\n",
      "ðŸŒ Slow attempt: 2ba387bc attempt 4 took 77.2s\r\n",
      "âœ… 2ba387bc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4a21e3da attempt 4 took 74.2s\r\n",
      "âœ… 4a21e3da: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… a251c730: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7b0280bc attempt 4 took 74.0s\r\n",
      "âœ… 7b0280bc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a47bf94d attempt 1 took 65.6s\r\n",
      "âœ… 6e4f6532: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "âœ… 88e364bc: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 1 took 80.1s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 1 took 78.6s\r\n",
      "ðŸ“Š [19:43:33] SGLang: 31R/30Q, Cache 82.5%, Reqs 349, 350.2tok/s\r\n",
      "â³ No completions in last 15s â€” 345/480 done; 135 remaining\r\n",
      "ðŸŒ Slow attempt: 64efde09 attempt 1 took 69.1s\r\n",
      "âœ… 36a08778: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 1 took 75.9s\r\n",
      "âœ… a47bf94d: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 1 took 84.8s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 2 took 73.9s\r\n",
      "ðŸŒ Slow attempt: 5dbc8537 attempt 4 took 195.0s\r\n",
      "âœ… 5dbc8537: 4 attempts | 3 valid outputs, 1 max length | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 1 took 91.0s\r\n",
      "â³ No completions in last 15s â€” 356/480 done; 124 remaining\r\n",
      "ðŸŒ Slow attempt: 2d0172a1 attempt 3 took 63.6s\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 2 took 73.0s\r\n",
      "âœ… 2d0172a1: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 1 took 89.5s\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 2 took 81.4s\r\n",
      "âœ… 64efde09: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 1 took 88.0s\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 2 took 84.7s\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 3 took 69.2s\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 2 took 89.6s\r\n",
      "â³ No completions in last 15s â€” 368/480 done; 112 remaining\r\n",
      "ðŸ“Š [19:44:03] SGLang: 26R/37Q, Cache 84.0%, Reqs 372, 332.4tok/s\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 2 took 97.4s\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 3 took 77.3s\r\n",
      "ðŸŒ Slow attempt: 2c181942 attempt 4 took 61.0s\r\n",
      "âœ… 2c181942: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 4 took 63.5s\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 2 took 90.8s\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 4 took 63.2s\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 3 took 75.7s\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 3 took 90.0s\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 3 took 86.0s\r\n",
      "ðŸŒ Slow attempt: cb2d8a2c attempt 3 took 86.7s\r\n",
      "âœ… cb2d8a2c: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 2 took 93.5s\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 3 took 83.4s\r\n",
      "ðŸŒ Slow attempt: a395ee82 attempt 4 took 68.5s\r\n",
      "âœ… a395ee82: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: e12f9a14 attempt 1 took 62.9s\r\n",
      "â³ No completions in last 15s â€” 385/480 done; 95 remaining\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 1 took 64.4s\r\n",
      "ðŸŒ Slow attempt: 67e490f4 attempt 4 took 88.2s\r\n",
      "âœ… 67e490f4: 4 attempts | 2 valid outputs, 1 execution errors, 1 invalid outputs | 2 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: b10624e5 attempt 2 took 62.1s\r\n",
      "ðŸŒ Slow attempt: cbebaa4b attempt 4 took 85.5s\r\n",
      "âœ… cbebaa4b: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 8b9c3697 attempt 4 took 88.9s\r\n",
      "âœ… 8b9c3697: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 395/480 done; 85 remaining\r\n",
      "ðŸ“Š [19:44:33] SGLang: 23R/38Q, Cache 84.2%, Reqs 399, 327.0tok/s\r\n",
      "ðŸŒ Slow attempt: b5ca7ac4 attempt 4 took 87.7s\r\n",
      "âœ… b5ca7ac4: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: e87109e9 attempt 2 took 67.0s\r\n",
      "âœ… e87109e9: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸ¥ Health [400 attempts]: Success 96% | ExecTimeout 0% | ExecErr 4% | APITimeout 0% | AvgTime 70.22s\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 1 took 77.9s\r\n",
      "âœ… c4d067a0: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 1 took 92.6s\r\n",
      "âœ… 8f215267: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 405/480 done; 75 remaining\r\n",
      "ðŸŒ Slow attempt: 8b7bacbf attempt 4 took 98.0s\r\n",
      "âœ… 8b7bacbf: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 1 took 99.6s\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 1 took 103.8s\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 2 took 82.9s\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 2 took 78.3s\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 2 took 96.9s\r\n",
      "â³ No completions in last 15s â€” 413/480 done; 67 remaining\r\n",
      "ðŸ“Š [19:45:03] SGLang: 18R/46Q, Cache 86.2%, Reqs 417, 229.1tok/s\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 1 took 111.3s\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 2 took 94.3s\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 1 took 114.6s\r\n",
      "âœ… 20a9e565: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 1 took 110.4s\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 1 took 117.6s\r\n",
      "â³ No completions in last 15s â€” 421/480 done; 59 remaining\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 3 took 85.5s\r\n",
      "ðŸŒ Slow attempt: b10624e5 attempt 3 took 94.7s\r\n",
      "âœ… b10624e5: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 3 took 97.5s\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 3 took 95.5s\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 1 took 126.9s\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 2 took 113.3s\r\n",
      "â³ No completions in last 15s â€” 427/480 done; 53 remaining\r\n",
      "ðŸ“Š [19:45:33] SGLang: 17R/33Q, Cache 87.2%, Reqs 433, 205.2tok/s\r\n",
      "ðŸŒ Slow attempt: 5961cc34 attempt 4 took 79.8s\r\n",
      "âœ… 5961cc34: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 2 took 125.0s\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 2 took 127.8s\r\n",
      "ðŸŒ Slow attempt: 3e6067c3 attempt 4 took 81.0s\r\n",
      "âœ… 3e6067c3: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 2 took 127.2s\r\n",
      "ðŸŒ Slow attempt: 4c7dc4dd attempt 4 took 94.9s\r\n",
      "âœ… 4c7dc4dd: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 3 took 104.4s\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 1 took 78.0s\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 3 took 114.0s\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 2 took 68.3s\r\n",
      "â³ No completions in last 15s â€” 437/480 done; 43 remaining\r\n",
      "ðŸŒ Slow attempt: 221dfab4 attempt 4 took 99.4s\r\n",
      "âœ… 221dfab4: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 7c66cb00 attempt 2 took 80.7s\r\n",
      "ðŸŒ Slow attempt: 4c416de3 attempt 1 took 215.3s\r\n",
      "âœ… 4c416de3: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 1 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 2 took 139.2s\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 3 took 65.4s\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 2 took 80.2s\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 3 took 134.7s\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 3 took 77.8s\r\n",
      "ðŸŒ Slow attempt: 16b78196 attempt 4 took 105.9s\r\n",
      "âœ… 16b78196: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 446/480 done; 34 remaining\r\n",
      "ðŸ“Š [19:46:03] SGLang: 17R/14Q, Cache 76.8%, Reqs 453, 247.6tok/s\r\n",
      "ðŸŒ Slow attempt: 7c66cb00 attempt 4 took 65.9s\r\n",
      "ðŸŒ Slow attempt: 7c66cb00 attempt 3 took 84.3s\r\n",
      "âœ… 7c66cb00: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 2 took 141.8s\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 2 took 95.6s\r\n",
      "ðŸŒ Slow attempt: 195c6913 attempt 4 took 73.3s\r\n",
      "âœ… 195c6913: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 3 took 85.8s\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 3 took 139.6s\r\n",
      "â³ No completions in last 15s â€” 453/480 done; 27 remaining\r\n",
      "ðŸŒ Slow attempt: aa4ec2a5 attempt 4 took 130.5s\r\n",
      "âœ… aa4ec2a5: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 1 took 117.9s\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 3 took 148.6s\r\n",
      "ðŸŒ Slow attempt: 62593bfd attempt 4 took 130.5s\r\n",
      "âœ… 62593bfd: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 13e47133 attempt 4 took 135.5s\r\n",
      "âœ… 13e47133: 4 attempts | 3 valid outputs, 1 execution errors | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 4 took 79.4s\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 1 took 132.6s\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 3 took 149.4s\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 4 took 91.1s\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 3 took 105.4s\r\n",
      "â³ No completions in last 15s â€” 463/480 done; 17 remaining\r\n",
      "ðŸ“Š [19:46:33] SGLang: 8R/6Q, Cache 48.2%, Reqs 469, 143.0tok/s\r\n",
      "ðŸŒ Slow attempt: b99e7126 attempt 2 took 117.7s\r\n",
      "âœ… b99e7126: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a25697e4 attempt 4 took 140.1s\r\n",
      "âœ… a25697e4: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 2 took 126.6s\r\n",
      "ðŸŒ Slow attempt: d8e07eb2 attempt 1 took 137.4s\r\n",
      "âœ… d8e07eb2: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 2 trans) (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 4 took 110.9s\r\n",
      "ðŸŒ Slow attempt: a32d8b75 attempt 3 took 126.1s\r\n",
      "âœ… a32d8b75: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 0934a4d8 attempt 4 took 149.4s\r\n",
      "âœ… 0934a4d8: 4 attempts | 4 valid outputs | 4 train-incorrect (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 470/480 done; 10 remaining\r\n",
      "â³ No completions in last 15s â€” 470/480 done; 10 remaining\r\n",
      "ðŸ“Š [19:47:03] SGLang: 13R/0Q, Cache 51.5%, Reqs 474, 164.7tok/s\r\n",
      "ðŸŒ Slow attempt: e12f9a14 attempt 3 took 190.4s\r\n",
      "âœ… e12f9a14: 4 attempts | 3 valid outputs, 1 max length | 3 train-incorrect (best: 0.0% train)\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 1 took 159.6s\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 4 took 123.2s\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 2 took 152.9s\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 1 took 173.6s\r\n",
      "â³ No completions in last 15s â€” 475/480 done; 5 remaining\r\n",
      "ðŸŒ Slow attempt: 981571dc attempt 3 took 147.0s\r\n",
      "âœ… 981571dc: 4 attempts | 4 valid outputs | 4 train-partial (best: 75.0% train)\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 4 took 144.0s\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 2 took 166.5s\r\n",
      "ðŸŒ Slow attempt: e3721c99 attempt 3 took 158.6s\r\n",
      "âœ… e3721c99: 4 attempts | 4 valid outputs | 4 train-incorrect (of which 4 trans) (best: 0.0% train)\r\n",
      "â³ No completions in last 15s â€” 479/480 done; 1 remaining\r\n",
      "ðŸ“Š [19:47:33] SGLang: 4R/0Q, Cache 17.0%, Reqs 483, 56.9tok/s\r\n",
      "â³ No completions in last 15s â€” 479/480 done; 1 remaining\r\n",
      "â³ No completions in last 15s â€” 479/480 done; 1 remaining\r\n",
      "ðŸ“Š [19:48:03] SGLang: 1R/0Q, Cache 9.2%, Reqs 483, 14.4tok/s\r\n",
      "ðŸŒ Slow attempt: 9aaea919 attempt 4 took 183.7s\r\n",
      "âœ… 9aaea919: 4 attempts | 3 valid outputs, 1 max length | 3 train-incorrect (of which 3 trans) (best: 0.0% train)\r\n",
      "â³ Progress: 480/480 attempts done; 0 remaining\r\n",
      "âœ… All 480 attempts completed in 545.1s\r\n",
      "ðŸ“Š Final status: 480 successful, 0 failed, 0 cancelled\r\n",
      "Converting task results to summary format...\r\n",
      "âœ… Converted results for 120/120 tasks\r\n",
      "\r\n",
      "==================================================\r\n",
      "SUBMIT MODE SUMMARY\r\n",
      "==================================================\r\n",
      "Dataset: arc-prize-2025\r\n",
      "Subset: evaluation\r\n",
      "Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/Soar-qwen-14b-FP8-Dynamic\r\n",
      "Total tasks processed: 120\r\n",
      "Total time: 545.1s\r\n",
      "Successful API calls: 120/120 (100.0%)\r\n",
      "Total tokens used: 3,089,574\r\n",
      "Total cost: $0.542281\r\n",
      "\r\n",
      "ðŸ“Š RESPONSE METRICS:\r\n",
      "  Total responses: 480\r\n",
      "  Code extracted: 476/480 (99.2%)\r\n",
      "  Max length responses: 4/480 (0.8%)\r\n",
      "  Timeout responses: 0/480 (0.0%)\r\n",
      "  API failure responses: 0/480 (0.0%)\r\n",
      "  Execution timeout responses (of all attempts): 1/480 (0.2%)\r\n",
      "  Execution error responses (of all attempts): 20/480 (4.2%)\r\n",
      "\r\n",
      "ðŸ“Š TRAIN METRICS:\r\n",
      "  All train correct: 0/120 (0.0%)\r\n",
      "  Min 1 train correct: 2/120 (1.7%)\r\n",
      "\r\n",
      "âš ï¸  Note: Test accuracy metrics unavailable in SUBMIT mode (no test outputs)\r\n",
      "\r\n",
      "ðŸŽ¯ To generate submission file, run:\r\n",
      "   uv run python llm_python/generate_submission.py --dataset arc-prize-2025 --subset evaluation\r\n",
      "All sampled programs saved to /kaggle/working/20250914_193858__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\r\n",
      "Graceful exit starting, process will be force terminated in 10 seconds.\r\n"
     ]
    }
   ],
   "source": [
    "# Second Inference Run - ENABLE_REFINEMENT\n",
    "# Only runs when ENABLE_REFINEMENT=true\n",
    "\n",
    "import glob\n",
    "\n",
    "if ENABLE_REFINEMENT:\n",
    "    print(\"ðŸ”„ Running SECOND inference (ENABLE_REFINEMENT mode)\")\n",
    "    \n",
    "    if not IS_KAGGLE:\n",
    "        %cd /workspace/arc-agi-2025\n",
    "\n",
    "    # Use SECOND_ATTEMPTS and SECOND_WORKERS for second inference\n",
    "    MAX_ATTEMPTS = SECOND_ATTEMPTS\n",
    "    MAX_WORKERS  = SECOND_WORKERS\n",
    "\n",
    "    SUBSET = \"test\" if IS_RERUN else \"evaluation\"\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n",
    "\n",
    "    print(f\"ENABLE_REFINEMENT Second Run â†’ {'competition' if IS_RERUN else 'dev'} | attempts={MAX_ATTEMPTS} | workers={MAX_WORKERS} | subset={SUBSET}\")\n",
    "\n",
    "    # ðŸ”‘ Find the latest parquet file in inference_dir\n",
    "    parquet_files = glob.glob(os.path.join(inference_dir, \"*.parquet\"))\n",
    "    if not parquet_files:\n",
    "        raise FileNotFoundError(f\"No parquet files found in {inference_dir}\")\n",
    "    latest_parquet = max(parquet_files, key=os.path.getctime)\n",
    "    print(f\"ðŸ“‚ Using latest parquet file for refinement: {latest_parquet}\")\n",
    "\n",
    "    # Build the command\n",
    "    cmd_args = [\n",
    "        \"uv\", \"run\", \"python\", \"-u\", \"-m\", \"llm_python.run_arc_tasks_soar\",\n",
    "        \"--dataset\", DATASET,\n",
    "        \"--subset\", SUBSET,\n",
    "        \"--max_workers\", str(MAX_WORKERS),\n",
    "        \"--max_attempts\", str(MAX_ATTEMPTS),\n",
    "        \"--model\", model_name,\n",
    "        \"--base-url\", \"http://127.0.0.1:8080/v1\",\n",
    "        \"--unsafe-executor\",\n",
    "        \"--max-tokens\", \"2000\",\n",
    "        \"--qwen-no-think\",\n",
    "        \"--refinement-ds\", latest_parquet,   # ðŸ‘ˆ add parquet path here\n",
    "        \"--include-outputs\"\n",
    "    ]\n",
    "\n",
    "    # Add parquet output directory if set\n",
    "    if os.getenv(\"ARC_PROGRAMS_PARQUET\"):\n",
    "      cmd_args.extend([\"--parquet-output-dir\", os.getenv(\"ARC_PROGRAMS_PARQUET\")])\n",
    "\n",
    "    print(f\"Running ENABLE_REFINEMENT second inference: {' '.join(cmd_args)}\")\n",
    "\n",
    "    # Handle output redirection properly\n",
    "    if IS_RERUN or not IS_KAGGLE:\n",
    "        # For quiet mode, redirect to file using subprocess\n",
    "        import subprocess\n",
    "        log_file_path = f\"{SUBMIT_DIR}/run_second.log\"\n",
    "        print(f\"ðŸ“ Logging ENABLE_REFINEMENT second run output to: {log_file_path}\")\n",
    "        \n",
    "        with open(log_file_path, \"w\") as log_file:\n",
    "            process = subprocess.Popen(\n",
    "                cmd_args,\n",
    "                stdout=log_file,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                cwd=os.getcwd()\n",
    "            )\n",
    "            \n",
    "            # Wait for completion\n",
    "            print(\"â³ Running ENABLE_REFINEMENT second inference (output being written to log file)...\")\n",
    "            return_code = process.wait()\n",
    "            \n",
    "        if return_code == 0:\n",
    "            print(f\"âœ… ENABLE_REFINEMENT second inference completed successfully. Check {log_file_path} for details.\")\n",
    "        else:\n",
    "            print(f\"âŒ ENABLE_REFINEMENT second inference failed with return code {return_code}\")\n",
    "            print(f\"ðŸ“ Check {log_file_path} for error details\")\n",
    "            # Show last few lines of log\n",
    "            !tail -n 20 {log_file_path}\n",
    "    else:\n",
    "        # For interactive mode, show output directly\n",
    "        cmd = \" \".join(cmd_args)\n",
    "        print(f\"Running ENABLE_REFINEMENT second inference: {cmd}\\n\")\n",
    "        !{cmd}\n",
    "\n",
    "else:\n",
    "    print(\"ðŸ”„ Skipping second inference (ENABLE_REFINEMENT=false)\")\n",
    "    print(\"   â†’ Standard mode runs first inference only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d971bad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:48:09.929901Z",
     "iopub.status.busy": "2025-09-14T19:48:09.929651Z",
     "iopub.status.idle": "2025-09-14T19:48:20.104571Z",
     "shell.execute_reply": "2025-09-14T19:48:20.104008Z"
    },
    "papermill": {
     "duration": 10.205901,
     "end_time": "2025-09-14T19:48:20.105564",
     "exception": false,
     "start_time": "2025-09-14T19:48:09.899663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Generating submission from the two most recent parquet files...\n",
      "Running submission generation: uv run python -m llm_python.generate_submission --parquet-path /kaggle/working --n-files 2 --dataset arc-prize-2025 --subset evaluation --output-dir /kaggle/working --debug\n",
      "ðŸ“‚ Looking for parquet files in: /kaggle/working\n",
      "âœ… Submission generation completed successfully!\n",
      "ðŸ” Selected 2 most recent parquet files from /kaggle/working:\n",
      "  â€¢ 20250914_193858__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet (modified: 2025-09-14 19:48:09)\n",
      "  â€¢ 20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet (modified: 2025-09-14 19:35:42)\n",
      "âœ… Loaded 450 rows from /kaggle/working/20250914_193858__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\n",
      "âœ… Loaded 443 rows from /kaggle/working/20250914_192704__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_Soar-qwen-14b-FP8-Dynamic_arc-prize-2025_evaluation.parquet\n",
      "ðŸ“Š Combined data: 893 total rows from 2 files\n",
      "ðŸ“Š Transduction summary: 200/893 marked as transductive after recomputation\n",
      "ðŸŽ¯ Generating submission for 120 tasks from arc-prize-2025/evaluation\n",
      "\n",
      "âœ… Submission files created:\n",
      "ðŸ“Š Summary:\n",
      "  Total tasks in dataset: 120\n",
      "  Tasks with predictions: 120\n",
      "  Tasks with duplicated attempts: 2\n",
      "  Tasks with empty fallback: 0\n",
      "  Official file: /kaggle/working/submission.json\n",
      "  Backup file: /kaggle/working/submission_arc-prize-2025_evaluation_193858__20250914_194819.json\n",
      "â„¹ï¸ Note: Run separate validation if needed\n",
      "ðŸŽ¯ Submission generation complete: /kaggle/working/submission.json\n",
      "\n",
      "ðŸ“ Submission file: /kaggle/working/submission.json\n"
     ]
    }
   ],
   "source": [
    "# Generate submission using the two most recent parquet files\n",
    "if os.environ.get(\"SUBMIT\", \"false\").lower() == \"true\":\n",
    "    print(\"ðŸŽ¯ Generating submission from the two most recent parquet files...\")\n",
    "    \n",
    "    import subprocess\n",
    "    \n",
    "    output_dir = str(SUBMIT_DIR)\n",
    "    \n",
    "    # Command to generate submission using the two most recent parquet files\n",
    "    submission_cmd = [\n",
    "        \"uv\", \"run\", \"python\", \"-m\", \"llm_python.generate_submission\",\n",
    "        \"--parquet-path\", inference_dir,\n",
    "        \"--n-files\", \"2\",\n",
    "        \"--dataset\", DATASET,\n",
    "        \"--subset\", SUBSET,\n",
    "        \"--output-dir\", output_dir,\n",
    "        \"--debug\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running submission generation: {' '.join(submission_cmd)}\")\n",
    "    print(f\"ðŸ“‚ Looking for parquet files in: {inference_dir}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            submission_cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300,  # 5 minute timeout\n",
    "            cwd=os.getcwd()\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… Submission generation completed successfully!\")\n",
    "            print(result.stdout)\n",
    "            \n",
    "            # Update submit_dir to point to the generated file\n",
    "            submit_dir = f\"{output_dir}/submission.json\"\n",
    "            print(f\"ðŸ“ Submission file: {submit_dir}\")\n",
    "        else:\n",
    "            print(f\"âŒ Submission generation failed with return code {result.returncode}\")\n",
    "            print(f\"STDOUT: {result.stdout}\")\n",
    "            print(f\"STDERR: {result.stderr}\")\n",
    "            # Fallback to default submission path\n",
    "            submit_dir = f\"{SUBMIT_DIR}/submission.json\"\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"â±ï¸ Submission generation timed out\")\n",
    "        submit_dir = f\"{SUBMIT_DIR}/submission.json\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Submission generation error: {e}\")\n",
    "        submit_dir = f\"{SUBMIT_DIR}/submission.json\"\n",
    "else:\n",
    "    print(\"ðŸ“ Skipping submission generation (SUBMIT=false)\")\n",
    "    submit_dir = f\"{SUBMIT_DIR}/submission.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae7a2ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:48:20.165095Z",
     "iopub.status.busy": "2025-09-14T19:48:20.164875Z",
     "iopub.status.idle": "2025-09-14T19:48:21.429021Z",
     "shell.execute_reply": "2025-09-14T19:48:21.428293Z"
    },
    "papermill": {
     "duration": 1.295028,
     "end_time": "2025-09-14T19:48:21.430229",
     "exception": false,
     "start_time": "2025-09-14T19:48:20.135201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Validating submission file: /kaggle/working/submission.json\r\n",
      "\r\n",
      "ðŸ” VALIDATING SUBMISSION: /kaggle/working/submission.json\r\n",
      "ðŸ“Š Validation Results:\r\n",
      "  Total tasks: 120\r\n",
      "  Total predictions: 172\r\n",
      "  Empty predictions ([[0,0],[0,0]]): 0\r\n",
      "âœ… VALIDATION PASSED - No structural errors found\r\n",
      "ðŸŽ¯ Submission file is ready for competition!\r\n",
      "ðŸ“‚ Loading submission: /kaggle/working/submission.json\r\n",
      "ðŸ” Scoring against arc-prize-2025/evaluation\r\n",
      "============================================================\r\n",
      "SUBMISSION SCORING RESULTS\r\n",
      "============================================================\r\n",
      "Dataset: arc-prize-2025\r\n",
      "Subset: evaluation\r\n",
      "Reference tasks: 120\r\n",
      "Tasks scored: 120\r\n",
      "Total predictions: 344\r\n",
      "\r\n",
      "ðŸ“Š PREDICTION-LEVEL METRICS:\r\n",
      "  Pass@1 (first attempt): 1/344 (0.3%)\r\n",
      "  Pass@2 (either attempt): 1/344 (0.3%)\r\n",
      "\r\n",
      "ðŸ“Š TASK-LEVEL METRICS:\r\n",
      "  Tasks Pass@1 (all outputs correct on first attempt): 1/120 (0.8%)\r\n",
      "  Tasks Pass@2 (all outputs correct on either attempt): 1/120 (0.8%)\r\n"
     ]
    }
   ],
   "source": [
    "# Only score in dev/commit runs\n",
    "if SCORE and not IS_RERUN:\n",
    "    !uv run python -m llm_python.score_submission --submission {submit_dir} --dataset {DATASET} --subset {SUBSET}\n",
    "else:\n",
    "    print(\"Skipping local scoring (competition rerun or SCORE=False).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cb5561b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T19:48:21.490664Z",
     "iopub.status.busy": "2025-09-14T19:48:21.490402Z",
     "iopub.status.idle": "2025-09-14T19:48:21.548679Z",
     "shell.execute_reply": "2025-09-14T19:48:21.548130Z"
    },
    "papermill": {
     "duration": 0.089127,
     "end_time": "2025-09-14T19:48:21.549571",
     "exception": false,
     "start_time": "2025-09-14T19:48:21.460444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Cleaning up server and resources...\n",
      "Server stopped and CUDA memory cleared.\n"
     ]
    }
   ],
   "source": [
    "# Final cleanup - stop server and free resources\n",
    "if START_SERVER and 'full_cleanup' in globals():\n",
    "    print(\"ðŸ§¹ Cleaning up server and resources...\")\n",
    "    full_cleanup()\n",
    "else:\n",
    "    print(\"ðŸ” No server cleanup needed (START_SERVER=False or cleanup function not available)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 8063856,
     "isSourceIdPinned": true,
     "sourceId": 13032060,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8211105,
     "isSourceIdPinned": false,
     "sourceId": 13038659,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 261818576,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1863.748367,
   "end_time": "2025-09-14T19:48:24.194420",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-14T19:17:20.446053",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
