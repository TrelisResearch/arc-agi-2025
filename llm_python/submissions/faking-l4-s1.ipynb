{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca837b4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-16T18:08:24.089997Z",
     "iopub.status.busy": "2025-08-16T18:08:24.089511Z",
     "iopub.status.idle": "2025-08-16T18:08:24.097572Z",
     "shell.execute_reply": "2025-08-16T18:08:24.097066Z"
    },
    "papermill": {
     "duration": 0.013124,
     "end_time": "2025-08-16T18:08:24.098514",
     "exception": false,
     "start_time": "2025-08-16T18:08:24.085390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Development run - setting short timeout for testing\n",
      "‚è∞ Global timeout set to 60s (0.0 hours)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "IS_RERUN = os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\", \"\").lower() == \"true\"\n",
    "\n",
    "# Set global timeout based on whether this is a competition rerun\n",
    "if IS_RERUN:\n",
    "  # Competition rerun - FULL timeout for actual scoring\n",
    "  timeout_seconds = 39600  # 11 hours\n",
    "  print(\"üèÜ Competition rerun detected - setting FULL timeout for scoring\")\n",
    "else:\n",
    "  # Development/testing - short timeout\n",
    "  timeout_seconds = 60  # 1 minute\n",
    "  print(\"üîß Development run - setting short timeout for testing\")\n",
    "\n",
    "os.environ['GLOBAL_TIMEOUT'] = str(timeout_seconds)\n",
    "print(f\"‚è∞ Global timeout set to {timeout_seconds}s ({timeout_seconds/3600:.1f} hours)\")\n",
    "\n",
    "START_SERVER = True\n",
    "TEST_INFERENCE = False #set false unless you want to see inference hitting the endpoint, before the task runner\n",
    "SUBMIT = True #to run the task runner\n",
    "SCORE = True # score if not a competition rerun\n",
    "\n",
    "os.environ[\"ARC_DATA_ROOT\"]  = \"/kaggle/input\"\n",
    "\n",
    "# to have the task runner generate a submission file\n",
    "os.environ[\"SUBMIT\"] = \"true\"\n",
    "\n",
    "# the directory for where the submission.json file will go\n",
    "os.environ[\"SUBMIT_DIR\"] = \"/kaggle/working\"\n",
    "\n",
    "# location of the db (current just saving here, not reading from it yet)\n",
    "os.environ[\"ARC_PROGRAMS_DB\"]=\"/kaggle/working/local.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2de8231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:08:24.104871Z",
     "iopub.status.busy": "2025-08-16T18:08:24.104429Z",
     "iopub.status.idle": "2025-08-16T18:08:37.323838Z",
     "shell.execute_reply": "2025-08-16T18:08:37.323246Z"
    },
    "papermill": {
     "duration": 13.223512,
     "end_time": "2025-08-16T18:08:37.324918",
     "exception": false,
     "start_time": "2025-08-16T18:08:24.101406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "PyTorch version: 2.7.1+cu126\n",
      "CUDA version (PyTorch): 12.6\n",
      "CUDA available: True\n",
      "NumPy version: 1.26.4\n",
      "GPU count: 4\n",
      "GPU name: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version (PyTorch): {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "   print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "   print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3311407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:08:37.331753Z",
     "iopub.status.busy": "2025-08-16T18:08:37.331456Z",
     "iopub.status.idle": "2025-08-16T18:08:37.334296Z",
     "shell.execute_reply": "2025-08-16T18:08:37.333810Z"
    },
    "papermill": {
     "duration": 0.007118,
     "end_time": "2025-08-16T18:08:37.335136",
     "exception": false,
     "start_time": "2025-08-16T18:08:37.328018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls ../input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19c9afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:08:37.341311Z",
     "iopub.status.busy": "2025-08-16T18:08:37.340949Z",
     "iopub.status.idle": "2025-08-16T18:08:41.106357Z",
     "shell.execute_reply": "2025-08-16T18:08:41.105722Z"
    },
    "papermill": {
     "duration": 3.769582,
     "end_time": "2025-08-16T18:08:41.107450",
     "exception": false,
     "start_time": "2025-08-16T18:08:37.337868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang version: 0.4.9.post3\n",
      "FlashInfer version: 0.2.7.post1\n"
     ]
    }
   ],
   "source": [
    "import sglang\n",
    "print(\"SGLang version:\", sglang.__version__)\n",
    "\n",
    "try:\n",
    "    import flashinfer\n",
    "    print(\"FlashInfer version:\", flashinfer.__version__)\n",
    "except ImportError:\n",
    "    print(\"FlashInfer not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7788cf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:08:41.114361Z",
     "iopub.status.busy": "2025-08-16T18:08:41.113829Z",
     "iopub.status.idle": "2025-08-16T18:08:41.572052Z",
     "shell.execute_reply": "2025-08-16T18:08:41.571472Z"
    },
    "papermill": {
     "duration": 0.462872,
     "end_time": "2025-08-16T18:08:41.573355",
     "exception": false,
     "start_time": "2025-08-16T18:08:41.110483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure that ptxas can access writable directories\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Copy PTXAS and other binaries\n",
    "os.makedirs(\"/kaggle/working/bin\", exist_ok=True)\n",
    "for binary in [\"ptxas\", \"cuobjdump\", \"nvdisasm\"]:\n",
    "    src = f\"/kaggle/usr/lib/sglang_utility/triton/backends/nvidia/bin/{binary}\"  # Fixed path\n",
    "    dst = f\"/kaggle/working/bin/{binary}\"\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "        os.chmod(dst, 0o755)\n",
    "\n",
    "# Set environment variables\n",
    "env = os.environ.copy()\n",
    "env[\"TRITON_PTXAS_PATH\"] = \"/kaggle/working/bin/ptxas\"\n",
    "env[\"PATH\"] = f\"/kaggle/working/bin:{env.get('PATH', '')}\"\n",
    "env[\"TRITON_CACHE_DIR\"] = \"/kaggle/working/.triton\"\n",
    "env[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.makedirs(\"/kaggle/working/.triton\", exist_ok=True)\n",
    "\n",
    "# Apply the environment variables to the current process\n",
    "os.environ.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6fc525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:08:41.580426Z",
     "iopub.status.busy": "2025-08-16T18:08:41.579921Z",
     "iopub.status.idle": "2025-08-16T18:11:41.864050Z",
     "shell.execute_reply": "2025-08-16T18:11:41.863299Z"
    },
    "papermill": {
     "duration": 180.288617,
     "end_time": "2025-08-16T18:11:41.865164",
     "exception": false,
     "start_time": "2025-08-16T18:08:41.576547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started sglang server PID=37 | logging to /kaggle/working/sglang_server.log\n",
      "Command: /usr/bin/python3 -m sglang.launch_server --host 0.0.0.0 --port 8080 --model-path /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802 --dp 4 --kv-cache-dtype fp8_e4m3\n",
      "sglang not ready after timeout. Showing last 60 log lines:\n",
      "2025-08-16 18:09:18.916101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1755367759.066113      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1755367759.109535      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "[2025-08-16 18:09:50] server_args=ServerArgs(model_path='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802', tokenizer_path='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=8080, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='fp8_e4m3', mem_fraction_static=0.871, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=2048, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=534673215, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=4, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1755367812.825352     116 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1755367812.825768     115 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1755367812.831522     116 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1755367812.832030     115 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "[2025-08-16 18:10:28] Launch DP0 starting at GPU #0.\r\n",
      "[2025-08-16 18:10:28] Launch DP1 starting at GPU #1.\r\n",
      "[2025-08-16 18:10:28] Launch DP2 starting at GPU #2.\r\n",
      "[2025-08-16 18:10:28] Launch DP3 starting at GPU #3.\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1755367849.435805     353 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1755367849.435811     351 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1755367849.435813     349 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1755367849.435814     354 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1755367849.441973     353 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1755367849.441985     349 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1755367849.441985     351 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1755367849.441997     354 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "[2025-08-16 18:11:05 DP0] Attention backend not explicitly specified. Use flashinfer backend by default.\r\n",
      "[2025-08-16 18:11:05 DP0] Init torch distributed begin.\r\n",
      "[2025-08-16 18:11:05 DP2] Attention backend not explicitly specified. Use flashinfer backend by default.\r\n",
      "[2025-08-16 18:11:05 DP2] Init torch distributed begin.\r\n",
      "[2025-08-16 18:11:05 DP1] Attention backend not explicitly specified. Use flashinfer backend by default.\r\n",
      "[2025-08-16 18:11:05 DP1] Init torch distributed begin.\r\n",
      "[2025-08-16 18:11:05 DP3] Attention backend not explicitly specified. Use flashinfer backend by default.\r\n",
      "[2025-08-16 18:11:05 DP3] Init torch distributed begin.\r\n",
      "[W816 18:11:14.363176069 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:14.363300350 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:14.363698490 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:14.363747820 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:22.365219575 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:22.365241362 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:22.365227905 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W816 18:11:22.365266649 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[2025-08-16 18:11:22 DP1] Init torch distributed ends. mem usage=0.00 GB\r\n",
      "[2025-08-16 18:11:22 DP3] Init torch distributed ends. mem usage=0.00 GB\r\n",
      "[2025-08-16 18:11:22 DP0] Init torch distributed ends. mem usage=0.00 GB\r\n",
      "[2025-08-16 18:11:22 DP2] Init torch distributed ends. mem usage=0.00 GB\r\n",
      "[2025-08-16 18:11:31 DP3] Load weight begin. avail mem=22.06 GB\r\n",
      "[2025-08-16 18:11:31 DP0] Load weight begin. avail mem=22.06 GB\r\n",
      "[2025-08-16 18:11:31 DP1] Load weight begin. avail mem=22.06 GB\r\n",
      "[2025-08-16 18:11:31 DP2] Load weight begin. avail mem=22.06 GB\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\r\n",
      "Call stop_server() to shut it down gracefully.\n"
     ]
    }
   ],
   "source": [
    "if START_SERVER:\n",
    "    # Background server launcher for Kaggle with SGLang\n",
    "    import os, sys, time, subprocess, json, socket, requests\n",
    "    \n",
    "    MODEL_PATH = \"/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\"\n",
    "    PORT = 8080\n",
    "    LOG = f\"/kaggle/working/sglang_server.log\"\n",
    "    \n",
    "    # Auto-detect GPUs for sensible parallelism\n",
    "    try:\n",
    "        import torch\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "    except Exception:\n",
    "        num_gpus = 0\n",
    "    \n",
    "    SERVER_CMD = [\n",
    "        sys.executable, \"-m\", \"sglang.launch_server\",\n",
    "        \"--host\", \"0.0.0.0\",\n",
    "        \"--port\", str(PORT),\n",
    "        \"--model-path\", MODEL_PATH,\n",
    "        \"--dp\", str(max(1, min(num_gpus, 4))),\n",
    "        \"--kv-cache-dtype\", \"fp8_e4m3\"\n",
    "    ]\n",
    "    HEALTH_URL = f\"http://127.0.0.1:{PORT}/v1/models\"  # sglang doesn't always expose /health\n",
    "    \n",
    "    # ---------- 2) Launch in background ----------\n",
    "    log_f = open(LOG, \"w\")\n",
    "    env = os.environ.copy()\n",
    "    proc = subprocess.Popen(SERVER_CMD, stdout=log_f, stderr=subprocess.STDOUT, env=env, cwd=\"/kaggle/working\")\n",
    "    print(f\"Started sglang server PID={proc.pid} | logging to {LOG}\")\n",
    "    print(\"Command:\", \" \".join(SERVER_CMD))\n",
    "    \n",
    "    # ---------- 3) Wait for readiness ----------\n",
    "    def wait_ready(url, timeout_s=180):\n",
    "        t0 = time.time()\n",
    "        while time.time() - t0 < timeout_s:\n",
    "            try:\n",
    "                r = requests.get(url, timeout=3)\n",
    "                if r.status_code == 200:\n",
    "                    return True\n",
    "            except Exception:\n",
    "                pass\n",
    "            time.sleep(2)\n",
    "        return False\n",
    "    \n",
    "    ready = wait_ready(HEALTH_URL)\n",
    "    log_f.flush()\n",
    "    \n",
    "    if ready:\n",
    "        print(f\"sglang is READY on port {PORT}.\")\n",
    "        print(f\"- Tail logs: !tail -n 50 {LOG}\")\n",
    "        print(f\"- List models: !curl -s http://127.0.0.1:{PORT}/v1/models | jq .\")\n",
    "    else:\n",
    "        print(f\"sglang not ready after timeout. Showing last 60 log lines:\")\n",
    "        log_f.close()\n",
    "        !tail -n 60 {LOG}\n",
    "    \n",
    "    # Provide a tiny helper to stop it later\n",
    "    def stop_server(p=proc):\n",
    "        try:\n",
    "            p.terminate()\n",
    "            p.wait(timeout=10)\n",
    "        except Exception:\n",
    "            p.kill()\n",
    "        print(\"Server stopped.\")\n",
    "    \n",
    "    print(\"Call stop_server() to shut it down gracefully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f838278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:11:41.872969Z",
     "iopub.status.busy": "2025-08-16T18:11:41.872373Z",
     "iopub.status.idle": "2025-08-16T18:13:41.891360Z",
     "shell.execute_reply": "2025-08-16T18:13:41.890761Z"
    },
    "papermill": {
     "duration": 120.023984,
     "end_time": "2025-08-16T18:13:41.892497",
     "exception": false,
     "start_time": "2025-08-16T18:11:41.868513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Connection failed - server may not be ready yet\n",
      "‚è≥ Waiting 30 seconds before retrying...\n",
      "‚ùå Connection failed - server may not be ready yet\n",
      "‚è≥ Waiting 30 seconds before retrying...\n",
      "‚ùå Connection failed - server may not be ready yet\n",
      "‚è≥ Waiting 30 seconds before retrying...\n",
      "‚ùå Connection failed - server may not be ready yet\n",
      "‚è≥ Waiting 30 seconds before retrying...\n",
      "‚úÖ Server is responding!\n",
      "Available models:\n",
      "  - /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\n",
      "\n",
      "‚úÖ Found model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\n"
     ]
    }
   ],
   "source": [
    "if START_SERVER:\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    def check_models():\n",
    "        url = \"http://127.0.0.1:8080/v1/models\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "    \n",
    "            print(\"‚úÖ Server is responding!\")\n",
    "            print(\"Available models:\")\n",
    "            for model in result['data']:\n",
    "                print(f\"  - {model['id']}\")\n",
    "    \n",
    "            return result['data'][0]['id'] if result['data'] else None\n",
    "    \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"‚ùå Connection failed - server may not be ready yet\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Poll every 30 seconds until we get a model\n",
    "    model_name = None\n",
    "    while not model_name:\n",
    "        model_name = check_models()\n",
    "        if not model_name:\n",
    "            print(\"‚è≥ Waiting 30 seconds before retrying...\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Found model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ade88f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:13:41.900611Z",
     "iopub.status.busy": "2025-08-16T18:13:41.900377Z",
     "iopub.status.idle": "2025-08-16T18:13:41.907080Z",
     "shell.execute_reply": "2025-08-16T18:13:41.906600Z"
    },
    "papermill": {
     "duration": 0.01183,
     "end_time": "2025-08-16T18:13:41.907930",
     "exception": false,
     "start_time": "2025-08-16T18:13:41.896100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TEST_INFERENCE:\n",
    "    import time\n",
    "    import requests\n",
    "    \n",
    "    url = \"http://127.0.0.1:8080/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation  \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\n```python\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n```\\n\"}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,  # from your polling loop\n",
    "        \"messages\": messages,\n",
    "        # \"max_tokens\": 1000\n",
    "        \"max_tokens\": 10\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers=headers, json=payload, timeout=600)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    output_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Estimate token count (4 chars/token assumption)\n",
    "    estimated_tokens = len(output_text) / 4\n",
    "    elapsed_time = end_time - start_time\n",
    "    tokens_per_second = estimated_tokens / elapsed_time\n",
    "    \n",
    "    print(\"‚úÖ Response received:\")\n",
    "    print(output_text)\n",
    "    print(f\"\\n‚è± Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"üî¢ Estimated tokens: {estimated_tokens:.1f}\")\n",
    "    print(f\"‚ö° Output tokens/sec: {tokens_per_second:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1459c0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:13:41.915690Z",
     "iopub.status.busy": "2025-08-16T18:13:41.915385Z",
     "iopub.status.idle": "2025-08-16T18:13:41.922485Z",
     "shell.execute_reply": "2025-08-16T18:13:41.921985Z"
    },
    "papermill": {
     "duration": 0.012063,
     "end_time": "2025-08-16T18:13:41.923356",
     "exception": false,
     "start_time": "2025-08-16T18:13:41.911293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TEST_INFERENCE:\n",
    "    import time\n",
    "    import requests\n",
    "    \n",
    "    url = \"http://127.0.0.1:8080/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Your messages from before\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n",
    "        {\"role\": \"user\", \"content\": \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\npython\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n\\n\"}\n",
    "    ]\n",
    "    \n",
    "    # Number of identical requests to send\n",
    "    N = 32\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,  # define this before runninga\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 24000\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    responses = []\n",
    "    for _ in range(N):\n",
    "        r = requests.post(url, headers=headers, json=payload, timeout=1200)\n",
    "        r.raise_for_status()\n",
    "        responses.append(r.json())\n",
    "    end_time = time.time()\n",
    "    \n",
    "    total_elapsed = end_time - start_time\n",
    "    \n",
    "    # Token counting (rough estimate: 4 chars/token)\n",
    "    total_tokens = 0\n",
    "    for resp in responses:\n",
    "        output_text = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        total_tokens += len(output_text) / 4\n",
    "    \n",
    "    tokens_per_sec = total_tokens / total_elapsed\n",
    "    avg_time_per_request = total_elapsed / N\n",
    "    \n",
    "    print(f\"‚úÖ Completed {N} requests\")\n",
    "    print(f\"‚è± Total elapsed: {total_elapsed:.2f} sec\")\n",
    "    print(f\"‚è± Avg per request: {avg_time_per_request:.2f} sec\")\n",
    "    print(f\"üî¢ Estimated total output tokens: {total_tokens:.1f}\")\n",
    "    print(f\"‚ö° Output tokens/sec: {tokens_per_sec:.2f}\")\n",
    "    \n",
    "    # Optional: print first response\n",
    "    print(\"\\nExample output:\")\n",
    "    print(responses[0][\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64c5de0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:13:41.930705Z",
     "iopub.status.busy": "2025-08-16T18:13:41.930271Z",
     "iopub.status.idle": "2025-08-16T18:16:26.062832Z",
     "shell.execute_reply": "2025-08-16T18:16:26.062032Z"
    },
    "papermill": {
     "duration": 164.13757,
     "end_time": "2025-08-16T18:16:26.064153",
     "exception": false,
     "start_time": "2025-08-16T18:13:41.926583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: dev | SUBMIT=True | attempts=8 | workers=32 | subset=evaluation\n",
      "Running uv run python -m llm_python.run_arc_tasks_soar --dataset arc-prize-2025 --subset evaluation --max_workers 32 --max_attempts 8 --model \"/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\" --base-url http://127.0.0.1:8080/v1 --unsafe-executor --max-tokens 2000 --qwen-no-think\n",
      "\n",
      "\n",
      "‚è∞ Global timeout set to 60s via GLOBAL_TIMEOUT environment variable\r\n",
      "‚ö†Ô∏è  WARNING: Using unrestricted executor - generated code will run directly on your system!\r\n",
      "Loading all task data into memory...\r\n",
      "Loading arc-prize-2025...\r\n",
      "  Training: 1000 tasks\r\n",
      "  Evaluation: 120 tasks\r\n",
      "  Test: 240 tasks\r\n",
      "Loaded 1120 total tasks and 3 subsets\r\n",
      "‚è∞ API timeout: 1800s (network safety only, no infrastructure timeouts)\r\n",
      "üóÑÔ∏è Database logging: enabled\r\n",
      "üîç Validating 120 tasks...\r\n",
      "‚úÖ Task validation complete: 120 valid tasks\r\n",
      "‚úÖ Task validation complete: 120 valid tasks\r\n",
      "\r\n",
      "Running 120 tasks from arc-prize-2025/evaluation\r\n",
      "Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\r\n",
      "API: All Attempts Mode (8 attempts per task)\r\n",
      "Mode: True parallelization - 960 total attempts\r\n",
      "Parallelization: ENABLED (32 workers)\r\n",
      "Scheduling: Batched (4 tasks √ó 8 attempts = 32 workers used)\r\n",
      "\r\n",
      "‚úÖ No infrastructure timeouts - requests complete naturally to avoid GPU overload\r\n",
      "\r\n",
      "Sampling Parameters: {'max_tokens': 2000, 'temperature': 1.0, 'extra_body': {'min_p': 0.05}}\r\n",
      "Executor: unrestricted (timeout: 0.5s) ‚ö†Ô∏è  UNSAFE MODE\r\n",
      "--------------------------------------------------\r\n",
      "üöÄ Started 960 attempts with 32 workers\r\n",
      "‚è≥ No completions in last 15s ‚Äî 0/960 done; 960 remaining (timeout in 60s)\r\n",
      "‚è≥ No completions in last 15s ‚Äî 0/960 done; 960 remaining (timeout in 45s)\r\n",
      "‚è≥ No completions in last 15s ‚Äî 0/960 done; 960 remaining (timeout in 30s)\r\n",
      "‚è≥ No completions in last 15s ‚Äî 0/960 done; 960 remaining (timeout in 15s)\r\n",
      "‚è∞ Global timeout reached (60s). Cancelling remaining attempts...\r\n",
      "‚è∞ Timeout: 0 attempts completed, 928 cancelled, 32 already running\r\n",
      "‚è∞ Execution stopped after 60.0s due to global timeout\r\n",
      "üõë 928 attempts were cancelled due to timeout\r\n",
      "üìä Final status: 0 successful, 0 failed, 928 cancelled\r\n",
      "üêå Slow attempt: 135a2760 attempt 8 took 63.9s\r\n",
      "üêå Slow attempt: 135a2760 attempt 3 took 65.0s\r\n",
      "üêå Slow attempt: 135a2760 attempt 2 took 67.0s\r\n",
      "üêå Slow attempt: 135a2760 attempt 4 took 68.4s\r\n",
      "üêå Slow attempt: 135a2760 attempt 6 took 68.9s\r\n",
      "üêå Slow attempt: 135a2760 attempt 7 took 70.5s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 7 took 70.7s\r\n",
      "üêå Slow attempt: 135a2760 attempt 1 took 71.1s\r\n",
      "üêå Slow attempt: 13e47133 attempt 5 took 72.8s\r\n",
      "üêå Slow attempt: 13e47133 attempt 1 took 73.2s\r\n",
      "üêå Slow attempt: 135a2760 attempt 5 took 74.5s\r\n",
      "‚úÖ 135a2760: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-transductive, 4 train-exec-error, 4 test-exec-error (best: 0.0% train)\r\n",
      "üêå Slow attempt: 13e47133 attempt 6 took 74.5s\r\n",
      "üêå Slow attempt: 13e47133 attempt 3 took 74.8s\r\n",
      "üêå Slow attempt: 13e47133 attempt 8 took 79.6s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 5 took 81.8s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 2 took 82.1s\r\n",
      "üêå Slow attempt: 13e47133 attempt 2 took 84.5s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 1 took 85.8s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 4 took 86.1s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 3 took 86.6s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 8 took 86.6s\r\n",
      "üêå Slow attempt: 13e47133 attempt 4 took 89.2s\r\n",
      "üêå Slow attempt: 136b0064 attempt 7 took 98.2s\r\n",
      "üêå Slow attempt: 0934a4d8 attempt 6 took 101.0s\r\n",
      "‚úÖ 0934a4d8: 1 train-perfect, no-partial (SUBMIT mode) | Issues: 4 train-transductive, 4 test-transductive (best: 100.0% train)\r\n",
      "üêå Slow attempt: 136b0064 attempt 4 took 125.6s\r\n",
      "üêå Slow attempt: 136b0064 attempt 6 took 128.1s\r\n",
      "üêå Slow attempt: 136b0064 attempt 2 took 130.0s\r\n",
      "üêå Slow attempt: 136b0064 attempt 3 took 132.9s\r\n",
      "üêå Slow attempt: 136b0064 attempt 5 took 135.6s\r\n",
      "üêå Slow attempt: 136b0064 attempt 1 took 136.7s\r\n",
      "üêå Slow attempt: 136b0064 attempt 8 took 140.2s\r\n",
      "‚úÖ 136b0064: 5 train-perfect, no-partial (SUBMIT mode) | Issues: 2 train-exec-error, 2 test-exec-error (best: 100.0% train)\r\n",
      "Not logging missing extracted\r\n",
      "üêå Slow attempt: 13e47133 attempt 7 took 154.8s\r\n",
      "‚úÖ 13e47133: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 max-len, 1 no-code, 1 train-exec-error, 1 test-exec-error (best: 0.0% train)\r\n",
      "‚ö†Ô∏è Task 142ca369 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 16b78196 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 16de56c4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 1818057f has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 195c6913 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 1ae2feb7 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 20270e3b has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 20a9e565 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 21897d95 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 221dfab4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 247ef758 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 269e22fb has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 271d71e2 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 28a6681f has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 291dc1e1 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 2b83f449 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 2ba387bc has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 2c181942 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 2d0172a1 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 31f7f899 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 332f06d7 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 35ab12c3 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 36a08778 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 38007db0 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 3a25b0d8 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 3dc255db has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 3e6067c3 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 409aa875 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 446ef5d2 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 45a5af55 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 4a21e3da has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 4c3d4a41 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 4c416de3 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 4c7dc4dd has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 4e34c42c has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 53fb4810 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 5545f144 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 581f7754 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 58490d8a has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 58f5dbd5 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 5961cc34 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 5dbc8537 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 62593bfd has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 64efde09 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 65b59efc has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 67e490f4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 6e453dd6 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 6e4f6532 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 6ffbe589 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 71e489b6 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7491f3cf has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7666fa5d has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 78332cb0 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7b0280bc has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7b3084d4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7b5033c1 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7b80bb43 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7c66cb00 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 7ed72f31 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 800d221b has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 80a900e0 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 8698868d has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 88bcf3b4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 88e364bc has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 89565ca0 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 898e7135 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 8b7bacbf has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 8b9c3697 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 8e5c0c38 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 8f215267 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 8f3a5a89 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 9385bd28 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 97d7923e has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 981571dc has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 9aaea919 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task 9bbf930d has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task a251c730 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task a25697e4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task a32d8b75 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task a395ee82 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task a47bf94d has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task a6f40cea has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task aa4ec2a5 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task abc82100 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task b0039139 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task b10624e5 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task b5ca7ac4 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task b6f77b65 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task b99e7126 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task b9e38dc0 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task bf45cf4b has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task c4d067a0 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task c7f57c3e has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task cb2d8a2c has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task cbebaa4b has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task d35bdbdc has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task d59b0160 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task d8e07eb2 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task da515329 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task db0c5428 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task db695cfb has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task dbff022c has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task dd6b8c4b has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task de809cff has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task dfadab01 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task e12f9a14 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task e3721c99 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task e376de54 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task e8686506 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task e87109e9 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task edb79dae has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task eee78d87 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task f560132c has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task f931b4a8 has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task faa9f03d has no valid attempts - skipping\r\n",
      "‚ö†Ô∏è Task fc7cae8d has no valid attempts - skipping\r\n",
      "\r\n",
      "==================================================\r\n",
      "SUBMIT MODE SUMMARY\r\n",
      "==================================================\r\n",
      "Dataset: arc-prize-2025\r\n",
      "Subset: evaluation\r\n",
      "Model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\r\n",
      "Total tasks processed: 4\r\n",
      "Total time: 60.0s\r\n",
      "Successful API calls: 4/4 (100.0%)\r\n",
      "Total tokens used: 264,393\r\n",
      "Total cost: $0.050081\r\n",
      "\r\n",
      "üìä RESPONSE METRICS:\r\n",
      "  Total responses: 32\r\n",
      "  Code extracted: 31/32 (96.9%)\r\n",
      "  Max length responses: 1/32 (3.1%)\r\n",
      "  Timeout responses: 0/32 (0.0%)\r\n",
      "  API failure responses: 0/32 (0.0%)\r\n",
      "\r\n",
      "üìä TRAIN METRICS:\r\n",
      "  All train correct: 2/4 (50.0%)\r\n",
      "  Min 1 train correct: 2/4 (50.0%)\r\n",
      "\r\n",
      "‚ö†Ô∏è  Note: Test accuracy metrics unavailable in SUBMIT mode (no test outputs)\r\n",
      "\r\n",
      "üéØ SUBMIT MODE: Creating submission file\r\n",
      "üìÅ Submit directory: /kaggle/working\r\n",
      "‚ö†Ô∏è No results for task 142ca369, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 16b78196, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 16de56c4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 1818057f, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 195c6913, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 1ae2feb7, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 20270e3b, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 20a9e565, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 21897d95, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 221dfab4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 247ef758, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 269e22fb, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 271d71e2, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 28a6681f, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 291dc1e1, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 2b83f449, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 2ba387bc, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 2c181942, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 2d0172a1, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 31f7f899, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 332f06d7, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 35ab12c3, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 36a08778, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 38007db0, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 3a25b0d8, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 3dc255db, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 3e6067c3, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 409aa875, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 446ef5d2, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 45a5af55, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 4a21e3da, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 4c3d4a41, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 4c416de3, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 4c7dc4dd, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 4e34c42c, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 53fb4810, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 5545f144, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 581f7754, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 58490d8a, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 58f5dbd5, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 5961cc34, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 5dbc8537, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 62593bfd, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 64efde09, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 65b59efc, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 67e490f4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 6e453dd6, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 6e4f6532, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 6ffbe589, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 71e489b6, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7491f3cf, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7666fa5d, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 78332cb0, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7b0280bc, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7b3084d4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7b5033c1, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7b80bb43, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7c66cb00, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 7ed72f31, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 800d221b, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 80a900e0, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 8698868d, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 88bcf3b4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 88e364bc, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 89565ca0, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 898e7135, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 8b7bacbf, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 8b9c3697, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 8e5c0c38, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 8f215267, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 8f3a5a89, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 9385bd28, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 97d7923e, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 981571dc, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 9aaea919, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task 9bbf930d, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task a251c730, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task a25697e4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task a32d8b75, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task a395ee82, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task a47bf94d, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task a6f40cea, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task aa4ec2a5, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task abc82100, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task b0039139, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task b10624e5, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task b5ca7ac4, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task b6f77b65, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task b99e7126, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task b9e38dc0, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task bf45cf4b, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task c4d067a0, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task c7f57c3e, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task cb2d8a2c, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task cbebaa4b, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task d35bdbdc, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task d59b0160, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task d8e07eb2, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task da515329, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task db0c5428, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task db695cfb, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task dbff022c, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task dd6b8c4b, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task de809cff, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task dfadab01, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task e12f9a14, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task e3721c99, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task e376de54, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task e8686506, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task e87109e9, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task edb79dae, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task eee78d87, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task f560132c, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task f931b4a8, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task faa9f03d, using empty fallback\r\n",
      "‚ö†Ô∏è No results for task fc7cae8d, using empty fallback\r\n",
      "‚úÖ Submission file created: submission.json\r\n",
      "üìä Submission Summary:\r\n",
      "  Total tasks in dataset: 120\r\n",
      "  Tasks processed: 4\r\n",
      "  Tasks with predictions: 4\r\n",
      "  Tasks with duplicated attempts: 3\r\n",
      "  Tasks with empty fallback: 116\r\n",
      "  Official file: /kaggle/working/submission.json\r\n",
      "  Backup file: /kaggle/working/submission_arc-prize-2025_evaluation__kaggle_input_arc-1-fake-ttt-blended-c802-dataset_arc-1-fake-ttt-blended-c802_20250816_181625.json\r\n",
      "\r\n",
      "üîç VALIDATING SUBMISSION: /kaggle/working/submission.json\r\n",
      "üìä Validation Results:\r\n",
      "  Total tasks: 120\r\n",
      "  Total predictions: 172\r\n",
      "  Empty predictions ([[0,0],[0,0]]): 336\r\n",
      "‚úÖ VALIDATION PASSED - No structural errors found\r\n",
      "üéØ Submission file is ready for competition!\r\n"
     ]
    }
   ],
   "source": [
    "# Derive attempts/workers for the two modes\n",
    "MAX_ATTEMPTS = 100 if (IS_RERUN and SUBMIT) else 8\n",
    "MAX_WORKERS  = 32\n",
    "SUBSET = \"test\" if IS_RERUN else \"evaluation\"\n",
    "\n",
    "# Common env for your runner\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n",
    "\n",
    "print(f\"Mode: {'competition' if IS_RERUN else 'dev'} | SUBMIT={SUBMIT} | attempts={MAX_ATTEMPTS} | workers={MAX_WORKERS} | subset={SUBSET}\")\n",
    "\n",
    "# Build the command\n",
    "cmd = (\n",
    "  \"uv run python -m llm_python.run_arc_tasks_soar \"\n",
    "  \"--dataset arc-prize-2025 \"\n",
    "  f\"--subset {SUBSET} \"\n",
    "  f\"--max_workers {MAX_WORKERS} \"\n",
    "  f\"--max_attempts {MAX_ATTEMPTS} \"\n",
    "  f\"--model \\\"{model_name}\\\" \"\n",
    "  \"--base-url http://127.0.0.1:8080/v1 \"\n",
    "  \"--unsafe-executor \"\n",
    "  \"--max-tokens 2000 \"\n",
    "  \"--qwen-no-think\"\n",
    ")\n",
    "\n",
    "# Optionally quiet the private rerun by redirecting logs to a file\n",
    "if IS_RERUN:\n",
    "    cmd += \" >> /kaggle/working/run.log 2>&1\"\n",
    "\n",
    "print(f\"Running {cmd}\\n\\n\")\n",
    "\n",
    "# Run\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bc65fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T18:16:26.076972Z",
     "iopub.status.busy": "2025-08-16T18:16:26.076387Z",
     "iopub.status.idle": "2025-08-16T18:16:27.379083Z",
     "shell.execute_reply": "2025-08-16T18:16:27.378378Z"
    },
    "papermill": {
     "duration": 1.310252,
     "end_time": "2025-08-16T18:16:27.380280",
     "exception": false,
     "start_time": "2025-08-16T18:16:26.070028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading submission: /kaggle/working/submission.json\r\n",
      "üîç Scoring against arc-prize-2025/evaluation\r\n",
      "Loading all task data into memory...\r\n",
      "Loading arc-prize-2025...\r\n",
      "  Training: 1000 tasks\r\n",
      "  Evaluation: 120 tasks\r\n",
      "  Test: 240 tasks\r\n",
      "Loaded 1120 total tasks and 3 subsets\r\n",
      "============================================================\r\n",
      "SUBMISSION SCORING RESULTS\r\n",
      "============================================================\r\n",
      "Dataset: arc-prize-2025\r\n",
      "Subset: evaluation\r\n",
      "Reference tasks: 120\r\n",
      "Tasks scored: 120\r\n",
      "Total predictions: 344\r\n",
      "\r\n",
      "üìä PREDICTION-LEVEL METRICS:\r\n",
      "  Pass@1 (first attempt): 2/344 (0.6%)\r\n",
      "  Pass@2 (either attempt): 2/344 (0.6%)\r\n",
      "\r\n",
      "üìä TASK-LEVEL METRICS:\r\n",
      "  Tasks Pass@1 (all outputs correct on first attempt): 2/120 (1.7%)\r\n",
      "  Tasks Pass@2 (all outputs correct on either attempt): 2/120 (1.7%)\r\n"
     ]
    }
   ],
   "source": [
    "# Only score in dev/commit runs\n",
    "if SCORE and not IS_RERUN:\n",
    "    !uv run python -m llm_python.score_submission --submission \"/kaggle/working/submission.json\"\n",
    "else:\n",
    "    print(\"Skipping local scoring (competition rerun or SCORE=False).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6517bd",
   "metadata": {
    "papermill": {
     "duration": 0.00544,
     "end_time": "2025-08-16T18:16:27.391713",
     "exception": false,
     "start_time": "2025-08-16T18:16:27.386273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 8063856,
     "isSourceIdPinned": true,
     "sourceId": 12755863,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 256290376,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 256344117,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 496.738854,
   "end_time": "2025-08-16T18:16:30.013818",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-16T18:08:13.274964",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
