{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":12755863,"sourceType":"datasetVersion","datasetId":8063856,"isSourceIdPinned":true},{"sourceId":256290376,"sourceType":"kernelVersion"},{"sourceId":256427571,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nIS_RERUN = os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\", \"\").lower() == \"true\"\n\n# Set global timeout based on whether this is a competition rerun\nif IS_RERUN:\n  # Competition rerun - FULL timeout for actual scoring\n  timeout_seconds = 39600  # 11 hours\n  print(\"ğŸ† Competition rerun detected - setting FULL timeout for scoring\")\nelse:\n  # Development/testing - short timeout\n  timeout_seconds = 300  # 5 minutes\n  print(\"ğŸ”§ Development run - setting short timeout for testing\")\n\nos.environ['GLOBAL_TIMEOUT'] = str(timeout_seconds)\nprint(f\"â° Global timeout set to {timeout_seconds}s ({timeout_seconds/3600:.1f} hours)\")\n\nSTART_SERVER = True\nTEST_INFERENCE = False #set false unless you want to see inference hitting the endpoint, before the task runner\nSUBMIT = True #to run the task runner\nSCORE = True # score if not a competition rerun\n\nos.environ[\"ARC_DATA_ROOT\"]  = \"/kaggle/input\"\n\n# to have the task runner generate a submission file\nos.environ[\"SUBMIT\"] = \"true\"\n\n# the directory for where the submission.json file will go\nos.environ[\"SUBMIT_DIR\"] = \"/kaggle/working\"\n\n# location of the db (current just saving here, not reading from it yet)\nos.environ[\"ARC_PROGRAMS_DB\"]=\"/kaggle/working/local.db\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T19:59:36.059465Z","iopub.execute_input":"2025-08-17T19:59:36.059819Z","iopub.status.idle":"2025-08-17T19:59:36.069169Z","shell.execute_reply.started":"2025-08-17T19:59:36.059802Z","shell.execute_reply":"2025-08-17T19:59:36.068696Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Development run - setting short timeout for testing\nâ° Global timeout set to 300s (0.1 hours)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sys\nimport torch\nimport numpy as np\n\nprint(f\"Python version: {sys.version}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA version (PyTorch): {torch.version.cuda}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"NumPy version: {np.__version__}\")\nif torch.cuda.is_available():\n   print(f\"GPU count: {torch.cuda.device_count()}\")\n   print(f\"GPU name: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T19:59:36.070204Z","iopub.execute_input":"2025-08-17T19:59:36.070425Z","iopub.status.idle":"2025-08-17T19:59:50.170852Z","shell.execute_reply.started":"2025-08-17T19:59:36.070411Z","shell.execute_reply":"2025-08-17T19:59:50.170323Z"}},"outputs":[{"name":"stdout","text":"Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch version: 2.7.1+cu126\nCUDA version (PyTorch): 12.6\nCUDA available: True\nNumPy version: 1.26.4\nGPU count: 4\nGPU name: NVIDIA L4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# !ls ../input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T19:59:50.171421Z","iopub.execute_input":"2025-08-17T19:59:50.171690Z","iopub.status.idle":"2025-08-17T19:59:50.174508Z","shell.execute_reply.started":"2025-08-17T19:59:50.171675Z","shell.execute_reply":"2025-08-17T19:59:50.173983Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import sglang\nprint(\"SGLang version:\", sglang.__version__)\n\ntry:\n    import flashinfer\n    print(\"FlashInfer version:\", flashinfer.__version__)\nexcept ImportError:\n    print(\"FlashInfer not installed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T19:59:50.175063Z","iopub.execute_input":"2025-08-17T19:59:50.175277Z","iopub.status.idle":"2025-08-17T19:59:54.614062Z","shell.execute_reply.started":"2025-08-17T19:59:50.175260Z","shell.execute_reply":"2025-08-17T19:59:54.613532Z"}},"outputs":[{"name":"stdout","text":"SGLang version: 0.4.9.post3\nFlashInfer version: 0.2.7.post1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ensure that ptxas can access writable directories\nimport shutil\nimport os\nimport sys\nimport subprocess\n\n# Copy PTXAS and other binaries\nos.makedirs(\"/kaggle/working/bin\", exist_ok=True)\nfor binary in [\"ptxas\", \"cuobjdump\", \"nvdisasm\"]:\n    src = f\"/kaggle/usr/lib/sglang_utility/triton/backends/nvidia/bin/{binary}\"  # Fixed path\n    dst = f\"/kaggle/working/bin/{binary}\"\n    if os.path.exists(src):\n        shutil.copy(src, dst)\n        os.chmod(dst, 0o755)\n\n# Set environment variables\nenv = os.environ.copy()\nenv[\"TRITON_PTXAS_PATH\"] = \"/kaggle/working/bin/ptxas\"\nenv[\"PATH\"] = f\"/kaggle/working/bin:{env.get('PATH', '')}\"\nenv[\"TRITON_CACHE_DIR\"] = \"/kaggle/working/.triton\"\nenv[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.makedirs(\"/kaggle/working/.triton\", exist_ok=True)\n\n# Apply the environment variables to the current process\nos.environ.update(env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T19:59:54.614642Z","iopub.execute_input":"2025-08-17T19:59:54.614904Z","iopub.status.idle":"2025-08-17T19:59:55.120551Z","shell.execute_reply.started":"2025-08-17T19:59:54.614887Z","shell.execute_reply":"2025-08-17T19:59:55.120005Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if START_SERVER:\n    # Background server launcher for Kaggle with SGLang\n    import os, sys, time, subprocess, json, socket, requests\n    \n    MODEL_PATH = \"/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\"\n    PORT = 8080\n    LOG = f\"/kaggle/working/sglang_server.log\"\n    \n    # Auto-detect GPUs for sensible parallelism\n    try:\n        import torch\n        num_gpus = torch.cuda.device_count()\n    except Exception:\n        num_gpus = 0\n    \n    SERVER_CMD = [\n        sys.executable, \"-m\", \"sglang.launch_server\",\n        \"--host\", \"0.0.0.0\",\n        \"--port\", str(PORT),\n        \"--model-path\", MODEL_PATH,\n        \"--dp\", str(max(1, min(num_gpus, 4))),\n        \"--kv-cache-dtype\", \"fp8_e4m3\"\n    ]\n    HEALTH_URL = f\"http://127.0.0.1:{PORT}/v1/models\"  # sglang doesn't always expose /health\n    \n    # ---------- 2) Launch in background ----------\n    log_f = open(LOG, \"w\")\n    env = os.environ.copy()\n    proc = subprocess.Popen(SERVER_CMD, stdout=log_f, stderr=subprocess.STDOUT, env=env, cwd=\"/kaggle/working\")\n    print(f\"Started sglang server PID={proc.pid} | logging to {LOG}\")\n    print(\"Command:\", \" \".join(SERVER_CMD))\n    \n    # ---------- 3) Wait for readiness ----------\n    def wait_ready(url, timeout_s=180):\n        t0 = time.time()\n        while time.time() - t0 < timeout_s:\n            try:\n                r = requests.get(url, timeout=3)\n                if r.status_code == 200:\n                    return True\n            except Exception:\n                pass\n            time.sleep(2)\n        return False\n    \n    ready = wait_ready(HEALTH_URL)\n    log_f.flush()\n    \n    if ready:\n        print(f\"sglang is READY on port {PORT}.\")\n        print(f\"- Tail logs: !tail -n 50 {LOG}\")\n        print(f\"- List models: !curl -s http://127.0.0.1:{PORT}/v1/models | jq .\")\n    else:\n        print(f\"sglang not ready after timeout. Showing last 60 log lines:\")\n        log_f.close()\n        !tail -n 60 {LOG}\n    \n    # Provide a tiny helper to stop it later\n    def stop_server(p=proc):\n        try:\n            p.terminate()\n            p.wait(timeout=10)\n        except Exception:\n            p.kill()\n        print(\"Server stopped.\")\n    \n    print(\"Call stop_server() to shut it down gracefully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T19:59:55.121197Z","iopub.execute_input":"2025-08-17T19:59:55.121403Z","iopub.status.idle":"2025-08-17T20:02:55.402353Z","shell.execute_reply.started":"2025-08-17T19:59:55.121386Z","shell.execute_reply":"2025-08-17T20:02:55.401502Z"}},"outputs":[{"name":"stdout","text":"Started sglang server PID=122 | logging to /kaggle/working/sglang_server.log\nCommand: /usr/bin/python3 -m sglang.launch_server --host 0.0.0.0 --port 8080 --model-path /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802 --dp 4 --kv-cache-dtype fp8_e4m3\nsglang not ready after timeout. Showing last 60 log lines:\n2025-08-17 20:00:34.954899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460835.200814     122 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755460835.278661     122 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-08-17 20:01:11] server_args=ServerArgs(model_path='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802', tokenizer_path='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=8080, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='fp8_e4m3', mem_fraction_static=0.871, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=2048, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=887004482, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=4, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460889.626086     200 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460889.626316     201 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755460889.632168     200 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1755460889.632424     201 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-08-17 20:01:43] Launch DP0 starting at GPU #0.\n[2025-08-17 20:01:43] Launch DP1 starting at GPU #1.\n[2025-08-17 20:01:43] Launch DP2 starting at GPU #2.\n[2025-08-17 20:01:43] Launch DP3 starting at GPU #3.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460920.535113     437 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460920.535177     438 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460920.535434     439 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755460920.536091     435 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755460920.541099     437 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1755460920.541143     438 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1755460920.541388     439 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1755460920.542084     435 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[2025-08-17 20:02:14 DP0] Attention backend not explicitly specified. Use flashinfer backend by default.\n[2025-08-17 20:02:14 DP0] Init torch distributed begin.\n[2025-08-17 20:02:14 DP3] Attention backend not explicitly specified. Use flashinfer backend by default.\n[2025-08-17 20:02:14 DP3] Init torch distributed begin.\n[2025-08-17 20:02:14 DP2] Attention backend not explicitly specified. Use flashinfer backend by default.\n[2025-08-17 20:02:14 DP2] Init torch distributed begin.\n[2025-08-17 20:02:14 DP1] Attention backend not explicitly specified. Use flashinfer backend by default.\n[2025-08-17 20:02:14 DP1] Init torch distributed begin.\n[W817 20:02:23.396959239 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:23.396966440 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:23.396952580 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:23.397046739 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:31.399248607 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:31.399249283 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:31.399249347 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[W817 20:02:31.399305355 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n[2025-08-17 20:02:31 DP3] Init torch distributed ends. mem usage=0.00 GB\n[2025-08-17 20:02:31 DP0] Init torch distributed ends. mem usage=0.00 GB\n[2025-08-17 20:02:31 DP2] Init torch distributed ends. mem usage=0.00 GB\n[2025-08-17 20:02:31 DP1] Init torch distributed ends. mem usage=0.00 GB\n[2025-08-17 20:02:39 DP1] Load weight begin. avail mem=22.06 GB\n[2025-08-17 20:02:39 DP0] Load weight begin. avail mem=22.06 GB\n[2025-08-17 20:02:39 DP3] Load weight begin. avail mem=22.06 GB\n[2025-08-17 20:02:39 DP2] Load weight begin. avail mem=22.06 GB\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\nLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\nCall stop_server() to shut it down gracefully.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"if START_SERVER:\n    import requests\n    import time\n    \n    def check_models():\n        url = \"http://127.0.0.1:8080/v1/models\"\n        try:\n            response = requests.get(url, timeout=10)\n            response.raise_for_status()\n            result = response.json()\n    \n            print(\"âœ… Server is responding!\")\n            print(\"Available models:\")\n            for model in result['data']:\n                print(f\"  - {model['id']}\")\n    \n            return result['data'][0]['id'] if result['data'] else None\n    \n        except requests.exceptions.ConnectionError:\n            print(\"âŒ Connection failed - server may not be ready yet\")\n            return None\n        except Exception as e:\n            print(f\"âŒ Error: {e}\")\n            return None\n    \n    # Poll every 30 seconds until we get a model\n    model_name = None\n    while not model_name:\n        model_name = check_models()\n        if not model_name:\n            print(\"â³ Waiting 30 seconds before retrying...\")\n            time.sleep(30)\n    \n    print(f\"\\nâœ… Found model: {model_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T20:02:55.404293Z","iopub.execute_input":"2025-08-17T20:02:55.404517Z","iopub.status.idle":"2025-08-17T20:04:55.425276Z","shell.execute_reply.started":"2025-08-17T20:02:55.404497Z","shell.execute_reply":"2025-08-17T20:04:55.424266Z"}},"outputs":[{"name":"stdout","text":"âŒ Connection failed - server may not be ready yet\nâ³ Waiting 30 seconds before retrying...\nâŒ Connection failed - server may not be ready yet\nâ³ Waiting 30 seconds before retrying...\nâŒ Connection failed - server may not be ready yet\nâ³ Waiting 30 seconds before retrying...\nâŒ Connection failed - server may not be ready yet\nâ³ Waiting 30 seconds before retrying...\nâœ… Server is responding!\nAvailable models:\n  - /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\n\nâœ… Found model: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"if TEST_INFERENCE:\n    import time\n    import requests\n    \n    url = \"http://127.0.0.1:8080/v1/chat/completions\"\n    \n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    \n    messages = [\n        {\"role\" : \"system\", \"content\" : \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n        {\"role\" : \"user\", \"content\" : \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation  \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\n```python\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n```\\n\"}\n    ]\n    \n    payload = {\n        \"model\": model_name,  # from your polling loop\n        \"messages\": messages,\n        # \"max_tokens\": 1000\n        \"max_tokens\": 10\n    }\n    \n    start_time = time.time()\n    response = requests.post(url, headers=headers, json=payload, timeout=600)\n    end_time = time.time()\n    \n    response.raise_for_status()\n    result = response.json()\n    output_text = result[\"choices\"][0][\"message\"][\"content\"]\n    \n    # Estimate token count (4 chars/token assumption)\n    estimated_tokens = len(output_text) / 4\n    elapsed_time = end_time - start_time\n    tokens_per_second = estimated_tokens / elapsed_time\n    \n    print(\"âœ… Response received:\")\n    print(output_text)\n    print(f\"\\nâ± Elapsed time: {elapsed_time:.2f} seconds\")\n    print(f\"ğŸ”¢ Estimated tokens: {estimated_tokens:.1f}\")\n    print(f\"âš¡ Output tokens/sec: {tokens_per_second:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T20:04:55.426343Z","iopub.execute_input":"2025-08-17T20:04:55.426631Z","iopub.status.idle":"2025-08-17T20:04:55.437940Z","shell.execute_reply.started":"2025-08-17T20:04:55.426605Z","shell.execute_reply":"2025-08-17T20:04:55.436988Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"if TEST_INFERENCE:\n    import time\n    import requests\n    \n    url = \"http://127.0.0.1:8080/v1/chat/completions\"\n    headers = {\"Content-Type\": \"application/json\"}\n    \n    # Your messages from before\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are an expert at solving abstract reasoning puzzles. Write clean, efficient Python code.\"},\n        {\"role\": \"user\", \"content\": \"You are solving an ARC (Abstraction and Reasoning Corpus) task. \\nI will show you training examples with input and output grids, plus a test input grid. Your task is to:\\n\\n1. **Analyze the training examples** to discover patterns that map input grids to output grids\\n2. **Write a Python program** that implements your best understanding of the transformation \\n3. **DO NOT predict or generate the test output** - your job is only to write the transformation program\\n4. **Attempt a solution** - even if the pattern isn't completely clear, provide your best hypothesis\\n5. **Do not repeat the same transformation** - if you have already tried a transformation, do not repeat it.\\n\\n**IMPORTANT: Your transformation must always produce a 10\\u00d710 output grid.**\\n\\nThe test input is shown for context so you understand what type of grid your program will eventually process. Focus on learning patterns from training examples and writing code that captures your understanding.\\n\\nTraining Examples:\\n\\nExample 1:\\nInput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n5 0 0 5 0 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n2 0 0 2 0 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 2:\\nInput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 5 0 5 5 0 0 5 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 2 0 2 2 0 0 2 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n\\nExample 3:\\nInput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\nOutput:\\n0 0 5 5 0 5 0 5 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 2 2 0 2 0 2 2 5\\n0 0 0 0 0 0 0 0 0 0\\n\\nTest Input:\\n5 0 5 5 0 0 5 0 5 0\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n0 0 0 0 0 0 0 0 0 0\\n0 0 0 0 0 0 0 0 0 5\\n\\nAnalyze the patterns in the training examples and write a Python function that performs this transformation.\\n\\n**Approach Guidelines:**\\n- Look for patterns in shapes, colors, positions, sizes, rotations, reflections, etc.\\n- Even if you can't solve all training examples perfectly, implement what patterns you do observe\\n- A partial solution that captures some aspects is better than returning the input unchanged\\n- If the pattern is unclear, make your best educated guess based on what you can see\\n\\nRequirements:\\n- The function takes a 2D list (grid) where grid[row][col] gives the value at that position\\n- Values are integers from 0-9\\n- Return a new grid (2D list) with the transformation applied\\n- You can use numpy if needed - just add 'import numpy as np' at the start of your function\\n- Aim to handle the training examples as well as possible, even if not perfectly\\n- Your function should attempt some meaningful transformation based on the patterns you observe\\n\\nYou MUST end your response with the following exact format:\\n\\nFinal answer:\\npython\\ndef transform(grid):\\n    # Your transformation logic here (implement your best understanding)\\n    return transformed_grid\\n\\n\"}\n    ]\n    \n    # Number of identical requests to send\n    N = 32\n    \n    payload = {\n        \"model\": model_name,  # define this before runninga\n        \"messages\": messages,\n        \"max_tokens\": 24000\n    }\n    \n    start_time = time.time()\n    responses = []\n    for _ in range(N):\n        r = requests.post(url, headers=headers, json=payload, timeout=1200)\n        r.raise_for_status()\n        responses.append(r.json())\n    end_time = time.time()\n    \n    total_elapsed = end_time - start_time\n    \n    # Token counting (rough estimate: 4 chars/token)\n    total_tokens = 0\n    for resp in responses:\n        output_text = resp[\"choices\"][0][\"message\"][\"content\"]\n        total_tokens += len(output_text) / 4\n    \n    tokens_per_sec = total_tokens / total_elapsed\n    avg_time_per_request = total_elapsed / N\n    \n    print(f\"âœ… Completed {N} requests\")\n    print(f\"â± Total elapsed: {total_elapsed:.2f} sec\")\n    print(f\"â± Avg per request: {avg_time_per_request:.2f} sec\")\n    print(f\"ğŸ”¢ Estimated total output tokens: {total_tokens:.1f}\")\n    print(f\"âš¡ Output tokens/sec: {tokens_per_sec:.2f}\")\n    \n    # Optional: print first response\n    print(\"\\nExample output:\")\n    print(responses[0][\"choices\"][0][\"message\"][\"content\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T20:04:55.439207Z","iopub.execute_input":"2025-08-17T20:04:55.439483Z","iopub.status.idle":"2025-08-17T20:04:55.671210Z","shell.execute_reply.started":"2025-08-17T20:04:55.439460Z","shell.execute_reply":"2025-08-17T20:04:55.670318Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Derive attempts/workers for the two modes\nMAX_ATTEMPTS = 100 if (IS_RERUN and SUBMIT) else 8\nMAX_WORKERS  = 32\nSUBSET = \"test\" if IS_RERUN else \"evaluation\"\n\n# Common env for your runner\nos.environ[\"OPENAI_API_KEY\"] = \"EMPTY\"\n\nprint(f\"Mode: {'competition' if IS_RERUN else 'dev'} | SUBMIT={SUBMIT} | attempts={MAX_ATTEMPTS} | workers={MAX_WORKERS} | subset={SUBSET}\")\n\n# Build the command\ncmd = (\n  \"uv run python -m llm_python.run_arc_tasks_soar \"\n  \"--dataset arc-prize-2025 \"\n  f\"--subset {SUBSET} \"\n  f\"--max_workers {MAX_WORKERS} \"\n  f\"--max_attempts {MAX_ATTEMPTS} \"\n  f\"--model \\\"{model_name}\\\" \"\n  \"--base-url http://127.0.0.1:8080/v1 \"\n  \"--unsafe-executor \"\n  \"--max-tokens 2000 \"\n  \"--qwen-no-think\"\n)\n\n# Optionally quiet the private rerun by redirecting logs to a file\nif IS_RERUN:\n    cmd += \" >> /kaggle/working/run.log 2>&1\"\n\nprint(f\"Running {cmd}\\n\\n\")\n\n# Run\n!{cmd}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T20:04:55.672151Z","iopub.execute_input":"2025-08-17T20:04:55.672458Z"}},"outputs":[{"name":"stdout","text":"Mode: dev | SUBMIT=True | attempts=8 | workers=32 | subset=evaluation\nRunning uv run python -m llm_python.run_arc_tasks_soar --dataset arc-prize-2025 --subset evaluation --max_workers 32 --max_attempts 8 --model \"/kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\" --base-url http://127.0.0.1:8080/v1 --unsafe-executor --max-tokens 2000 --qwen-no-think\n\n\nâ° Global timeout set to 300s via GLOBAL_TIMEOUT environment variable\nâš ï¸  WARNING: Using unrestricted executor - generated code will run directly on your system!\nLoading all task data into memory...\nLoading arc-prize-2025...\n  Training: 1000 tasks\n  Evaluation: 120 tasks\n  Test: 240 tasks\nLoaded 1120 total tasks and 3 subsets\nâ° API timeout: 1800s (network safety only, no infrastructure timeouts)\nğŸ—„ï¸ Database logging: enabled\nğŸ” Validating 120 tasks...\nâœ… Task validation complete: 120 valid tasks\nâœ… Task validation complete: 120 valid tasks\n\nRunning 120 tasks from arc-prize-2025/evaluation\nModel: /kaggle/input/arc-1-fake-ttt-blended-c802-dataset/arc-1-fake-ttt-blended-c802\nAPI: All Attempts Mode (8 attempts per task)\nMode: True parallelization - 960 total attempts\nParallelization: ENABLED (32 workers)\nScheduling: Batched (4 tasks Ã— 8 attempts = 32 workers used)\n\nâœ… No infrastructure timeouts - requests complete naturally to avoid GPU overload\n\nSampling Parameters: {'max_tokens': 2000, 'temperature': 1.0, 'extra_body': {'min_p': 0.05}}\nExecutor: unrestricted (timeout: 0.5s) âš ï¸  UNSAFE MODE\n--------------------------------------------------\nğŸš€ Started 960 attempts with 32 workers\nâ³ No completions in last 15s â€” 0/960 done; 960 remaining (timeout in 300s)\nâ³ No completions in last 15s â€” 0/960 done; 960 remaining (timeout in 285s)\nâ³ No completions in last 15s â€” 0/960 done; 960 remaining (timeout in 270s)\nâ³ No completions in last 15s â€” 6/960 done; 954 remaining (timeout in 255s)\nğŸŒ Slow attempt: 13e47133 attempt 2 took 60.8s\nğŸŒ Slow attempt: 135a2760 attempt 4 took 61.0s\nğŸŒ Slow attempt: 13e47133 attempt 6 took 61.8s\nğŸŒ Slow attempt: 135a2760 attempt 1 took 64.6s\nğŸŒ Slow attempt: 13e47133 attempt 4 took 67.1s\nğŸŒ Slow attempt: 13e47133 attempt 7 took 68.4s\nğŸŒ Slow attempt: 0934a4d8 attempt 8 took 68.8s\nğŸŒ Slow attempt: 135a2760 attempt 6 took 69.3s\nâœ… 135a2760: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-exec-error, 1 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 13e47133 attempt 8 took 69.5s\nğŸŒ Slow attempt: 0934a4d8 attempt 4 took 70.6s\nğŸŒ Slow attempt: 0934a4d8 attempt 7 took 73.2s\nğŸŒ Slow attempt: 13e47133 attempt 1 took 73.6s\nğŸŒ Slow attempt: 13e47133 attempt 5 took 73.9s\nâ³ No completions in last 15s â€” 20/960 done; 940 remaining (timeout in 240s)\nğŸŒ Slow attempt: 0934a4d8 attempt 6 took 80.8s\nğŸŒ Slow attempt: 0934a4d8 attempt 5 took 83.8s\nğŸŒ Slow attempt: 0934a4d8 attempt 1 took 84.1s\nğŸŒ Slow attempt: 0934a4d8 attempt 3 took 88.0s\nâœ… 0934a4d8: 2 train-perfect, no-partial (SUBMIT mode) | Issues: 3 train-transductive, 3 test-transductive, 1 train-exec-error, 1 test-exec-error (best: 100.0% train)\nâ³ No completions in last 15s â€” 32/960 done; 928 remaining (timeout in 225s)\nâ³ No completions in last 15s â€” 40/960 done; 920 remaining (timeout in 210s)\nâŒ Inconsistent grid width for 136b0064_test_0: row 2 has 20 items, expected 19\nâš ï¸  136b0064 test_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 136b0064_test_debug_0: row 2 has 20 items, expected 19\nâš ï¸  136b0064 test_debug_0: Grid failed ARC validation, using fallback\nğŸŒ Slow attempt: 136b0064 attempt 8 took 105.8s\nâŒ Inconsistent grid width for 136b0064_test_0: row 2 has 8 items, expected 7\nâš ï¸  136b0064 test_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 136b0064_train_0: row 3 has 9 items, expected 7\nâš ï¸  136b0064 train_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 136b0064_test_debug_0: row 2 has 8 items, expected 7\nâš ï¸  136b0064 test_debug_0: Grid failed ARC validation, using fallback\nğŸŒ Slow attempt: 136b0064 attempt 2 took 111.1s\nâœ… 16b78196: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 3 train-exec-error, 3 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 136b0064 attempt 4 took 117.3s\nğŸŒ Slow attempt: 136b0064 attempt 7 took 118.0s\nâœ… 1818057f: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 2 train-exec-error, 2 test-exec-error (best: 0.0% train)\nâ³ No completions in last 15s â€” 56/960 done; 904 remaining (timeout in 195s)\nğŸŒ Slow attempt: 136b0064 attempt 1 took 123.6s\nğŸŒ Slow attempt: 136b0064 attempt 3 took 125.9s\nğŸŒ Slow attempt: 136b0064 attempt 6 took 128.3s\nâŒ Inconsistent grid width for 20a9e565_test_0: row 11 has 16 items, expected 20\nâš ï¸  20a9e565 test_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 20a9e565_test_1: row 14 has 9 items, expected 13\nâš ï¸  20a9e565 test_1: Grid failed ARC validation, using fallback\nğŸŒ Slow attempt: 136b0064 attempt 5 took 131.0s\nâœ… 136b0064: 5 train-perfect, no-partial (SUBMIT mode) (best: 100.0% train)\nâ³ No completions in last 15s â€” 67/960 done; 893 remaining (timeout in 180s)\nâŒ Inconsistent grid width for 20270e3b_test_0: row 1 has 5 items, expected 4\nâš ï¸  20270e3b test_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 20270e3b_test_1: row 1 has 3 items, expected 2\nâš ï¸  20270e3b test_1: Grid failed ARC validation, using fallback\nâœ… 1ae2feb7: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-exec-error, 1 test-exec-error (best: 0.0% train)\nâ³ No completions in last 15s â€” 76/960 done; 884 remaining (timeout in 165s)\nğŸŒ Slow attempt: 142ca369 attempt 3 took 88.2s\nğŸŒ Slow attempt: 142ca369 attempt 6 took 78.4s\nNot logging missing extracted\nğŸŒ Slow attempt: 13e47133 attempt 3 took 154.8s\nâœ… 13e47133: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 max-len, 1 no-code, 3 train-exec-error, 3 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 16de56c4 attempt 3 took 88.8s\nğŸŒ Slow attempt: 142ca369 attempt 4 took 88.9s\nâœ… 142ca369: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-exec-error, 1 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 16de56c4 attempt 5 took 86.8s\nğŸŒ Slow attempt: 16de56c4 attempt 4 took 91.1s\nâ³ No completions in last 15s â€” 95/960 done; 865 remaining (timeout in 150s)\nğŸ¥ Health [100 attempts]: Success 71% | Timeout 0% | ExecErr 29% | AvgTime 45.72s\nâŒ Inconsistent grid width for 16de56c4_test_0: row 2 has 22 items, expected 21\nâš ï¸  16de56c4 test_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 16de56c4_test_1: row 2 has 22 items, expected 21\nâš ï¸  16de56c4 test_1: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 16de56c4_test_debug_0: row 2 has 22 items, expected 21\nâš ï¸  16de56c4 test_debug_0: Grid failed ARC validation, using fallback\nâŒ Inconsistent grid width for 16de56c4_test_debug_1: row 2 has 22 items, expected 21\nâš ï¸  16de56c4 test_debug_1: Grid failed ARC validation, using fallback\nğŸŒ Slow attempt: 16de56c4 attempt 6 took 96.7s\nâœ… 16de56c4: 1 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-exec-error, 1 test-exec-error (best: 100.0% train)\nâ³ No completions in last 15s â€” 108/960 done; 852 remaining (timeout in 135s)\nğŸŒ Slow attempt: 20270e3b attempt 4 took 72.3s\nğŸŒ Slow attempt: 195c6913 attempt 7 took 63.1s\nğŸŒ Slow attempt: 20270e3b attempt 2 took 83.9s\nâœ… 20270e3b: 0 train-perfect, train-partial (SUBMIT mode) | Issues: 5 train-exec-error, 6 test-exec-error (best: 75.0% train)\nâœ… 269e22fb: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 5 train-exec-error, 4 test-exec-error (best: 0.0% train)\nâ³ No completions in last 15s â€” 120/960 done; 840 remaining (timeout in 120s)\nâŒ Inconsistent grid width for 221dfab4_test_0: row 4 has 21 items, expected 25\nâš ï¸  221dfab4 test_0: Grid failed ARC validation, using fallback\nğŸŒ Slow attempt: 221dfab4 attempt 1 took 67.6s\nğŸŒ Slow attempt: 20a9e565 attempt 8 took 76.2s\nâœ… 20a9e565: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 3 train-exec-error, 3 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 221dfab4 attempt 3 took 62.2s\nâ³ No completions in last 15s â€” 135/960 done; 825 remaining (timeout in 105s)\nğŸŒ Slow attempt: 221dfab4 attempt 5 took 60.5s\nâœ… 28a6681f: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-transductive (best: 0.0% train)\nğŸŒ Slow attempt: 195c6913 attempt 6 took 98.6s\nâœ… 195c6913: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-transductive, 2 train-exec-error, 1 test-exec-error (best: 0.0% train)\nâŒ Invalid cell value for 271d71e2_test_0 at [1][12]: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (type: <class 'list'>, expected native Python int)\nâš ï¸  271d71e2 test_0: Grid failed ARC validation, using fallback\nâ³ No completions in last 15s â€” 145/960 done; 815 remaining (timeout in 90s)\nâŒ Inconsistent grid width for 221dfab4_test_0: row 4 has 21 items, expected 25\nâš ï¸  221dfab4 test_0: Grid failed ARC validation, using fallback\nğŸŒ Slow attempt: 221dfab4 attempt 2 took 87.2s\nâœ… 221dfab4: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 2 train-exec-error, 2 test-exec-error (best: 0.0% train)\nâœ… 271d71e2: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 train-exec-error, 1 test-exec-error (best: 0.0% train)\nNot logging missing extracted\nğŸŒ Slow attempt: 247ef758 attempt 1 took 107.4s\nâ³ No completions in last 15s â€” 156/960 done; 804 remaining (timeout in 75s)\nNot logging missing extracted\nğŸŒ Slow attempt: 21897d95 attempt 1 took 119.2s\nğŸŒ Slow attempt: 291dc1e1 attempt 1 took 82.2s\nâ³ No completions in last 15s â€” 168/960 done; 792 remaining (timeout in 60s)\nğŸŒ Slow attempt: 21897d95 attempt 8 took 93.2s\nâœ… 21897d95: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 1 max-len, 1 no-code, 6 train-exec-error, 6 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 291dc1e1 attempt 3 took 82.8s\nâœ… 2b83f449: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 2 train-exec-error, 2 test-exec-error (best: 0.0% train)\nâœ… 31f7f899: 0 train-perfect, no-partial (SUBMIT mode) (best: 0.0% train)\nNot logging missing extracted\nğŸŒ Slow attempt: 247ef758 attempt 6 took 111.0s\nâ³ No completions in last 15s â€” 181/960 done; 779 remaining (timeout in 45s)\nNot logging missing extracted\nğŸŒ Slow attempt: 247ef758 attempt 7 took 111.4s\nâœ… 247ef758: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 3 max-len, 3 no-code, 3 train-exec-error, 3 test-exec-error (best: 0.0% train)\nğŸŒ Slow attempt: 291dc1e1 attempt 6 took 84.7s\nâœ… 2c181942: 0 train-perfect, no-partial (SUBMIT mode) | Issues: 6 train-exec-error, 6 test-exec-error (best: 0.0% train)\nâ³ No completions in last 15s â€” 194/960 done; 766 remaining (timeout in 30s)\nğŸ¥ Health [200 attempts]: Success 70% | Timeout 0% | ExecErr 30% | AvgTime 39.15s\nğŸŒ Slow attempt: 291dc1e1 attempt 8 took 89.5s\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Only score in dev/commit runs\nif SCORE and not IS_RERUN:\n    !uv run python -m llm_python.score_submission --submission \"/kaggle/working/submission.json\"\nelse:\n    print(\"Skipping local scoring (competition rerun or SCORE=False).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}