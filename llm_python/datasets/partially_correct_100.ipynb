{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad01f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "table_name = \"trelis-arc.arc.partially_correct_100\"\n",
    "file_name = table_name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e1fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery table creation...\n",
      "✓ Table `trelis-arc.arc.partially_correct_100` created successfully\n"
     ]
    }
   ],
   "source": [
    "create_final_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{table_name}` AS\n",
    "\n",
    "WITH arc_2_eval_tasks AS (\n",
    "    SELECT DISTINCT task_id\n",
    "    FROM `trelis-arc.arc.arc_task_ids`\n",
    "    WHERE subset = \"arc-agi-2/evaluation\"\n",
    "),\n",
    "-- Clean programs by collapsing multiple empty lines into single empty lines\n",
    "programs_cleaned AS (\n",
    "    SELECT \n",
    "        k.task_id,\n",
    "        -- Clean code by collapsing multiple consecutive newlines into at most one empty line\n",
    "        -- Pattern matches multiple consecutive newlines with optional whitespace\n",
    "        REGEXP_REPLACE(k.code, r'\\\\n(\\\\s*\\\\n)+', '\\\\n\\\\n') as code,\n",
    "        k.model,\n",
    "        k.predicted_train_output,\n",
    "        k.predicted_test_output,\n",
    "        k.correct_train_input,\n",
    "        k.correct_test_input\n",
    "    FROM `trelis-arc.arc.superking` k\n",
    "    WHERE task_id NOT IN (SELECT task_id FROM arc_2_eval_tasks)\n",
    "),\n",
    "-- Calculate metrics and filter by grid size\n",
    "programs_with_metrics AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        code,\n",
    "        model,\n",
    "        predicted_train_output,\n",
    "        predicted_test_output,\n",
    "        correct_train_input,\n",
    "        correct_test_input,\n",
    "        LENGTH(code) as program_length,\n",
    "        -- Check if all train inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) as all_train_correct,\n",
    "        -- Check if all test inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as all_test_correct,\n",
    "        -- Count correct examples\n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) + \n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as total_correct,\n",
    "        ARRAY_LENGTH(correct_train_input.list) + ARRAY_LENGTH(correct_test_input.list) as total_possible,\n",
    "        -- Check grid sizes for train output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d) as max_train_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_train_grid_width,\n",
    "        -- Check grid sizes for test output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d) as max_test_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_test_grid_width,\n",
    "        -- Normalize code for deduplication (remove all whitespace, lowercase)\n",
    "        LOWER(REGEXP_REPLACE(code, r'\\\\s+', '')) as normalized_code\n",
    "    FROM programs_cleaned\n",
    "),\n",
    "-- Filter by grid size (40x40) and require at least one correct\n",
    "programs_filtered AS (\n",
    "    SELECT *,\n",
    "        -- Calculate success rate for ranking\n",
    "        SAFE_DIVIDE(total_correct, total_possible) as success_rate\n",
    "    FROM programs_with_metrics\n",
    "    WHERE max_train_grid_height <= 40 AND max_train_grid_width <= 40\n",
    "      AND max_test_grid_height <= 40 AND max_test_grid_width <= 40\n",
    "      AND total_correct > 0\n",
    "),\n",
    "-- Find shortest, most correct program per task\n",
    "task_benchmarks AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        MIN(program_length) as shortest_best_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            task_id,\n",
    "            program_length,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY task_id \n",
    "                ORDER BY success_rate DESC, program_length ASC, code ASC\n",
    "            ) as rank\n",
    "        FROM programs_filtered\n",
    "    ) ranked\n",
    "    WHERE rank = 1\n",
    "    GROUP BY task_id\n",
    "),\n",
    "-- Filter programs to those within 2.5x the shortest best program per task\n",
    "programs_length_filtered AS (\n",
    "    SELECT p.*\n",
    "    FROM programs_filtered p\n",
    "    INNER JOIN task_benchmarks b ON p.task_id = b.task_id\n",
    "    WHERE p.program_length <= 2.5 * b.shortest_best_length\n",
    "),\n",
    "-- Deduplicate programs (same normalized code + task_id)\n",
    "programs_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length, success_rate,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_length_filtered\n",
    "),\n",
    "-- Take top 500 per task, prioritizing correctness then length\n",
    "final_selection AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as final_rank\n",
    "    FROM programs_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input\n",
    "FROM final_selection\n",
    "WHERE final_rank <= 100\n",
    "ORDER BY task_id, final_rank\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"✓ Table `{table_name}` created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc2d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigQuery table data...\n",
      "Exporting BigQuery table 'trelis-arc.arc.partially_correct_100' to GCS...\n",
      "Waiting for BigQuery export to complete...\n",
      "✓ Export to GCS completed successfully\n",
      "Downloading from GCS to /tmp/partially_correct_100.parquet...\n",
      "✓ Download completed\n",
      "Reading parquet file...\n",
      "Loaded 49972 rows from BigQuery table\n",
      "Loaded 49972 programs from BigQuery table\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_export import load_bigquery_table_as_dataframe\n",
    "\n",
    "# Load BigQuery table as DataFrame using our reusable function\n",
    "print(\"Loading BigQuery table data...\")\n",
    "raw_data = load_bigquery_table_as_dataframe(\n",
    "    client=client,\n",
    "    table_name=table_name\n",
    ")\n",
    "print(f\"Loaded {len(raw_data)} programs from BigQuery table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fe6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting BigQuery data structure...\n",
      "Sample row columns: ['task_id', 'code', 'model', 'predicted_train_output', 'predicted_test_output', 'correct_train_input', 'correct_test_input']\n",
      "Train output type: <class 'dict'>\n",
      "Train correct type: <class 'dict'>\n",
      "\n",
      "==================================================\n",
      "Converting BigQuery data to SOAR format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting BQ to SOAR: 100%|██████████| 49972/49972 [00:06<00:00, 8104.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 49972 programs from 49972 input rows\n",
      "Saving final dataset to: /tmp/partially_correct_100.parquet\n",
      "PyArrow save failed (\"name 'is_test_transductive' present in the specified schema is not found in the columns or index\"), using pandas fallback\n",
      "✓ Saved 49972 programs to /tmp/partially_correct_100.parquet with pandas\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_converter import convert_bigquery_to_soar\n",
    "from llm_python.datasets.validation import validate_soar_dataframe\n",
    "\n",
    "print(\"Converting BigQuery data to SOAR format...\")\n",
    "final_dataset = convert_bigquery_to_soar(raw_data, show_progress=True)\n",
    "\n",
    "# Validate the final dataset\n",
    "is_valid, validation_message = validate_soar_dataframe(final_dataset)\n",
    "print(validation_message)\n",
    "if not is_valid:\n",
    "    raise ValueError(\"Validation failed\")\n",
    "\n",
    "output_path = f\"/tmp/{file_name}.parquet\"\n",
    "print(f\"Saving final dataset to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44192e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.statistics import analyze_dataset_statistics\n",
    "\n",
    "analyze_dataset_statistics(final_dataset, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
