{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc92836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c214e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "table_name = \"trelis-arc.arc.fully_correct_50\"\n",
    "file_name = table_name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24461c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery table creation...\n",
      "✓ Table `trelis-arc.arc.fully_correct_50` created successfully\n"
     ]
    }
   ],
   "source": [
    "create_final_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{table_name}` AS\n",
    "\n",
    "WITH arc_2_eval_tasks AS (\n",
    "    SELECT DISTINCT task_id\n",
    "    FROM `trelis-arc.arc.arc_task_ids`\n",
    "    WHERE subset = \"arc-agi-2/evaluation\"\n",
    "),\n",
    "-- Clean programs by collapsing multiple empty lines into single empty lines\n",
    "programs_cleaned AS (\n",
    "    SELECT \n",
    "        k.task_id,\n",
    "        -- Clean code by collapsing multiple consecutive newlines into at most one empty line\n",
    "        -- Pattern matches multiple consecutive newlines with optional whitespace\n",
    "        REGEXP_REPLACE(k.code, r'\\\\n(\\\\s*\\\\n)+', '\\\\n\\\\n') as code,\n",
    "        k.model,\n",
    "        k.predicted_train_output,\n",
    "        k.predicted_test_output,\n",
    "        k.correct_train_input,\n",
    "        k.correct_test_input\n",
    "    FROM `trelis-arc.arc.superking` k\n",
    "    WHERE task_id NOT IN (SELECT task_id FROM arc_2_eval_tasks)\n",
    "),\n",
    "-- Calculate metrics and filter by grid size\n",
    "programs_with_metrics AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        code,\n",
    "        model,\n",
    "        predicted_train_output,\n",
    "        predicted_test_output,\n",
    "        correct_train_input,\n",
    "        correct_test_input,\n",
    "        LENGTH(code) as program_length,\n",
    "        -- Check if all train inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) as all_train_correct,\n",
    "        -- Check if all test inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as all_test_correct,\n",
    "        -- Count correct examples\n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) + \n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as total_correct,\n",
    "        ARRAY_LENGTH(correct_train_input.list) + ARRAY_LENGTH(correct_test_input.list) as total_possible,\n",
    "        -- Check grid sizes for train output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d) as max_train_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_train_grid_width,\n",
    "        -- Check grid sizes for test output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d) as max_test_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_test_grid_width,\n",
    "        -- Normalize code for deduplication (remove all whitespace, lowercase)\n",
    "        LOWER(REGEXP_REPLACE(code, r'\\\\s+', '')) as normalized_code\n",
    "    FROM programs_cleaned\n",
    "),\n",
    "-- Filter by grid size (40x40) and require ALL examples to be correct (fully correct only)\n",
    "programs_filtered AS (\n",
    "    SELECT *,\n",
    "        -- Calculate success rate for ranking\n",
    "        SAFE_DIVIDE(total_correct, total_possible) as success_rate\n",
    "    FROM programs_with_metrics\n",
    "    WHERE max_train_grid_height <= 40 AND max_train_grid_width <= 40\n",
    "      AND max_test_grid_height <= 40 AND max_test_grid_width <= 40\n",
    "      AND all_train_correct = TRUE AND all_test_correct = TRUE  -- Only fully correct programs\n",
    "),\n",
    "-- Find shortest, most correct program per task\n",
    "task_benchmarks AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        MIN(program_length) as shortest_best_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            task_id,\n",
    "            program_length,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY task_id \n",
    "                ORDER BY success_rate DESC, program_length ASC, code ASC\n",
    "            ) as rank\n",
    "        FROM programs_filtered\n",
    "    ) ranked\n",
    "    WHERE rank = 1\n",
    "    GROUP BY task_id\n",
    "),\n",
    "-- Filter programs to those within 2.5x the shortest best program per task\n",
    "programs_length_filtered AS (\n",
    "    SELECT p.*\n",
    "    FROM programs_filtered p\n",
    "    INNER JOIN task_benchmarks b ON p.task_id = b.task_id\n",
    "    WHERE p.program_length <= 2.5 * b.shortest_best_length\n",
    "),\n",
    "-- Deduplicate programs (same normalized code + task_id)\n",
    "programs_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length, success_rate,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_length_filtered\n",
    "),\n",
    "-- Take top 100 per task, prioritizing correctness then length\n",
    "final_selection AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as final_rank\n",
    "    FROM programs_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input\n",
    "FROM final_selection\n",
    "WHERE final_rank <= 50\n",
    "ORDER BY task_id, final_rank\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"✓ Table `{table_name}` created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88087110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigQuery table data...\n",
      "Exporting BigQuery table 'trelis-arc.arc.fully_correct_50' to GCS...\n",
      "Waiting for BigQuery export to complete...\n",
      "✓ Export to GCS completed successfully\n",
      "Downloading from GCS to /tmp/fully_correct_50.parquet...\n",
      "✓ Download completed\n",
      "Reading parquet file...\n",
      "Loaded 16210 rows from BigQuery table\n",
      "Loaded 16210 programs from BigQuery table\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_export import load_bigquery_table_as_dataframe\n",
    "\n",
    "# Load BigQuery table as DataFrame using our reusable function\n",
    "print(\"Loading BigQuery table data...\")\n",
    "raw_data = load_bigquery_table_as_dataframe(\n",
    "    client=client,\n",
    "    table_name=table_name\n",
    ")\n",
    "print(f\"Loaded {len(raw_data)} programs from BigQuery table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec46dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting BigQuery data to SOAR format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting BQ to SOAR: 100%|██████████| 16210/16210 [00:01<00:00, 10429.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 16210 programs from 16210 input rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_converter import convert_bigquery_to_soar\n",
    "\n",
    "print(\"Converting BigQuery data to SOAR format...\")\n",
    "final_dataset = convert_bigquery_to_soar(raw_data, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['is_transductive'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921f293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading arc-prize-2024...\n",
      "  Training: 400 tasks\n",
      "  Evaluation: 400 tasks\n",
      "  Test: 100 tasks\n",
      "Loading arc-prize-2025...\n",
      "  Training: 1000 tasks\n",
      "  Evaluation: 120 tasks\n",
      "  Test: 240 tasks\n",
      "Validation results:\n",
      "    Total programs: 16210\n",
      "    Rows failing schema validation: 1 [FAIL]\n",
      "    Rows failing data inspection: 0 [PASS]\n",
      "    Rows failing correctness checks: 0 [PASS]\n",
      "    Sample of errors:\n",
      "      Schema: Schema validation failed: \"name 'is_transductive' present in the specified schema is not found in the columns or index\"\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.validation import validate_soar_dataframe\n",
    "\n",
    "\n",
    "validation_result = validate_soar_dataframe(final_dataset)\n",
    "print(validation_result.summary())\n",
    "if not validation_result.is_valid:\n",
    "    raise ValueError(\"Validation failed: Some programs do not meet the schema requirements.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda67672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final dataset to: /tmp/fully_correct_50.parquet\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"name 'is_transductive' present in the specified schema is not found in the columns or index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'is_transductive'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:452\u001b[39m, in \u001b[36m_get_columns_to_convert_given_schema\u001b[39m\u001b[34m(df, schema, preserve_index)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     col = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    453\u001b[39m     is_index = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'is_transductive'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:456\u001b[39m, in \u001b[36m_get_columns_to_convert_given_schema\u001b[39m\u001b[34m(df, schema, preserve_index)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     col = \u001b[43m_get_index_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m):\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# name not found as index level\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:508\u001b[39m, in \u001b[36m_get_index_level\u001b[39m\u001b[34m(df, name)\u001b[39m\n\u001b[32m    507\u001b[39m     key = \u001b[38;5;28mint\u001b[39m(name[\u001b[38;5;28mlen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__index_level_\u001b[39m\u001b[33m\"\u001b[39m):-\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:2109\u001b[39m, in \u001b[36mIndex._get_level_values\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2074\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2075\u001b[39m \u001b[33;03mReturn an Index of values for requested level.\u001b[39;00m\n\u001b[32m   2076\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2107\u001b[39m \u001b[33;03mIndex(['a', 'b', 'c'], dtype='object')\u001b[39;00m\n\u001b[32m   2108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2109\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_index_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:2019\u001b[39m, in \u001b[36mIndex._validate_index_level\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2018\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m level != \u001b[38;5;28mself\u001b[39m.name:\n\u001b[32m-> \u001b[39m\u001b[32m2019\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   2020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequested level (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) does not match index name (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2021\u001b[39m     )\n",
      "\u001b[31mKeyError\u001b[39m: 'Requested level (is_transductive) does not match index name (None)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m output_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/tmp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaving final dataset to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mwrite_soar_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/llm_python/datasets/io.py:47\u001b[39m, in \u001b[36mwrite_soar_parquet\u001b[39m\u001b[34m(df, path)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03mWrite parquet file with proper schema preservation and enforcement.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \u001b[33;03m    path: Output path\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Convert to PyArrow table with strict schema enforcement\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Schema validation happens automatically here\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m table = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPARQUET_SCHEMA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Write with PyArrow to ensure schema compliance\u001b[39;00m\n\u001b[32m     50\u001b[39m pq.write_table(table, path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/table.pxi:4795\u001b[39m, in \u001b[36mpyarrow.lib.Table.from_pandas\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:594\u001b[39m, in \u001b[36mdataframe_to_arrays\u001b[39m\u001b[34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdataframe_to_arrays\u001b[39m(df, schema, preserve_index, nthreads=\u001b[32m1\u001b[39m, columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    586\u001b[39m                         safe=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    587\u001b[39m     (all_names,\n\u001b[32m    588\u001b[39m      column_names,\n\u001b[32m    589\u001b[39m      column_field_names,\n\u001b[32m    590\u001b[39m      index_column_names,\n\u001b[32m    591\u001b[39m      index_descriptors,\n\u001b[32m    592\u001b[39m      index_columns,\n\u001b[32m    593\u001b[39m      columns_to_convert,\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m      convert_fields) = \u001b[43m_get_columns_to_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m     \u001b[38;5;66;03m# NOTE(wesm): If nthreads=None, then we use a heuristic to decide whether\u001b[39;00m\n\u001b[32m    598\u001b[39m     \u001b[38;5;66;03m# using a thread pool is worth it. Currently the heuristic is whether the\u001b[39;00m\n\u001b[32m    599\u001b[39m     \u001b[38;5;66;03m# nrows > 100 * ncols and ncols > 1.\u001b[39;00m\n\u001b[32m    600\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nthreads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:379\u001b[39m, in \u001b[36m_get_columns_to_convert\u001b[39m\u001b[34m(df, schema, preserve_index, columns)\u001b[39m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    375\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDuplicate column names found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    376\u001b[39m     )\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_columns_to_convert_given_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m column_names = []\n\u001b[32m    382\u001b[39m column_field_names = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/trelis-arc/.venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:459\u001b[39m, in \u001b[36m_get_columns_to_convert_given_schema\u001b[39m\u001b[34m(df, schema, preserve_index)\u001b[39m\n\u001b[32m    456\u001b[39m     col = _get_index_level(df, name)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m):\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# name not found as index level\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    460\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mname \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m present in the specified schema is not found \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33min the columns or index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    464\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mname \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m present in the specified schema corresponds \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto the index, but \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpreserve_index=False\u001b[39m\u001b[33m'\u001b[39m\u001b[33m was \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mspecified\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"name 'is_transductive' present in the specified schema is not found in the columns or index\""
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.io import write_soar_parquet\n",
    "\n",
    "\n",
    "output_path = f\"/tmp/{file_name}.parquet\"\n",
    "print(f\"Saving final dataset to: {output_path}\")\n",
    "write_soar_parquet(final_dataset, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.statistics import analyze_dataset_statistics\n",
    "\n",
    "analyze_dataset_statistics(final_dataset, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbcffc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
