{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "table_name = \"trelis-arc.arc.shortest_ratio_2_5x_filtered_250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_final_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{table_name}` AS\n",
    "\n",
    "WITH training_tasks AS (\n",
    "    SELECT DISTINCT task_id\n",
    "    FROM `trelis-arc.arc.arc_task_ids`\n",
    "    WHERE subset = \"arc-agi-1/training\"\n",
    "),\n",
    "-- Clean programs by collapsing multiple empty lines into single empty lines\n",
    "programs_cleaned AS (\n",
    "    SELECT \n",
    "        k.task_id,\n",
    "        -- Clean code by collapsing multiple consecutive newlines into at most one empty line\n",
    "        -- Pattern matches multiple consecutive newlines with optional whitespace\n",
    "        REGEXP_REPLACE(k.code, r'\\\\n(\\\\s*\\\\n)+', '\\\\n\\\\n') as code,\n",
    "        k.model,\n",
    "        k.predicted_train_output,\n",
    "        k.predicted_test_output,\n",
    "        k.correct_train_input,\n",
    "        k.correct_test_input\n",
    "    FROM `trelis-arc.arc.king_programs_ext` k\n",
    "    INNER JOIN training_tasks t ON k.task_id = t.task_id\n",
    "    WHERE k.model != 'hodel-translated'\n",
    "),\n",
    "-- Calculate metrics and filter by grid size\n",
    "programs_with_metrics AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        code,\n",
    "        model,\n",
    "        predicted_train_output,\n",
    "        predicted_test_output,\n",
    "        correct_train_input,\n",
    "        correct_test_input,\n",
    "        LENGTH(code) as program_length,\n",
    "        -- Check if all train inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) as all_train_correct,\n",
    "        -- Check if all test inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as all_test_correct,\n",
    "        -- Count correct examples\n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) + \n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as total_correct,\n",
    "        ARRAY_LENGTH(correct_train_input.list) + ARRAY_LENGTH(correct_test_input.list) as total_possible,\n",
    "        -- Check grid sizes for train output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d) as max_train_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_train_grid_width,\n",
    "        -- Check grid sizes for test output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d) as max_test_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_test_grid_width,\n",
    "        -- Normalize code for deduplication (remove all whitespace, lowercase)\n",
    "        LOWER(REGEXP_REPLACE(code, r'\\\\s+', '')) as normalized_code\n",
    "    FROM programs_cleaned\n",
    "),\n",
    "-- Filter by grid size (40x40) and require at least one correct\n",
    "programs_filtered AS (\n",
    "    SELECT *,\n",
    "        -- Calculate success rate for ranking\n",
    "        SAFE_DIVIDE(total_correct, total_possible) as success_rate\n",
    "    FROM programs_with_metrics\n",
    "    WHERE max_train_grid_height <= 40 AND max_train_grid_width <= 40\n",
    "      AND max_test_grid_height <= 40 AND max_test_grid_width <= 40\n",
    "      AND total_correct > 0\n",
    "),\n",
    "-- Find shortest, most correct program per task\n",
    "task_benchmarks AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        MIN(program_length) as shortest_best_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            task_id,\n",
    "            program_length,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY task_id \n",
    "                ORDER BY success_rate DESC, program_length ASC, code ASC\n",
    "            ) as rank\n",
    "        FROM programs_filtered\n",
    "    ) ranked\n",
    "    WHERE rank = 1\n",
    "    GROUP BY task_id\n",
    "),\n",
    "-- Filter programs to those within 2.5x the shortest best program per task\n",
    "programs_length_filtered AS (\n",
    "    SELECT p.*\n",
    "    FROM programs_filtered p\n",
    "    INNER JOIN task_benchmarks b ON p.task_id = b.task_id\n",
    "    WHERE p.program_length <= 2.5 * b.shortest_best_length\n",
    "),\n",
    "-- Deduplicate programs (same normalized code + task_id)\n",
    "programs_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length, success_rate,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_length_filtered\n",
    "),\n",
    "-- Take top 500 per task, prioritizing correctness then length\n",
    "final_selection AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as final_rank\n",
    "    FROM programs_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input\n",
    "FROM final_selection\n",
    "WHERE final_rank <= 250\n",
    "ORDER BY task_id, final_rank\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"‚úì Table `{table_name}` created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "import pandas as pd\n",
    "\n",
    "# Fast GCS export approach for large datasets\n",
    "print(\"Using Google Cloud Storage export for fast data transfer...\")\n",
    "\n",
    "file_name = table_name.split('.')[-1]  # Extract the last part of the table name\n",
    "\n",
    "# Use descriptive filenames\n",
    "gcs_uri = f\"gs://trelis-arc/tmp/{file_name}.parquet\"\n",
    "local_file = f\"/tmp/{file_name}.parquet\"\n",
    "\n",
    "print(f\"Exporting BigQuery table to: {gcs_uri}\")\n",
    "\n",
    "# Export to Cloud Storage (much faster for large datasets)\n",
    "export_job_config = bigquery.ExtractJobConfig()\n",
    "export_job_config.destination_format = bigquery.DestinationFormat.PARQUET\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    table_name,  # Use the full table name\n",
    "    gcs_uri,\n",
    "    job_config=export_job_config\n",
    ")\n",
    "\n",
    "print(\"Waiting for BigQuery export to complete...\")\n",
    "extract_job.result()  # Wait for export to complete\n",
    "print(\"‚úì Export to GCS completed successfully\")\n",
    "\n",
    "# Download and read the parquet file directly\n",
    "print(\"Downloading from GCS...\")\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket('trelis-arc')\n",
    "blob = bucket.blob(f'tmp/{file_name}.parquet')\n",
    "blob.download_to_filename(local_file)\n",
    "print(\"‚úì Download completed\")\n",
    "\n",
    "# Read the parquet file\n",
    "print(\"Reading parquet file...\")\n",
    "raw_data = pd.read_parquet(local_file)\n",
    "print(f\"Loaded {len(raw_data)} programs from parquet file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from llm_python.datasets.schema import PARQUET_SCHEMA\n",
    "\n",
    "# First, let's inspect the actual data structure\n",
    "print(\"Inspecting BigQuery data structure...\")\n",
    "sample_row = raw_data.iloc[0]\n",
    "print(f\"Sample row columns: {sample_row.index.tolist()}\")\n",
    "print(f\"Train output type: {type(sample_row['predicted_train_output'])}\")\n",
    "print(f\"Train output content: {sample_row['predicted_train_output']}\")\n",
    "print(f\"Train correct type: {type(sample_row['correct_train_input'])}\")\n",
    "print(f\"Train correct content: {sample_row['correct_train_input']}\")\n",
    "\n",
    "if hasattr(sample_row['predicted_train_output'], 'keys'):\n",
    "    print(f\"Train output keys: {list(sample_row['predicted_train_output'].keys())}\")\n",
    "if hasattr(sample_row['correct_train_input'], 'keys'):\n",
    "    print(f\"Train correct keys: {list(sample_row['correct_train_input'].keys())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "def convert_bq_nested_structure(bq_data):\n",
    "    \"\"\"Convert BigQuery nested structure to proper list format\n",
    "    Handles the complex nested structure from BigQuery exports\n",
    "    \"\"\"\n",
    "    if bq_data is None:\n",
    "        return []\n",
    "    \n",
    "    # If it's already a simple list, return it\n",
    "    if isinstance(bq_data, list):\n",
    "        return bq_data\n",
    "    \n",
    "    # Handle BigQuery's nested structure\n",
    "    if isinstance(bq_data, dict):\n",
    "        if 'list' in bq_data:\n",
    "            list_data = bq_data['list']\n",
    "            \n",
    "            # Convert numpy array to list if needed\n",
    "            if hasattr(list_data, 'tolist'):\n",
    "                list_data = list_data.tolist()\n",
    "            \n",
    "            # If it's a list of dicts with 'element' key, extract the elements\n",
    "            if isinstance(list_data, list) and len(list_data) > 0:\n",
    "                if isinstance(list_data[0], dict) and 'element' in list_data[0]:\n",
    "                    # This is a list of {\"element\": actual_data} structures\n",
    "                    result = []\n",
    "                    for item in list_data:\n",
    "                        if isinstance(item, dict) and 'element' in item:\n",
    "                            element = item['element']\n",
    "                            # Recursively convert nested structures\n",
    "                            if isinstance(element, dict) and 'list' in element:\n",
    "                                result.append(convert_bq_nested_structure(element))\n",
    "                            else:\n",
    "                                result.append(element)\n",
    "                        else:\n",
    "                            result.append(item)\n",
    "                    return result\n",
    "                else:\n",
    "                    return list_data\n",
    "            else:\n",
    "                return list_data if isinstance(list_data, list) else []\n",
    "        else:\n",
    "            # Not a standard BigQuery list structure\n",
    "            return []\n",
    "    \n",
    "    return []\n",
    "\n",
    "def extract_boolean_values(bool_array):\n",
    "    \"\"\"Extract boolean values from the {'element': bool} format\"\"\"\n",
    "    if not isinstance(bool_array, list):\n",
    "        return []\n",
    "    \n",
    "    result = []\n",
    "    for item in bool_array:\n",
    "        if isinstance(item, dict) and 'element' in item:\n",
    "            result.append(bool(item['element']))\n",
    "        else:\n",
    "            result.append(bool(item))\n",
    "    return result\n",
    "\n",
    "def validate_converted_data(data_dict):\n",
    "    \"\"\"Validate a single converted data dict against the expected schema\"\"\"\n",
    "    try:\n",
    "        # Check required fields exist\n",
    "        required_fields = ['task_id', 'code', 'model', 'predicted_train_output', \n",
    "                          'predicted_test_output', 'correct_train_input', 'correct_test_input']\n",
    "        for field in required_fields:\n",
    "            if field not in data_dict:\n",
    "                return False, f\"Missing field: {field}\"\n",
    "        \n",
    "        # Check types\n",
    "        if not isinstance(data_dict['task_id'], str):\n",
    "            return False, f\"task_id should be str, got {type(data_dict['task_id'])}\"\n",
    "        if not isinstance(data_dict['code'], str):\n",
    "            return False, f\"code should be str, got {type(data_dict['code'])}\"\n",
    "        if not isinstance(data_dict['model'], str):\n",
    "            return False, f\"model should be str, got {type(data_dict['model'])}\"\n",
    "        \n",
    "        # Check 3D arrays (List[List[List[int]]])\n",
    "        for field in ['predicted_train_output', 'predicted_test_output']:\n",
    "            arr = data_dict[field]\n",
    "            if not isinstance(arr, list):\n",
    "                return False, f\"{field} should be list, got {type(arr)}\"\n",
    "            for i, grid in enumerate(arr):\n",
    "                if not isinstance(grid, list):\n",
    "                    return False, f\"{field}[{i}] should be list (2D grid), got {type(grid)}\"\n",
    "                for j, row in enumerate(grid):\n",
    "                    if not isinstance(row, list):\n",
    "                        return False, f\"{field}[{i}][{j}] should be list (row), got {type(row)}\"\n",
    "                    for k, cell in enumerate(row):\n",
    "                        if not isinstance(cell, int):\n",
    "                            return False, f\"{field}[{i}][{j}][{k}] should be int, got {type(cell)}\"\n",
    "        \n",
    "        # Check boolean arrays\n",
    "        for field in ['correct_train_input', 'correct_test_input']:\n",
    "            arr = data_dict[field]\n",
    "            if not isinstance(arr, list):\n",
    "                return False, f\"{field} should be list, got {type(arr)}\"\n",
    "            for i, val in enumerate(arr):\n",
    "                if not isinstance(val, bool):\n",
    "                    return False, f\"{field}[{i}] should be bool, got {type(val)}\"\n",
    "        \n",
    "        return True, \"Valid\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Validation error: {e}\"\n",
    "\n",
    "print(\"Converting BigQuery nested structures to proper arrays...\")\n",
    "\n",
    "# Test conversion on first few rows to debug\n",
    "print(\"Testing conversion on first row...\")\n",
    "test_row = raw_data.iloc[0]\n",
    "print(f\"Original train output: {test_row['predicted_train_output']}\")\n",
    "converted_train = convert_bq_nested_structure(test_row['predicted_train_output'])\n",
    "print(f\"Converted train output: {converted_train}\")\n",
    "print(f\"Converted type: {type(converted_train)}\")\n",
    "if isinstance(converted_train, list) and len(converted_train) > 0:\n",
    "    print(f\"First grid type: {type(converted_train[0])}\")\n",
    "    print(f\"First grid content: {converted_train[0]}\")\n",
    "\n",
    "# Convert data with proper handling of BigQuery structure\n",
    "converted_data = []\n",
    "validation_errors = []\n",
    "\n",
    "for idx in tqdm(range(len(raw_data)), desc=\"Converting structures\"):\n",
    "    row = raw_data.iloc[idx]\n",
    "    \n",
    "    try:\n",
    "        converted_row = {\n",
    "            'task_id': row['task_id'],\n",
    "            'code': row['code'], \n",
    "            'model': row['model'],\n",
    "            'predicted_train_output': convert_bq_nested_structure(row['predicted_train_output']),\n",
    "            'predicted_test_output': convert_bq_nested_structure(row['predicted_test_output']),\n",
    "            'correct_train_input': extract_boolean_values(convert_bq_nested_structure(row['correct_train_input'])),\n",
    "            'correct_test_input': extract_boolean_values(convert_bq_nested_structure(row['correct_test_input']))\n",
    "        }\n",
    "        \n",
    "        # Validate the converted row\n",
    "        is_valid, error_msg = validate_converted_data(converted_row)\n",
    "        if is_valid:\n",
    "            converted_data.append(converted_row)\n",
    "        else:\n",
    "            validation_errors.append(f\"Row {idx}: {error_msg}\")\n",
    "            if len(validation_errors) <= 5:  # Only print first few errors\n",
    "                print(f\"Validation error for row {idx}: {error_msg}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        validation_errors.append(f\"Row {idx}: Conversion error: {e}\")\n",
    "        if len(validation_errors) <= 5:\n",
    "            print(f\"Conversion error for row {idx}: {e}\")\n",
    "\n",
    "print(f\"Successfully converted {len(converted_data)} programs\")\n",
    "if validation_errors:\n",
    "    print(f\"Had {len(validation_errors)} validation/conversion errors\")\n",
    "\n",
    "# Create DataFrame from successfully converted data\n",
    "final_dataset = pd.DataFrame(converted_data)\n",
    "print(f\"Final dataset has {len(final_dataset)} programs\")\n",
    "\n",
    "# Save the final dataset\n",
    "if len(final_dataset) > 0:\n",
    "    # Add missing columns with default values for schema compliance\n",
    "    schema_df = final_dataset.copy()\n",
    "    schema_df['reasoning'] = ''  # Empty reasoning for now\n",
    "    schema_df['train_input'] = [[] for _ in range(len(schema_df))]  # Empty for now\n",
    "    schema_df['test_input'] = [[] for _ in range(len(schema_df))]   # Empty for now\n",
    "    schema_df['generation'] = 0  # Default generation\n",
    "\n",
    "    # Reorder columns to match schema\n",
    "    schema_columns = ['task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input',\n",
    "                     'predicted_train_output', 'predicted_test_output', 'train_input', 'test_input',\n",
    "                     'model', 'generation']\n",
    "    schema_df = schema_df[schema_columns]\n",
    "    \n",
    "    # Save with PyArrow to ensure proper schema\n",
    "    output_path = f\"/tmp/{file_name}.parquet\"\n",
    "    print(f\"Saving final dataset to: {output_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Convert to PyArrow table with explicit schema\n",
    "        table = pa.Table.from_pandas(schema_df, schema=PARQUET_SCHEMA)\n",
    "        pq.write_table(table, output_path)\n",
    "        print(\"‚úì Saved with proper PyArrow schema\")\n",
    "    except Exception as e:\n",
    "        print(f\"PyArrow save failed ({e}), using pandas fallback\")\n",
    "        schema_df.to_parquet(output_path, index=False)\n",
    "\n",
    "else:\n",
    "    print(\"No valid data to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84683efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive verification of the final dataset\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE DATASET VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "file_path = f\"/tmp/{file_name}.parquet\"\n",
    "\n",
    "# 1. Basic file and structure verification\n",
    "print(\"\\n1. BASIC DATASET INFO:\")\n",
    "print(\"-\" * 40)\n",
    "verification_df = pd.read_parquet(file_path)\n",
    "print(f\"‚úì File loaded successfully\")\n",
    "print(f\"‚úì Dataset shape: {verification_df.shape}\")\n",
    "print(f\"‚úì Columns: {list(verification_df.columns)}\")\n",
    "print(f\"‚úì Unique tasks: {verification_df['task_id'].nunique()}\")\n",
    "print(f\"‚úì Programs per task (mean): {verification_df.groupby('task_id').size().mean():.2f}\")\n",
    "print(f\"‚úì Programs per task (max): {verification_df.groupby('task_id').size().max()}\")\n",
    "print(f\"‚úì Programs per task (min): {verification_df.groupby('task_id').size().min()}\")\n",
    "\n",
    "# 2. Data type verification\n",
    "print(\"\\n2. DATA TYPE VERIFICATION:\")\n",
    "print(\"-\" * 40)\n",
    "sample = verification_df.iloc[0]\n",
    "\n",
    "# Check predicted outputs (should be 3D arrays: List[List[List[int]]])\n",
    "train_output = sample['predicted_train_output']\n",
    "test_output = sample['predicted_test_output']\n",
    "\n",
    "print(f\"‚úì Train output type: {type(train_output)} (expected: list)\")\n",
    "print(f\"‚úì Train output length: {len(train_output)} grids\")\n",
    "if len(train_output) > 0:\n",
    "    first_grid = train_output[0]\n",
    "    print(f\"‚úì First grid type: {type(first_grid)} (expected: list)\")\n",
    "    if isinstance(first_grid, list) and len(first_grid) > 0:\n",
    "        print(f\"‚úì Grid dimensions: {len(first_grid)} x {len(first_grid[0])}\")\n",
    "        if len(first_grid[0]) > 0:\n",
    "            cell_value = first_grid[0][0]\n",
    "            print(f\"‚úì Cell value type: {type(cell_value)} = {cell_value} (expected: int)\")\n",
    "\n",
    "print(f\"‚úì Test output type: {type(test_output)} (expected: list)\")\n",
    "print(f\"‚úì Test output length: {len(test_output)} grids\")\n",
    "\n",
    "# Check correctness arrays (should be 1D boolean arrays: List[bool])\n",
    "train_correct = sample['correct_train_input']\n",
    "test_correct = sample['correct_test_input']\n",
    "\n",
    "print(f\"‚úì Train correct type: {type(train_correct)} (expected: list)\")\n",
    "print(f\"‚úì Train correct values: {train_correct}\")\n",
    "if len(train_correct) > 0:\n",
    "    print(f\"‚úì First correct value type: {type(train_correct[0])} (expected: bool)\")\n",
    "\n",
    "print(f\"‚úì Test correct type: {type(test_correct)} (expected: list)\")\n",
    "print(f\"‚úì Test correct values: {test_correct}\")\n",
    "\n",
    "# 3. Data completeness verification\n",
    "print(\"\\n3. DATA COMPLETENESS:\")\n",
    "print(\"-\" * 40)\n",
    "non_empty_train = verification_df['predicted_train_output'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_test = verification_df['predicted_test_output'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_train_correct = verification_df['correct_train_input'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_test_correct = verification_df['correct_test_input'].apply(lambda x: len(x) > 0).sum()\n",
    "\n",
    "print(f\"‚úì Rows with train outputs: {non_empty_train}/{len(verification_df)} ({100*non_empty_train/len(verification_df):.1f}%)\")\n",
    "print(f\"‚úì Rows with test outputs: {non_empty_test}/{len(verification_df)} ({100*non_empty_test/len(verification_df):.1f}%)\")\n",
    "print(f\"‚úì Rows with train correctness: {non_empty_train_correct}/{len(verification_df)} ({100*non_empty_train_correct/len(verification_df):.1f}%)\")\n",
    "print(f\"‚úì Rows with test correctness: {non_empty_test_correct}/{len(verification_df)} ({100*non_empty_test_correct/len(verification_df):.1f}%)\")\n",
    "\n",
    "# 4. Code cleaning verification\n",
    "print(\"\\n4. CODE CLEANING VERIFICATION:\")\n",
    "print(\"-\" * 40)\n",
    "# Check if codes have whitespace-only lines removed\n",
    "codes_with_empty_lines = 0\n",
    "total_codes_checked = min(100, len(verification_df))  # Check first 100\n",
    "\n",
    "for i in range(total_codes_checked):\n",
    "    code = verification_df.iloc[i]['code']\n",
    "    lines = code.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.strip() == '':\n",
    "            codes_with_empty_lines += 1\n",
    "            break\n",
    "\n",
    "print(f\"‚úì Codes with empty lines: {codes_with_empty_lines}/{total_codes_checked} (should be 0)\")\n",
    "\n",
    "# 5. DuckDB compatibility verification\n",
    "print(\"\\n5. DUCKDB COMPATIBILITY:\")\n",
    "print(\"-\" * 40)\n",
    "con = duckdb.connect()\n",
    "\n",
    "try:\n",
    "    # Schema check\n",
    "    schema = con.execute(f\"DESCRIBE '{file_path}'\").fetchdf()\n",
    "    print(f\"‚úì DuckDB can read schema ({len(schema)} columns)\")\n",
    "    \n",
    "    # Basic query check\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT \n",
    "        task_id,\n",
    "        model,\n",
    "        length(predicted_train_output) as num_train_grids,\n",
    "        length(predicted_test_output) as num_test_grids,\n",
    "        length(correct_train_input) as num_train_examples,\n",
    "        length(correct_test_input) as num_test_examples\n",
    "    FROM '{file_path}' \n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    sample_data = con.execute(sample_query).fetchdf()\n",
    "    print(f\"‚úì Basic queries work\")\n",
    "    print(f\"  Sample data shape: {sample_data.shape}\")\n",
    "    \n",
    "    # 3D array access check\n",
    "    nested_query = f\"\"\"\n",
    "    SELECT \n",
    "        task_id,\n",
    "        predicted_train_output[1] as first_train_grid,\n",
    "        length(predicted_train_output[1]) as grid_height,\n",
    "        length(predicted_train_output[1][1]) as grid_width\n",
    "    FROM '{file_path}' \n",
    "    WHERE length(predicted_train_output) > 0 \n",
    "      AND length(predicted_train_output[1]) > 0\n",
    "    LIMIT 2\n",
    "    \"\"\"\n",
    "    nested_data = con.execute(nested_query).fetchdf()\n",
    "    print(f\"‚úì 3D array access works\")\n",
    "    print(f\"  Grid access sample: {nested_data.shape}\")\n",
    "    \n",
    "    print(f\"‚úì All DuckDB operations successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó DuckDB error: {e}\")\n",
    "\n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "# 6. Summary statistics\n",
    "print(\"\\n6. DATASET STATISTICS:\")\n",
    "print(\"-\" * 40)\n",
    "task_stats = verification_df.groupby('task_id').size()\n",
    "model_stats = verification_df['model'].value_counts()\n",
    "\n",
    "print(f\"‚úì Tasks with programs: {len(task_stats)}\")\n",
    "print(f\"‚úì Programs per task: min={task_stats.min()}, max={task_stats.max()}, mean={task_stats.mean():.1f}\")\n",
    "print(f\"‚úì Models represented: {len(model_stats)}\")\n",
    "print(f\"‚úì Top 3 models: {dict(model_stats.head(3))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ VERIFICATION COMPLETE - Filtered dataset is ready for use!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìÅ Final dataset location: {file_path}\")\n",
    "print(f\"üìä Total programs: {len(verification_df):,}\")\n",
    "print(f\"üéØ Unique tasks: {verification_df['task_id'].nunique()}\")\n",
    "print(f\"ü§ñ Models: {len(model_stats)}\")\n",
    "print(f\"üìè Max programs per task: {task_stats.max()} (target: ‚â§500)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00037e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "sample_df = con.execute(f\"SELECT * FROM '{file_path}' LIMIT 10\").fetchdf()\n",
    "con.close()\n",
    "print(sample_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
