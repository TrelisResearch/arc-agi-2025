{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad01f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "table_name = \"trelis-arc.arc.shortest_ratio_2_5x_filtered_250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e1fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery table creation...\n",
      "‚úì Table `trelis-arc.arc.shortest_ratio_2_5x_filtered_250` created successfully\n",
      "‚úì Table `trelis-arc.arc.shortest_ratio_2_5x_filtered_250` created successfully\n"
     ]
    }
   ],
   "source": [
    "create_final_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{table_name}` AS\n",
    "\n",
    "WITH training_tasks AS (\n",
    "    SELECT DISTINCT task_id\n",
    "    FROM `trelis-arc.arc.arc_task_ids`\n",
    "    WHERE subset = \"arc-agi-1/training\"\n",
    "),\n",
    "-- Clean programs by collapsing multiple empty lines into single empty lines\n",
    "programs_cleaned AS (\n",
    "    SELECT \n",
    "        k.task_id,\n",
    "        -- Clean code by collapsing multiple consecutive newlines into at most one empty line\n",
    "        -- Pattern matches multiple consecutive newlines with optional whitespace\n",
    "        REGEXP_REPLACE(k.code, r'\\\\n(\\\\s*\\\\n)+', '\\\\n\\\\n') as code,\n",
    "        k.model,\n",
    "        k.predicted_train_output,\n",
    "        k.predicted_test_output,\n",
    "        k.correct_train_input,\n",
    "        k.correct_test_input\n",
    "    FROM `trelis-arc.arc.king_programs_ext` k\n",
    "    INNER JOIN training_tasks t ON k.task_id = t.task_id\n",
    "    WHERE k.model != 'hodel-translated'\n",
    "),\n",
    "-- Calculate metrics and filter by grid size\n",
    "programs_with_metrics AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        code,\n",
    "        model,\n",
    "        predicted_train_output,\n",
    "        predicted_test_output,\n",
    "        correct_train_input,\n",
    "        correct_test_input,\n",
    "        LENGTH(code) as program_length,\n",
    "        -- Check if all train inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) as all_train_correct,\n",
    "        -- Check if all test inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as all_test_correct,\n",
    "        -- Count correct examples\n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) + \n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as total_correct,\n",
    "        ARRAY_LENGTH(correct_train_input.list) + ARRAY_LENGTH(correct_test_input.list) as total_possible,\n",
    "        -- Check grid sizes for train output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d) as max_train_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_train_grid_width,\n",
    "        -- Check grid sizes for test output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d) as max_test_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_test_grid_width,\n",
    "        -- Normalize code for deduplication (remove all whitespace, lowercase)\n",
    "        LOWER(REGEXP_REPLACE(code, r'\\\\s+', '')) as normalized_code\n",
    "    FROM programs_cleaned\n",
    "),\n",
    "-- Filter by grid size (40x40) and require at least one correct\n",
    "programs_filtered AS (\n",
    "    SELECT *,\n",
    "        -- Calculate success rate for ranking\n",
    "        SAFE_DIVIDE(total_correct, total_possible) as success_rate\n",
    "    FROM programs_with_metrics\n",
    "    WHERE max_train_grid_height <= 40 AND max_train_grid_width <= 40\n",
    "      AND max_test_grid_height <= 40 AND max_test_grid_width <= 40\n",
    "      AND total_correct > 0\n",
    "),\n",
    "-- Find shortest, most correct program per task\n",
    "task_benchmarks AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        MIN(program_length) as shortest_best_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            task_id,\n",
    "            program_length,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY task_id \n",
    "                ORDER BY success_rate DESC, program_length ASC, code ASC\n",
    "            ) as rank\n",
    "        FROM programs_filtered\n",
    "    ) ranked\n",
    "    WHERE rank = 1\n",
    "    GROUP BY task_id\n",
    "),\n",
    "-- Filter programs to those within 2.5x the shortest best program per task\n",
    "programs_length_filtered AS (\n",
    "    SELECT p.*\n",
    "    FROM programs_filtered p\n",
    "    INNER JOIN task_benchmarks b ON p.task_id = b.task_id\n",
    "    WHERE p.program_length <= 2.5 * b.shortest_best_length\n",
    "),\n",
    "-- Deduplicate programs (same normalized code + task_id)\n",
    "programs_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length, success_rate,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_length_filtered\n",
    "),\n",
    "-- Take top 500 per task, prioritizing correctness then length\n",
    "final_selection AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as final_rank\n",
    "    FROM programs_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input\n",
    "FROM final_selection\n",
    "WHERE final_rank <= 250\n",
    "ORDER BY task_id, final_rank\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"‚úì Table `{table_name}` created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigQuery table data...\n",
      "Exporting BigQuery table 'trelis-arc.arc.shortest_ratio_2_5x_filtered_250' to GCS...\n",
      "Waiting for BigQuery export to complete...\n",
      "Waiting for BigQuery export to complete...\n",
      "‚úì Export to GCS completed successfully\n",
      "Downloading from GCS to /tmp/shortest_ratio_2_5x_filtered_250.parquet...\n",
      "‚úì Export to GCS completed successfully\n",
      "Downloading from GCS to /tmp/shortest_ratio_2_5x_filtered_250.parquet...\n",
      "‚úì Download completed\n",
      "Reading parquet file...\n",
      "‚úì Download completed\n",
      "Reading parquet file...\n",
      "Loaded 59170 rows from BigQuery table\n",
      "Loaded 59170 programs from BigQuery table\n",
      "Loaded 59170 rows from BigQuery table\n",
      "Loaded 59170 programs from BigQuery table\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_export import load_bigquery_table_as_dataframe\n",
    "\n",
    "# Load BigQuery table as DataFrame using our reusable function\n",
    "print(\"Loading BigQuery table data...\")\n",
    "raw_data = load_bigquery_table_as_dataframe(\n",
    "    client=client,\n",
    "    table_name=table_name\n",
    ")\n",
    "print(f\"Loaded {len(raw_data)} programs from BigQuery table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00fe6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting BigQuery data structure...\n",
      "Sample row columns: ['task_id', 'code', 'model', 'predicted_train_output', 'predicted_test_output', 'correct_train_input', 'correct_test_input']\n",
      "Train output type: <class 'dict'>\n",
      "Train correct type: <class 'dict'>\n",
      "\n",
      "==================================================\n",
      "Converting BigQuery data to SOAR format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting BQ to SOAR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59170/59170 [00:06<00:00, 9365.96it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 59170 programs from 59170 input rows\n",
      "Saving final dataset to: /tmp/shortest_ratio_2_5x_filtered_250.parquet\n",
      "‚úì Saved 59170 programs to /tmp/shortest_ratio_2_5x_filtered_250.parquet with proper PyArrow schema\n",
      "‚úì Saved 59170 programs to /tmp/shortest_ratio_2_5x_filtered_250.parquet with proper PyArrow schema\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets import convert_bigquery_to_soar, save_soar_parquet\n",
    "\n",
    "# First, let's inspect the actual data structure\n",
    "print(\"Inspecting BigQuery data structure...\")\n",
    "sample_row = raw_data.iloc[0]\n",
    "print(f\"Sample row columns: {sample_row.index.tolist()}\")\n",
    "print(f\"Train output type: {type(sample_row['predicted_train_output'])}\")\n",
    "print(f\"Train correct type: {type(sample_row['correct_train_input'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Convert BigQuery data to SOAR format using our reusable function\n",
    "print(\"Converting BigQuery data to SOAR format...\")\n",
    "final_dataset = convert_bigquery_to_soar(raw_data, show_progress=True)\n",
    "\n",
    "# Save the final dataset\n",
    "if len(final_dataset) > 0:\n",
    "    file_name = table_name.split('.')[-1]  # Extract the last part of the table name\n",
    "    output_path = f\"/tmp/{file_name}.parquet\"\n",
    "    print(f\"Saving final dataset to: {output_path}\")\n",
    "    \n",
    "    save_soar_parquet(final_dataset, output_path)\n",
    "else:\n",
    "    print(\"No valid data to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84683efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE DATASET VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "1. BASIC DATASET INFO:\n",
      "----------------------------------------\n",
      "‚úì File loaded successfully\n",
      "‚úì Dataset shape: (59170, 11)\n",
      "‚úì Columns: ['task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input', 'predicted_train_output', 'predicted_test_output', 'train_input', 'test_input', 'model', 'generation']\n",
      "‚úì Unique tasks: 399\n",
      "‚úì Programs per task (mean): 148.30\n",
      "‚úì Programs per task (max): 250\n",
      "‚úì Programs per task (min): 2\n",
      "\n",
      "2. DATA TYPE VERIFICATION:\n",
      "----------------------------------------\n",
      "‚úì Train output type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Train output length: 5 grids\n",
      "‚úì First grid type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Test output type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Test output length: 1 grids\n",
      "‚úì Train correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Train correct values: [ True  True  True  True  True]\n",
      "‚úì First correct value type: <class 'numpy.bool'> (expected: bool)\n",
      "‚úì Test correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Test correct values: [ True]\n",
      "\n",
      "3. DATA COMPLETENESS:\n",
      "----------------------------------------\n",
      "‚úì Rows with train outputs: 59170/59170 (100.0%)\n",
      "‚úì Rows with test outputs: 59170/59170 (100.0%)\n",
      "‚úì Rows with train correctness: 59170/59170 (100.0%)\n",
      "‚úì Rows with test correctness: 59170/59170 (100.0%)\n",
      "\n",
      "4. CODE CLEANING VERIFICATION:\n",
      "----------------------------------------\n",
      "‚úì Codes with empty lines: 73/100 (should be 0)\n",
      "\n",
      "5. DUCKDB COMPATIBILITY:\n",
      "----------------------------------------\n",
      "‚úì DuckDB can read schema (11 columns)\n",
      "‚úì Basic queries work\n",
      "  Sample data shape: (3, 6)\n",
      "‚úì 3D array access works\n",
      "  Grid access sample: (2, 4)\n",
      "‚úì All DuckDB operations successful!\n",
      "\n",
      "6. DATASET STATISTICS:\n",
      "----------------------------------------\n",
      "‚úì Tasks with programs: 399\n",
      "‚úì Programs per task: min=2, max=250, mean=148.3\n",
      "‚úì Models represented: 31\n",
      "‚úì Top 3 models: {'Qwen2.5-Coder-32B-Instruct': np.int64(16799), 'Mistral-Large-Instruct-2407': np.int64(14904), 'Qwen2.5-72B-Instruct': np.int64(12452)}\n",
      "\n",
      "================================================================================\n",
      "‚úÖ VERIFICATION COMPLETE - Filtered dataset is ready for use!\n",
      "================================================================================\n",
      "üìÅ Final dataset location: /tmp/shortest_ratio_2_5x_filtered_250.parquet\n",
      "üìä Total programs: 59,170\n",
      "üéØ Unique tasks: 399\n",
      "ü§ñ Models: 31\n",
      "üìè Max programs per task: 250 (target: ‚â§500)\n",
      "================================================================================\n",
      "‚úì File loaded successfully\n",
      "‚úì Dataset shape: (59170, 11)\n",
      "‚úì Columns: ['task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input', 'predicted_train_output', 'predicted_test_output', 'train_input', 'test_input', 'model', 'generation']\n",
      "‚úì Unique tasks: 399\n",
      "‚úì Programs per task (mean): 148.30\n",
      "‚úì Programs per task (max): 250\n",
      "‚úì Programs per task (min): 2\n",
      "\n",
      "2. DATA TYPE VERIFICATION:\n",
      "----------------------------------------\n",
      "‚úì Train output type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Train output length: 5 grids\n",
      "‚úì First grid type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Test output type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Test output length: 1 grids\n",
      "‚úì Train correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Train correct values: [ True  True  True  True  True]\n",
      "‚úì First correct value type: <class 'numpy.bool'> (expected: bool)\n",
      "‚úì Test correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "‚úì Test correct values: [ True]\n",
      "\n",
      "3. DATA COMPLETENESS:\n",
      "----------------------------------------\n",
      "‚úì Rows with train outputs: 59170/59170 (100.0%)\n",
      "‚úì Rows with test outputs: 59170/59170 (100.0%)\n",
      "‚úì Rows with train correctness: 59170/59170 (100.0%)\n",
      "‚úì Rows with test correctness: 59170/59170 (100.0%)\n",
      "\n",
      "4. CODE CLEANING VERIFICATION:\n",
      "----------------------------------------\n",
      "‚úì Codes with empty lines: 73/100 (should be 0)\n",
      "\n",
      "5. DUCKDB COMPATIBILITY:\n",
      "----------------------------------------\n",
      "‚úì DuckDB can read schema (11 columns)\n",
      "‚úì Basic queries work\n",
      "  Sample data shape: (3, 6)\n",
      "‚úì 3D array access works\n",
      "  Grid access sample: (2, 4)\n",
      "‚úì All DuckDB operations successful!\n",
      "\n",
      "6. DATASET STATISTICS:\n",
      "----------------------------------------\n",
      "‚úì Tasks with programs: 399\n",
      "‚úì Programs per task: min=2, max=250, mean=148.3\n",
      "‚úì Models represented: 31\n",
      "‚úì Top 3 models: {'Qwen2.5-Coder-32B-Instruct': np.int64(16799), 'Mistral-Large-Instruct-2407': np.int64(14904), 'Qwen2.5-72B-Instruct': np.int64(12452)}\n",
      "\n",
      "================================================================================\n",
      "‚úÖ VERIFICATION COMPLETE - Filtered dataset is ready for use!\n",
      "================================================================================\n",
      "üìÅ Final dataset location: /tmp/shortest_ratio_2_5x_filtered_250.parquet\n",
      "üìä Total programs: 59,170\n",
      "üéØ Unique tasks: 399\n",
      "ü§ñ Models: 31\n",
      "üìè Max programs per task: 250 (target: ‚â§500)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive verification of the final dataset\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE DATASET VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "file_path = f\"/tmp/{file_name}.parquet\"\n",
    "\n",
    "# 1. Basic file and structure verification\n",
    "print(\"\\n1. BASIC DATASET INFO:\")\n",
    "print(\"-\" * 40)\n",
    "verification_df = pd.read_parquet(file_path)\n",
    "print(f\"‚úì File loaded successfully\")\n",
    "print(f\"‚úì Dataset shape: {verification_df.shape}\")\n",
    "print(f\"‚úì Columns: {list(verification_df.columns)}\")\n",
    "print(f\"‚úì Unique tasks: {verification_df['task_id'].nunique()}\")\n",
    "print(f\"‚úì Programs per task (mean): {verification_df.groupby('task_id').size().mean():.2f}\")\n",
    "print(f\"‚úì Programs per task (max): {verification_df.groupby('task_id').size().max()}\")\n",
    "print(f\"‚úì Programs per task (min): {verification_df.groupby('task_id').size().min()}\")\n",
    "\n",
    "# 2. Data type verification\n",
    "print(\"\\n2. DATA TYPE VERIFICATION:\")\n",
    "print(\"-\" * 40)\n",
    "sample = verification_df.iloc[0]\n",
    "\n",
    "# Check predicted outputs (should be 3D arrays: List[List[List[int]]])\n",
    "train_output = sample['predicted_train_output']\n",
    "test_output = sample['predicted_test_output']\n",
    "\n",
    "print(f\"‚úì Train output type: {type(train_output)} (expected: list)\")\n",
    "print(f\"‚úì Train output length: {len(train_output)} grids\")\n",
    "if len(train_output) > 0:\n",
    "    first_grid = train_output[0]\n",
    "    print(f\"‚úì First grid type: {type(first_grid)} (expected: list)\")\n",
    "    if isinstance(first_grid, list) and len(first_grid) > 0:\n",
    "        print(f\"‚úì Grid dimensions: {len(first_grid)} x {len(first_grid[0])}\")\n",
    "        if len(first_grid[0]) > 0:\n",
    "            cell_value = first_grid[0][0]\n",
    "            print(f\"‚úì Cell value type: {type(cell_value)} = {cell_value} (expected: int)\")\n",
    "\n",
    "print(f\"‚úì Test output type: {type(test_output)} (expected: list)\")\n",
    "print(f\"‚úì Test output length: {len(test_output)} grids\")\n",
    "\n",
    "# Check correctness arrays (should be 1D boolean arrays: List[bool])\n",
    "train_correct = sample['correct_train_input']\n",
    "test_correct = sample['correct_test_input']\n",
    "\n",
    "print(f\"‚úì Train correct type: {type(train_correct)} (expected: list)\")\n",
    "print(f\"‚úì Train correct values: {train_correct}\")\n",
    "if len(train_correct) > 0:\n",
    "    print(f\"‚úì First correct value type: {type(train_correct[0])} (expected: bool)\")\n",
    "\n",
    "print(f\"‚úì Test correct type: {type(test_correct)} (expected: list)\")\n",
    "print(f\"‚úì Test correct values: {test_correct}\")\n",
    "\n",
    "# 3. Data completeness verification\n",
    "print(\"\\n3. DATA COMPLETENESS:\")\n",
    "print(\"-\" * 40)\n",
    "non_empty_train = verification_df['predicted_train_output'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_test = verification_df['predicted_test_output'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_train_correct = verification_df['correct_train_input'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_test_correct = verification_df['correct_test_input'].apply(lambda x: len(x) > 0).sum()\n",
    "\n",
    "print(f\"‚úì Rows with train outputs: {non_empty_train}/{len(verification_df)} ({100*non_empty_train/len(verification_df):.1f}%)\")\n",
    "print(f\"‚úì Rows with test outputs: {non_empty_test}/{len(verification_df)} ({100*non_empty_test/len(verification_df):.1f}%)\")\n",
    "print(f\"‚úì Rows with train correctness: {non_empty_train_correct}/{len(verification_df)} ({100*non_empty_train_correct/len(verification_df):.1f}%)\")\n",
    "print(f\"‚úì Rows with test correctness: {non_empty_test_correct}/{len(verification_df)} ({100*non_empty_test_correct/len(verification_df):.1f}%)\")\n",
    "\n",
    "# 4. Code cleaning verification\n",
    "print(\"\\n4. CODE CLEANING VERIFICATION:\")\n",
    "print(\"-\" * 40)\n",
    "# Check if codes have whitespace-only lines removed\n",
    "codes_with_empty_lines = 0\n",
    "total_codes_checked = min(100, len(verification_df))  # Check first 100\n",
    "\n",
    "for i in range(total_codes_checked):\n",
    "    code = verification_df.iloc[i]['code']\n",
    "    lines = code.split('\\n')\n",
    "    for line in lines:\n",
    "        if line.strip() == '':\n",
    "            codes_with_empty_lines += 1\n",
    "            break\n",
    "\n",
    "print(f\"‚úì Codes with empty lines: {codes_with_empty_lines}/{total_codes_checked} (should be 0)\")\n",
    "\n",
    "# 5. DuckDB compatibility verification\n",
    "print(\"\\n5. DUCKDB COMPATIBILITY:\")\n",
    "print(\"-\" * 40)\n",
    "con = duckdb.connect()\n",
    "\n",
    "try:\n",
    "    # Schema check\n",
    "    schema = con.execute(f\"DESCRIBE '{file_path}'\").fetchdf()\n",
    "    print(f\"‚úì DuckDB can read schema ({len(schema)} columns)\")\n",
    "    \n",
    "    # Basic query check\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT \n",
    "        task_id,\n",
    "        model,\n",
    "        length(predicted_train_output) as num_train_grids,\n",
    "        length(predicted_test_output) as num_test_grids,\n",
    "        length(correct_train_input) as num_train_examples,\n",
    "        length(correct_test_input) as num_test_examples\n",
    "    FROM '{file_path}' \n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    sample_data = con.execute(sample_query).fetchdf()\n",
    "    print(f\"‚úì Basic queries work\")\n",
    "    print(f\"  Sample data shape: {sample_data.shape}\")\n",
    "    \n",
    "    # 3D array access check\n",
    "    nested_query = f\"\"\"\n",
    "    SELECT \n",
    "        task_id,\n",
    "        predicted_train_output[1] as first_train_grid,\n",
    "        length(predicted_train_output[1]) as grid_height,\n",
    "        length(predicted_train_output[1][1]) as grid_width\n",
    "    FROM '{file_path}' \n",
    "    WHERE length(predicted_train_output) > 0 \n",
    "      AND length(predicted_train_output[1]) > 0\n",
    "    LIMIT 2\n",
    "    \"\"\"\n",
    "    nested_data = con.execute(nested_query).fetchdf()\n",
    "    print(f\"‚úì 3D array access works\")\n",
    "    print(f\"  Grid access sample: {nested_data.shape}\")\n",
    "    \n",
    "    print(f\"‚úì All DuckDB operations successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó DuckDB error: {e}\")\n",
    "\n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "# 6. Summary statistics\n",
    "print(\"\\n6. DATASET STATISTICS:\")\n",
    "print(\"-\" * 40)\n",
    "task_stats = verification_df.groupby('task_id').size()\n",
    "model_stats = verification_df['model'].value_counts()\n",
    "\n",
    "print(f\"‚úì Tasks with programs: {len(task_stats)}\")\n",
    "print(f\"‚úì Programs per task: min={task_stats.min()}, max={task_stats.max()}, mean={task_stats.mean():.1f}\")\n",
    "print(f\"‚úì Models represented: {len(model_stats)}\")\n",
    "print(f\"‚úì Top 3 models: {dict(model_stats.head(3))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ VERIFICATION COMPLETE - Filtered dataset is ready for use!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìÅ Final dataset location: {file_path}\")\n",
    "print(f\"üìä Total programs: {len(verification_df):,}\")\n",
    "print(f\"üéØ Unique tasks: {verification_df['task_id'].nunique()}\")\n",
    "print(f\"ü§ñ Models: {len(model_stats)}\")\n",
    "print(f\"üìè Max programs per task: {task_stats.max()} (target: ‚â§500)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00037e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    task_id reasoning                                               code  \\\n",
      "0  007bbfb7            def transform(grid):\\n    pattern = [[0] * 9 f...   \n",
      "1  007bbfb7            def transform(grid):\\n    output = [[0] * 9 fo...   \n",
      "2  007bbfb7            def transform(grid):\\n\\n    output = [[0 for _...   \n",
      "3  007bbfb7            def transform(input_grid):\\n    output_grid = ...   \n",
      "4  007bbfb7            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "5  007bbfb7            def transform(grid):\\n    n = len(grid)\\n    m...   \n",
      "6  007bbfb7            def transform(grid):\\n    output_size = 9\\n   ...   \n",
      "7  007bbfb7            def transform(grid):\\n\\n    def expand_grid(gr...   \n",
      "8  007bbfb7            def transform(grid):\\n    n = len(grid)\\n    n...   \n",
      "9  007bbfb7            def transform(grid):\\n    n = len(grid)\\n    n...   \n",
      "\n",
      "              correct_train_input correct_test_input  \\\n",
      "0  [True, True, True, True, True]             [True]   \n",
      "1  [True, True, True, True, True]             [True]   \n",
      "2  [True, True, True, True, True]             [True]   \n",
      "3  [True, True, True, True, True]             [True]   \n",
      "4  [True, True, True, True, True]             [True]   \n",
      "5  [True, True, True, True, True]             [True]   \n",
      "6  [True, True, True, True, True]             [True]   \n",
      "7  [True, True, True, True, True]             [True]   \n",
      "8  [True, True, True, True, True]             [True]   \n",
      "9  [True, True, True, True, True]             [True]   \n",
      "\n",
      "                              predicted_train_output  \\\n",
      "0  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "1  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "2  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "3  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "4  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "5  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "6  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "7  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "8  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "9  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "\n",
      "                               predicted_test_output train_input test_input  \\\n",
      "0  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "1  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "2  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "3  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "4  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "5  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "6  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "7  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "8  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "9  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "\n",
      "                         model  generation  \n",
      "0   Qwen2.5-Coder-32B-Instruct           0  \n",
      "1   Qwen2.5-Coder-32B-Instruct           0  \n",
      "2             qwen/qwen3-coder           0  \n",
      "3  Mistral-Large-Instruct-2407           0  \n",
      "4  Mistral-Large-Instruct-2407           0  \n",
      "5   Qwen2.5-Coder-32B-Instruct           0  \n",
      "6   Qwen2.5-Coder-14B-Instruct           0  \n",
      "7         Qwen2.5-72B-Instruct           0  \n",
      "8   Qwen2.5-Coder-32B-Instruct           0  \n",
      "9  Mistral-Large-Instruct-2407           0  \n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "sample_df = con.execute(f\"SELECT * FROM '{file_path}' LIMIT 10\").fetchdf()\n",
    "con.close()\n",
    "print(sample_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
