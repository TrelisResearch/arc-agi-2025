{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad01f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "table_name = \"trelis-arc.arc.shortest_ratio_2_5x_filtered_250\"\n",
    "file_name = table_name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e1fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery table creation...\n",
      "âœ“ Table `trelis-arc.arc.shortest_ratio_2_5x_filtered_250` created successfully\n",
      "âœ“ Table `trelis-arc.arc.shortest_ratio_2_5x_filtered_250` created successfully\n"
     ]
    }
   ],
   "source": [
    "create_final_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{table_name}` AS\n",
    "\n",
    "WITH training_tasks AS (\n",
    "    SELECT DISTINCT task_id\n",
    "    FROM `trelis-arc.arc.arc_task_ids`\n",
    "    WHERE subset = \"arc-agi-1/training\"\n",
    "),\n",
    "-- Clean programs by collapsing multiple empty lines into single empty lines\n",
    "programs_cleaned AS (\n",
    "    SELECT \n",
    "        k.task_id,\n",
    "        -- Clean code by collapsing multiple consecutive newlines into at most one empty line\n",
    "        -- Pattern matches multiple consecutive newlines with optional whitespace\n",
    "        REGEXP_REPLACE(k.code, r'\\\\n(\\\\s*\\\\n)+', '\\\\n\\\\n') as code,\n",
    "        k.model,\n",
    "        k.predicted_train_output,\n",
    "        k.predicted_test_output,\n",
    "        k.correct_train_input,\n",
    "        k.correct_test_input\n",
    "    FROM `trelis-arc.arc.king_programs_ext` k\n",
    "    INNER JOIN training_tasks t ON k.task_id = t.task_id\n",
    "    WHERE k.model != 'hodel-translated'\n",
    "),\n",
    "-- Calculate metrics and filter by grid size\n",
    "programs_with_metrics AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        code,\n",
    "        model,\n",
    "        predicted_train_output,\n",
    "        predicted_test_output,\n",
    "        correct_train_input,\n",
    "        correct_test_input,\n",
    "        LENGTH(code) as program_length,\n",
    "        -- Check if all train inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) as all_train_correct,\n",
    "        -- Check if all test inputs are correct\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as all_test_correct,\n",
    "        -- Count correct examples\n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_train_input.list) AS correct_val) + \n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(correct_test_input.list) AS correct_val) as total_correct,\n",
    "        ARRAY_LENGTH(correct_train_input.list) + ARRAY_LENGTH(correct_test_input.list) as total_possible,\n",
    "        -- Check grid sizes for train output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d) as max_train_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_train_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_train_grid_width,\n",
    "        -- Check grid sizes for test output\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d) as max_test_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(predicted_test_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_test_grid_width,\n",
    "        -- Normalize code for deduplication (remove all whitespace, lowercase)\n",
    "        LOWER(REGEXP_REPLACE(code, r'\\\\s+', '')) as normalized_code\n",
    "    FROM programs_cleaned\n",
    "),\n",
    "-- Filter by grid size (40x40) and require at least one correct\n",
    "programs_filtered AS (\n",
    "    SELECT *,\n",
    "        -- Calculate success rate for ranking\n",
    "        SAFE_DIVIDE(total_correct, total_possible) as success_rate\n",
    "    FROM programs_with_metrics\n",
    "    WHERE max_train_grid_height <= 40 AND max_train_grid_width <= 40\n",
    "      AND max_test_grid_height <= 40 AND max_test_grid_width <= 40\n",
    "      AND total_correct > 0\n",
    "),\n",
    "-- Find shortest, most correct program per task\n",
    "task_benchmarks AS (\n",
    "    SELECT \n",
    "        task_id,\n",
    "        MIN(program_length) as shortest_best_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            task_id,\n",
    "            program_length,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY task_id \n",
    "                ORDER BY success_rate DESC, program_length ASC, code ASC\n",
    "            ) as rank\n",
    "        FROM programs_filtered\n",
    "    ) ranked\n",
    "    WHERE rank = 1\n",
    "    GROUP BY task_id\n",
    "),\n",
    "-- Filter programs to those within 2.5x the shortest best program per task\n",
    "programs_length_filtered AS (\n",
    "    SELECT p.*\n",
    "    FROM programs_filtered p\n",
    "    INNER JOIN task_benchmarks b ON p.task_id = b.task_id\n",
    "    WHERE p.program_length <= 2.5 * b.shortest_best_length\n",
    "),\n",
    "-- Deduplicate programs (same normalized code + task_id)\n",
    "programs_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length, success_rate,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_length_filtered\n",
    "),\n",
    "-- Take top 500 per task, prioritizing correctness then length\n",
    "final_selection AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY success_rate DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as final_rank\n",
    "    FROM programs_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input\n",
    "FROM final_selection\n",
    "WHERE final_rank <= 250\n",
    "ORDER BY task_id, final_rank\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"âœ“ Table `{table_name}` created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc2d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigQuery table data...\n",
      "Exporting BigQuery table 'trelis-arc.arc.shortest_ratio_2_5x_filtered_250' to GCS...\n",
      "Waiting for BigQuery export to complete...\n",
      "Waiting for BigQuery export to complete...\n",
      "âœ“ Export to GCS completed successfully\n",
      "Downloading from GCS to /tmp/shortest_ratio_2_5x_filtered_250.parquet...\n",
      "âœ“ Export to GCS completed successfully\n",
      "Downloading from GCS to /tmp/shortest_ratio_2_5x_filtered_250.parquet...\n",
      "âœ“ Download completed\n",
      "Reading parquet file...\n",
      "âœ“ Download completed\n",
      "Reading parquet file...\n",
      "Loaded 59170 rows from BigQuery table\n",
      "Loaded 59170 programs from BigQuery table\n",
      "Loaded 59170 rows from BigQuery table\n",
      "Loaded 59170 programs from BigQuery table\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_export import load_bigquery_table_as_dataframe\n",
    "\n",
    "# Load BigQuery table as DataFrame using our reusable function\n",
    "print(\"Loading BigQuery table data...\")\n",
    "raw_data = load_bigquery_table_as_dataframe(\n",
    "    client=client,\n",
    "    table_name=table_name\n",
    ")\n",
    "print(f\"Loaded {len(raw_data)} programs from BigQuery table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00fe6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting BigQuery data structure...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# First, let's inspect the actual data structure\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInspecting BigQuery data structure...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m sample_row = \u001b[43mraw_data\u001b[49m.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample row columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_row.index.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain output type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(sample_row[\u001b[33m'\u001b[39m\u001b[33mpredicted_train_output\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.bigquery_converter import convert_bigquery_to_soar, save_soar_parquet\n",
    "\n",
    "# First, let's inspect the actual data structure\n",
    "print(\"Inspecting BigQuery data structure...\")\n",
    "sample_row = raw_data.iloc[0]\n",
    "print(f\"Sample row columns: {sample_row.index.tolist()}\")\n",
    "print(f\"Train output type: {type(sample_row['predicted_train_output'])}\")\n",
    "print(f\"Train correct type: {type(sample_row['correct_train_input'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Convert BigQuery data to SOAR format using our reusable function\n",
    "print(\"Converting BigQuery data to SOAR format...\")\n",
    "final_dataset = convert_bigquery_to_soar(raw_data, show_progress=True)\n",
    "\n",
    "# Save the final dataset\n",
    "if len(final_dataset) > 0:\n",
    "    output_path = f\"/tmp/{file_name}.parquet\"\n",
    "    print(f\"Saving final dataset to: {output_path}\")\n",
    "    \n",
    "    save_soar_parquet(final_dataset, output_path)\n",
    "else:\n",
    "    print(\"No valid data to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84683efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET VALIDATION\n",
      "================================================================================\n",
      "âœ“ Starting dataset validation...\n",
      "âœ“ Dataset shape: (59170, 11)\n",
      "âœ“ Unique tasks: 399\n",
      "âœ… Dataset validation passed!\n",
      "ðŸ“Š 59,170 programs across 399 tasks\n",
      "ðŸ¤– Models: 31\n",
      "ðŸ“ Programs per task: 2-250 (avg: 148.3)\n",
      "\n",
      "================================================================================\n",
      "âœ… VALIDATION COMPLETE - Dataset is ready for training!\n",
      "================================================================================\n",
      "ðŸ“ Final dataset location: /tmp/shortest_ratio_2_5x_filtered_250.parquet\n",
      "âŒ VALIDATION FAILED: 'NoneType' object is not subscriptable\n",
      "âœ“ Starting dataset validation...\n",
      "âœ“ Dataset shape: (59170, 11)\n",
      "âœ“ Unique tasks: 399\n",
      "âœ… Dataset validation passed!\n",
      "ðŸ“Š 59,170 programs across 399 tasks\n",
      "ðŸ¤– Models: 31\n",
      "ðŸ“ Programs per task: 2-250 (avg: 148.3)\n",
      "\n",
      "================================================================================\n",
      "âœ… VALIDATION COMPLETE - Dataset is ready for training!\n",
      "================================================================================\n",
      "ðŸ“ Final dataset location: /tmp/shortest_ratio_2_5x_filtered_250.parquet\n",
      "âŒ VALIDATION FAILED: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ“ Final dataset location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Total programs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstats\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtotal_programs\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ Unique tasks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mstats\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33munique_tasks\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ¤– Models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results[\u001b[33m'\u001b[39m\u001b[33mstats\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Validate the final dataset using our reusable validation function\n",
    "from llm_python.datasets.schema import validate_soar_dataset\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "file_path = f\"/tmp/{file_name}.parquet\"\n",
    "\n",
    "results = validate_soar_dataset(pd.read_parquet(file_path), max_grid_size=40, silent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00037e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    task_id reasoning                                               code  \\\n",
      "0  007bbfb7            def transform(grid):\\n    pattern = [[0] * 9 f...   \n",
      "1  007bbfb7            def transform(grid):\\n    output = [[0] * 9 fo...   \n",
      "2  007bbfb7            def transform(grid):\\n\\n    output = [[0 for _...   \n",
      "3  007bbfb7            def transform(input_grid):\\n    output_grid = ...   \n",
      "4  007bbfb7            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "5  007bbfb7            def transform(grid):\\n    n = len(grid)\\n    m...   \n",
      "6  007bbfb7            def transform(grid):\\n    output_size = 9\\n   ...   \n",
      "7  007bbfb7            def transform(grid):\\n\\n    def expand_grid(gr...   \n",
      "8  007bbfb7            def transform(grid):\\n    n = len(grid)\\n    n...   \n",
      "9  007bbfb7            def transform(grid):\\n    n = len(grid)\\n    n...   \n",
      "\n",
      "              correct_train_input correct_test_input  \\\n",
      "0  [True, True, True, True, True]             [True]   \n",
      "1  [True, True, True, True, True]             [True]   \n",
      "2  [True, True, True, True, True]             [True]   \n",
      "3  [True, True, True, True, True]             [True]   \n",
      "4  [True, True, True, True, True]             [True]   \n",
      "5  [True, True, True, True, True]             [True]   \n",
      "6  [True, True, True, True, True]             [True]   \n",
      "7  [True, True, True, True, True]             [True]   \n",
      "8  [True, True, True, True, True]             [True]   \n",
      "9  [True, True, True, True, True]             [True]   \n",
      "\n",
      "                              predicted_train_output  \\\n",
      "0  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "1  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "2  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "3  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "4  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "5  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "6  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "7  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "8  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "9  [[[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7,...   \n",
      "\n",
      "                               predicted_test_output train_input test_input  \\\n",
      "0  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "1  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "2  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "3  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "4  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "5  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "6  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "7  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "8  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "9  [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0,...          []         []   \n",
      "\n",
      "                         model  generation  \n",
      "0   Qwen2.5-Coder-32B-Instruct           0  \n",
      "1   Qwen2.5-Coder-32B-Instruct           0  \n",
      "2             qwen/qwen3-coder           0  \n",
      "3  Mistral-Large-Instruct-2407           0  \n",
      "4  Mistral-Large-Instruct-2407           0  \n",
      "5   Qwen2.5-Coder-32B-Instruct           0  \n",
      "6   Qwen2.5-Coder-14B-Instruct           0  \n",
      "7         Qwen2.5-72B-Instruct           0  \n",
      "8   Qwen2.5-Coder-32B-Instruct           0  \n",
      "9  Mistral-Large-Instruct-2407           0  \n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "sample_df = con.execute(f\"SELECT * FROM '{file_path}' LIMIT 10\").fetchdf()\n",
    "con.close()\n",
    "print(sample_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
