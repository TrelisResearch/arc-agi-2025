{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd06c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0f5a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing BigQuery table creation...\n",
      "✓ Table `trelis-arc.arc.programs_50_correct_200_partial` created successfully\n",
      "✓ Table `trelis-arc.arc.programs_50_correct_200_partial` created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/code/trelis-arc/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1965: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table statistics:\n",
      "        program_type  num_programs  unique_tasks\n",
      "0      fully_correct         12008           370\n",
      "1  partially_correct         57475           398\n",
      "\n",
      "Programs per task distribution:\n",
      "Total task-type combinations: 768\n",
      "Distribution summary:\n",
      "                   count        mean        std  min   25%    50%    75%  \\\n",
      "program_type                                                               \n",
      "fully_correct      370.0   32.454054   18.38166  1.0  12.0   38.5   50.0   \n",
      "partially_correct  398.0  144.409548  71.175383  1.0  73.0  200.0  200.0   \n",
      "\n",
      "                     max  \n",
      "program_type              \n",
      "fully_correct       50.0  \n",
      "partially_correct  200.0  \n",
      "\n",
      "Programs per task distribution:\n",
      "Total task-type combinations: 768\n",
      "Distribution summary:\n",
      "                   count        mean        std  min   25%    50%    75%  \\\n",
      "program_type                                                               \n",
      "fully_correct      370.0   32.454054   18.38166  1.0  12.0   38.5   50.0   \n",
      "partially_correct  398.0  144.409548  71.175383  1.0  73.0  200.0  200.0   \n",
      "\n",
      "                     max  \n",
      "program_type              \n",
      "fully_correct       50.0  \n",
      "partially_correct  200.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/code/trelis-arc/.venv/lib/python3.11/site-packages/google/cloud/bigquery/table.py:1965: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "create_final_table_query = \"\"\"\n",
    "CREATE OR REPLACE TABLE `trelis-arc.arc.programs_50_correct_200_partial` AS\n",
    "\n",
    "WITH training_tasks AS (\n",
    "    SELECT DISTINCT task_id\n",
    "    FROM `trelis-arc.arc.arc_task_ids`\n",
    "    WHERE subset = \"arc-agi-1/training\"\n",
    "),\n",
    "-- Common base view with all filtering and computed fields\n",
    "programs_base AS (\n",
    "    SELECT \n",
    "        k.task_id,\n",
    "        k.code,\n",
    "        k.model,\n",
    "        k.predicted_train_output,\n",
    "        k.predicted_test_output,\n",
    "        k.correct_train_input,\n",
    "        k.correct_test_input,\n",
    "        LENGTH(k.code) as program_length,\n",
    "        -- Check if all train inputs are correct - access .list first, then .element\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(k.correct_train_input.list) AS correct_val) as all_train_correct,\n",
    "        -- Check if all test inputs are correct - access .list first, then .element\n",
    "        (SELECT LOGICAL_AND(correct_val.element) \n",
    "         FROM UNNEST(k.correct_test_input.list) AS correct_val) as all_test_correct,\n",
    "        -- Count correct examples - access .list first, then .element\n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(k.correct_train_input.list) AS correct_val) + \n",
    "        (SELECT COUNTIF(correct_val.element) \n",
    "         FROM UNNEST(k.correct_test_input.list) AS correct_val) as total_correct,\n",
    "        ARRAY_LENGTH(k.correct_train_input.list) + ARRAY_LENGTH(k.correct_test_input.list) as total_possible,\n",
    "        -- Check grid sizes for train output - access .list first, then .element.list\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(k.predicted_train_output.list) AS grid_2d) as max_train_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(k.predicted_train_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_train_grid_width,\n",
    "        -- Check grid sizes for test output - access .list first, then .element.list\n",
    "        (SELECT MAX(ARRAY_LENGTH(grid_2d.element.list)) \n",
    "         FROM UNNEST(k.predicted_test_output.list) AS grid_2d) as max_test_grid_height,\n",
    "        (SELECT MAX(ARRAY_LENGTH(row_1d.element.list)) \n",
    "         FROM UNNEST(k.predicted_test_output.list) AS grid_2d,\n",
    "              UNNEST(grid_2d.element.list) AS row_1d) as max_test_grid_width,\n",
    "        -- Normalize code for deduplication\n",
    "        LOWER(REGEXP_REPLACE(k.code, r'\\\\s+', '')) as normalized_code\n",
    "    FROM `trelis-arc.arc.king_programs_ext` k\n",
    "    INNER JOIN training_tasks t ON k.task_id = t.task_id\n",
    "    WHERE k.model != 'hodel-translated'\n",
    "),\n",
    "-- Filter base to only valid programs (grid size constraints and at least one correct)\n",
    "programs_filtered AS (\n",
    "    SELECT *\n",
    "    FROM programs_base\n",
    "    WHERE max_train_grid_height <= 30 AND max_train_grid_width <= 30\n",
    "      AND max_test_grid_height <= 30 AND max_test_grid_width <= 30\n",
    "      AND total_correct > 0  -- At least one correct (moved here after calculation)\n",
    "),\n",
    "-- Fully correct programs: deduplicate and rank\n",
    "fully_correct_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_filtered\n",
    "    WHERE all_train_correct AND all_test_correct\n",
    "),\n",
    "fully_correct_ranked AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        'fully_correct' as program_type,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY program_length ASC, model ASC, code ASC\n",
    "        ) as rank_in_task\n",
    "    FROM fully_correct_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    "),\n",
    "-- Partially correct programs: deduplicate and rank\n",
    "partially_correct_deduplicated AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input, program_length, total_correct,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id, normalized_code\n",
    "            ORDER BY program_length ASC, model ASC, code ASC\n",
    "        ) as dedup_rank\n",
    "    FROM programs_filtered\n",
    "    WHERE NOT (all_train_correct AND all_test_correct)  -- Exclude fully correct\n",
    "),\n",
    "partially_correct_ranked AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        'partially_correct' as program_type,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY total_correct DESC, program_length ASC, model ASC, code ASC\n",
    "        ) as rank_in_task\n",
    "    FROM partially_correct_deduplicated\n",
    "    WHERE dedup_rank = 1\n",
    "),\n",
    "-- Combine both types with limit of 50 fully correct and 200 partially correct\n",
    "combined_programs AS (\n",
    "    SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "           correct_train_input, correct_test_input, program_type\n",
    "    FROM fully_correct_ranked WHERE rank_in_task <= 50\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "           correct_train_input, correct_test_input, program_type\n",
    "    FROM partially_correct_ranked WHERE rank_in_task <= 200\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input, program_type\n",
    "FROM combined_programs\n",
    "ORDER BY task_id, program_type, code\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"✓ Table `trelis-arc.arc.programs_50_correct_200_partial` created successfully\")\n",
    "\n",
    "# Get statistics about the created table\n",
    "stats_query = \"\"\"\n",
    "SELECT \n",
    "    program_type,\n",
    "    COUNT(*) as num_programs,\n",
    "    COUNT(DISTINCT task_id) as unique_tasks\n",
    "FROM `trelis-arc.arc.programs_50_correct_200_partial`\n",
    "GROUP BY program_type\n",
    "ORDER BY program_type\n",
    "\"\"\"\n",
    "\n",
    "stats = client.query(stats_query).to_dataframe()\n",
    "print(f\"\\nTable statistics:\")\n",
    "print(stats)\n",
    "\n",
    "# Check programs per task distribution\n",
    "distribution_query = \"\"\"\n",
    "SELECT \n",
    "    task_id,\n",
    "    program_type,\n",
    "    COUNT(*) as num_programs\n",
    "FROM `trelis-arc.arc.programs_50_correct_200_partial`\n",
    "GROUP BY task_id, program_type\n",
    "ORDER BY task_id, program_type\n",
    "\"\"\"\n",
    "\n",
    "distribution = client.query(distribution_query).to_dataframe()\n",
    "print(f\"\\nPrograms per task distribution:\")\n",
    "print(f\"Total task-type combinations: {len(distribution)}\")\n",
    "print(f\"Distribution summary:\")\n",
    "print(distribution.groupby('program_type')['num_programs'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ec6b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Google Cloud Storage export for fast data transfer...\n",
      "Exporting BigQuery table to: gs://trelis-arc/tmp/mixed_partial_dataset_50_200.parquet\n",
      "Waiting for BigQuery export to complete...\n",
      "Waiting for BigQuery export to complete...\n",
      "✓ Export to GCS completed successfully\n",
      "Downloading from GCS...\n",
      "✓ Export to GCS completed successfully\n",
      "Downloading from GCS...\n",
      "✓ Download completed\n",
      "Reading parquet file...\n",
      "✓ Download completed\n",
      "Reading parquet file...\n",
      "Loaded 69483 programs from parquet file\n",
      "Loaded 69483 programs from parquet file\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Fast GCS export approach for large datasets\n",
    "print(\"Using Google Cloud Storage export for fast data transfer...\")\n",
    "\n",
    "# Use fixed filenames for this notebook\n",
    "gcs_uri = f\"gs://trelis-arc/tmp/mixed_partial_dataset_50_200.parquet\"\n",
    "local_file = f\"/tmp/mixed_partial_dataset_50_200.parquet\"\n",
    "\n",
    "print(f\"Exporting BigQuery table to: {gcs_uri}\")\n",
    "\n",
    "# Export to Cloud Storage (much faster for large datasets)\n",
    "export_job_config = bigquery.ExtractJobConfig()\n",
    "export_job_config.destination_format = bigquery.DestinationFormat.PARQUET\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    \"trelis-arc.arc.programs_50_correct_200_partial\",\n",
    "    gcs_uri,\n",
    "    job_config=export_job_config\n",
    ")\n",
    "\n",
    "print(\"Waiting for BigQuery export to complete...\")\n",
    "extract_job.result()  # Wait for export to complete\n",
    "print(\"✓ Export to GCS completed successfully\")\n",
    "\n",
    "# Download and read the parquet file directly\n",
    "print(\"Downloading from GCS...\")\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket('trelis-arc')\n",
    "blob = bucket.blob('tmp/mixed_partial_dataset_50_200.parquet')\n",
    "blob.download_to_filename(local_file)\n",
    "print(\"✓ Download completed\")\n",
    "\n",
    "# Read the parquet file\n",
    "print(\"Reading parquet file...\")\n",
    "raw_data = pd.read_parquet(local_file)\n",
    "print(f\"Loaded {len(raw_data)} programs from parquet file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0380357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting BigQuery data structure...\n",
      "Sample row columns: ['task_id', 'code', 'model', 'predicted_train_output', 'predicted_test_output', 'correct_train_input', 'correct_test_input', 'program_type']\n",
      "Train output type: <class 'dict'>\n",
      "Train output content: {'list': array([{'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 1}, {'element': 1}, {'element': 1},\n",
      "                     {'element': 1}, {'element': 1}, {'element': 1}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 1}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 1}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 1}, {'element': 1}, {'element': 1},\n",
      "                     {'element': 1}, {'element': 1}, {'element': 1}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 2}, {'element': 2}, {'element': 2}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 2}, {'element': 2}, {'element': 2}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ],\n",
      "             dtype=object)}}                                                                                                  ,\n",
      "       {'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ],\n",
      "             dtype=object)}}                                                                                                  ,\n",
      "       {'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ],\n",
      "             dtype=object)}}                                                                                                  ,\n",
      "       {'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 7}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 7},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ],\n",
      "             dtype=object)}}                                                                                                  ],\n",
      "      dtype=object)}\n",
      "Train correct type: <class 'dict'>\n",
      "Train correct content: {'list': array([{'element': False}, {'element': True}, {'element': True},\n",
      "       {'element': False}], dtype=object)}\n",
      "Train output keys: ['list']\n",
      "Train correct keys: ['list']\n",
      "\n",
      "==================================================\n",
      "Converting BigQuery nested structures to proper arrays...\n",
      "Testing conversion on first row...\n",
      "Original train output: {'list': array([{'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 1}, {'element': 1}, {'element': 1},\n",
      "                     {'element': 1}, {'element': 1}, {'element': 1}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 1}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 1}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 1}, {'element': 1}, {'element': 1},\n",
      "                     {'element': 1}, {'element': 1}, {'element': 1}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 2}, {'element': 2}, {'element': 2}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 2},\n",
      "                     {'element': 2}, {'element': 2}, {'element': 2}, {'element': 2},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ],\n",
      "             dtype=object)}}                                                                                                  ,\n",
      "       {'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 3}, {'element': 3}, {'element': 0},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0}],\n",
      "                    dtype=object)}}                                                                      ],\n",
      "             dtype=object)}}                                                                                                  ,\n",
      "       {'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 4}, {'element': 4}, {'element': 4},\n",
      "                     {'element': 4}, {'element': 4}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}], dtype=object)}}                                    ],\n",
      "             dtype=object)}}                                                                                                  ,\n",
      "       {'element': {'list': array([{'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 7}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 7},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 7}, {'element': 7}, {'element': 7}, {'element': 7},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ,\n",
      "              {'element': {'list': array([{'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}, {'element': 0},\n",
      "                     {'element': 0}, {'element': 0}, {'element': 0}], dtype=object)}}                    ],\n",
      "             dtype=object)}}                                                                                                  ],\n",
      "      dtype=object)}\n",
      "Converted train output: [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 3, 0, 0, 0, 0, 0], [0, 3, 3, 0, 0, 0, 0, 0], [0, 3, 3, 0, 7, 7, 7, 7], [0, 3, 3, 0, 7, 7, 7, 7], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0], [0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0], [0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
      "Converted type: <class 'list'>\n",
      "First grid type: <class 'list'>\n",
      "First grid content: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting structures: 100%|██████████| 69483/69483 [00:06<00:00, 11428.77it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 69483 programs\n",
      "Final dataset has 69483 programs\n",
      "Saving final dataset to: /tmp/mixed_partial_dataset_50_200_final.parquet\n",
      "✓ Saved with proper PyArrow schema\n",
      "✓ Saved with proper PyArrow schema\n"
     ]
    }
   ],
   "source": [
    "# First, let's inspect the actual data structure\n",
    "print(\"Inspecting BigQuery data structure...\")\n",
    "sample_row = raw_data.iloc[0]\n",
    "print(f\"Sample row columns: {sample_row.index.tolist()}\")\n",
    "print(f\"Train output type: {type(sample_row['predicted_train_output'])}\")\n",
    "print(f\"Train output content: {sample_row['predicted_train_output']}\")\n",
    "print(f\"Train correct type: {type(sample_row['correct_train_input'])}\")\n",
    "print(f\"Train correct content: {sample_row['correct_train_input']}\")\n",
    "\n",
    "if hasattr(sample_row['predicted_train_output'], 'keys'):\n",
    "    print(f\"Train output keys: {list(sample_row['predicted_train_output'].keys())}\")\n",
    "if hasattr(sample_row['correct_train_input'], 'keys'):\n",
    "    print(f\"Train correct keys: {list(sample_row['correct_train_input'].keys())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from llm_python.datasets.schema import PARQUET_SCHEMA\n",
    "\n",
    "def convert_bq_nested_structure(bq_data):\n",
    "    \"\"\"Convert BigQuery nested structure to proper list format\n",
    "    Handles the complex nested structure from BigQuery exports\n",
    "    \"\"\"\n",
    "    if bq_data is None:\n",
    "        return []\n",
    "    \n",
    "    # If it's already a simple list, return it\n",
    "    if isinstance(bq_data, list):\n",
    "        return bq_data\n",
    "    \n",
    "    # Handle BigQuery's nested structure\n",
    "    if isinstance(bq_data, dict):\n",
    "        if 'list' in bq_data:\n",
    "            list_data = bq_data['list']\n",
    "            \n",
    "            # Convert numpy array to list if needed\n",
    "            if hasattr(list_data, 'tolist'):\n",
    "                list_data = list_data.tolist()\n",
    "            \n",
    "            # If it's a list of dicts with 'element' key, extract the elements\n",
    "            if isinstance(list_data, list) and len(list_data) > 0:\n",
    "                if isinstance(list_data[0], dict) and 'element' in list_data[0]:\n",
    "                    # This is a list of {\"element\": actual_data} structures\n",
    "                    result = []\n",
    "                    for item in list_data:\n",
    "                        if isinstance(item, dict) and 'element' in item:\n",
    "                            element = item['element']\n",
    "                            # Recursively convert nested structures\n",
    "                            if isinstance(element, dict) and 'list' in element:\n",
    "                                result.append(convert_bq_nested_structure(element))\n",
    "                            else:\n",
    "                                result.append(element)\n",
    "                        else:\n",
    "                            result.append(item)\n",
    "                    return result\n",
    "                else:\n",
    "                    return list_data\n",
    "            else:\n",
    "                return list_data if isinstance(list_data, list) else []\n",
    "        else:\n",
    "            # Not a standard BigQuery list structure\n",
    "            return []\n",
    "    \n",
    "    return []\n",
    "\n",
    "def extract_boolean_values(bool_array):\n",
    "    \"\"\"Extract boolean values from the {'element': bool} format\"\"\"\n",
    "    if not isinstance(bool_array, list):\n",
    "        return []\n",
    "    \n",
    "    result = []\n",
    "    for item in bool_array:\n",
    "        if isinstance(item, dict) and 'element' in item:\n",
    "            result.append(bool(item['element']))\n",
    "        else:\n",
    "            result.append(bool(item))\n",
    "    return result\n",
    "\n",
    "def validate_converted_data(data_dict):\n",
    "    \"\"\"Validate a single converted data dict against the expected schema\"\"\"\n",
    "    try:\n",
    "        # Check required fields exist\n",
    "        required_fields = ['task_id', 'code', 'model', 'predicted_train_output', \n",
    "                          'predicted_test_output', 'correct_train_input', 'correct_test_input']\n",
    "        for field in required_fields:\n",
    "            if field not in data_dict:\n",
    "                return False, f\"Missing field: {field}\"\n",
    "        \n",
    "        # Check types\n",
    "        if not isinstance(data_dict['task_id'], str):\n",
    "            return False, f\"task_id should be str, got {type(data_dict['task_id'])}\"\n",
    "        if not isinstance(data_dict['code'], str):\n",
    "            return False, f\"code should be str, got {type(data_dict['code'])}\"\n",
    "        if not isinstance(data_dict['model'], str):\n",
    "            return False, f\"model should be str, got {type(data_dict['model'])}\"\n",
    "        \n",
    "        # Check 3D arrays (List[List[List[int]]])\n",
    "        for field in ['predicted_train_output', 'predicted_test_output']:\n",
    "            arr = data_dict[field]\n",
    "            if not isinstance(arr, list):\n",
    "                return False, f\"{field} should be list, got {type(arr)}\"\n",
    "            for i, grid in enumerate(arr):\n",
    "                if not isinstance(grid, list):\n",
    "                    return False, f\"{field}[{i}] should be list (2D grid), got {type(grid)}\"\n",
    "                for j, row in enumerate(grid):\n",
    "                    if not isinstance(row, list):\n",
    "                        return False, f\"{field}[{i}][{j}] should be list (row), got {type(row)}\"\n",
    "                    for k, cell in enumerate(row):\n",
    "                        if not isinstance(cell, int):\n",
    "                            return False, f\"{field}[{i}][{j}][{k}] should be int, got {type(cell)}\"\n",
    "        \n",
    "        # Check boolean arrays\n",
    "        for field in ['correct_train_input', 'correct_test_input']:\n",
    "            arr = data_dict[field]\n",
    "            if not isinstance(arr, list):\n",
    "                return False, f\"{field} should be list, got {type(arr)}\"\n",
    "            for i, val in enumerate(arr):\n",
    "                if not isinstance(val, bool):\n",
    "                    return False, f\"{field}[{i}] should be bool, got {type(val)}\"\n",
    "        \n",
    "        return True, \"Valid\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Validation error: {e}\"\n",
    "\n",
    "print(\"Converting BigQuery nested structures to proper arrays...\")\n",
    "\n",
    "# Test conversion on first few rows to debug\n",
    "print(\"Testing conversion on first row...\")\n",
    "test_row = raw_data.iloc[0]\n",
    "print(f\"Original train output: {test_row['predicted_train_output']}\")\n",
    "converted_train = convert_bq_nested_structure(test_row['predicted_train_output'])\n",
    "print(f\"Converted train output: {converted_train}\")\n",
    "print(f\"Converted type: {type(converted_train)}\")\n",
    "if isinstance(converted_train, list) and len(converted_train) > 0:\n",
    "    print(f\"First grid type: {type(converted_train[0])}\")\n",
    "    print(f\"First grid content: {converted_train[0]}\")\n",
    "\n",
    "# Convert data with proper handling of BigQuery structure\n",
    "converted_data = []\n",
    "validation_errors = []\n",
    "\n",
    "for idx in tqdm(range(len(raw_data)), desc=\"Converting structures\"):\n",
    "    row = raw_data.iloc[idx]\n",
    "    \n",
    "    try:\n",
    "        converted_row = {\n",
    "            'task_id': row['task_id'],\n",
    "            'code': row['code'], \n",
    "            'model': row['model'],\n",
    "            'predicted_train_output': convert_bq_nested_structure(row['predicted_train_output']),\n",
    "            'predicted_test_output': convert_bq_nested_structure(row['predicted_test_output']),\n",
    "            'correct_train_input': extract_boolean_values(convert_bq_nested_structure(row['correct_train_input'])),\n",
    "            'correct_test_input': extract_boolean_values(convert_bq_nested_structure(row['correct_test_input']))\n",
    "        }\n",
    "        \n",
    "        # Validate the converted row\n",
    "        is_valid, error_msg = validate_converted_data(converted_row)\n",
    "        if is_valid:\n",
    "            converted_data.append(converted_row)\n",
    "        else:\n",
    "            validation_errors.append(f\"Row {idx}: {error_msg}\")\n",
    "            if len(validation_errors) <= 5:  # Only print first few errors\n",
    "                print(f\"Validation error for row {idx}: {error_msg}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        validation_errors.append(f\"Row {idx}: Conversion error: {e}\")\n",
    "        if len(validation_errors) <= 5:\n",
    "            print(f\"Conversion error for row {idx}: {e}\")\n",
    "\n",
    "print(f\"Successfully converted {len(converted_data)} programs\")\n",
    "if validation_errors:\n",
    "    print(f\"Had {len(validation_errors)} validation/conversion errors\")\n",
    "\n",
    "# Create DataFrame from successfully converted data\n",
    "final_dataset = pd.DataFrame(converted_data)\n",
    "print(f\"Final dataset has {len(final_dataset)} programs\")\n",
    "\n",
    "# Save the final dataset\n",
    "if len(final_dataset) > 0:\n",
    "    # Add missing columns with default values for schema compliance\n",
    "    schema_df = final_dataset.copy()\n",
    "    schema_df['reasoning'] = ''  # Empty reasoning for now\n",
    "    schema_df['train_input'] = [[] for _ in range(len(schema_df))]  # Empty for now\n",
    "    schema_df['test_input'] = [[] for _ in range(len(schema_df))]   # Empty for now\n",
    "    schema_df['generation'] = 0  # Default generation\n",
    "\n",
    "    # Reorder columns to match schema\n",
    "    schema_columns = ['task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input',\n",
    "                     'predicted_train_output', 'predicted_test_output', 'train_input', 'test_input',\n",
    "                     'model', 'generation']\n",
    "    schema_df = schema_df[schema_columns]\n",
    "    \n",
    "    # Save with PyArrow to ensure proper schema - use fixed filename\n",
    "    output_path = \"/tmp/mixed_partial_dataset_50_200_final.parquet\"\n",
    "    print(f\"Saving final dataset to: {output_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Convert to PyArrow table with explicit schema\n",
    "        table = pa.Table.from_pandas(schema_df, schema=PARQUET_SCHEMA)\n",
    "        pq.write_table(table, output_path)\n",
    "        print(\"✓ Saved with proper PyArrow schema\")\n",
    "    except Exception as e:\n",
    "        print(f\"PyArrow save failed ({e}), using pandas fallback\")\n",
    "        schema_df.to_parquet(output_path, index=False)\n",
    "\n",
    "else:\n",
    "    print(\"No valid data to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d12087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE DATASET VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "1. BASIC DATASET INFO:\n",
      "----------------------------------------\n",
      "✓ File loaded successfully\n",
      "✓ Dataset shape: (69483, 8)\n",
      "✓ Columns: ['task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input', 'predicted_train_output', 'predicted_test_output', 'model']\n",
      "✓ Unique tasks: 399\n",
      "✓ Programs per task (mean): 174.14\n",
      "\n",
      "2. DATA TYPE VERIFICATION:\n",
      "----------------------------------------\n",
      "✓ Train output type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Train output length: 4 grids\n",
      "✓ First grid type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Test output type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Test output length: 1 grids\n",
      "✓ Train correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Train correct values: [False  True  True False]\n",
      "✓ First correct value type: <class 'numpy.bool'> (expected: bool)\n",
      "✓ Test correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Test correct values: [False]\n",
      "\n",
      "3. DATA COMPLETENESS:\n",
      "----------------------------------------\n",
      "✓ Rows with train outputs: 69483/69483 (100.0%)\n",
      "✓ Rows with test outputs: 69483/69483 (100.0%)\n",
      "✓ Rows with train correctness: 69483/69483 (100.0%)\n",
      "✓ Rows with test correctness: 69483/69483 (100.0%)\n",
      "\n",
      "4. DUCKDB COMPATIBILITY:\n",
      "----------------------------------------\n",
      "✓ DuckDB can read schema (8 columns)\n",
      "✓ Basic queries work\n",
      "  Sample data shape: (3, 6)\n",
      "✓ 3D array access works\n",
      "  Grid access sample: (2, 4)\n",
      "✓ All DuckDB operations successful!\n",
      "\n",
      "5. DATASET STATISTICS:\n",
      "----------------------------------------\n",
      "✓ Tasks with programs: 399\n",
      "✓ Programs per task: min=2, max=250, mean=174.1\n",
      "✓ Models represented: 31\n",
      "✓ Top 3 models: {'Qwen2.5-Coder-32B-Instruct': np.int64(19849), 'Mistral-Large-Instruct-2407': np.int64(15952), 'Qwen2.5-72B-Instruct': np.int64(15129)}\n",
      "\n",
      "================================================================================\n",
      "✅ VERIFICATION COMPLETE - Dataset is ready for use!\n",
      "================================================================================\n",
      "📁 Final dataset location: /tmp/mixed_partial_dataset_50_200_final.parquet\n",
      "📊 Total programs: 69,483\n",
      "🎯 Unique tasks: 399\n",
      "🤖 Models: 31\n",
      "================================================================================\n",
      "✓ File loaded successfully\n",
      "✓ Dataset shape: (69483, 8)\n",
      "✓ Columns: ['task_id', 'reasoning', 'code', 'correct_train_input', 'correct_test_input', 'predicted_train_output', 'predicted_test_output', 'model']\n",
      "✓ Unique tasks: 399\n",
      "✓ Programs per task (mean): 174.14\n",
      "\n",
      "2. DATA TYPE VERIFICATION:\n",
      "----------------------------------------\n",
      "✓ Train output type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Train output length: 4 grids\n",
      "✓ First grid type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Test output type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Test output length: 1 grids\n",
      "✓ Train correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Train correct values: [False  True  True False]\n",
      "✓ First correct value type: <class 'numpy.bool'> (expected: bool)\n",
      "✓ Test correct type: <class 'numpy.ndarray'> (expected: list)\n",
      "✓ Test correct values: [False]\n",
      "\n",
      "3. DATA COMPLETENESS:\n",
      "----------------------------------------\n",
      "✓ Rows with train outputs: 69483/69483 (100.0%)\n",
      "✓ Rows with test outputs: 69483/69483 (100.0%)\n",
      "✓ Rows with train correctness: 69483/69483 (100.0%)\n",
      "✓ Rows with test correctness: 69483/69483 (100.0%)\n",
      "\n",
      "4. DUCKDB COMPATIBILITY:\n",
      "----------------------------------------\n",
      "✓ DuckDB can read schema (8 columns)\n",
      "✓ Basic queries work\n",
      "  Sample data shape: (3, 6)\n",
      "✓ 3D array access works\n",
      "  Grid access sample: (2, 4)\n",
      "✓ All DuckDB operations successful!\n",
      "\n",
      "5. DATASET STATISTICS:\n",
      "----------------------------------------\n",
      "✓ Tasks with programs: 399\n",
      "✓ Programs per task: min=2, max=250, mean=174.1\n",
      "✓ Models represented: 31\n",
      "✓ Top 3 models: {'Qwen2.5-Coder-32B-Instruct': np.int64(19849), 'Mistral-Large-Instruct-2407': np.int64(15952), 'Qwen2.5-72B-Instruct': np.int64(15129)}\n",
      "\n",
      "================================================================================\n",
      "✅ VERIFICATION COMPLETE - Dataset is ready for use!\n",
      "================================================================================\n",
      "📁 Final dataset location: /tmp/mixed_partial_dataset_50_200_final.parquet\n",
      "📊 Total programs: 69,483\n",
      "🎯 Unique tasks: 399\n",
      "🤖 Models: 31\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive verification of the final dataset\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE DATASET VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "file_path = \"/tmp/mixed_partial_dataset_50_200_final.parquet\"\n",
    "\n",
    "# 1. Basic file and structure verification\n",
    "print(\"\\n1. BASIC DATASET INFO:\")\n",
    "print(\"-\" * 40)\n",
    "verification_df = pd.read_parquet(file_path)\n",
    "print(f\"✓ File loaded successfully\")\n",
    "print(f\"✓ Dataset shape: {verification_df.shape}\")\n",
    "print(f\"✓ Columns: {list(verification_df.columns)}\")\n",
    "print(f\"✓ Unique tasks: {verification_df['task_id'].nunique()}\")\n",
    "print(f\"✓ Programs per task (mean): {verification_df.groupby('task_id').size().mean():.2f}\")\n",
    "\n",
    "# 2. Data type verification\n",
    "print(\"\\n2. DATA TYPE VERIFICATION:\")\n",
    "print(\"-\" * 40)\n",
    "sample = verification_df.iloc[0]\n",
    "\n",
    "# Check predicted outputs (should be 3D arrays: List[List[List[int]]])\n",
    "train_output = sample['predicted_train_output']\n",
    "test_output = sample['predicted_test_output']\n",
    "\n",
    "print(f\"✓ Train output type: {type(train_output)} (expected: list)\")\n",
    "print(f\"✓ Train output length: {len(train_output)} grids\")\n",
    "if len(train_output) > 0:\n",
    "    first_grid = train_output[0]\n",
    "    print(f\"✓ First grid type: {type(first_grid)} (expected: list)\")\n",
    "    if isinstance(first_grid, list) and len(first_grid) > 0:\n",
    "        print(f\"✓ Grid dimensions: {len(first_grid)} x {len(first_grid[0])}\")\n",
    "        if len(first_grid[0]) > 0:\n",
    "            cell_value = first_grid[0][0]\n",
    "            print(f\"✓ Cell value type: {type(cell_value)} = {cell_value} (expected: int)\")\n",
    "\n",
    "print(f\"✓ Test output type: {type(test_output)} (expected: list)\")\n",
    "print(f\"✓ Test output length: {len(test_output)} grids\")\n",
    "\n",
    "# Check correctness arrays (should be 1D boolean arrays: List[bool])\n",
    "train_correct = sample['correct_train_input']\n",
    "test_correct = sample['correct_test_input']\n",
    "\n",
    "print(f\"✓ Train correct type: {type(train_correct)} (expected: list)\")\n",
    "print(f\"✓ Train correct values: {train_correct}\")\n",
    "if len(train_correct) > 0:\n",
    "    print(f\"✓ First correct value type: {type(train_correct[0])} (expected: bool)\")\n",
    "\n",
    "print(f\"✓ Test correct type: {type(test_correct)} (expected: list)\")\n",
    "print(f\"✓ Test correct values: {test_correct}\")\n",
    "\n",
    "# 3. Data completeness verification\n",
    "print(\"\\n3. DATA COMPLETENESS:\")\n",
    "print(\"-\" * 40)\n",
    "non_empty_train = verification_df['predicted_train_output'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_test = verification_df['predicted_test_output'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_train_correct = verification_df['correct_train_input'].apply(lambda x: len(x) > 0).sum()\n",
    "non_empty_test_correct = verification_df['correct_test_input'].apply(lambda x: len(x) > 0).sum()\n",
    "\n",
    "print(f\"✓ Rows with train outputs: {non_empty_train}/{len(verification_df)} ({100*non_empty_train/len(verification_df):.1f}%)\")\n",
    "print(f\"✓ Rows with test outputs: {non_empty_test}/{len(verification_df)} ({100*non_empty_test/len(verification_df):.1f}%)\")\n",
    "print(f\"✓ Rows with train correctness: {non_empty_train_correct}/{len(verification_df)} ({100*non_empty_train_correct/len(verification_df):.1f}%)\")\n",
    "print(f\"✓ Rows with test correctness: {non_empty_test_correct}/{len(verification_df)} ({100*non_empty_test_correct/len(verification_df):.1f}%)\")\n",
    "\n",
    "# 4. DuckDB compatibility verification\n",
    "print(\"\\n4. DUCKDB COMPATIBILITY:\")\n",
    "print(\"-\" * 40)\n",
    "con = duckdb.connect()\n",
    "\n",
    "try:\n",
    "    # Schema check\n",
    "    schema = con.execute(f\"DESCRIBE '{file_path}'\").fetchdf()\n",
    "    print(f\"✓ DuckDB can read schema ({len(schema)} columns)\")\n",
    "    \n",
    "    # Basic query check\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT \n",
    "        task_id,\n",
    "        model,\n",
    "        length(predicted_train_output) as num_train_grids,\n",
    "        length(predicted_test_output) as num_test_grids,\n",
    "        length(correct_train_input) as num_train_examples,\n",
    "        length(correct_test_input) as num_test_examples\n",
    "    FROM '{file_path}' \n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    sample_data = con.execute(sample_query).fetchdf()\n",
    "    print(f\"✓ Basic queries work\")\n",
    "    print(f\"  Sample data shape: {sample_data.shape}\")\n",
    "    \n",
    "    # 3D array access check\n",
    "    nested_query = f\"\"\"\n",
    "    SELECT \n",
    "        task_id,\n",
    "        predicted_train_output[1] as first_train_grid,\n",
    "        length(predicted_train_output[1]) as grid_height,\n",
    "        length(predicted_train_output[1][1]) as grid_width\n",
    "    FROM '{file_path}' \n",
    "    WHERE length(predicted_train_output) > 0 \n",
    "      AND length(predicted_train_output[1]) > 0\n",
    "    LIMIT 2\n",
    "    \"\"\"\n",
    "    nested_data = con.execute(nested_query).fetchdf()\n",
    "    print(f\"✓ 3D array access works\")\n",
    "    print(f\"  Grid access sample: {nested_data.shape}\")\n",
    "    \n",
    "    print(f\"✓ All DuckDB operations successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ DuckDB error: {e}\")\n",
    "\n",
    "finally:\n",
    "    con.close()\n",
    "\n",
    "# 5. Summary statistics\n",
    "print(\"\\n5. DATASET STATISTICS:\")\n",
    "print(\"-\" * 40)\n",
    "task_stats = verification_df.groupby('task_id').size()\n",
    "model_stats = verification_df['model'].value_counts()\n",
    "\n",
    "print(f\"✓ Tasks with programs: {len(task_stats)}\")\n",
    "print(f\"✓ Programs per task: min={task_stats.min()}, max={task_stats.max()}, mean={task_stats.mean():.1f}\")\n",
    "print(f\"✓ Models represented: {len(model_stats)}\")\n",
    "print(f\"✓ Top 3 models: {dict(model_stats.head(3))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ VERIFICATION COMPLETE - Dataset is ready for use!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"📁 Final dataset location: {file_path}\")\n",
    "print(f\"📊 Total programs: {len(verification_df):,}\")\n",
    "print(f\"🎯 Unique tasks: {verification_df['task_id'].nunique()}\")\n",
    "print(f\"🤖 Models: {len(model_stats)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1ee38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    task_id reasoning                                               code  \\\n",
      "0  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "1  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "2  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "3  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "4  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "5  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "6  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "7  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "8  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "9  56ff96f3            import numpy as np\\n\\ndef transform(grid_lst: ...   \n",
      "\n",
      "          correct_train_input correct_test_input  \\\n",
      "0  [False, True, True, False]            [False]   \n",
      "1   [True, True, False, True]             [True]   \n",
      "2    [True, True, True, True]            [False]   \n",
      "3  [False, False, True, True]            [False]   \n",
      "4  [False, False, True, True]            [False]   \n",
      "5    [True, True, True, True]            [False]   \n",
      "6    [True, True, True, True]            [False]   \n",
      "7    [True, True, True, True]            [False]   \n",
      "8   [True, False, True, True]            [False]   \n",
      "9   [True, True, False, True]             [True]   \n",
      "\n",
      "                              predicted_train_output  \\\n",
      "0  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "1  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "2  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "3  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "4  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "5  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "6  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "7  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "8  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "9  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1,...   \n",
      "\n",
      "                               predicted_test_output  \\\n",
      "0  [[[8, 8, 8, 0, 0, 0, 0, 0], [8, 8, 8, 0, 0, 0,...   \n",
      "1  [[[8, 8, 8, 0, 0, 0, 0, 0], [8, 8, 8, 0, 0, 0,...   \n",
      "2  [[[1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0,...   \n",
      "3  [[[8, 6, 6, 6, 6, 6, 0, 0], [6, 6, 8, 6, 6, 6,...   \n",
      "4  [[[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0,...   \n",
      "5  [[[8, 8, 8, 8, 8, 8, 0, 0], [8, 8, 8, 8, 8, 8,...   \n",
      "6  [[[8, 8, 8, 0, 0, 0, 0, 0], [8, 8, 8, 0, 0, 0,...   \n",
      "7  [[[8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8,...   \n",
      "8  [[[8, 8, 8, 8, 0, 0, 0, 0], [8, 8, 8, 8, 0, 0,...   \n",
      "9  [[[8, 8, 8, 0, 0, 0, 0, 0], [8, 8, 8, 0, 0, 0,...   \n",
      "\n",
      "                        model  \n",
      "0  Qwen2.5-Coder-32B-Instruct  \n",
      "1  Qwen2.5-Coder-32B-Instruct  \n",
      "2   Qwen2.5-Coder-7B-Instruct  \n",
      "3  Qwen2.5-Coder-32B-Instruct  \n",
      "4  Qwen2.5-Coder-32B-Instruct  \n",
      "5        Qwen2.5-72B-Instruct  \n",
      "6   Qwen2.5-Coder-7B-Instruct  \n",
      "7  Qwen2.5-Coder-14B-Instruct  \n",
      "8  Qwen2.5-Coder-14B-Instruct  \n",
      "9  Qwen2.5-Coder-32B-Instruct  \n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "sample_df = con.execute(f\"SELECT * FROM '{file_path}' LIMIT 10\").fetchdf()\n",
    "con.close()\n",
    "print(sample_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
