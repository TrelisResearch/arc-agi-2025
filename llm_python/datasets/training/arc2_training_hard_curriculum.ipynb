{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268bc65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_root / \"arc_2_training_hard_curriculum.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.superking import load_superking\n",
    "\n",
    "superking_df = load_superking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ef713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only refined examples.\n",
    "from llm_python.datasets.query import filter_soar_df\n",
    "\n",
    "df = superking_df.copy()\n",
    "df = filter_soar_df(\n",
    "    df,\n",
    "    include_subset=\"arc-prize-2025/training-hard\",\n",
    "    exclude_transductive=True,\n",
    "    any_train_correct=True,\n",
    ")\n",
    "print(f\"Number of rows after filtering to arc-prize-2025/training-hard: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ce597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def select_top_n_by_task(\n",
    "    df,\n",
    "    n=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Groups the dataframe by `groupby_column`, sorts within each group by the sum of `correct_columns` (descending),\n",
    "    then by the length of `code_column` (ascending), and selects the top N rows per group.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        n (int): Number of top rows to select per group.\n",
    "        correct_columns (tuple): Columns to sum for correctness.\n",
    "        code_column (str): Column containing code whose length is used for sorting.\n",
    "        groupby_column (str): Column to group by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered dataframe with top N per group.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"correct_train_input_count\"] = df[\"correct_train_input\"].apply(\n",
    "        lambda x: np.sum(x)\n",
    "    )\n",
    "    df[\"correct_test_input_count\"] = df[\"correct_test_input\"].apply(lambda x: np.sum(x))\n",
    "    df[\"code_length\"] = df[\"code\"].str.len()\n",
    "    grouped = (\n",
    "        df.sort_values(\n",
    "            by=[\"correct_test_input_count\", \"correct_train_input_count\", \"code_length\"],\n",
    "            ascending=[False, False, True],\n",
    "        )\n",
    "        .groupby(\"task_id\")\n",
    "    )\n",
    "    def filter_group(group):\n",
    "        top_code_length = group.iloc[0][\"code_length\"]\n",
    "        filtered = group[group[\"code_length\"] <= 2.5 * top_code_length]\n",
    "        return filtered.head(n)\n",
    "\n",
    "    grouped = grouped.apply(filter_group).reset_index(drop=True)\n",
    "    return grouped.drop(columns=[\"correct_train_input_count\", \"code_length\"])\n",
    "\n",
    "\n",
    "df_top = select_top_n_by_task(df, n=10)\n",
    "print(df_top.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from llm_python.datasets.schema import PARQUET_SCHEMA\n",
    "\n",
    "\n",
    "print(f\"Saving final dataset to: {output_path}\")\n",
    "table = pa.Table.from_pandas(df, schema=PARQUET_SCHEMA)\n",
    "pq.write_table(table, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44192e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.statistics import analyze_dataset_statistics\n",
    "\n",
    "analyze_dataset_statistics(df_top, \"curriculum\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trelis-arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
