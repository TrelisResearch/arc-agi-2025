{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"trelis-arc\")\n",
    "\n",
    "table_name = \"trelis-arc.arc.train_eval_blended_fake_ttt_50\"\n",
    "file_name = table_name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_final_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{table_name}` AS\n",
    "\n",
    "-- Get top 25 from training dataset (already filtered and ranked)\n",
    "WITH training_top25 AS (\n",
    "    SELECT \n",
    "        task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "        correct_train_input, correct_test_input,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY task_id \n",
    "            ORDER BY task_id, code  -- Using existing order from the table\n",
    "        ) as rank_in_task\n",
    "    FROM `trelis-arc.arc.shortest_ratio_2_5x_filtered_250`\n",
    "),\n",
    "training_limited AS (\n",
    "    SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "           correct_train_input, correct_test_input\n",
    "    FROM training_top25\n",
    "    WHERE rank_in_task <= 25\n",
    "),\n",
    "-- Get all from eval dataset (already limited to 25 per task)\n",
    "eval_data AS (\n",
    "    SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "           correct_train_input, correct_test_input\n",
    "    FROM `trelis-arc.arc.shortest_ratio_2_5x_filtered_25_eval_masked_partialplus`\n",
    "),\n",
    "-- Union both datasets\n",
    "blended_data AS (\n",
    "    SELECT * FROM training_limited\n",
    "    UNION ALL\n",
    "    SELECT * FROM eval_data\n",
    ")\n",
    "SELECT task_id, code, model, predicted_train_output, predicted_test_output,\n",
    "       correct_train_input, correct_test_input\n",
    "FROM blended_data\n",
    "ORDER BY task_id, code\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing BigQuery table creation...\")\n",
    "job = client.query(create_final_table_query)\n",
    "result = job.result()\n",
    "print(f\"âœ“ Table `{table_name}` created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.bigquery_export import load_bigquery_table_as_dataframe\n",
    "\n",
    "# Load BigQuery table as DataFrame using our reusable function\n",
    "print(\"Loading BigQuery table data...\")\n",
    "raw_data = load_bigquery_table_as_dataframe(\n",
    "    client=client,\n",
    "    table_name=table_name\n",
    ")\n",
    "print(f\"Loaded {len(raw_data)} programs from BigQuery table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.bigquery_converter import convert_bigquery_to_soar, save_soar_parquet\n",
    "\n",
    "# First, let's inspect the actual data structure\n",
    "print(\"Inspecting BigQuery data structure...\")\n",
    "sample_row = raw_data.iloc[0]\n",
    "print(f\"Sample row columns: {sample_row.index.tolist()}\")\n",
    "print(f\"Train output type: {type(sample_row['predicted_train_output'])}\")\n",
    "print(f\"Train correct type: {type(sample_row['correct_train_input'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Convert BigQuery data to SOAR format using our reusable function\n",
    "print(\"Converting BigQuery data to SOAR format...\")\n",
    "final_dataset = convert_bigquery_to_soar(raw_data, show_progress=True)\n",
    "\n",
    "# Save the final dataset\n",
    "if len(final_dataset) > 0:\n",
    "    output_path = f\"/tmp/{file_name}.parquet\"\n",
    "    print(f\"Saving final dataset to: {output_path}\")\n",
    "    \n",
    "    save_soar_parquet(final_dataset, output_path)\n",
    "else:\n",
    "    print(\"No valid data to save!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84683efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the final dataset using our reusable validation function\n",
    "from llm_python.datasets.schema import validate_soar_dataset\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "file_path = f\"/tmp/{file_name}.parquet\"\n",
    "\n",
    "results = validate_soar_dataset(pd.read_parquet(file_path), max_grid_size=40, silent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00037e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "sample_df = con.execute(f\"SELECT * FROM '{file_path}' LIMIT 10\").fetchdf()\n",
    "con.close()\n",
    "print(sample_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
