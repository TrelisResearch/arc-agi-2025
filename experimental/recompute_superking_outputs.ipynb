{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5229e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/tmp/superking.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.superking import download_superking\n",
    "\n",
    "download_superking(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llm_python.utils.numpy import convert_numpy_types\n",
    "\n",
    "df = pd.read_parquet(output_path)\n",
    "df[\"predicted_train_output\"] = df[\"predicted_train_output\"].apply(convert_numpy_types)\n",
    "df[\"correct_train_input\"] = df[\"correct_train_input\"].apply(convert_numpy_types)\n",
    "df[\"predicted_test_output\"] = df[\"predicted_test_output\"].apply(convert_numpy_types)\n",
    "df[\"correct_test_input\"] = df[\"correct_test_input\"].apply(convert_numpy_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e85581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.utils.arc_tester import ArcTester\n",
    "from llm_python.utils.task_loader import get_task_loader\n",
    "from llm_python.datasets.validation import validate_soar_dataframe\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Original columns: {df.columns.tolist()}\")\n",
    "\n",
    "task_loader = get_task_loader()\n",
    "\n",
    "def process_single_row(row_data):\n",
    "    \"\"\"Process a single row - this function will be called in parallel\"\"\"\n",
    "    idx, row = row_data\n",
    "    try:\n",
    "        # Create instances inside the worker process\n",
    "        arc_tester = ArcTester()\n",
    "        \n",
    "        result = arc_tester.test_program(\n",
    "            row[\"code\"], task_loader.get_task(row[\"task_id\"])\n",
    "        )\n",
    "        \n",
    "        # Create corrected row with actual values from arc_tester\n",
    "        corrected_row = row.copy()\n",
    "        corrected_row[\"predicted_train_output\"] = result.train_outputs\n",
    "        corrected_row[\"predicted_test_output\"] = result.test_outputs\n",
    "        corrected_row[\"correct_train_input\"] = result.correct_train_input\n",
    "        corrected_row[\"correct_test_input\"] = result.correct_test_input\n",
    "        \n",
    "        return ('success', idx, corrected_row)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return ('failed', idx, str(e))\n",
    "\n",
    "# Determine optimal number of workers\n",
    "num_workers = min(mp.cpu_count(), 8)  # Don't use too many to avoid memory issues\n",
    "print(f\"Using {num_workers} parallel workers\")\n",
    "\n",
    "# Process in batches for better memory management\n",
    "batch_size = 5000  # Larger batches since we're using parallel processing\n",
    "total_rows = len(df)\n",
    "all_corrected_rows = []\n",
    "all_failed_indices = []\n",
    "\n",
    "print(f\"Processing {total_rows} rows in batches of {batch_size}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for batch_start in range(0, total_rows, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, total_rows)\n",
    "    batch_df = df.iloc[batch_start:batch_end].copy()\n",
    "    \n",
    "    print(f\"\\nProcessing batch {batch_start//batch_size + 1}: rows {batch_start} to {batch_end-1}\")\n",
    "    \n",
    "    # Prepare data for parallel processing\n",
    "    row_data = [(idx + batch_start, row) for idx, (_, row) in enumerate(batch_df.iterrows())]\n",
    "    \n",
    "    batch_corrected_rows = []\n",
    "    batch_failed_indices = []\n",
    "    \n",
    "    # Process batch in parallel with progress bar\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_idx = {executor.submit(process_single_row, data): data[0] \n",
    "                        for data in row_data}\n",
    "        \n",
    "        # Process results with progress bar\n",
    "        with tqdm(total=len(row_data), desc=f\"Batch {batch_start//batch_size + 1}\") as pbar:\n",
    "            for future in as_completed(future_to_idx):\n",
    "                result_type, idx, result_data = future.result()\n",
    "                \n",
    "                if result_type == 'success':\n",
    "                    batch_corrected_rows.append(result_data)\n",
    "                else:\n",
    "                    batch_failed_indices.append(idx)\n",
    "                    if len(batch_failed_indices) <= 5:  # Only print first few errors per batch\n",
    "                        print(f\"    Failed row {idx}: {result_data}\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Add batch results to overall results\n",
    "    all_corrected_rows.extend(batch_corrected_rows)\n",
    "    all_failed_indices.extend(batch_failed_indices)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    processed_so_far = batch_end\n",
    "    rate = processed_so_far / elapsed\n",
    "    remaining = total_rows - processed_so_far\n",
    "    eta = remaining / rate if rate > 0 else 0\n",
    "    \n",
    "    print(f\"  Batch completed: {len(batch_corrected_rows)} successful, {len(batch_failed_indices)} failed\")\n",
    "    print(f\"  Total so far: {len(all_corrected_rows)} successful, {len(all_failed_indices)} failed\")\n",
    "    print(f\"  Rate: {rate:.1f} rows/sec, ETA: {eta/60:.1f} minutes\")\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Total successful rows: {len(all_corrected_rows)}\")\n",
    "print(f\"Total failed rows: {len(all_failed_indices)}\")\n",
    "print(f\"Total time: {(time.time() - start_time)/60:.1f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final cleaned dataframe and filter out invalid rows\n",
    "\n",
    "# Force reload the validation module\n",
    "import sys\n",
    "if 'llm_python.datasets.validation' in sys.modules:\n",
    "    del sys.modules['llm_python.datasets.validation']\n",
    "\n",
    "from llm_python.datasets.validation import validate_soar_sample, validate_soar_dataframe\n",
    "from llm_python.programsdb.schema import PARQUET_SCHEMA\n",
    "\n",
    "if all_corrected_rows:\n",
    "    df_cleaned = pd.DataFrame(all_corrected_rows)\n",
    "    print(f\"Original cleaned dataset shape: {df_cleaned.shape}\")\n",
    "    \n",
    "    # Validate each row and keep only valid ones\n",
    "    valid_rows = []\n",
    "    invalid_count = 0\n",
    "    \n",
    "    for i, row in df_cleaned.iterrows():\n",
    "        is_valid, error_msg = validate_soar_sample(row.to_dict())\n",
    "        if is_valid:\n",
    "            valid_rows.append(row.to_dict())\n",
    "        else:\n",
    "            invalid_count += 1\n",
    "            if invalid_count <= 5:  # Print first few errors\n",
    "                print(f\"Row {i} invalid: {error_msg}\")\n",
    "    \n",
    "    print(f\"\\nValidation results:\")\n",
    "    print(f\"Valid rows: {len(valid_rows)}\")\n",
    "    print(f\"Invalid rows: {invalid_count}\")\n",
    "    \n",
    "    if valid_rows:\n",
    "        # Create new dataframe with only valid rows\n",
    "        df_final = pd.DataFrame(valid_rows)\n",
    "        print(f\"Final dataset shape after filtering: {df_final.shape}\")\n",
    "        \n",
    "        # Save the final cleaned dataset\n",
    "        output_file = \"/tmp/superking_cleaned_v2.parquet\"\n",
    "        df_final.to_parquet(output_file, schema=PARQUET_SCHEMA)\n",
    "        print(f\"Saved final cleaned dataset to {output_file}\")\n",
    "        \n",
    "        # Double-check validation on the final dataset\n",
    "        is_valid, validation_message = validate_soar_dataframe(df_final)\n",
    "        print(f\"Final validation result: {validation_message}\")\n",
    "    else:\n",
    "        print(\"No valid rows found!\")\n",
    "else:\n",
    "    print(\"No rows were successfully processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-agi-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
