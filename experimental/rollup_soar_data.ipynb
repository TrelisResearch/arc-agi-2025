{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8af7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fdfddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want this to load early.\n",
    "import sandbox.forkserver_executor  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ee7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path.home().joinpath(\"julien_soar\").iterdir():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfbe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Parquet schema inspection\n",
    "for file in Path.home().joinpath(\"julien_soar\").iterdir():\n",
    "    if file.suffix == '.parquet':\n",
    "        print(f\"Schema for {file.name}:\")\n",
    "        if pq is not None:\n",
    "            pf = pq.ParquetFile(file)\n",
    "            print(pf.schema)\n",
    "        else:\n",
    "            print(\"pyarrow not available, falling back to pandas (loads data).\")\n",
    "            df = pd.read_parquet(file)\n",
    "            print(df.dtypes)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from llm_python.datasets.collector import generate_unique_hex_id\n",
    "from llm_python.datasets.io import write_soar_parquet\n",
    "\n",
    "def process_refinement_pickle(pkl_path, out_dir):\n",
    "    \"\"\"\n",
    "    Loads a pickle file with dict-of-list structure, merges task_id into each dict, flattens, and writes to parquet.\n",
    "    \"\"\"\n",
    "    obj = pd.read_pickle(pkl_path)\n",
    "    rows = []\n",
    "    for task_id, sample_list in obj.items():\n",
    "        for sample in sample_list:\n",
    "            sample = dict(sample)  # copy to avoid mutating original\n",
    "            sample['task_id'] = task_id\n",
    "            sample['row_id'] = generate_unique_hex_id()\n",
    "            sample['is_transductive'] = False\n",
    "            rows.append(sample)\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_path = Path(out_dir) / (Path(pkl_path).stem + '.parquet')\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_soar_parquet(df, out_path)\n",
    "    print(f\"Wrote {out_path} with {len(df)} rows.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_files = [f for f in Path.home().joinpath(\"julien_soar\").iterdir() if f.suffix == '.pkl']\n",
    "# for pkl_file in pkl_files:\n",
    "#     process_refinement_pickle(pkl_file, Path.home().joinpath(\"julien_soar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.validation import (\n",
    "    CorrectnessRowValidationResult,\n",
    "    validate_soar_dataframe,\n",
    "    validate_soar_dataframe_correctness,\n",
    "    validate_soar_row,\n",
    "    validate_soar_row_correctness,\n",
    ")\n",
    "from llm_python.transduction.code_classifier import CodeTransductionClassifier\n",
    "from llm_python.utils.arc_tester import ArcTester\n",
    "from llm_python.utils.numpy import convert_numpy_types\n",
    "import concurrent.futures\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "arc_tester = ArcTester()\n",
    "transductive_classifier = CodeTransductionClassifier()\n",
    "\n",
    "def clean_soar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans the SOAR DataFrame by ensuring required columns are present and correctly typed.\n",
    "    \"\"\"\n",
    "    # We have already checked required columns in previous steps.\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[~df[\"code\"].str.lower().str.contains(\"random|randbelow|rvs\")]\n",
    "    print(f\"Kept {len(df)}/{len(df)} rows after filtering for randomness.\")\n",
    "\n",
    "    print(\"Validating row correctness with ThreadPoolExecutor...\")\n",
    "    \n",
    "    def validate_correctness_wrapper(row_tuple):\n",
    "        _, row = row_tuple\n",
    "        res = validate_soar_row_correctness(row, arc_tester)\n",
    "        # print(res.correctness_errors)\n",
    "        # print(res.new_predicted_train_output)\n",
    "        return res\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        correctness_results = list(tqdm(executor.map(validate_correctness_wrapper, df.iterrows()), total=len(df), desc=\"Validating correctness\"))\n",
    "\n",
    "    cleaned_rows = []\n",
    "    original_rows = df.to_dict('records')\n",
    "    for i, (correctness_result) in enumerate(correctness_results):\n",
    "        row = original_rows[i]\n",
    "        \n",
    "        if not correctness_result.correctness_valid:\n",
    "            # For safety, check if counts change\n",
    "            orig_true_count = sum(row[\"correct_train_input\"]) if isinstance(row[\"correct_train_input\"], list) else 0\n",
    "            new_true_count = sum(correctness_result.new_correct_train_input) if isinstance(correctness_result.new_correct_train_input, list) else 0\n",
    "            if orig_true_count != new_true_count:\n",
    "                print(\n",
    "                    f\"Warning: correct_train_input True count changed from {orig_true_count} to {new_true_count} for row_id {row.get('row_id', '<unknown>')}\"\n",
    "                )\n",
    "                # Print original and corrected train_0 arrays, each row on a new line for readability\n",
    "                # print(\"Original train_0:\")\n",
    "                # for row_item in row['predicted_train_output'][0]:\n",
    "                #     print(row_item)\n",
    "                # print(\"Corrected train_0:\")\n",
    "                # for row_item in correctness_result.new_predicted_train_output[0]:\n",
    "                #     print(row_item)\n",
    "\n",
    "            row[\"predicted_train_output\"] = correctness_result.new_predicted_train_output\n",
    "            row[\"predicted_test_output\"] = correctness_result.new_predicted_test_output\n",
    "            row[\"correct_train_input\"] = correctness_result.new_correct_train_input\n",
    "            row[\"correct_test_input\"] = correctness_result.new_correct_test_input\n",
    "        \n",
    "        cleaned_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(cleaned_rows)\n",
    "\n",
    "    def process_row_initial(row_tuple):\n",
    "        _ , row = row_tuple\n",
    "        row = row.to_dict()\n",
    "        row[\"predicted_train_output\"] = convert_numpy_types(row[\"predicted_train_output\"])\n",
    "        row[\"predicted_test_output\"] = convert_numpy_types(row[\"predicted_test_output\"])\n",
    "        row[\"correct_train_input\"] = convert_numpy_types(row[\"correct_train_input\"])\n",
    "        row[\"correct_test_input\"] = convert_numpy_types(row[\"correct_test_input\"])\n",
    "        row[\"reasoning\"] = str(row[\"reasoning\"])\n",
    "        row[\"row_id\"] = generate_unique_hex_id()\n",
    "        row[\"is_transductive\"] = transductive_classifier.is_transductive(row[\"code\"])[0]\n",
    "        return row\n",
    "\n",
    "    print(\"Computing base fields in parallel...\")\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        processed_rows = list(tqdm(executor.map(process_row_initial, df.iterrows()), total=len(df), desc=\"Computing base fields\"))\n",
    "    \n",
    "    df = pd.DataFrame(processed_rows)\n",
    "\n",
    "    def validate_and_log_errors_parallel(df: pd.DataFrame) -> pd.Series:\n",
    "        errors_set = set()\n",
    "        \n",
    "        def validate_row_wrapper(row_tuple):\n",
    "            _ , row = row_tuple\n",
    "            result = validate_soar_row(row)\n",
    "            return result.is_valid, result.errors\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            results = list(tqdm(executor.map(validate_row_wrapper, df.iterrows()), total=len(df), desc=\"Validating rows\"))\n",
    "\n",
    "        is_valid_list = []\n",
    "        for is_valid, errors in results:\n",
    "            is_valid_list.append(is_valid)\n",
    "            if errors:\n",
    "                errors_set.update(errors)\n",
    "        \n",
    "        if errors_set:\n",
    "            print(f\"Unique validation errors encountered: {errors_set}\")\n",
    "            \n",
    "        return pd.Series(is_valid_list, index=df.index)\n",
    "\n",
    "    print(\"Validating rows in parallel...\")\n",
    "    df[\"is_valid\"] = validate_and_log_errors_parallel(df)\n",
    "    print(f\"After cleaning, {df['is_valid'].sum()} out of {len(df)} rows are valid.\")\n",
    "    df = df[df[\"is_valid\"]]\n",
    "    df = df.drop(columns=[\"is_valid\"])\n",
    "\n",
    "    print(f\"{len(df[df['is_transductive']])} out of {len(df)} rows are transductive.\")\n",
    "    \n",
    "    print(\"Validating rows post-fix in parallel...\")\n",
    "    df[\"is_valid\"] = validate_and_log_errors_parallel(df)\n",
    "    print(f\"After cleaning, {df['is_valid'].sum()} out of {len(df)} rows are valid.\")\n",
    "    df = df[df[\"is_valid\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8554689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.io import read_soar_parquet\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "parquet_files = [f for f in Path.home().joinpath(\"julien_soar\").iterdir() if f.suffix == '.parquet']\n",
    "\n",
    "for file in parquet_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    df = read_soar_parquet(file)\n",
    "    def any_true(x):\n",
    "        if isinstance(x, (list, np.ndarray)):\n",
    "            return np.any(x)\n",
    "        return False\n",
    "\n",
    "    df[\"any_train_correct\"] = df[\"correct_train_input\"].apply(any_true)\n",
    "    df[\"any_test_correct\"] = df[\"correct_test_input\"].apply(any_true)\n",
    "    original_len = len(df)\n",
    "    df = df[df[\"any_test_correct\"] | df[\"any_train_correct\"]]\n",
    "    print(f\"Filtered from {original_len} to {len(df)} rows based on any_train_correct or any_test_correct.\")\n",
    "    df = clean_soar_dataframe(df)\n",
    "    out_dir = Path.home().joinpath(\"julien_soar_cleaned\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    write_soar_parquet(df, out_dir / file.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trelis-arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
