{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8af7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fdfddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fork server worker started with PID: 476673\n",
      "Fork server worker started with PID: 476676\n",
      "Fork server worker started with PID: 476682\n",
      "Fork server worker started with PID: 476688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fork server worker started with PID: 476694\n",
      "Fork server worker started with PID: 476700\n",
      "Fork server worker started with PID: 476706\n",
      "Fork server worker started with PID: 476712\n",
      "Fork server worker started with PID: 476718\n",
      "Fork server worker started with PID: 476724\n",
      "Fork server worker started with PID: 476730\n",
      "Fork server worker started with PID: 476736\n",
      "Fork server worker started with PID: 476742\n",
      "Fork server worker started with PID: 476748\n",
      "Fork server worker started with PID: 476754\n",
      "Fork server worker started with PID: 476758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-2:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-12:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 158, in _fork_server_main_loop\n",
      "    os.waitpid(child_pid, 0)\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/code/trelis-arc/sandbox/forkserver_executor.py\", line 131, in _fork_server_main_loop\n",
      "    task = request_queue.get()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/home/lewis/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Want this to load early.\n",
    "import sandbox.forkserver_executor  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349ee7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lewis/julien_soar/arc_1_val_Qwen2.5-72B-Instruct_solution.parquet\n",
      "/home/lewis/julien_soar/arc_1_val_Qwen2.5-Coder-7B-Instruct_solution.parquet\n",
      "/home/lewis/julien_soar/arc_1_val_Qwen2.5-Coder-14B-Instruct_solution.parquet\n",
      "/home/lewis/julien_soar/arc_1_val_refinement.pkl\n",
      "/home/lewis/julien_soar/arc_1_train_refinement.pkl\n",
      "/home/lewis/julien_soar/arc_1_val_Qwen2.5-Coder-32B-Instruct_solution.parquet\n",
      "/home/lewis/julien_soar/arc_1_val_Mistral-Large-Instruct-2407_solution.parquet\n"
     ]
    }
   ],
   "source": [
    "for file in Path.home().joinpath(\"julien_soar\").iterdir():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdfbe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for arc_1_val_Qwen2.5-72B-Instruct_solution.parquet:\n",
      "<pyarrow._parquet.ParquetSchema object at 0x7d01e77ef240>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 task_id (String);\n",
      "  optional binary field_id=-1 text (String);\n",
      "  optional binary field_id=-1 code (String);\n",
      "  optional group field_id=-1 correct_train_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_train_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 correct_test_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_test_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional binary field_id=-1 model (String);\n",
      "}\n",
      "\n",
      "\n",
      "Schema for arc_1_val_Qwen2.5-Coder-7B-Instruct_solution.parquet:\n",
      "<pyarrow._parquet.ParquetSchema object at 0x7d01e5517bc0>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 task_id (String);\n",
      "  optional binary field_id=-1 text (String);\n",
      "  optional binary field_id=-1 code (String);\n",
      "  optional group field_id=-1 correct_train_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_train_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 correct_test_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_test_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional binary field_id=-1 model (String);\n",
      "}\n",
      "\n",
      "\n",
      "Schema for arc_1_val_Qwen2.5-Coder-14B-Instruct_solution.parquet:\n",
      "<pyarrow._parquet.ParquetSchema object at 0x7d01e771f000>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 task_id (String);\n",
      "  optional binary field_id=-1 text (String);\n",
      "  optional binary field_id=-1 code (String);\n",
      "  optional group field_id=-1 correct_train_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_train_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 correct_test_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_test_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional binary field_id=-1 model (String);\n",
      "}\n",
      "\n",
      "\n",
      "Schema for arc_1_val_Qwen2.5-Coder-32B-Instruct_solution.parquet:\n",
      "<pyarrow._parquet.ParquetSchema object at 0x7d01e5516040>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 task_id (String);\n",
      "  optional binary field_id=-1 text (String);\n",
      "  optional binary field_id=-1 code (String);\n",
      "  optional group field_id=-1 correct_train_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_train_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 correct_test_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_test_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional binary field_id=-1 model (String);\n",
      "}\n",
      "\n",
      "\n",
      "Schema for arc_1_val_Mistral-Large-Instruct-2407_solution.parquet:\n",
      "<pyarrow._parquet.ParquetSchema object at 0x7d026014d280>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 task_id (String);\n",
      "  optional binary field_id=-1 text (String);\n",
      "  optional binary field_id=-1 code (String);\n",
      "  optional group field_id=-1 correct_train_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_train_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 correct_test_input (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional boolean field_id=-1 element;\n",
      "    }\n",
      "  }\n",
      "  optional group field_id=-1 predicted_test_output (List) {\n",
      "    repeated group field_id=-1 list {\n",
      "      optional group field_id=-1 element (List) {\n",
      "        repeated group field_id=-1 list {\n",
      "          optional group field_id=-1 element (List) {\n",
      "            repeated group field_id=-1 list {\n",
      "              optional int64 field_id=-1 element;\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional binary field_id=-1 model (String);\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Parquet schema inspection\n",
    "for file in Path.home().joinpath(\"julien_soar\").iterdir():\n",
    "    if file.suffix == '.parquet':\n",
    "        print(f\"Schema for {file.name}:\")\n",
    "        if pq is not None:\n",
    "            pf = pq.ParquetFile(file)\n",
    "            print(pf.schema)\n",
    "        else:\n",
    "            print(\"pyarrow not available, falling back to pandas (loads data).\")\n",
    "            df = pd.read_parquet(file)\n",
    "            print(df.dtypes)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b53bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from llm_python.datasets.collector import generate_unique_hex_id\n",
    "from llm_python.datasets.io import write_soar_parquet\n",
    "\n",
    "def process_refinement_pickle(pkl_path, out_dir):\n",
    "    \"\"\"\n",
    "    Loads a pickle file with dict-of-list structure, merges task_id into each dict, flattens, and writes to parquet.\n",
    "    \"\"\"\n",
    "    obj = pd.read_pickle(pkl_path)\n",
    "    rows = []\n",
    "    for task_id, sample_list in obj.items():\n",
    "        for sample in sample_list:\n",
    "            sample = dict(sample)  # copy to avoid mutating original\n",
    "            sample['task_id'] = task_id\n",
    "            sample['row_id'] = generate_unique_hex_id()\n",
    "            sample['is_transductive'] = False\n",
    "            rows.append(sample)\n",
    "    df = pd.DataFrame(rows)\n",
    "    out_path = Path(out_dir) / (Path(pkl_path).stem + '.parquet')\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_soar_parquet(df, out_path)\n",
    "    print(f\"Wrote {out_path} with {len(df)} rows.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6586684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_files = [f for f in Path.home().joinpath(\"julien_soar\").iterdir() if f.suffix == '.pkl']\n",
    "# for pkl_file in pkl_files:\n",
    "#     process_refinement_pickle(pkl_file, Path.home().joinpath(\"julien_soar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3bb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/code/trelis-arc/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.validation import (\n",
    "    CorrectnessRowValidationResult,\n",
    "    validate_soar_dataframe,\n",
    "    validate_soar_dataframe_correctness,\n",
    "    validate_soar_row,\n",
    "    validate_soar_row_correctness,\n",
    ")\n",
    "from llm_python.transduction.code_classifier import CodeTransductionClassifier\n",
    "from llm_python.utils.arc_tester import ArcTester\n",
    "from llm_python.utils.numpy import convert_numpy_types\n",
    "import concurrent.futures\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "arc_tester = ArcTester()\n",
    "transductive_classifier = CodeTransductionClassifier()\n",
    "\n",
    "def clean_soar_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans the SOAR DataFrame by ensuring required columns are present and correctly typed.\n",
    "    \"\"\"\n",
    "    # We have already checked required columns in previous steps.\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[~df[\"code\"].str.lower().str.contains(\"random|randbelow|rvs\")]\n",
    "    print(f\"Kept {len(df)}/{len(df)} rows after filtering for randomness.\")\n",
    "\n",
    "    print(\"Validating row correctness with ThreadPoolExecutor...\")\n",
    "    \n",
    "    def validate_correctness_wrapper(row_tuple):\n",
    "        _, row = row_tuple\n",
    "        res = validate_soar_row_correctness(row, arc_tester)\n",
    "        # print(res.correctness_errors)\n",
    "        # print(res.new_predicted_train_output)\n",
    "        return res\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        correctness_results = list(tqdm(executor.map(validate_correctness_wrapper, df.iterrows()), total=len(df), desc=\"Validating correctness\"))\n",
    "\n",
    "    cleaned_rows = []\n",
    "    original_rows = df.to_dict('records')\n",
    "    for i, (correctness_result) in enumerate(correctness_results):\n",
    "        row = original_rows[i]\n",
    "        \n",
    "        if not correctness_result.correctness_valid:\n",
    "            # For safety, check if counts change\n",
    "            orig_true_count = sum(row[\"correct_train_input\"]) if isinstance(row[\"correct_train_input\"], list) else 0\n",
    "            new_true_count = sum(correctness_result.new_correct_train_input) if isinstance(correctness_result.new_correct_train_input, list) else 0\n",
    "            if orig_true_count != new_true_count:\n",
    "                print(\n",
    "                    f\"Warning: correct_train_input True count changed from {orig_true_count} to {new_true_count} for row_id {row.get('row_id', '<unknown>')}\"\n",
    "                )\n",
    "                # Print original and corrected train_0 arrays, each row on a new line for readability\n",
    "                # print(\"Original train_0:\")\n",
    "                # for row_item in row['predicted_train_output'][0]:\n",
    "                #     print(row_item)\n",
    "                # print(\"Corrected train_0:\")\n",
    "                # for row_item in correctness_result.new_predicted_train_output[0]:\n",
    "                #     print(row_item)\n",
    "\n",
    "            row[\"predicted_train_output\"] = correctness_result.new_predicted_train_output\n",
    "            row[\"predicted_test_output\"] = correctness_result.new_predicted_test_output\n",
    "            row[\"correct_train_input\"] = correctness_result.new_correct_train_input\n",
    "            row[\"correct_test_input\"] = correctness_result.new_correct_test_input\n",
    "        \n",
    "        cleaned_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(cleaned_rows)\n",
    "\n",
    "    def process_row_initial(row_tuple):\n",
    "        _ , row = row_tuple\n",
    "        row = row.to_dict()\n",
    "        row[\"predicted_train_output\"] = convert_numpy_types(row[\"predicted_train_output\"])\n",
    "        row[\"predicted_test_output\"] = convert_numpy_types(row[\"predicted_test_output\"])\n",
    "        row[\"correct_train_input\"] = convert_numpy_types(row[\"correct_train_input\"])\n",
    "        row[\"correct_test_input\"] = convert_numpy_types(row[\"correct_test_input\"])\n",
    "        row[\"reasoning\"] = str(row[\"reasoning\"])\n",
    "        row[\"row_id\"] = generate_unique_hex_id()\n",
    "        row[\"is_transductive\"] = transductive_classifier.is_transductive(row[\"code\"])[0]\n",
    "        return row\n",
    "\n",
    "    print(\"Computing base fields in parallel...\")\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        processed_rows = list(tqdm(executor.map(process_row_initial, df.iterrows()), total=len(df), desc=\"Computing base fields\"))\n",
    "    \n",
    "    df = pd.DataFrame(processed_rows)\n",
    "\n",
    "    def validate_and_log_errors_parallel(df: pd.DataFrame) -> pd.Series:\n",
    "        errors_set = set()\n",
    "        \n",
    "        def validate_row_wrapper(row_tuple):\n",
    "            _ , row = row_tuple\n",
    "            result = validate_soar_row(row)\n",
    "            return result.is_valid, result.errors\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            results = list(tqdm(executor.map(validate_row_wrapper, df.iterrows()), total=len(df), desc=\"Validating rows\"))\n",
    "\n",
    "        is_valid_list = []\n",
    "        for is_valid, errors in results:\n",
    "            is_valid_list.append(is_valid)\n",
    "            if errors:\n",
    "                errors_set.update(errors)\n",
    "        \n",
    "        if errors_set:\n",
    "            print(f\"Unique validation errors encountered: {errors_set}\")\n",
    "            \n",
    "        return pd.Series(is_valid_list, index=df.index)\n",
    "\n",
    "    print(\"Validating rows in parallel...\")\n",
    "    df[\"is_valid\"] = validate_and_log_errors_parallel(df)\n",
    "    print(f\"After cleaning, {df['is_valid'].sum()} out of {len(df)} rows are valid.\")\n",
    "    df = df[df[\"is_valid\"]]\n",
    "    df = df.drop(columns=[\"is_valid\"])\n",
    "\n",
    "    print(f\"{len(df[df['is_transductive']])} out of {len(df)} rows are transductive.\")\n",
    "    \n",
    "    print(\"Validating rows post-fix in parallel...\")\n",
    "    df[\"is_valid\"] = validate_and_log_errors_parallel(df)\n",
    "    print(f\"After cleaning, {df['is_valid'].sum()} out of {len(df)} rows are valid.\")\n",
    "    df = df[df[\"is_valid\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8554689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/lewis/julien_soar/arc_1_val_Qwen2.5-Coder-7B-Instruct_solution.parquet\n",
      "Filtered from 1667360 to 60007 rows based on any_train_correct or any_test_correct.\n",
      "Kept 59970/59970 rows after filtering for randomness.\n",
      "Validating row correctness with ThreadPoolExecutor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating correctness:   1%|‚ñè         | 795/59970 [00:26<33:16, 29.64it/s] \n"
     ]
    }
   ],
   "source": [
    "from llm_python.datasets.io import read_soar_parquet\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "parquet_files = [f for f in Path.home().joinpath(\"julien_soar\").iterdir() if f.suffix == '.parquet']\n",
    "\n",
    "file = \"/home/lewis/julien_soar/arc_1_val_Qwen2.5-Coder-7B-Instruct_solution.parquet\"\n",
    "\n",
    "print(f\"Processing file: {file}\")\n",
    "df = read_soar_parquet(file)\n",
    "def any_true(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        return np.any(x)\n",
    "    return False\n",
    "\n",
    "df[\"any_train_correct\"] = df[\"correct_train_input\"].apply(any_true)\n",
    "df[\"any_test_correct\"] = df[\"correct_test_input\"].apply(any_true)\n",
    "original_len = len(df)\n",
    "df = df[df[\"any_test_correct\"] | df[\"any_train_correct\"]]\n",
    "print(f\"Filtered from {original_len} to {len(df)} rows based on any_train_correct or any_test_correct.\")\n",
    "df = clean_soar_dataframe(df)\n",
    "out_dir = Path.home().joinpath(\"julien_soar_cleaned\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "write_soar_parquet(df, out_dir / file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f215744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = grid_lst[0]\n",
      "    n = len(grid)\n",
      "    output_size = n * 2 - 1\n",
      "    output_grid = [[0 for _ in range(output_size)] for _ in range(output_size)]\n",
      "    for i in range(n):\n",
      "        if grid[i] != 0:\n",
      "            for j in range(output_size):\n",
      "                if i + j < output_size:\n",
      "                    output_grid[i + j][output_size - 1 - j] = grid[i]\n",
      "                if i - j >= 0:\n",
      "                    output_grid[i - j][j] = grid[i]\n",
      "                if i + j < output_size:\n",
      "                    output_grid[output_size - 1 - i - j][j] = 1\n",
      "                if i - j >= 0:\n",
      "                    output_grid[j][i - j] = 1\n",
      "    return output_grid\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    non_zero_indices = np.argwhere(grid != 0)\n",
      "    if non_zero_indices.size == 0:\n",
      "        return grid.tolist()\n",
      "    min_row, min_col = non_zero_indices.min(axis=0)\n",
      "    max_row, max_col = non_zero_indices.max(axis=0)\n",
      "    new_grid = np.zeros_like(grid)\n",
      "    for row in range(min_row, max_row + 1):\n",
      "        for col in range(min_col, max_col + 1):\n",
      "            if grid[row, col] != 0:\n",
      "                new_grid[row, col] = grid[row, col]\n",
      "                new_grid[row, min_col] = grid[row, col]\n",
      "                new_grid[row, max_col] = grid[row, col]\n",
      "                new_grid[min_row, col] = grid[row, col]\n",
      "                new_grid[max_row, col] = grid[row, col]\n",
      "                new_grid[min_row, min_col] = grid[row, col]\n",
      "                new_grid[min_row, max_col] = grid[row, col]\n",
      "                new_grid[max_row, min_col] = grid[row, col]\n",
      "                new_grid[max_row, max_col] = grid[row, col]\n",
      "    return new_grid.tolist()\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = [row[:] for row in grid_lst]\n",
      "    rows, cols = (len(grid), len(grid[0]))\n",
      "    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
      "    for row in range(rows):\n",
      "        for col in range(cols):\n",
      "            if grid[row][col] == 0:\n",
      "                continue\n",
      "            if grid[row][col] == 1 or grid[row][col] == 2:\n",
      "                for dr, dc in directions:\n",
      "                    new_row, new_col = (row + dr, col + dc)\n",
      "                    if 0 <= new_row < rows and 0 <= new_col < cols:\n",
      "                        if grid[new_row][new_col] == 8:\n",
      "                            grid[row][col] = 3 if grid[row][col] == 1 else 4\n",
      "                            break\n",
      "                else:\n",
      "                    for dr, dc in directions:\n",
      "                        new_row, new_col = (row + dr, col + dc)\n",
      "                        if 0 <= new_row < rows and 0 <= new_col < cols:\n",
      "                            if grid[new_row][new_col] == 1:\n",
      "                                grid[row][col] = 2\n",
      "                                break\n",
      "                            elif grid[new_row][new_col] == 2:\n",
      "                                grid[row][col] = 1\n",
      "                                break\n",
      "            elif grid[row][col] == 3 or grid[row][col] == 4:\n",
      "                for dr, dc in directions:\n",
      "                    new_row, new_col = (row + dr, col + dc)\n",
      "                    if 0 <= new_row < rows and 0 <= new_col < cols:\n",
      "                        if grid[new_row][new_col] == 8:\n",
      "                            grid[row][col] = 6 if grid[row][col] == 3 else 2\n",
      "                            break\n",
      "                else:\n",
      "                    for dr, dc in directions:\n",
      "                        new_row, new_col = (row + dr, col + dc)\n",
      "                        if 0 <= new_row < rows and 0 <= new_col < cols:\n",
      "                            if grid[new_row][new_col] == 3:\n",
      "                                grid[row][col] = 4\n",
      "                                break\n",
      "                            elif grid[new_row][new_col] == 4:\n",
      "                                grid[row][col] = 3\n",
      "                                break\n",
      "    return grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    rows = len(grid_lst)\n",
      "    cols = len(grid_lst[0])\n",
      "    new_grid = [row[:] for row in grid_lst]\n",
      "    for i in range(rows):\n",
      "        for j in range(cols):\n",
      "            if grid_lst[i][j] == 1:\n",
      "                if i + 1 < rows and j + 1 < cols and (grid_lst[i + 1][j] == 1) and (grid_lst[i][j + 1] == 1) and (grid_lst[i + 1][j + 1] == 1):\n",
      "                    new_grid[i + 1][j] = 3\n",
      "                    new_grid[i][j + 1] = 3\n",
      "                    new_grid[i + 1][j + 1] = 3\n",
      "                elif i + 1 < rows and grid_lst[i + 1][j] == 1:\n",
      "                    new_grid[i + 1][j] = 2\n",
      "                elif j + 1 < cols and grid_lst[i][j + 1] == 1:\n",
      "                    new_grid[i][j + 1] = 2\n",
      "    return new_grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "\n",
      "    def map_to_7x7(x, y):\n",
      "        if x < 3:\n",
      "            new_x = 0 if x == 0 else 1 if x == 1 else 2\n",
      "        elif x > 13:\n",
      "            new_x = 4 if x == 14 else 5 if x == 15 else 6\n",
      "        else:\n",
      "            new_x = 3\n",
      "        if y < 3:\n",
      "            new_y = 0 if y == 0 else 1 if y == 1 else 2\n",
      "        elif y > 12:\n",
      "            new_y = 4 if y == 13 else 5 if y == 14 else 6\n",
      "        else:\n",
      "            new_y = 3\n",
      "        return (new_x, new_y)\n",
      "    grid = grid_lst\n",
      "    output_grid = [[0] * 7 for _ in range(7)]\n",
      "    for i in range(len(grid)):\n",
      "        for j in range(len(grid[0])):\n",
      "            if grid[i][j] != 0:\n",
      "                new_i, new_j = map_to_7x7(i, j)\n",
      "                if output_grid[new_i][new_j] == 0:\n",
      "                    output_grid[new_i][new_j] = grid[i][j]\n",
      "    return output_grid\n",
      "\n",
      "import numpy as np\n",
      "from collections import Counter\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    non_zero_grid = grid[grid != 0]\n",
      "    if non_zero_grid.size == 0:\n",
      "        return [[0]]\n",
      "    counts = Counter(non_zero_grid)\n",
      "    most_frequent_color = counts.most_common(1)[0][0]\n",
      "    if most_frequent_color == 8:\n",
      "        output_shape = (8, 9)\n",
      "    elif most_frequent_color == 4:\n",
      "        output_shape = (6, 8)\n",
      "    elif most_frequent_color == 3:\n",
      "        output_shape = (6, 9)\n",
      "    elif most_frequent_color == 6:\n",
      "        output_shape = (8, 8)\n",
      "    elif most_frequent_color == 2:\n",
      "        output_shape = (8, 10)\n",
      "    else:\n",
      "        output_shape = (8, 10)\n",
      "    output_grid = np.zeros(output_shape, dtype=int)\n",
      "    sorted_colors = sorted(counts.items(), key=lambda x: (-x[1], x[0]))\n",
      "    color_index = 0\n",
      "    for i in range(output_shape[0]):\n",
      "        for j in range(output_shape[1]):\n",
      "            if color_index < len(sorted_colors):\n",
      "                output_grid[i, j] = sorted_colors[color_index][0]\n",
      "                if j < output_shape[1] - 1:\n",
      "                    color_index += 1\n",
      "            else:\n",
      "                color_index = 0\n",
      "                output_grid[i, j] = sorted_colors[color_index][0]\n",
      "    return output_grid.tolist()\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    rows, cols = grid.shape\n",
      "    orange_color = 7\n",
      "    pink_color = 6\n",
      "    orange_cells = np.argwhere(grid == orange_color)\n",
      "    if len(orange_cells) == 0:\n",
      "        return grid_lst\n",
      "    for row, col in orange_cells:\n",
      "        for i in range(col + 4, cols, 4):\n",
      "            if grid[row, i] == 0:\n",
      "                grid[row, i] = pink_color\n",
      "            else:\n",
      "                break\n",
      "        for i in range(col - 4, -1, -4):\n",
      "            if grid[row, i] == 0:\n",
      "                grid[row, i] = pink_color\n",
      "            else:\n",
      "                break\n",
      "        for i in range(row + 4, rows, 4):\n",
      "            if grid[i, col] == 0:\n",
      "                grid[i, col] = pink_color\n",
      "            else:\n",
      "                break\n",
      "        for i in range(row - 4, -1, -4):\n",
      "            if grid[i, col] == 0:\n",
      "                grid[i, col] = pink_color\n",
      "            else:\n",
      "                break\n",
      "    for row, col in orange_cells:\n",
      "        for dr, dc in [(0, 4), (0, -4), (4, 0), (-4, 0)]:\n",
      "            new_row, new_col = (row + dr, col + dc)\n",
      "            if 0 <= new_row < rows and 0 <= new_col < cols and (grid[new_row, new_col] == pink_color):\n",
      "                if dr == 0 and dc == 4:\n",
      "                    for i in range(col, col + 4):\n",
      "                        if grid[row, i] == 0:\n",
      "                            grid[row, i] = orange_color\n",
      "                elif dr == 0 and dc == -4:\n",
      "                    for i in range(col - 3, col + 1):\n",
      "                        if grid[row, i] == 0:\n",
      "                            grid[row, i] = orange_color\n",
      "                elif dr == 4 and dc == 0:\n",
      "                    for i in range(row, row + 4):\n",
      "                        if grid[i, col] == 0:\n",
      "                            grid[i, col] = orange_color\n",
      "                elif dr == -4 and dc == 0:\n",
      "                    for i in range(row - 3, row + 1):\n",
      "                        if grid[i, col] == 0:\n",
      "                            grid[i, col] = orange_color\n",
      "    return grid.tolist()\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = [row[:] for row in grid_lst]\n",
      "    rows, cols = (len(grid), len(grid[0]))\n",
      "    sequence = []\n",
      "    for i in range(cols):\n",
      "        if grid[0][i] != 0:\n",
      "            if not sequence or grid[0][i] == (sequence[-1] + 1) % 10:\n",
      "                sequence.append(grid[0][i])\n",
      "            else:\n",
      "                break\n",
      "        else:\n",
      "            break\n",
      "    for i in range(1, rows):\n",
      "        for j in range(cols):\n",
      "            if grid[i][j] != 0:\n",
      "                expected_value = sequence[(j + i) % len(sequence)]\n",
      "                if grid[i][j] != expected_value:\n",
      "                    grid[i][j] = expected_value\n",
      "    return grid\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    rows, cols = grid.shape\n",
      "    new_grid = np.copy(grid)\n",
      "    temp_grid = np.zeros_like(grid)\n",
      "\n",
      "    def fill_between(val1, val2, row, col, end_row, end_col):\n",
      "        if row == end_row:\n",
      "            start_col = min(col, end_col)\n",
      "            end_col = max(col, end_col)\n",
      "            for c in range(start_col, end_col + 1):\n",
      "                if new_grid[row, c] == 0:\n",
      "                    new_grid[row, c] = val2\n",
      "                    temp_grid[row, c] = val2\n",
      "        elif col == end_col:\n",
      "            start_row = min(row, end_row)\n",
      "            end_row = max(row, end_row)\n",
      "            for r in range(start_row, end_row + 1):\n",
      "                if new_grid[r, col] == 0:\n",
      "                    new_grid[r, col] = val2\n",
      "                    temp_grid[r, col] = val2\n",
      "    for row in range(rows):\n",
      "        for col in range(cols):\n",
      "            if grid[row, col] == 4:\n",
      "                for end_col in range(cols):\n",
      "                    if grid[row, end_col] == 8:\n",
      "                        fill_between(4, 3, row, col, row, end_col)\n",
      "                        break\n",
      "                for end_row in range(rows):\n",
      "                    if grid[end_row, col] == 8:\n",
      "                        fill_between(4, 3, row, col, end_row, col)\n",
      "                        break\n",
      "    for row in range(rows):\n",
      "        for col in range(cols):\n",
      "            if grid[row, col] == 8:\n",
      "                for end_col in range(cols):\n",
      "                    if grid[row, end_col] == 2:\n",
      "                        fill_between(8, 8, row, col, row, end_col)\n",
      "                        break\n",
      "                for end_row in range(rows):\n",
      "                    if grid[end_row, col] == 2:\n",
      "                        fill_between(8, 8, row, col, end_row, col)\n",
      "                        break\n",
      "    for row in range(rows):\n",
      "        for col in range(cols):\n",
      "            if grid[row, col] == 2:\n",
      "                for end_col in range(cols):\n",
      "                    if grid[row, end_col] == 8:\n",
      "                        fill_between(2, 2, row, col, row, end_col)\n",
      "                        break\n",
      "                for end_row in range(rows):\n",
      "                    if grid[end_row, col] == 8:\n",
      "                        fill_between(2, 2, row, col, end_row, col)\n",
      "                        break\n",
      "    for row in range(rows):\n",
      "        for col in range(cols):\n",
      "            if temp_grid[row, col] == 3:\n",
      "                for end_col in range(cols):\n",
      "                    if grid[row, end_col] == 4:\n",
      "                        fill_between(3, 4, row, col, row, end_col)\n",
      "                        break\n",
      "                for end_row in range(rows):\n",
      "                    if grid[end_row, col] == 4:\n",
      "                        fill_between(3, 4, row, col, end_row, col)\n",
      "                        break\n",
      "    return new_grid.tolist()\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    rows, cols = grid.shape\n",
      "    out_grid = np.zeros((rows, cols), dtype=int)\n",
      "    for row in range(rows):\n",
      "        for col in range(cols):\n",
      "            if grid[row, col] == 3:\n",
      "                out_grid[row, col] = 3\n",
      "                for i in range(1, min(rows, cols)):\n",
      "                    if row + i < rows and grid[row + i, col] == 0:\n",
      "                        out_grid[row + i, col] = 3\n",
      "                        break\n",
      "                    if row - i >= 0 and grid[row - i, col] == 0:\n",
      "                        out_grid[row - i, col] = 3\n",
      "                        break\n",
      "                    if col + i < cols and grid[row, col + i] == 0:\n",
      "                        out_grid[row, col + i] = 3\n",
      "                        break\n",
      "                    if col - i >= 0 and grid[row, col - i] == 0:\n",
      "                        out_grid[row, col - i] = 3\n",
      "                        break\n",
      "    return out_grid.tolist()\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = grid_lst\n",
      "    rows, cols = (len(grid), len(grid[0]))\n",
      "    out_grid = [[0] * cols for _ in range(3)]\n",
      "    for j in range(cols):\n",
      "        for i in range(rows):\n",
      "            if grid[i][j] != 0 and grid[i][j] != 5:\n",
      "                out_grid[1][j] = grid[i][j]\n",
      "                break\n",
      "    for j in range(cols):\n",
      "        found = False\n",
      "        for i in range(rows):\n",
      "            if grid[i][j] != 0 and grid[i][j] != 5:\n",
      "                out_grid[1][j] = grid[i][j]\n",
      "                found = True\n",
      "                break\n",
      "        if not found:\n",
      "            for i in range(rows):\n",
      "                if grid[i][j] != 0:\n",
      "                    out_grid[0][j] = grid[i][j]\n",
      "                    break\n",
      "            else:\n",
      "                for i in range(rows - 1, -1, -1):\n",
      "                    if grid[i][j] != 0:\n",
      "                        out_grid[2][j] = grid[i][j]\n",
      "                        break\n",
      "    return out_grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    flat_grid = [cell for row in grid_lst for cell in row]\n",
      "    unique_values = set(flat_grid)\n",
      "    value_counts = {value: flat_grid.count(value) for value in unique_values}\n",
      "    sorted_values = sorted(unique_values, key=lambda x: (value_counts[x], x))\n",
      "    output_shape = (len(sorted_values), len(sorted_values))\n",
      "    output_grid = [[0] * output_shape[1] for _ in range(output_shape[0])]\n",
      "    for i, value in enumerate(sorted_values):\n",
      "        output_grid[i][i] = value\n",
      "    return output_grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = [row[:] for row in grid_lst]\n",
      "    rows, cols = (len(grid), len(grid[0]))\n",
      "    for i in range(rows):\n",
      "        for j in range(cols):\n",
      "            if grid[i][j] == 5:\n",
      "                for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
      "                    ni, nj = (i + dx, j + dy)\n",
      "                    if 0 <= ni < rows and 0 <= nj < cols and (grid[ni][nj] == 8):\n",
      "                        for ci in range(max(0, i - 2), min(rows, i + 3)):\n",
      "                            for cj in range(max(0, j - 2), min(cols, j + 3)):\n",
      "                                if grid[ci][cj] == 0:\n",
      "                                    grid[ci][cj] = 4\n",
      "                        break\n",
      "                else:\n",
      "                    for ci in range(max(0, i - 2), min(rows, i + 3)):\n",
      "                        for cj in range(max(0, j - 2), min(cols, j + 3)):\n",
      "                            if grid[ci][cj] == 0:\n",
      "                                grid[ci][cj] = 2\n",
      "    return grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    top_left_subgrid = [row[:2] for row in grid_lst[:2]]\n",
      "    bottom_right_subgrid = [row[-2:] for row in grid_lst[-2:]]\n",
      "    output_grid = [[top_left_subgrid[0][1], bottom_right_subgrid[0][1]], [bottom_right_subgrid[1][0], top_left_subgrid[1][0]]]\n",
      "    return output_grid\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    rows, cols = grid.shape\n",
      "    output_grid = np.copy(grid)\n",
      "    non_one_positions = np.argwhere(grid != 1)\n",
      "    for pos in non_one_positions:\n",
      "        x, y = pos\n",
      "        value = grid[x, y]\n",
      "        if value in [2, 3, 4, 6, 8]:\n",
      "            for i in range(1, min(rows, cols)):\n",
      "                if x + i < rows and output_grid[x + i, y] == 1:\n",
      "                    output_grid[x + i, y] = value\n",
      "                    break\n",
      "                if x - i >= 0 and output_grid[x - i, y] == 1:\n",
      "                    output_grid[x - i, y] = value\n",
      "                    break\n",
      "                if y + i < cols and output_grid[x, y + i] == 1:\n",
      "                    output_grid[x, y + i] = value\n",
      "                    break\n",
      "                if y - i >= 0 and output_grid[x, y - i] == 1:\n",
      "                    output_grid[x, y - i] = value\n",
      "                    break\n",
      "    return output_grid.tolist()\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = [row[:] for row in grid_lst]\n",
      "    n = len(grid)\n",
      "    m = len(grid[0])\n",
      "    top_left_rows = (n + 2) // 3\n",
      "    top_left_cols = (m + 2) // 3\n",
      "    for i in range(n):\n",
      "        for j in range(m):\n",
      "            if i < top_left_rows and j < top_left_cols:\n",
      "                continue\n",
      "            elif i < top_left_rows and j >= top_left_cols:\n",
      "                grid[i][j] = grid[i][m - j - 1]\n",
      "            elif i >= top_left_rows and j < top_left_cols:\n",
      "                grid[i][j] = grid[n - i - 1][j]\n",
      "            else:\n",
      "                grid[i][j] = grid[n - i - 1][m - j - 1]\n",
      "    return grid\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = np.array(grid_lst)\n",
      "    new_grid = np.copy(grid)\n",
      "    unique_colors = np.setdiff1d(np.unique(grid), [0])\n",
      "    if len(unique_colors) < 2:\n",
      "        return grid_lst\n",
      "    color1 = unique_colors[0]\n",
      "    color2 = unique_colors[1] if len(unique_colors) > 1 else None\n",
      "    color3 = unique_colors[2] if len(unique_colors) > 2 else None\n",
      "    color4 = unique_colors[3] if len(unique_colors) > 3 else None\n",
      "    coords1 = np.argwhere(grid == color1)\n",
      "    coords2 = np.argwhere(grid == color2) if color2 is not None else np.array([])\n",
      "    coords3 = np.argwhere(grid == color3) if color3 is not None else np.array([])\n",
      "    coords4 = np.argwhere(grid == color4) if color4 is not None else np.array([])\n",
      "    for coord in coords2:\n",
      "        closest1 = min(coords1, key=lambda x: np.linalg.norm(x - coord))\n",
      "        if np.linalg.norm(coord - closest1) == 1:\n",
      "            new_grid[coord[0], coord[1]] = color1\n",
      "    for coord in coords3:\n",
      "        closest1 = min(coords1, key=lambda x: np.linalg.norm(x - coord))\n",
      "        closest2 = min(coords2, key=lambda x: np.linalg.norm(x - coord))\n",
      "        if np.linalg.norm(coord - closest1) == 1:\n",
      "            new_grid[coord[0], coord[1]] = color1\n",
      "        elif np.linalg.norm(coord - closest2) == 1:\n",
      "            new_grid[coord[0], coord[1]] = color2\n",
      "    for coord in coords4:\n",
      "        closest1 = min(coords1, key=lambda x: np.linalg.norm(x - coord))\n",
      "        closest2 = min(coords2, key=lambda x: np.linalg.norm(x - coord))\n",
      "        closest3 = min(coords3, key=lambda x: np.linalg.norm(x - coord))\n",
      "        if np.linalg.norm(coord - closest1) == 1:\n",
      "            new_grid[coord[0], coord[1]] = color1\n",
      "        elif np.linalg.norm(coord - closest2) == 1:\n",
      "            new_grid[coord[0], coord[1]] = color2\n",
      "        elif np.linalg.norm(coord - closest3) == 1:\n",
      "            new_grid[coord[0], coord[1]] = color3\n",
      "    return new_grid.tolist()\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = [row[:] for row in grid_lst]\n",
      "    rows, cols = (len(grid), len(grid[0]))\n",
      "    max_val = max((max(row) for row in grid))\n",
      "\n",
      "    def next_value(val):\n",
      "        return val % max_val + 1 if max_val > 1 else 0\n",
      "\n",
      "    def is_valid(i, j):\n",
      "        return 0 <= i < rows and 0 <= j < cols\n",
      "\n",
      "    def get_next_non_zero(i, j):\n",
      "        if is_valid(i, j + 1) and grid[i][j + 1] != 0:\n",
      "            return grid[i][j + 1]\n",
      "        elif is_valid(i + 1, j) and grid[i + 1][j] != 0:\n",
      "            return grid[i + 1][j]\n",
      "        elif is_valid(i - 1, j) and grid[i - 1][j] != 0:\n",
      "            return grid[i - 1][j]\n",
      "        elif is_valid(i, j - 1) and grid[i][j - 1] != 0:\n",
      "            return grid[i][j - 1]\n",
      "        return 0\n",
      "    for i in range(rows):\n",
      "        for j in range(cols):\n",
      "            if grid[i][j] == 0:\n",
      "                next_non_zero = get_next_non_zero(i, j)\n",
      "                if next_non_zero != 0:\n",
      "                    grid[i][j] = next_value(next_non_zero)\n",
      "                else:\n",
      "                    grid[i][j] = next_value(max_val)\n",
      "    return grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    grid = [row[:] for row in grid_lst]\n",
      "    grey_color = 5\n",
      "    grey_column = next((i for i, cell in enumerate(grid[0]) if cell == grey_color), None)\n",
      "    if grey_column is None:\n",
      "        return grid\n",
      "    new_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    for i, row in enumerate(grid):\n",
      "        for j, cell in enumerate(row):\n",
      "            if cell != grey_color:\n",
      "                new_grid[i][j] = cell\n",
      "    output_grid = [[0 for _ in range(len(grid[0]))] for _ in range(len(grid))]\n",
      "    for i, row in enumerate(new_grid):\n",
      "        for j, cell in enumerate(row):\n",
      "            if cell != 0:\n",
      "                if j < grey_column:\n",
      "                    output_grid[i][j] = cell\n",
      "                elif j > grey_column:\n",
      "                    output_grid[i][j - 1] = cell\n",
      "    for i, row in enumerate(output_grid):\n",
      "        for j, cell in enumerate(row):\n",
      "            if cell != 0:\n",
      "                if j < grey_column:\n",
      "                    output_grid[i][grey_column - 1] = cell\n",
      "                elif j > grey_column:\n",
      "                    output_grid[i][grey_column + 1] = cell\n",
      "    for i, row in enumerate(output_grid):\n",
      "        for j, cell in enumerate(row):\n",
      "            if cell != 0:\n",
      "                if j < grey_column:\n",
      "                    output_grid[i][grey_column - 1] = cell\n",
      "                elif j > grey_column:\n",
      "                    output_grid[i][grey_column + 1] = cell\n",
      "    for i, row in enumerate(output_grid):\n",
      "        for j, cell in enumerate(row):\n",
      "            if cell != 0:\n",
      "                if j < grey_column:\n",
      "                    output_grid[i][grey_column - 1] = cell\n",
      "                elif j > grey_column:\n",
      "                    output_grid[i][grey_column + 1] = cell\n",
      "    reduced_grid = [[0 for _ in range(10)] for _ in range(10)]\n",
      "    for i in range(10):\n",
      "        for j in range(10):\n",
      "            reduced_grid[i][j] = output_grid[i][j]\n",
      "    return reduced_grid\n",
      "\n",
      "def transform(grid_lst: list[list[int]]) -> list[list[int]]:\n",
      "    rows = len(grid_lst)\n",
      "    cols = len(grid_lst[0])\n",
      "    colored_rows = [row for row in grid_lst if any((cell != 0 for cell in row))]\n",
      "    output_grid = [[0] * (2 * cols) for _ in range(2 * rows)]\n",
      "    for i, row in enumerate(colored_rows):\n",
      "        for j, cell in enumerate(row):\n",
      "            if cell != 0:\n",
      "                output_grid[i][j] = cell\n",
      "                output_grid[i + rows][j + cols] = cell\n",
      "    for i in range(2 * rows):\n",
      "        if all((output_grid[i][j] == 0 for j in range(2 * cols))):\n",
      "            output_grid[i] = [3] * (2 * cols)\n",
      "    return output_grid\n"
     ]
    }
   ],
   "source": [
    "for file in parquet_files[:1]:\n",
    "    df = read_soar_parquet(file)\n",
    "    print('\\n\\n'.join(df['code'].sample(20, random_state=42).tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trelis-arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
