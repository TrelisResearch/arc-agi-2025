{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0638b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = next((parent for parent in [Path.cwd()] + list(Path.cwd().parents) if (parent / \"pyproject.toml\").exists()), Path.cwd())\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "from llm_python.datasets.io import read_soar_parquet\n",
    "\n",
    "# Get all parquet file paths\n",
    "parquet_files = glob(\"/tmp/superking_snapshot/*.parquet\")\n",
    "\n",
    "# Read each parquet file into a dataframe using read_soar_parquet()\n",
    "dfs = []\n",
    "for f in parquet_files:\n",
    "    try:\n",
    "        df = read_soar_parquet(f)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {f}: {e}\")\n",
    "\n",
    "# Merge all dataframes into a single dataframe\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Merged {len(parquet_files)} parquet files with total {len(merged_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[0].info())\n",
    "print(dfs[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff01911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.io import validate_soar_dataframe_schema\n",
    "from llm_python.utils.numpy import convert_numpy_types\n",
    "\n",
    "merged_df[\"predicted_train_output\"] = merged_df[\"predicted_train_output\"].apply(convert_numpy_types)\n",
    "merged_df[\"correct_train_input\"] = merged_df[\"correct_train_input\"].apply(convert_numpy_types)\n",
    "merged_df[\"predicted_test_output\"] = merged_df[\"predicted_test_output\"].apply(convert_numpy_types)\n",
    "merged_df[\"correct_test_input\"] = merged_df[\"correct_test_input\"].apply(convert_numpy_types)\n",
    "validate_soar_dataframe_schema(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61da200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "\n",
    "def generate_unique_hex_id(n_rows, hex_length=32):\n",
    "    # 32 hex chars = 128 bits, collision probability is negligible for 10M rows\n",
    "    return [secrets.token_hex(hex_length // 2) for _ in range(n_rows)]\n",
    "\n",
    "fixed_df[\"id\"] = generate_unique_hex_id(len(fixed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171de997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.validation import validate_soar_row\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Validating rows formats...\")\n",
    "valid_mask = []\n",
    "errors = []\n",
    "for i, row in tqdm(merged_df.iterrows(), total=len(merged_df)):\n",
    "    result = validate_soar_row(row)\n",
    "    valid_mask.append(result.is_valid)\n",
    "    if not result.is_valid:\n",
    "        errors.append((i, result.errors))\n",
    "\n",
    "# Filter out invalid rows\n",
    "merged_df = merged_df[pd.Series(valid_mask, index=merged_df.index)]``\n",
    "print(f\"Filtered dataframe: {len(merged_df)} valid rows out of {len(valid_mask)} total.\")\n",
    "print(f\"Total invalid rows: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.validation import validate_soar_dataframe_correctness\n",
    "\n",
    "\n",
    "print(\"Validating row correctness...\")\n",
    "\n",
    "correctness_result = validate_soar_dataframe_correctness(merged_df, correctness_samples=1000)\n",
    "print(correctness_result.summary())\n",
    "if not correctness_result.is_valid:\n",
    "    raise ValueError(\n",
    "        \"Validation failed: Some programs do not meet the correctness requirements.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_df = pd.DataFrame(merged_df)\n",
    "fixed_df = fixed_df[~fixed_df[\"code\"].str.lower().str.contains(\"random|randbelow|rvs\")]\n",
    "print(f\"Kept {len(fixed_df)}/{len(merged_df)} rows after filtering for randomness.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9206703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_python.datasets.io import write_soar_parquet\n",
    "\n",
    "\n",
    "write_soar_parquet(fixed_df, \"/tmp/superking_merged_and_cleaned.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trelis-arc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
